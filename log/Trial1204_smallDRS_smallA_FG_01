/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-05 00:56:20,132] A new study created in memory with name: no-name-913f75f0-6071-4bc8-9b4c-3df6dd80b13a
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1204_smallDRS_smallA.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.0555574758034947, 'log_learning_rate_D': -2.6285791556552827, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.9449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  10 training error:  tensor(148.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  20 training error:  tensor(375.7197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  30 training error:  tensor(48.9161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  40 training error:  tensor(10.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  50 training error:  tensor(1.5950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  60 training error:  tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  70 training error:  tensor(1.1060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  80 training error:  tensor(2.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
	 epoch  90 training error:  tensor(1.9200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3740234375
Memory cached:  38.0
[I 2023-12-05 00:57:54,965] Trial 0 finished with value: 1.3669570684432983 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.0555574758034947, 'log_learning_rate_D': -2.6285791556552827, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 1.3669570684432983.
res:  tensor(1.3670, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  94.72475481033325
Memory status after this trial: 
Memory allocated:  121.0751953125
Memory cached:  136.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.291933960155185, 'log_learning_rate_D': -1.8662910175082423, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  168.0
	 epoch  10 training error:  tensor(1.1013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.9957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  40 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.9957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.9963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.9952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.21923828125
Memory cached:  172.0
[I 2023-12-05 00:58:55,756] Trial 1 finished with value: 0.9466440081596375 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.291933960155185, 'log_learning_rate_D': -1.8662910175082423, 'training_batch_size': 9, 'training_p': 8}. Best is trial 1 with value: 0.9466440081596375.
res:  tensor(0.9466, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(1.3670, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  60.67640042304993
Memory status after this trial: 
Memory allocated:  138.67236328125
Memory cached:  252.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.3133387580255635, 'log_learning_rate_D': -2.9912400458279733, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  256.0
	 epoch  10 training error:  tensor(51.0939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  20 training error:  tensor(2.1127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  30 training error:  tensor(2.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  40 training error:  tensor(1.5786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  50 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  60 training error:  tensor(1.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  80 training error:  tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.203125
Memory cached:  258.0
[I 2023-12-05 00:59:56,093] Trial 2 finished with value: 0.9463580250740051 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.3133387580255635, 'log_learning_rate_D': -2.9912400458279733, 'training_batch_size': 10, 'training_p': 8}. Best is trial 2 with value: 0.9463580250740051.
res:  tensor(0.9464, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.9466, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  60.23991298675537
Memory status after this trial: 
Memory allocated:  110.10009765625
Memory cached:  186.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.9562882592590007, 'log_learning_rate_D': -3.9179550629720397, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  190.0
	 epoch  10 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  20 training error:  tensor(0.9913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  30 training error:  tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  40 training error:  tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  50 training error:  tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  60 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  70 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  80 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
	 epoch  90 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.71484375
Memory cached:  192.0
[I 2023-12-05 01:00:46,291] Trial 3 finished with value: 0.9231729507446289 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.9562882592590007, 'log_learning_rate_D': -3.9179550629720397, 'training_batch_size': 7, 'training_p': 5}. Best is trial 3 with value: 0.9231729507446289.
res:  tensor(0.9232, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.9464, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  50.10691022872925
Memory status after this trial: 
Memory allocated:  71.0693359375
Memory cached:  182.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.349429967442063, 'log_learning_rate_D': -2.9816775013741257, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.8363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  20 training error:  tensor(0.6548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  30 training error:  tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  40 training error:  tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  50 training error:  tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  60 training error:  tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  70 training error:  tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  80 training error:  tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
	 epoch  90 training error:  tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.12158203125
Memory cached:  206.0
[I 2023-12-05 01:01:36,958] Trial 4 finished with value: 0.5315448641777039 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.349429967442063, 'log_learning_rate_D': -2.9816775013741257, 'training_batch_size': 8, 'training_p': 8}. Best is trial 4 with value: 0.5315448641777039.
res:  tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.9232, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  50.57173705101013
Memory status after this trial: 
Memory allocated:  119.78662109375
Memory cached:  204.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.852524066192176, 'log_learning_rate_D': -3.199569230019129, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  10 training error:  tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  20 training error:  tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  30 training error:  tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  40 training error:  tensor(0.9467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  50 training error:  tensor(0.9349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  60 training error:  tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  70 training error:  tensor(0.9144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  80 training error:  tensor(0.9046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
	 epoch  90 training error:  tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.9326171875
Memory cached:  206.0
[I 2023-12-05 01:02:24,553] Trial 5 finished with value: 0.9202055335044861 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.852524066192176, 'log_learning_rate_D': -3.199569230019129, 'training_batch_size': 9, 'training_p': 8}. Best is trial 4 with value: 0.5315448641777039.
Time for this trial:  47.481396436691284
Memory status after this trial: 
Memory allocated:  176.26123046875
Memory cached:  206.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.4033078693128362, 'log_learning_rate_D': -1.6133517152573655, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.2294921875
Memory cached:  206.0
[W 2023-12-05 01:02:28,290] Trial 6 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.4033078693128362, 'log_learning_rate_D': -1.6133517152573655, 'training_batch_size': 11, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:02:28,291] Trial 6 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.6214346885681152
Memory status after this trial: 
Memory allocated:  203.04541015625
Memory cached:  220.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.8051081618356588, 'log_learning_rate_D': -4.835281240357316, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  208.0
	 epoch  10 training error:  tensor(4.1048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  20 training error:  tensor(0.8997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  30 training error:  tensor(0.9400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  40 training error:  tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  50 training error:  tensor(0.7672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  60 training error:  tensor(0.7240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  70 training error:  tensor(0.9038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  80 training error:  tensor(0.7354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
	 epoch  90 training error:  tensor(0.7356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.2587890625
Memory cached:  210.0
[I 2023-12-05 01:03:11,129] Trial 7 finished with value: 0.8710441589355469 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.8051081618356588, 'log_learning_rate_D': -4.835281240357316, 'training_batch_size': 11, 'training_p': 2}. Best is trial 4 with value: 0.5315448641777039.
Time for this trial:  42.71631622314453
Memory status after this trial: 
Memory allocated:  177.23095703125
Memory cached:  208.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.179282869718911, 'log_learning_rate_D': -2.993992268017272, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.8512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.5851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.5593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.4038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.59375
Memory cached:  204.0
[I 2023-12-05 01:04:15,688] Trial 8 finished with value: 0.17762570083141327 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.179282869718911, 'log_learning_rate_D': -2.993992268017272, 'training_batch_size': 6, 'training_p': 3}. Best is trial 8 with value: 0.17762570083141327.
res:  tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  64.44751644134521
Memory status after this trial: 
Memory allocated:  16.98779296875
Memory cached:  164.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.142985268874375, 'log_learning_rate_D': -4.194159404074121, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  10 training error:  tensor(0.9687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.9415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.9242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.9077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.8920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.8764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.8601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.8435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0087890625
Memory cached:  166.0
[I 2023-12-05 01:04:58,267] Trial 9 finished with value: 0.6339954733848572 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.142985268874375, 'log_learning_rate_D': -4.194159404074121, 'training_batch_size': 7, 'training_p': 7}. Best is trial 8 with value: 0.17762570083141327.
Time for this trial:  42.47867202758789
Memory status after this trial: 
Memory allocated:  62.3955078125
Memory cached:  166.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.0435292958685656, 'log_learning_rate_D': -2.3867303909270494, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.9827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.9735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.9127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.6459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.4608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.38671875
Memory cached:  164.0
[I 2023-12-05 01:06:07,376] Trial 10 finished with value: 0.47557035088539124 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.0435292958685656, 'log_learning_rate_D': -2.3867303909270494, 'training_batch_size': 6, 'training_p': 6}. Best is trial 8 with value: 0.17762570083141327.
Time for this trial:  68.9891631603241
Memory status after this trial: 
Memory allocated:  67.4814453125
Memory cached:  164.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.4260606752014926, 'log_learning_rate_D': -1.1568785610634325, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  10 training error:  tensor(1.0203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  20 training error:  tensor(5.6651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.9408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.9190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.9066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.8945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.8802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.8627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.8402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7060546875
Memory cached:  164.0
[I 2023-12-05 01:06:42,742] Trial 11 finished with value: 0.7208766937255859 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.4260606752014926, 'log_learning_rate_D': -1.1568785610634325, 'training_batch_size': 12, 'training_p': 2}. Best is trial 8 with value: 0.17762570083141327.
Time for this trial:  35.20184135437012
Memory status after this trial: 
Memory allocated:  31.28173828125
Memory cached:  164.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.88577218569388, 'log_learning_rate_D': -2.098191312515654, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.7502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.6507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.6371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.4819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.744140625
Memory cached:  164.0
[I 2023-12-05 01:07:47,617] Trial 12 finished with value: 0.39867040514945984 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.88577218569388, 'log_learning_rate_D': -2.098191312515654, 'training_batch_size': 6, 'training_p': 4}. Best is trial 8 with value: 0.17762570083141327.
Time for this trial:  64.69537234306335
Memory status after this trial: 
Memory allocated:  57.69677734375
Memory cached:  164.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.018661381962698, 'log_learning_rate_D': -1.8429835061120179, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  20 training error:  tensor(0.7772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  30 training error:  tensor(0.6348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.7206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.5773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.6552734375
Memory cached:  186.0
[I 2023-12-05 01:08:29,449] Trial 13 finished with value: 0.5199530124664307 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.018661381962698, 'log_learning_rate_D': -1.8429835061120179, 'training_batch_size': 7, 'training_p': 4}. Best is trial 8 with value: 0.17762570083141327.
Time for this trial:  41.6617648601532
Memory status after this trial: 
Memory allocated:  85.92822265625
Memory cached:  186.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.8015696231203475, 'log_learning_rate_D': -3.4880909863248126, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.7972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.5979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.40234375
Memory cached:  164.0
[I 2023-12-05 01:09:29,529] Trial 14 finished with value: 0.16053257882595062 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.8015696231203475, 'log_learning_rate_D': -3.4880909863248126, 'training_batch_size': 6, 'training_p': 3}. Best is trial 14 with value: 0.16053257882595062.
res:  tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  59.903345823287964
Memory status after this trial: 
Memory allocated:  13.2861328125
Memory cached:  124.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.674137866934254, 'log_learning_rate_D': -3.5956728983210877, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.8605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  20 training error:  tensor(0.7955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  30 training error:  tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  40 training error:  tensor(0.6900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  50 training error:  tensor(0.6599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  60 training error:  tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  70 training error:  tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  80 training error:  tensor(0.6012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
	 epoch  90 training error:  tensor(0.5812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.73291015625
Memory cached:  124.0
[I 2023-12-05 01:10:07,111] Trial 15 finished with value: 0.529035210609436 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.674137866934254, 'log_learning_rate_D': -3.5956728983210877, 'training_batch_size': 8, 'training_p': 3}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  37.42482614517212
Memory status after this trial: 
Memory allocated:  25.84326171875
Memory cached:  124.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5065803206670445, 'log_learning_rate_D': -3.478928533106925, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.9384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  20 training error:  tensor(0.9069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  30 training error:  tensor(0.8712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  40 training error:  tensor(0.8292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  50 training error:  tensor(0.7738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  60 training error:  tensor(0.7023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  70 training error:  tensor(0.6539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  80 training error:  tensor(0.6040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
	 epoch  90 training error:  tensor(0.5756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.94775390625
Memory cached:  124.0
[I 2023-12-05 01:10:46,776] Trial 16 finished with value: 0.5607729554176331 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5065803206670445, 'log_learning_rate_D': -3.478928533106925, 'training_batch_size': 8, 'training_p': 3}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  39.512534856796265
Memory status after this trial: 
Memory allocated:  31.89501953125
Memory cached:  124.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.5539056118488324, 'log_learning_rate_D': -4.198964236300701, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  10 training error:  tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  20 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  30 training error:  tensor(0.3748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  40 training error:  tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  50 training error:  tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  60 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  70 training error:  tensor(0.2879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  80 training error:  tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
	 epoch  90 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.86474609375
Memory cached:  126.0
[I 2023-12-05 01:11:55,686] Trial 17 finished with value: 0.25862178206443787 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.5539056118488324, 'log_learning_rate_D': -4.198964236300701, 'training_batch_size': 6, 'training_p': 3}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  68.71904492378235
Memory status after this trial: 
Memory allocated:  51.73388671875
Memory cached:  124.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.2717460870401744, 'log_learning_rate_D': -2.7184181452761735, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  10 training error:  tensor(0.9282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  20 training error:  tensor(0.8712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  30 training error:  tensor(0.7847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  40 training error:  tensor(0.6906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  50 training error:  tensor(0.6389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  60 training error:  tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  70 training error:  tensor(0.5891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  80 training error:  tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
	 epoch  90 training error:  tensor(0.6320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  126.0
[I 2023-12-05 01:12:36,107] Trial 18 finished with value: 0.5959926843643188 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.2717460870401744, 'log_learning_rate_D': -2.7184181452761735, 'training_batch_size': 7, 'training_p': 4}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  40.245959520339966
Memory status after this trial: 
Memory allocated:  42.720703125
Memory cached:  126.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.728235207833353, 'log_learning_rate_D': -3.3826830198132822, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  20 training error:  tensor(0.9190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  30 training error:  tensor(0.9028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  40 training error:  tensor(0.8736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  50 training error:  tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  60 training error:  tensor(0.7752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  70 training error:  tensor(0.7487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  80 training error:  tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
	 epoch  90 training error:  tensor(0.7340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.48095703125
Memory cached:  124.0
[I 2023-12-05 01:13:15,905] Trial 19 finished with value: 0.6967532634735107 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.728235207833353, 'log_learning_rate_D': -3.3826830198132822, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  39.623348236083984
Memory status after this trial: 
Memory allocated:  39.802734375
Memory cached:  124.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.9484280984989875, 'log_learning_rate_D': -3.7562242877857095, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  10 training error:  tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  20 training error:  tensor(0.8057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  30 training error:  tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  40 training error:  tensor(0.6214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  50 training error:  tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  60 training error:  tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  70 training error:  tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  80 training error:  tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
	 epoch  90 training error:  tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.75244140625
Memory cached:  126.0
[I 2023-12-05 01:13:56,125] Trial 20 finished with value: 0.1808537095785141 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.9484280984989875, 'log_learning_rate_D': -3.7562242877857095, 'training_batch_size': 10, 'training_p': 5}. Best is trial 14 with value: 0.16053257882595062.
Time for this trial:  40.02162837982178
Memory status after this trial: 
Memory allocated:  44.7705078125
Memory cached:  126.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4557888092249582, 'log_learning_rate_D': -3.0554993672349986, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.6957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  20 training error:  tensor(0.6455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  30 training error:  tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  40 training error:  tensor(0.5529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  50 training error:  tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  60 training error:  tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  80 training error:  tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
	 epoch  90 training error:  tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.87451171875
Memory cached:  124.0
[I 2023-12-05 01:14:56,636] Trial 21 finished with value: 0.11125688999891281 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4557888092249582, 'log_learning_rate_D': -3.0554993672349986, 'training_batch_size': 6, 'training_p': 3}. Best is trial 21 with value: 0.11125688999891281.
res:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  60.32598114013672
Memory status after this trial: 
Memory allocated:  20.93896484375
Memory cached:  102.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4462402472952363, 'log_learning_rate_D': -3.138633281265015, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.6467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.6017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.4586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.52734375
Memory cached:  102.0
[I 2023-12-05 01:15:56,542] Trial 22 finished with value: 0.13713403046131134 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4462402472952363, 'log_learning_rate_D': -3.138633281265015, 'training_batch_size': 6, 'training_p': 3}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  59.74414825439453
Memory status after this trial: 
Memory allocated:  41.87744140625
Memory cached:  102.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.4563627501380476, 'log_learning_rate_D': -3.433738512663148, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.8220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.8376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.6845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.6306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.9970703125
Memory cached:  106.0
[I 2023-12-05 01:16:38,056] Trial 23 finished with value: 0.46162477135658264 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.4563627501380476, 'log_learning_rate_D': -3.433738512663148, 'training_batch_size': 7, 'training_p': 4}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  41.326441526412964
Memory status after this trial: 
Memory allocated:  66.21142578125
Memory cached:  104.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.2784199713726987, 'log_learning_rate_D': -3.1696215148358364, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.6475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.837890625
Memory cached:  102.0
[I 2023-12-05 01:17:34,562] Trial 24 finished with value: 0.1785547286272049 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.2784199713726987, 'log_learning_rate_D': -3.1696215148358364, 'training_batch_size': 6, 'training_p': 3}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  56.344276428222656
Memory status after this trial: 
Memory allocated:  55.09912109375
Memory cached:  102.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.7721838622000528, 'log_learning_rate_D': -3.833905056166924, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.7569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.7156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.6585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.5976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.3595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.3525390625
Memory cached:  102.0
[I 2023-12-05 01:18:09,721] Trial 25 finished with value: 0.21916750073432922 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.7721838622000528, 'log_learning_rate_D': -3.833905056166924, 'training_batch_size': 7, 'training_p': 2}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  35.008925437927246
Memory status after this trial: 
Memory allocated:  41.345703125
Memory cached:  102.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.601502191910896, 'log_learning_rate_D': -2.8672108378660024, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.7222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.5694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.5208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.34765625
Memory cached:  102.0
[I 2023-12-05 01:19:19,927] Trial 26 finished with value: 0.40076977014541626 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.601502191910896, 'log_learning_rate_D': -2.8672108378660024, 'training_batch_size': 6, 'training_p': 5}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  70.0316812992096
Memory status after this trial: 
Memory allocated:  97.05224609375
Memory cached:  102.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.7306127327192824, 'log_learning_rate_D': -2.5554467789614517, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.9649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.4344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.5849609375
Memory cached:  104.0
[I 2023-12-05 01:20:00,591] Trial 27 finished with value: 0.15292267501354218 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.7306127327192824, 'log_learning_rate_D': -2.5554467789614517, 'training_batch_size': 7, 'training_p': 3}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  40.51124620437622
Memory status after this trial: 
Memory allocated:  58.7490234375
Memory cached:  104.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.685641678451418, 'log_learning_rate_D': -2.550914361231411, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  104.0
	 epoch  10 training error:  tensor(5.8709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  20 training error:  tensor(1.7420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.8615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.8869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  50 training error:  tensor(1.0928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  70 training error:  tensor(1.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.9202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
	 epoch  90 training error:  tensor(1.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7060546875
Memory cached:  106.0
[I 2023-12-05 01:20:45,095] Trial 28 finished with value: 0.9303442239761353 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.685641678451418, 'log_learning_rate_D': -2.550914361231411, 'training_batch_size': 7, 'training_p': 4}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  44.3464081287384
Memory status after this trial: 
Memory allocated:  81.7265625
Memory cached:  104.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.180544228062879, 'log_learning_rate_D': -2.3325691522149397, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.8697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.6580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.5747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.7197265625
Memory cached:  106.0
[I 2023-12-05 01:21:27,915] Trial 29 finished with value: 0.14784708619117737 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.180544228062879, 'log_learning_rate_D': -2.3325691522149397, 'training_batch_size': 8, 'training_p': 2}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  42.63845157623291
Memory status after this trial: 
Memory allocated:  69.90283203125
Memory cached:  104.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.190812991499395, 'log_learning_rate_D': -2.3021544637474256, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.8121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  20 training error:  tensor(0.6742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  30 training error:  tensor(0.5415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  40 training error:  tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  50 training error:  tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  60 training error:  tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  70 training error:  tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  80 training error:  tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
	 epoch  90 training error:  tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.1962890625
Memory cached:  128.0
[I 2023-12-05 01:22:17,452] Trial 30 finished with value: 0.19572071731090546 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.190812991499395, 'log_learning_rate_D': -2.3021544637474256, 'training_batch_size': 10, 'training_p': 2}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  49.31185793876648
Memory status after this trial: 
Memory allocated:  82.3349609375
Memory cached:  126.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.4371793008713132, 'log_learning_rate_D': -2.685809614686858, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  106.0
	 epoch  10 training error:  tensor(1.4132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  20 training error:  tensor(1.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  30 training error:  tensor(0.7836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  40 training error:  tensor(0.9588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  50 training error:  tensor(0.9059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  60 training error:  tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  70 training error:  tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  80 training error:  tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
	 epoch  90 training error:  tensor(0.6267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.2236328125
Memory cached:  108.0
[I 2023-12-05 01:23:05,511] Trial 31 finished with value: 0.4740118682384491 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.4371793008713132, 'log_learning_rate_D': -2.685809614686858, 'training_batch_size': 8, 'training_p': 2}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  47.86530423164368
Memory status after this trial: 
Memory allocated:  82.32275390625
Memory cached:  106.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.7086225456278048, 'log_learning_rate_D': -2.5892553305168495, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.9176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.6494140625
Memory cached:  104.0
[I 2023-12-05 01:23:48,220] Trial 32 finished with value: 0.18729111552238464 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.7086225456278048, 'log_learning_rate_D': -2.5892553305168495, 'training_batch_size': 7, 'training_p': 3}. Best is trial 21 with value: 0.11125688999891281.
Time for this trial:  42.534554958343506
Memory status after this trial: 
Memory allocated:  59.50634765625
Memory cached:  104.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.3439220691248654, 'log_learning_rate_D': -2.7740057030288594, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  10 training error:  tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.6832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.8603515625
Memory cached:  106.0
[I 2023-12-05 01:24:27,594] Trial 33 finished with value: 0.05789090320467949 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.3439220691248654, 'log_learning_rate_D': -2.7740057030288594, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
res:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  39.21169090270996
Memory status after this trial: 
Memory allocated:  58.359375
Memory cached:  86.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.352735991168939, 'log_learning_rate_D': -3.140233047466134, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.6322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.4293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.20458984375
Memory cached:  112.0
[I 2023-12-05 01:25:10,870] Trial 34 finished with value: 0.1777474731206894 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.352735991168939, 'log_learning_rate_D': -3.140233047466134, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  43.118022203445435
Memory status after this trial: 
Memory allocated:  143.42236328125
Memory cached:  156.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.137856905653151, 'log_learning_rate_D': -2.914289308392366, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.3954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.07763671875
Memory cached:  92.0
[I 2023-12-05 01:25:51,460] Trial 35 finished with value: 0.18183739483356476 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.137856905653151, 'log_learning_rate_D': -2.914289308392366, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  40.43465065956116
Memory status after this trial: 
Memory allocated:  119.37890625
Memory cached:  124.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4426460746705363, 'log_learning_rate_D': -2.8176749077030556, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  106.0
	 epoch  10 training error:  tensor(0.7982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  20 training error:  tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  30 training error:  tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  40 training error:  tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  50 training error:  tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  60 training error:  tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  70 training error:  tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  80 training error:  tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
	 epoch  90 training error:  tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.26123046875
Memory cached:  108.0
[I 2023-12-05 01:26:27,230] Trial 36 finished with value: 0.3510616421699524 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4426460746705363, 'log_learning_rate_D': -2.8176749077030556, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.61782193183899
Memory status after this trial: 
Memory allocated:  122.32666015625
Memory cached:  140.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.074235413793475, 'log_learning_rate_D': -2.27406506975006, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  92.0
	 epoch  10 training error:  tensor(2.6021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  20 training error:  tensor(1.1872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  30 training error:  tensor(1.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.9700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.9710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.9704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.08544921875
Memory cached:  96.0
[I 2023-12-05 01:27:19,669] Trial 37 finished with value: 0.8854325413703918 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.074235413793475, 'log_learning_rate_D': -2.27406506975006, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  52.26711583137512
Memory status after this trial: 
Memory allocated:  149.9814453125
Memory cached:  154.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.0449999965810415, 'log_learning_rate_D': -2.782221146075994, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  10 training error:  tensor(364.7829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  20 training error:  tensor(1191.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  30 training error:  tensor(407.4264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  40 training error:  tensor(41.5314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  50 training error:  tensor(31.9250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  60 training error:  tensor(23.8765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  70 training error:  tensor(26.6289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  80 training error:  tensor(21.1484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
	 epoch  90 training error:  tensor(14.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.26123046875
Memory cached:  90.0
[I 2023-12-05 01:28:06,670] Trial 38 finished with value: 36.14277267456055 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.0449999965810415, 'log_learning_rate_D': -2.782221146075994, 'training_batch_size': 8, 'training_p': 6}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  46.809627294540405
Memory status after this trial: 
Memory allocated:  132.57568359375
Memory cached:  136.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.338247166175984, 'log_learning_rate_D': -3.2051729162441647, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.7317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.29443359375
Memory cached:  112.0
[I 2023-12-05 01:28:45,698] Trial 39 finished with value: 0.10674532502889633 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.338247166175984, 'log_learning_rate_D': -3.2051729162441647, 'training_batch_size': 9, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  38.843161821365356
Memory status after this trial: 
Memory allocated:  123.07275390625
Memory cached:  140.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4626135015436184, 'log_learning_rate_D': -3.0613073126498533, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.7533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.77685546875
Memory cached:  90.0
[I 2023-12-05 01:29:19,705] Trial 40 finished with value: 0.11396725475788116 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4626135015436184, 'log_learning_rate_D': -3.0613073126498533, 'training_batch_size': 11, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  33.847907304763794
Memory status after this trial: 
Memory allocated:  109.6552734375
Memory cached:  112.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.8995572085624148, 'log_learning_rate_D': -3.2326870511842114, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  106.0
	 epoch  10 training error:  tensor(1.7323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  20 training error:  tensor(2.3224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  30 training error:  tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  40 training error:  tensor(1.6176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  50 training error:  tensor(2.3887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  60 training error:  tensor(1.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  70 training error:  tensor(1.6598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  80 training error:  tensor(2.0126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
	 epoch  90 training error:  tensor(1.3044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.55419921875
Memory cached:  108.0
[I 2023-12-05 01:29:56,054] Trial 41 finished with value: 1.461524486541748 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.8995572085624148, 'log_learning_rate_D': -3.2326870511842114, 'training_batch_size': 12, 'training_p': 5}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.18890333175659
Memory status after this trial: 
Memory allocated:  140.5419921875
Memory cached:  156.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.441360022962012, 'log_learning_rate_D': -3.0652393739671693, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.8191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.6164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.84130859375
Memory cached:  88.0
[I 2023-12-05 01:30:32,376] Trial 42 finished with value: 0.29351547360420227 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.441360022962012, 'log_learning_rate_D': -3.0652393739671693, 'training_batch_size': 11, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.130450963974
Memory status after this trial: 
Memory allocated:  109.1875
Memory cached:  112.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.657192051516717, 'log_learning_rate_D': -3.232752870440435, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.28271484375
Memory cached:  90.0
[I 2023-12-05 01:31:08,629] Trial 43 finished with value: 0.10621215403079987 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.657192051516717, 'log_learning_rate_D': -3.232752870440435, 'training_batch_size': 9, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.102882862091064
Memory status after this trial: 
Memory allocated:  107.17236328125
Memory cached:  112.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.6597839594685246, 'log_learning_rate_D': -3.267619259276982, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.7630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.6312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.5841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.52685546875
Memory cached:  88.0
[I 2023-12-05 01:31:43,293] Trial 44 finished with value: 0.13646598160266876 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.6597839594685246, 'log_learning_rate_D': -3.267619259276982, 'training_batch_size': 9, 'training_p': 5}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  34.51227426528931
Memory status after this trial: 
Memory allocated:  107.14794921875
Memory cached:  112.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.9891178401317087, 'log_learning_rate_D': -2.970759698331284, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.8694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.6037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.00146484375
Memory cached:  92.0
[I 2023-12-05 01:32:18,968] Trial 45 finished with value: 0.1509629338979721 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.9891178401317087, 'log_learning_rate_D': -2.970759698331284, 'training_batch_size': 9, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.51874494552612
Memory status after this trial: 
Memory allocated:  95.43017578125
Memory cached:  98.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.2615970543089494, 'log_learning_rate_D': -3.00126747401779, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  10 training error:  tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  20 training error:  tensor(0.8054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  30 training error:  tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  50 training error:  tensor(0.4811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  60 training error:  tensor(0.4178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  80 training error:  tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
	 epoch  90 training error:  tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.12060546875
Memory cached:  86.0
[I 2023-12-05 01:32:52,720] Trial 46 finished with value: 0.2869022786617279 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.2615970543089494, 'log_learning_rate_D': -3.00126747401779, 'training_batch_size': 10, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  33.55458402633667
Memory status after this trial: 
Memory allocated:  95.05322265625
Memory cached:  98.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.0672754834053997, 'log_learning_rate_D': -3.262389807989236, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.7809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.6510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.5098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.3869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.33154296875
Memory cached:  90.0
[I 2023-12-05 01:33:30,806] Trial 47 finished with value: 0.2549012303352356 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.0672754834053997, 'log_learning_rate_D': -3.262389807989236, 'training_batch_size': 11, 'training_p': 5}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  37.93974184989929
Memory status after this trial: 
Memory allocated:  102.01416015625
Memory cached:  104.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.720968866338411, 'log_learning_rate_D': -3.626849777464974, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.78271484375
Memory cached:  90.0
[I 2023-12-05 01:34:06,929] Trial 48 finished with value: 0.14220158755779266 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.720968866338411, 'log_learning_rate_D': -3.626849777464974, 'training_batch_size': 9, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.97539305686951
Memory status after this trial: 
Memory allocated:  108.1474609375
Memory cached:  112.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.830902737112173, 'log_learning_rate_D': -2.860721178617709, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.4181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.07177734375
Memory cached:  90.0
[I 2023-12-05 01:34:42,555] Trial 49 finished with value: 0.477517694234848 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.830902737112173, 'log_learning_rate_D': -2.860721178617709, 'training_batch_size': 12, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.46414065361023
Memory status after this trial: 
Memory allocated:  111.08837890625
Memory cached:  114.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.5921243405135472, 'log_learning_rate_D': -3.3421818720451912, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.7212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.52880859375
Memory cached:  88.0
[I 2023-12-05 01:35:18,348] Trial 50 finished with value: 0.18811912834644318 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.5921243405135472, 'log_learning_rate_D': -3.3421818720451912, 'training_batch_size': 10, 'training_p': 5}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.64660048484802
Memory status after this trial: 
Memory allocated:  101.359375
Memory cached:  104.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2991031018000414, 'log_learning_rate_D': -3.6491732854246193, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.7104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.6034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.03466796875
Memory cached:  92.0
[I 2023-12-05 01:35:55,248] Trial 51 finished with value: 0.1215536966919899 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2991031018000414, 'log_learning_rate_D': -3.6491732854246193, 'training_batch_size': 10, 'training_p': 7}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.74317717552185
Memory status after this trial: 
Memory allocated:  120.2783203125
Memory cached:  124.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.305310406060243, 'log_learning_rate_D': -3.520405939204035, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.9780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.9163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.6648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.04248046875
Memory cached:  92.0
[I 2023-12-05 01:36:32,742] Trial 52 finished with value: 0.20318594574928284 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.305310406060243, 'log_learning_rate_D': -3.520405939204035, 'training_batch_size': 10, 'training_p': 7}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  37.321521520614624
Memory status after this trial: 
Memory allocated:  126.5830078125
Memory cached:  132.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.0838821320266816, 'log_learning_rate_D': -4.04134641623302, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.9289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.7691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.6384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.00341796875
Memory cached:  90.0
[I 2023-12-05 01:37:09,270] Trial 53 finished with value: 0.5373627543449402 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.0838821320266816, 'log_learning_rate_D': -4.04134641623302, 'training_batch_size': 11, 'training_p': 7}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.3423125743866
Memory status after this trial: 
Memory allocated:  107.6611328125
Memory cached:  110.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.9082999832996967, 'log_learning_rate_D': -3.3455736709091157, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.8089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.78662109375
Memory cached:  92.0
[I 2023-12-05 01:37:45,734] Trial 54 finished with value: 0.0626552402973175 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.9082999832996967, 'log_learning_rate_D': -3.3455736709091157, 'training_batch_size': 9, 'training_p': 8}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.29188847541809
Memory status after this trial: 
Memory allocated:  114.0
Memory cached:  118.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.967315425014104, 'log_learning_rate_D': -3.3744953883974844, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  10 training error:  tensor(0.6307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.5267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.5055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63818359375
Memory cached:  106.0
[I 2023-12-05 01:38:22,102] Trial 55 finished with value: 0.5101131796836853 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.967315425014104, 'log_learning_rate_D': -3.3744953883974844, 'training_batch_size': 9, 'training_p': 8}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.192381858825684
Memory status after this trial: 
Memory allocated:  110.0078125
Memory cached:  128.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.845742060366433, 'log_learning_rate_D': -3.0634827331502827, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75146484375
Memory cached:  88.0
[I 2023-12-05 01:38:57,708] Trial 56 finished with value: 0.09629663079977036 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.845742060366433, 'log_learning_rate_D': -3.0634827331502827, 'training_batch_size': 9, 'training_p': 6}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.428317070007324
Memory status after this trial: 
Memory allocated:  97.98046875
Memory cached:  100.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.8680433998621684, 'log_learning_rate_D': -3.097451829523316, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  20 training error:  tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  30 training error:  tensor(0.5411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  50 training error:  tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  60 training error:  tensor(0.5174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  80 training error:  tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
	 epoch  90 training error:  tensor(0.4932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.52099609375
Memory cached:  86.0
[I 2023-12-05 01:39:32,488] Trial 57 finished with value: 0.5452300906181335 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.8680433998621684, 'log_learning_rate_D': -3.097451829523316, 'training_batch_size': 9, 'training_p': 8}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  34.60384249687195
Memory status after this trial: 
Memory allocated:  83.6875
Memory cached:  86.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.1446002972043883, 'log_learning_rate_D': -3.3828369596791115, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.6237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24951171875
Memory cached:  90.0
[I 2023-12-05 01:40:15,374] Trial 58 finished with value: 0.12507645785808563 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.1446002972043883, 'log_learning_rate_D': -3.3828369596791115, 'training_batch_size': 8, 'training_p': 6}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.72130346298218
Memory status after this trial: 
Memory allocated:  117.19921875
Memory cached:  120.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.6954542857563206, 'log_learning_rate_D': -2.879817889631381, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.8656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.7264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.6365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.63623046875
Memory cached:  94.0
[I 2023-12-05 01:40:52,113] Trial 59 finished with value: 0.2939135432243347 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.6954542857563206, 'log_learning_rate_D': -2.879817889631381, 'training_batch_size': 9, 'training_p': 6}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.58692932128906
Memory status after this trial: 
Memory allocated:  115.8369140625
Memory cached:  120.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.2551491578218688, 'log_learning_rate_D': -2.6938321924234687, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.9482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.9303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.9044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.8651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.7337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.6373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56982421875
Memory cached:  88.0
[I 2023-12-05 01:41:29,514] Trial 60 finished with value: 0.44985324144363403 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.2551491578218688, 'log_learning_rate_D': -2.6938321924234687, 'training_batch_size': 9, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  37.23346996307373
Memory status after this trial: 
Memory allocated:  73.44873046875
Memory cached:  86.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.8689617112208823, 'log_learning_rate_D': -3.221910457315241, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.6797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.02099609375
Memory cached:  90.0
[I 2023-12-05 01:42:06,903] Trial 61 finished with value: 0.2479553520679474 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.8689617112208823, 'log_learning_rate_D': -3.221910457315241, 'training_batch_size': 8, 'training_p': 7}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  37.237356185913086
Memory status after this trial: 
Memory allocated:  121.12109375
Memory cached:  126.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.5015133538350995, 'log_learning_rate_D': -3.0234203285300776, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.7910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78662109375
Memory cached:  88.0
[I 2023-12-05 01:42:42,974] Trial 62 finished with value: 0.13473528623580933 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.5015133538350995, 'log_learning_rate_D': -3.0234203285300776, 'training_batch_size': 9, 'training_p': 4}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.90069913864136
Memory status after this trial: 
Memory allocated:  110.392578125
Memory cached:  114.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.573494345047948, 'log_learning_rate_D': -3.1573217869823114, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78271484375
Memory cached:  90.0
[I 2023-12-05 01:43:19,177] Trial 63 finished with value: 0.0938287153840065 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.573494345047948, 'log_learning_rate_D': -3.1573217869823114, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.040030002593994
Memory status after this trial: 
Memory allocated:  110.09765625
Memory cached:  114.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.6016095815294435, 'log_learning_rate_D': -3.416217174650096, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.5742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.5667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.50927734375
Memory cached:  88.0
[I 2023-12-05 01:43:53,335] Trial 64 finished with value: 0.3106750547885895 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.6016095815294435, 'log_learning_rate_D': -3.416217174650096, 'training_batch_size': 9, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  33.987550020217896
Memory status after this trial: 
Memory allocated:  87.5029296875
Memory cached:  90.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7604831160864824, 'log_learning_rate_D': -3.5603407477962996, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  92.0
[I 2023-12-05 01:44:32,034] Trial 65 finished with value: 0.07867618650197983 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7604831160864824, 'log_learning_rate_D': -3.5603407477962996, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  38.53916907310486
Memory status after this trial: 
Memory allocated:  88.4345703125
Memory cached:  92.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.072180175443188, 'log_learning_rate_D': -3.561808056596088, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.7706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.6784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.6391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.5949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.73193359375
Memory cached:  94.0
[I 2023-12-05 01:45:10,786] Trial 66 finished with value: 0.15782420337200165 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.072180175443188, 'log_learning_rate_D': -3.561808056596088, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  38.587636947631836
Memory status after this trial: 
Memory allocated:  88.4345703125
Memory cached:  92.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.7724555010681566, 'log_learning_rate_D': -3.762683088262015, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.7248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.4289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.21435546875
Memory cached:  92.0
[I 2023-12-05 01:45:59,680] Trial 67 finished with value: 0.1612943559885025 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.7724555010681566, 'log_learning_rate_D': -3.762683088262015, 'training_batch_size': 10, 'training_p': 5}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  48.712056159973145
Memory status after this trial: 
Memory allocated:  127.2685546875
Memory cached:  130.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.007652725606717, 'log_learning_rate_D': -3.2969588287106464, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.8460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.5373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.62646484375
Memory cached:  92.0
[I 2023-12-05 01:46:34,872] Trial 68 finished with value: 0.39537015557289124 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.007652725606717, 'log_learning_rate_D': -3.2969588287106464, 'training_batch_size': 9, 'training_p': 8}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.00898599624634
Memory status after this trial: 
Memory allocated:  96.3505859375
Memory cached:  98.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.727996999233704, 'log_learning_rate_D': -3.466796745529264, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.3175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.92138671875
Memory cached:  90.0
[I 2023-12-05 01:47:18,117] Trial 69 finished with value: 0.2166065275669098 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.727996999233704, 'log_learning_rate_D': -3.466796745529264, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  43.07769823074341
Memory status after this trial: 
Memory allocated:  124.626953125
Memory cached:  128.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.9055790329707816, 'log_learning_rate_D': -3.170249088353109, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.4971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.75537109375
Memory cached:  90.0
[I 2023-12-05 01:47:53,441] Trial 70 finished with value: 0.15238730609416962 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.9055790329707816, 'log_learning_rate_D': -3.170249088353109, 'training_batch_size': 9, 'training_p': 6}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  35.15889930725098
Memory status after this trial: 
Memory allocated:  98.275390625
Memory cached:  100.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.621823312338476, 'log_learning_rate_D': -2.9382747397563853, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
[I 2023-12-05 01:48:33,767] Trial 71 finished with value: 0.08716510981321335 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.621823312338476, 'log_learning_rate_D': -2.9382747397563853, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  40.162248373031616
Memory status after this trial: 
Memory allocated:  109.5751953125
Memory cached:  112.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.5643742840564467, 'log_learning_rate_D': -2.9616757201264168, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
[I 2023-12-05 01:49:13,682] Trial 72 finished with value: 0.09883453696966171 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.5643742840564467, 'log_learning_rate_D': -2.9616757201264168, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.73353981971741
Memory status after this trial: 
Memory allocated:  109.5751953125
Memory cached:  112.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.5537042730462063, 'log_learning_rate_D': -2.77115220108127, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  108.0
	 epoch  10 training error:  tensor(0.6910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  20 training error:  tensor(0.6108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  30 training error:  tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  50 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  60 training error:  tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  70 training error:  tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  80 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
	 epoch  90 training error:  tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.64599609375
Memory cached:  110.0
[I 2023-12-05 01:49:55,284] Trial 73 finished with value: 0.13355539739131927 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.5537042730462063, 'log_learning_rate_D': -2.77115220108127, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  41.417375564575195
Memory status after this trial: 
Memory allocated:  124.373046875
Memory cached:  144.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.63434639051482, 'log_learning_rate_D': -2.5026754628347168, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.6976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.20849609375
Memory cached:  92.0
[I 2023-12-05 01:50:39,342] Trial 74 finished with value: 0.14608310163021088 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.63434639051482, 'log_learning_rate_D': -2.5026754628347168, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  43.86496353149414
Memory status after this trial: 
Memory allocated:  111.56787109375
Memory cached:  114.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.819184214857079, 'log_learning_rate_D': -2.9400377699213087, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.6230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.99951171875
Memory cached:  94.0
[I 2023-12-05 01:51:15,805] Trial 75 finished with value: 0.0675118938088417 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.819184214857079, 'log_learning_rate_D': -2.9400377699213087, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.29091739654541
Memory status after this trial: 
Memory allocated:  89.9287109375
Memory cached:  92.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.8025680418688497, 'log_learning_rate_D': -2.669807826129745, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.87255859375
Memory cached:  90.0
[I 2023-12-05 01:51:55,592] Trial 76 finished with value: 0.15016834437847137 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.8025680418688497, 'log_learning_rate_D': -2.669807826129745, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.59340810775757
Memory status after this trial: 
Memory allocated:  102.349609375
Memory cached:  104.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9949926773875357, 'log_learning_rate_D': -2.9291321227453677, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.6060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.31591796875
Memory cached:  88.0
[I 2023-12-05 01:52:37,838] Trial 77 finished with value: 0.1218191385269165 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9949926773875357, 'log_learning_rate_D': -2.9291321227453677, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.074315547943115
Memory status after this trial: 
Memory allocated:  116.1650390625
Memory cached:  118.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.9016553278011767, 'log_learning_rate_D': -2.8086855089100236, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.6770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.53466796875
Memory cached:  90.0
[I 2023-12-05 01:53:20,413] Trial 78 finished with value: 0.11790471524000168 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.9016553278011767, 'log_learning_rate_D': -2.8086855089100236, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.38574814796448
Memory status after this trial: 
Memory allocated:  122.71826171875
Memory cached:  126.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.1392421845287917, 'log_learning_rate_D': -2.9698588256753844, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.9049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.7385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.7064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.96240234375
Memory cached:  88.0
[I 2023-12-05 01:54:02,660] Trial 79 finished with value: 0.11353335529565811 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.1392421845287917, 'log_learning_rate_D': -2.9698588256753844, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.03670644760132
Memory status after this trial: 
Memory allocated:  83.025390625
Memory cached:  88.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.507335862728847, 'log_learning_rate_D': -3.126315512512986, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.56396484375
Memory cached:  90.0
[I 2023-12-05 01:54:42,598] Trial 80 finished with value: 0.14090807735919952 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.507335862728847, 'log_learning_rate_D': -3.126315512512986, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.70088720321655
Memory status after this trial: 
Memory allocated:  98.677734375
Memory cached:  100.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.4050564208284397, 'log_learning_rate_D': -2.654304223795918, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.6878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
[I 2023-12-05 01:55:21,676] Trial 81 finished with value: 0.09134682267904282 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.4050564208284397, 'log_learning_rate_D': -2.654304223795918, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  38.891077518463135
Memory status after this trial: 
Memory allocated:  103.1533203125
Memory cached:  106.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.38664664239556, 'log_learning_rate_D': -2.6686684111118884, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.78076171875
Memory cached:  90.0
[I 2023-12-05 01:56:01,461] Trial 82 finished with value: 0.22057490050792694 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.38664664239556, 'log_learning_rate_D': -2.6686684111118884, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.60304379463196
Memory status after this trial: 
Memory allocated:  103.1533203125
Memory cached:  106.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.780209173082357, 'log_learning_rate_D': -2.7626316350777613, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.7035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.5746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.78857421875
Memory cached:  94.0
[I 2023-12-05 01:56:41,471] Trial 83 finished with value: 0.13044734299182892 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.780209173082357, 'log_learning_rate_D': -2.7626316350777613, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.84173059463501
Memory status after this trial: 
Memory allocated:  109.4580078125
Memory cached:  112.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.2064211911767226, 'log_learning_rate_D': -2.4839515296459624, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.8175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  20 training error:  tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  30 training error:  tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  40 training error:  tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  50 training error:  tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  60 training error:  tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  70 training error:  tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  80 training error:  tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
	 epoch  90 training error:  tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03271484375
Memory cached:  110.0
[I 2023-12-05 01:57:24,845] Trial 84 finished with value: 0.07637100666761398 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.2064211911767226, 'log_learning_rate_D': -2.4839515296459624, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  43.1950478553772
Memory status after this trial: 
Memory allocated:  129.689453125
Memory cached:  148.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.235128591072376, 'log_learning_rate_D': -2.4118992322664736, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.5949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.15771484375
Memory cached:  92.0
[I 2023-12-05 01:58:08,009] Trial 85 finished with value: 0.15882524847984314 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.235128591072376, 'log_learning_rate_D': -2.4118992322664736, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.973970890045166
Memory status after this trial: 
Memory allocated:  119.5615234375
Memory cached:  124.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.3606582472885447, 'log_learning_rate_D': -2.5812704859898896, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.8564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  20 training error:  tensor(0.6660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  30 training error:  tensor(0.6079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  40 training error:  tensor(0.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  50 training error:  tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  60 training error:  tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  70 training error:  tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  80 training error:  tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
	 epoch  90 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.88623046875
Memory cached:  110.0
[I 2023-12-05 01:58:53,750] Trial 86 finished with value: 0.18079136312007904 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.3606582472885447, 'log_learning_rate_D': -2.5812704859898896, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  45.561068534851074
Memory status after this trial: 
Memory allocated:  134.44140625
Memory cached:  154.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.693685424984002, 'log_learning_rate_D': -2.4605261583050613, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.8957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.69873046875
Memory cached:  92.0
[I 2023-12-05 01:59:39,603] Trial 87 finished with value: 0.15701161324977875 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.693685424984002, 'log_learning_rate_D': -2.4605261583050613, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  45.653642416000366
Memory status after this trial: 
Memory allocated:  124.9443359375
Memory cached:  128.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.227203616885897, 'log_learning_rate_D': -2.5952104300407846, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.5639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.85888671875
Memory cached:  88.0
[I 2023-12-05 02:00:15,874] Trial 88 finished with value: 0.10533279180526733 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.227203616885897, 'log_learning_rate_D': -2.5952104300407846, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.0953528881073
Memory status after this trial: 
Memory allocated:  78.8720703125
Memory cached:  88.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.374876463439116, 'log_learning_rate_D': -2.8601708359071885, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.98779296875
Memory cached:  90.0
[I 2023-12-05 02:00:52,541] Trial 89 finished with value: 0.11150691658258438 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.374876463439116, 'log_learning_rate_D': -2.8601708359071885, 'training_batch_size': 10, 'training_p': 3}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  36.47994256019592
Memory status after this trial: 
Memory allocated:  89.6298828125
Memory cached:  92.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1325049554983035, 'log_learning_rate_D': -3.0309098675198674, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.25927734375
Memory cached:  90.0
[I 2023-12-05 02:01:35,338] Trial 90 finished with value: 0.3711467385292053 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1325049554983035, 'log_learning_rate_D': -3.0309098675198674, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.61072278022766
Memory status after this trial: 
Memory allocated:  112.4287109375
Memory cached:  114.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.524463183072335, 'log_learning_rate_D': -2.739219137260657, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.24169921875
Memory cached:  92.0
[I 2023-12-05 02:02:14,344] Trial 91 finished with value: 0.12750396132469177 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.524463183072335, 'log_learning_rate_D': -2.739219137260657, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  38.81976890563965
Memory status after this trial: 
Memory allocated:  101.1259765625
Memory cached:  104.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.58752127762604, 'log_learning_rate_D': -2.9704914012625547, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.4877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
[I 2023-12-05 02:02:54,174] Trial 92 finished with value: 0.06884714215993881 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.58752127762604, 'log_learning_rate_D': -2.9704914012625547, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.66263222694397
Memory status after this trial: 
Memory allocated:  109.5751953125
Memory cached:  112.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.635904891603418, 'log_learning_rate_D': -3.0923476441630875, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
[I 2023-12-05 02:03:34,066] Trial 93 finished with value: 0.0895039513707161 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.635904891603418, 'log_learning_rate_D': -3.0923476441630875, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.70409798622131
Memory status after this trial: 
Memory allocated:  109.5751953125
Memory cached:  112.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.4224378902661514, 'log_learning_rate_D': -3.300657240468008, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.02294921875
Memory cached:  90.0
[I 2023-12-05 02:04:13,923] Trial 94 finished with value: 0.06907416135072708 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.4224378902661514, 'log_learning_rate_D': -3.300657240468008, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.684755086898804
Memory status after this trial: 
Memory allocated:  109.5751953125
Memory cached:  112.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1802863628365716, 'log_learning_rate_D': -2.897484202478583, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.53076171875
Memory cached:  88.0
[I 2023-12-05 02:04:53,912] Trial 95 finished with value: 0.21748223900794983 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1802863628365716, 'log_learning_rate_D': -2.897484202478583, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  39.79422855377197
Memory status after this trial: 
Memory allocated:  110.5615234375
Memory cached:  114.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.444215798925268, 'log_learning_rate_D': -3.3078187059509148, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.7240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.09326171875
Memory cached:  88.0
[I 2023-12-05 02:05:34,228] Trial 96 finished with value: 0.16326633095741272 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.444215798925268, 'log_learning_rate_D': -3.3078187059509148, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  40.122597217559814
Memory status after this trial: 
Memory allocated:  110.6357421875
Memory cached:  114.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.024964573398815, 'log_learning_rate_D': -2.4966768335200844, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.7190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.7068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.5709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.52880859375
Memory cached:  92.0
[I 2023-12-05 02:06:15,710] Trial 97 finished with value: 0.4709981381893158 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.024964573398815, 'log_learning_rate_D': -2.4966768335200844, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  41.29386925697327
Memory status after this trial: 
Memory allocated:  99.95703125
Memory cached:  104.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.6435007392076666, 'log_learning_rate_D': -2.653050833706388, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.53076171875
Memory cached:  92.0
[I 2023-12-05 02:06:58,419] Trial 98 finished with value: 0.12472527474164963 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.6435007392076666, 'log_learning_rate_D': -2.653050833706388, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
Time for this trial:  42.51263070106506
Memory status after this trial: 
Memory allocated:  114.6943359375
Memory cached:  118.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.735108999941804, 'log_learning_rate_D': -2.811119084998996, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.82763671875
Memory cached:  90.0
[I 2023-12-05 02:07:39,018] Trial 99 finished with value: 0.14734075963497162 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.735108999941804, 'log_learning_rate_D': -2.811119084998996, 'training_batch_size': 11, 'training_p': 2}. Best is trial 33 with value: 0.05789090320467949.
[I 2023-12-05 02:07:39,036] A new study created in memory with name: no-name-dc812179-1733-4959-925b-1342df4a6832
Time for this trial:  40.41157841682434
Memory status after this trial: 
Memory allocated:  111.3857421875
Memory cached:  116.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.3532559900239143, 'log_learning_rate_D': -4.675224216356992, 'training_batch_size': 9, 'training_p': 2}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.0321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  10 training error:  tensor(3.1899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  20 training error:  tensor(1.2217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  30 training error:  tensor(5.9747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  40 training error:  tensor(1.5714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  50 training error:  tensor(3.7201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  70 training error:  tensor(1.9531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.9371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
	 epoch  90 training error:  tensor(1.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.68603515625
Memory cached:  24.0
[I 2023-12-05 02:07:54,192] Trial 0 finished with value: 0.7984246015548706 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.3532559900239143, 'log_learning_rate_D': -4.675224216356992, 'training_batch_size': 9, 'training_p': 2}. Best is trial 0 with value: 0.7984246015548706.
res:  tensor(0.7984, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  15.051594495773315
Memory status after this trial: 
Memory allocated:  57.6640625
Memory cached:  86.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.0659772193922912, 'log_learning_rate_D': -2.453002508663587, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  10 training error:  tensor(29325.3223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  94.0
	 epoch  20 training error:  tensor(711.3599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  30 training error:  tensor(34.5594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  40 training error:  tensor(33.0998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  94.0
	 epoch  50 training error:  tensor(30.1596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  60 training error:  tensor(26.5056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  70 training error:  tensor(22.4372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  94.0
	 epoch  80 training error:  tensor(18.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
	 epoch  90 training error:  tensor(13.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.1337890625
Memory cached:  92.0
[I 2023-12-05 02:08:09,755] Trial 1 finished with value: 12.750250816345215 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.0659772193922912, 'log_learning_rate_D': -2.453002508663587, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 0.7984246015548706.
Time for this trial:  15.472344398498535
Memory status after this trial: 
Memory allocated:  111.05224609375
Memory cached:  130.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.2790207779234066, 'log_learning_rate_D': -2.778418215081456, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.7516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.6691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.6621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.6612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.6606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.6606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.89453125
Memory cached:  92.0
[I 2023-12-05 02:08:24,451] Trial 2 finished with value: 0.6373639702796936 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.2790207779234066, 'log_learning_rate_D': -2.778418215081456, 'training_batch_size': 10, 'training_p': 5}. Best is trial 2 with value: 0.6373639702796936.
res:  tensor(0.6374, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.7984, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.593152523040771
Memory status after this trial: 
Memory allocated:  34.7451171875
Memory cached:  50.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.0430580301445165, 'log_learning_rate_D': -1.5307319746287336, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.7979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.7878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.7825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.7724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.7648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.7537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.158203125
Memory cached:  50.0
[I 2023-12-05 02:08:39,430] Trial 3 finished with value: 0.6808099150657654 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.0430580301445165, 'log_learning_rate_D': -1.5307319746287336, 'training_batch_size': 10, 'training_p': 3}. Best is trial 2 with value: 0.6373639702796936.
Time for this trial:  14.878024101257324
Memory status after this trial: 
Memory allocated:  79.57080078125
Memory cached:  92.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.041967567943699, 'log_learning_rate_D': -1.7266101262638198, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.7326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.7287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.7121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.6964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.67822265625
Memory cached:  72.0
[I 2023-12-05 02:08:55,237] Trial 4 finished with value: 0.5578408241271973 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.041967567943699, 'log_learning_rate_D': -1.7266101262638198, 'training_batch_size': 11, 'training_p': 2}. Best is trial 4 with value: 0.5578408241271973.
res:  tensor(0.5578, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.6374, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.715960025787354
Memory status after this trial: 
Memory allocated:  87.91796875
Memory cached:  150.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.1639692830202377, 'log_learning_rate_D': -1.258324249971713, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  10 training error:  tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.7543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.6591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.6481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.6344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.6277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.6259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.3271484375
Memory cached:  150.0
[I 2023-12-05 02:09:10,231] Trial 5 finished with value: 0.5480077266693115 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.1639692830202377, 'log_learning_rate_D': -1.258324249971713, 'training_batch_size': 9, 'training_p': 3}. Best is trial 5 with value: 0.5480077266693115.
res:  tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5578, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.896384000778198
Memory status after this trial: 
Memory allocated:  60.2060546875
Memory cached:  112.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.9684396580211025, 'log_learning_rate_D': -4.263633424572566, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.9897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.9772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.9628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.9400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.8662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.8297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.3037109375
Memory cached:  114.0
[I 2023-12-05 02:09:26,287] Trial 6 finished with value: 0.8144249320030212 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.9684396580211025, 'log_learning_rate_D': -4.263633424572566, 'training_batch_size': 12, 'training_p': 6}. Best is trial 5 with value: 0.5480077266693115.
Time for this trial:  15.9432053565979
Memory status after this trial: 
Memory allocated:  156.11279296875
Memory cached:  200.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -1.3554413551938804, 'log_learning_rate_D': -2.667757466889907, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  10 training error:  tensor(1.0139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  20 training error:  tensor(1.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.9149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.8971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.8216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.7384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.6853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.6955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.6015625
Memory cached:  114.0
[I 2023-12-05 02:09:40,420] Trial 7 finished with value: 0.7279672026634216 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -1.3554413551938804, 'log_learning_rate_D': -2.667757466889907, 'training_batch_size': 9, 'training_p': 8}. Best is trial 5 with value: 0.5480077266693115.
Time for this trial:  14.0452241897583
Memory status after this trial: 
Memory allocated:  71.04833984375
Memory cached:  116.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.1205981223191164, 'log_learning_rate_D': -4.755692740759155, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.8420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.6781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.6671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.833984375
Memory cached:  114.0
[I 2023-12-05 02:09:55,008] Trial 8 finished with value: 0.6708876490592957 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.1205981223191164, 'log_learning_rate_D': -4.755692740759155, 'training_batch_size': 11, 'training_p': 6}. Best is trial 5 with value: 0.5480077266693115.
Time for this trial:  14.4981689453125
Memory status after this trial: 
Memory allocated:  91.44091796875
Memory cached:  120.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.88319280186945, 'log_learning_rate_D': -1.6793657141593163, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.9838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.9737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.9634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.9374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.9203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.9005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.8784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.8542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.048828125
Memory cached:  118.0
[I 2023-12-05 02:10:10,731] Trial 9 finished with value: 0.6913051009178162 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.88319280186945, 'log_learning_rate_D': -1.6793657141593163, 'training_batch_size': 11, 'training_p': 5}. Best is trial 5 with value: 0.5480077266693115.
Time for this trial:  15.616067171096802
Memory status after this trial: 
Memory allocated:  126.21630859375
Memory cached:  142.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.0448970514307057, 'log_learning_rate_D': -1.0576190921721857, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.9267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.8553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.8205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.8097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.8091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.564453125
Memory cached:  112.0
[I 2023-12-05 02:10:24,381] Trial 10 finished with value: 0.7537436485290527 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.0448970514307057, 'log_learning_rate_D': -1.0576190921721857, 'training_batch_size': 7, 'training_p': 4}. Best is trial 5 with value: 0.5480077266693115.
Time for this trial:  13.49765920639038
Memory status after this trial: 
Memory allocated:  63.56298828125
Memory cached:  114.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.654966276497232, 'log_learning_rate_D': -1.0471084004507287, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  10 training error:  tensor(0.7472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.7350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.7132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.5886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.37109375
Memory cached:  122.0
[I 2023-12-05 02:10:40,517] Trial 11 finished with value: 0.509655773639679 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.654966276497232, 'log_learning_rate_D': -1.0471084004507287, 'training_batch_size': 7, 'training_p': 2}. Best is trial 11 with value: 0.509655773639679.
res:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.974417686462402
Memory status after this trial: 
Memory allocated:  85.46875
Memory cached:  176.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.379198047163524, 'log_learning_rate_D': -1.099010731238305, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.7948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.7025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.8050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.6307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.6254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.26025390625
Memory cached:  180.0
[I 2023-12-05 02:10:58,028] Trial 12 finished with value: 0.5606281161308289 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.379198047163524, 'log_learning_rate_D': -1.099010731238305, 'training_batch_size': 6, 'training_p': 3}. Best is trial 11 with value: 0.509655773639679.
Time for this trial:  17.340017080307007
Memory status after this trial: 
Memory allocated:  187.97900390625
Memory cached:  220.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6610075601322807, 'log_learning_rate_D': -2.044853537323113, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.8814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  20 training error:  tensor(0.7990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  30 training error:  tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  40 training error:  tensor(0.7600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  50 training error:  tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  60 training error:  tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  70 training error:  tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  80 training error:  tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
	 epoch  90 training error:  tensor(0.6258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.03369140625
Memory cached:  176.0
[I 2023-12-05 02:11:13,308] Trial 13 finished with value: 0.5488879084587097 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6610075601322807, 'log_learning_rate_D': -2.044853537323113, 'training_batch_size': 7, 'training_p': 3}. Best is trial 11 with value: 0.509655773639679.
Time for this trial:  15.106006860733032
Memory status after this trial: 
Memory allocated:  136.38623046875
Memory cached:  180.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.9482798560366583, 'log_learning_rate_D': -1.050540582310026, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  20 training error:  tensor(0.7347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  30 training error:  tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  40 training error:  tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  50 training error:  tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  60 training error:  tensor(0.5756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  70 training error:  tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  80 training error:  tensor(0.5697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
	 epoch  90 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.82275390625
Memory cached:  176.0
[I 2023-12-05 02:11:27,847] Trial 14 finished with value: 0.5089516043663025 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.9482798560366583, 'log_learning_rate_D': -1.050540582310026, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
res:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.374374151229858
Memory status after this trial: 
Memory allocated:  27.705078125
Memory cached:  76.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.523948990165103, 'log_learning_rate_D': -2.1078614589182063, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.5681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
[I 2023-12-05 02:11:43,167] Trial 15 finished with value: 0.5101301074028015 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.523948990165103, 'log_learning_rate_D': -2.1078614589182063, 'training_batch_size': 7, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.146025657653809
Memory status after this trial: 
Memory allocated:  77.99072265625
Memory cached:  118.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.91120891131329, 'log_learning_rate_D': -3.4998251968180476, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.7580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.6536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.6495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.6489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.13232421875
Memory cached:  78.0
[I 2023-12-05 02:11:58,398] Trial 16 finished with value: 0.5928518176078796 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.91120891131329, 'log_learning_rate_D': -3.4998251968180476, 'training_batch_size': 8, 'training_p': 4}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.068156957626343
Memory status after this trial: 
Memory allocated:  67.75830078125
Memory cached:  84.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.755182971709133, 'log_learning_rate_D': -1.0935244369015682, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.8975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.8645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.8369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.8241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.8174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.8119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.13916015625
Memory cached:  76.0
[I 2023-12-05 02:12:12,961] Trial 17 finished with value: 0.7536196112632751 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.755182971709133, 'log_learning_rate_D': -1.0935244369015682, 'training_batch_size': 6, 'training_p': 4}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.415865421295166
Memory status after this trial: 
Memory allocated:  29.96337890625
Memory cached:  76.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.7040257916591846, 'log_learning_rate_D': -3.1629715174306496, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.7603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.7374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.5996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.5742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.5709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.87255859375
Memory cached:  78.0
[I 2023-12-05 02:12:28,219] Trial 18 finished with value: 0.5152827501296997 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.7040257916591846, 'log_learning_rate_D': -3.1629715174306496, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.072928190231323
Memory status after this trial: 
Memory allocated:  72.52294921875
Memory cached:  84.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.315266884202696, 'log_learning_rate_D': -1.5091906089681681, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.9571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.9394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.9229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.9075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.8933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.8799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.8673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.8553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.4228515625
Memory cached:  76.0
[I 2023-12-05 02:12:42,536] Trial 19 finished with value: 0.6918070912361145 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.315266884202696, 'log_learning_rate_D': -1.5091906089681681, 'training_batch_size': 8, 'training_p': 4}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.16611099243164
Memory status after this trial: 
Memory allocated:  42.31396484375
Memory cached:  76.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.2792611787693846, 'log_learning_rate_D': -2.069414970514173, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.6946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.5749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.341796875
Memory cached:  76.0
[I 2023-12-05 02:12:58,127] Trial 20 finished with value: 0.5090295672416687 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.2792611787693846, 'log_learning_rate_D': -2.069414970514173, 'training_batch_size': 6, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.424712181091309
Memory status after this trial: 
Memory allocated:  45.32275390625
Memory cached:  80.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.373100344626601, 'log_learning_rate_D': -1.9813635203173, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.7134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.5769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.71875
Memory cached:  76.0
[I 2023-12-05 02:13:13,905] Trial 21 finished with value: 0.5125054717063904 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.373100344626601, 'log_learning_rate_D': -1.9813635203173, 'training_batch_size': 6, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.60959267616272
Memory status after this trial: 
Memory allocated:  44.85400390625
Memory cached:  78.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.4089807646282617, 'log_learning_rate_D': -1.3941710338553828, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.8502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.7891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.7886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.83349609375
Memory cached:  76.0
[I 2023-12-05 02:13:28,004] Trial 22 finished with value: 0.7262665033340454 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.4089807646282617, 'log_learning_rate_D': -1.3941710338553828, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  13.943281888961792
Memory status after this trial: 
Memory allocated:  45.13623046875
Memory cached:  78.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.9291115949478974, 'log_learning_rate_D': -1.0581942877029558, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.7534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.7145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.6542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.74609375
Memory cached:  78.0
[I 2023-12-05 02:13:42,704] Trial 23 finished with value: 0.5106903314590454 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.9291115949478974, 'log_learning_rate_D': -1.0581942877029558, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.517581939697266
Memory status after this trial: 
Memory allocated:  52.75927734375
Memory cached:  80.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.6237674618612035, 'log_learning_rate_D': -1.7825070674561283, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.7350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.6253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.6266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.6264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.6253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.6251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.35595703125
Memory cached:  78.0
[I 2023-12-05 02:13:59,435] Trial 24 finished with value: 0.551603376865387 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.6237674618612035, 'log_learning_rate_D': -1.7825070674561283, 'training_batch_size': 6, 'training_p': 3}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  16.552788496017456
Memory status after this trial: 
Memory allocated:  76.53955078125
Memory cached:  100.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.6630954168948673, 'log_learning_rate_D': -1.4115042968471965, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.8727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.7303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.7292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.7287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.20166015625
Memory cached:  76.0
[I 2023-12-05 02:14:13,675] Trial 25 finished with value: 0.7000901699066162 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.6630954168948673, 'log_learning_rate_D': -1.4115042968471965, 'training_batch_size': 7, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.068017959594727
Memory status after this trial: 
Memory allocated:  42.54638671875
Memory cached:  84.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.267833401208848, 'log_learning_rate_D': -2.2051144464424164, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.7936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.7613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.6320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.6443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.6330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.6264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.8427734375
Memory cached:  80.0
[I 2023-12-05 02:14:29,390] Trial 26 finished with value: 0.5500080585479736 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.267833401208848, 'log_learning_rate_D': -2.2051144464424164, 'training_batch_size': 8, 'training_p': 3}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.53383469581604
Memory status after this trial: 
Memory allocated:  90.17724609375
Memory cached:  104.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.943307128447706, 'log_learning_rate_D': -1.7732445573250326, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.6715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.6036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.5718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.26513671875
Memory cached:  76.0
[I 2023-12-05 02:14:44,962] Trial 27 finished with value: 0.5169421434402466 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.943307128447706, 'log_learning_rate_D': -1.7732445573250326, 'training_batch_size': 6, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.399974584579468
Memory status after this trial: 
Memory allocated:  42.54541015625
Memory cached:  82.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.121418609223972, 'log_learning_rate_D': -1.3430046876873925, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  10 training error:  tensor(1.0075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.8293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.8522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  40 training error:  tensor(1.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.9847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.9863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.9827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.0673828125
Memory cached:  104.0
[I 2023-12-05 02:15:01,206] Trial 28 finished with value: 0.912263035774231 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.121418609223972, 'log_learning_rate_D': -1.3430046876873925, 'training_batch_size': 7, 'training_p': 4}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  16.04780626296997
Memory status after this trial: 
Memory allocated:  129.32470703125
Memory cached:  160.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5736761806218524, 'log_learning_rate_D': -2.3043723791912334, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.8444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.7269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.7256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.7248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.22998046875
Memory cached:  76.0
[I 2023-12-05 02:15:14,889] Trial 29 finished with value: 0.6965842247009277 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5736761806218524, 'log_learning_rate_D': -2.3043723791912334, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  13.502450227737427
Memory status after this trial: 
Memory allocated:  34.00927734375
Memory cached:  82.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.1578297909862423, 'log_learning_rate_D': -1.9798932530870044, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.8400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.8332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.8280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.7939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.49658203125
Memory cached:  76.0
[I 2023-12-05 02:15:29,296] Trial 30 finished with value: 0.6835616827011108 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.1578297909862423, 'log_learning_rate_D': -1.9798932530870044, 'training_batch_size': 7, 'training_p': 8}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.225619554519653
Memory status after this trial: 
Memory allocated:  51.71728515625
Memory cached:  78.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.559302596644221, 'log_learning_rate_D': -2.340386025810648, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.5907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.5848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.69775390625
Memory cached:  76.0
[I 2023-12-05 02:15:44,761] Trial 31 finished with value: 0.5108607411384583 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.559302596644221, 'log_learning_rate_D': -2.340386025810648, 'training_batch_size': 7, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  15.289568185806274
Memory status after this trial: 
Memory allocated:  77.99072265625
Memory cached:  118.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.4481459097572285, 'log_learning_rate_D': -1.3268063487985717, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.7571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.8126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.8408203125
Memory cached:  80.0
[I 2023-12-05 02:16:01,249] Trial 32 finished with value: 0.5113646388053894 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.4481459097572285, 'log_learning_rate_D': -1.3268063487985717, 'training_batch_size': 6, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  16.30360245704651
Memory status after this trial: 
Memory allocated:  73.90576171875
Memory cached:  100.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.7817842904555876, 'log_learning_rate_D': -1.6064533057739052, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.8110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.7689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.6399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.6251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.56201171875
Memory cached:  80.0
[I 2023-12-05 02:16:16,283] Trial 33 finished with value: 0.5474169850349426 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.7817842904555876, 'log_learning_rate_D': -1.6064533057739052, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.857630729675293
Memory status after this trial: 
Memory allocated:  63.51904296875
Memory cached:  82.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.0834431105668085, 'log_learning_rate_D': -2.447490331684716, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.7975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.7266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.7174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.5901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.85986328125
Memory cached:  78.0
[I 2023-12-05 02:16:31,335] Trial 34 finished with value: 0.5128881335258484 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.0834431105668085, 'log_learning_rate_D': -2.447490331684716, 'training_batch_size': 8, 'training_p': 2}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  14.870831727981567
Memory status after this trial: 
Memory allocated:  59.82568359375
Memory cached:  82.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.3788516503002324, 'log_learning_rate_D': -1.960520251553041, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.8561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  20 training error:  tensor(1.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.9157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.6550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.6250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.02978515625
Memory cached:  82.0
[I 2023-12-05 02:16:48,237] Trial 35 finished with value: 0.5540143847465515 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.3788516503002324, 'log_learning_rate_D': -1.960520251553041, 'training_batch_size': 6, 'training_p': 3}. Best is trial 14 with value: 0.5089516043663025.
Time for this trial:  16.723804235458374
Memory status after this trial: 
Memory allocated:  83.74169921875
Memory cached:  110.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.685560762688818, 'log_learning_rate_D': -2.664462898397404, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.7427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.7340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.7178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.6136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.5956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.86962890625
Memory cached:  80.0
[I 2023-12-05 02:17:03,310] Trial 36 finished with value: 0.5074478983879089 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.685560762688818, 'log_learning_rate_D': -2.664462898397404, 'training_batch_size': 10, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
res:  tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.914240837097168
Memory status after this trial: 
Memory allocated:  38.623046875
Memory cached:  84.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.869519773572385, 'log_learning_rate_D': -2.712643717259724, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.8257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.8051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.85498046875
Memory cached:  84.0
[I 2023-12-05 02:17:18,479] Trial 37 finished with value: 0.6428660154342651 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.869519773572385, 'log_learning_rate_D': -2.712643717259724, 'training_batch_size': 10, 'training_p': 5}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.005043506622314
Memory status after this trial: 
Memory allocated:  91.35888671875
Memory cached:  124.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.9358003894447933, 'log_learning_rate_D': -2.5169032909930653, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.9692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.8327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.8270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.8163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.8097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.8013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.3720703125
Memory cached:  84.0
[I 2023-12-05 02:17:33,105] Trial 38 finished with value: 0.7793613076210022 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.9358003894447933, 'log_learning_rate_D': -2.5169032909930653, 'training_batch_size': 9, 'training_p': 7}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.46814751625061
Memory status after this trial: 
Memory allocated:  68.17138671875
Memory cached:  84.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.2482114368935195, 'log_learning_rate_D': -1.249365465427947, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4716796875
Memory cached:  84.0
[I 2023-12-05 02:17:47,403] Trial 39 finished with value: 0.5506278276443481 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.2482114368935195, 'log_learning_rate_D': -1.249365465427947, 'training_batch_size': 10, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.133259534835815
Memory status after this trial: 
Memory allocated:  66.83544921875
Memory cached:  84.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2228150044615185, 'log_learning_rate_D': -1.6533596165149098, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  10 training error:  tensor(1.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.9012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.8472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.7677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.7440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.953125
Memory cached:  84.0
[I 2023-12-05 02:18:02,806] Trial 40 finished with value: 0.6928747296333313 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2228150044615185, 'log_learning_rate_D': -1.6533596165149098, 'training_batch_size': 9, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.226432085037231
Memory status after this trial: 
Memory allocated:  97.69775390625
Memory cached:  106.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.6509663757425095, 'log_learning_rate_D': -2.1855014094119656, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.6930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.7428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.6192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.5719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.38232421875
Memory cached:  104.0
[I 2023-12-05 02:18:18,251] Trial 41 finished with value: 0.5111488699913025 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.6509663757425095, 'log_learning_rate_D': -2.1855014094119656, 'training_batch_size': 12, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.273704051971436
Memory status after this trial: 
Memory allocated:  100.54638671875
Memory cached:  124.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.9582370584758335, 'log_learning_rate_D': -2.8982646268619483, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  10 training error:  tensor(5.7686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  20 training error:  tensor(1.8072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  30 training error:  tensor(5.8367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  40 training error:  tensor(5.6199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  50 training error:  tensor(1.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.52392578125
Memory cached:  84.0
[I 2023-12-05 02:18:33,642] Trial 42 finished with value: 0.6212538480758667 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.9582370584758335, 'log_learning_rate_D': -2.8982646268619483, 'training_batch_size': 10, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.212734699249268
Memory status after this trial: 
Memory allocated:  97.49755859375
Memory cached:  128.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.090940642575175, 'log_learning_rate_D': -1.826083384648469, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.24462890625
Memory cached:  84.0
[I 2023-12-05 02:18:48,403] Trial 43 finished with value: 0.5504127144813538 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.090940642575175, 'log_learning_rate_D': -1.826083384648469, 'training_batch_size': 9, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.584140539169312
Memory status after this trial: 
Memory allocated:  69.76708984375
Memory cached:  104.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.516434810590467, 'log_learning_rate_D': -2.5426191204172364, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
[I 2023-12-05 02:19:03,546] Trial 44 finished with value: 0.5099712610244751 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.516434810590467, 'log_learning_rate_D': -2.5426191204172364, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.956970930099487
Memory status after this trial: 
Memory allocated:  87.13037109375
Memory cached:  104.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.8019958035096026, 'log_learning_rate_D': -2.596526533966362, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.5185546875
Memory cached:  84.0
[I 2023-12-05 02:19:18,426] Trial 45 finished with value: 0.6735812425613403 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.8019958035096026, 'log_learning_rate_D': -2.596526533966362, 'training_batch_size': 11, 'training_p': 6}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.69169020652771
Memory status after this trial: 
Memory allocated:  81.51611328125
Memory cached:  104.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.512007658639222, 'log_learning_rate_D': -1.2005121396431475, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.40478515625
Memory cached:  84.0
[I 2023-12-05 02:19:34,048] Trial 46 finished with value: 0.5466855764389038 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.512007658639222, 'log_learning_rate_D': -1.2005121396431475, 'training_batch_size': 10, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.44618844985962
Memory status after this trial: 
Memory allocated:  102.51904296875
Memory cached:  124.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.2174982704052786, 'log_learning_rate_D': -1.0287205572837799, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1611328125
Memory cached:  84.0
[I 2023-12-05 02:19:49,141] Trial 47 finished with value: 0.5081638097763062 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.2174982704052786, 'log_learning_rate_D': -1.0287205572837799, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.910488605499268
Memory status after this trial: 
Memory allocated:  79.02587890625
Memory cached:  104.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2066129397728673, 'log_learning_rate_D': -1.0161321503656926, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.48876953125
Memory cached:  84.0
[I 2023-12-05 02:20:04,228] Trial 48 finished with value: 0.5105583071708679 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2066129397728673, 'log_learning_rate_D': -1.0161321503656926, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.907419443130493
Memory status after this trial: 
Memory allocated:  48.83251953125
Memory cached:  84.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.433055045112996, 'log_learning_rate_D': -1.225575832734427, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.7346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.4326171875
Memory cached:  84.0
[I 2023-12-05 02:20:18,966] Trial 49 finished with value: 0.5711338520050049 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.433055045112996, 'log_learning_rate_D': -1.225575832734427, 'training_batch_size': 8, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.558408260345459
Memory status after this trial: 
Memory allocated:  75.39013671875
Memory cached:  104.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.037895860393009, 'log_learning_rate_D': -1.4957775424304738, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.81103515625
Memory cached:  84.0
[I 2023-12-05 02:20:34,095] Trial 50 finished with value: 0.7041330337524414 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.037895860393009, 'log_learning_rate_D': -1.4957775424304738, 'training_batch_size': 9, 'training_p': 7}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.928420543670654
Memory status after this trial: 
Memory allocated:  75.69482421875
Memory cached:  104.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7385430852304955, 'log_learning_rate_D': -1.5311344288943127, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.0556640625
Memory cached:  84.0
[I 2023-12-05 02:20:49,228] Trial 51 finished with value: 0.5102606415748596 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7385430852304955, 'log_learning_rate_D': -1.5311344288943127, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.951573371887207
Memory status after this trial: 
Memory allocated:  85.75732421875
Memory cached:  104.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2451432475131012, 'log_learning_rate_D': -1.1745489237446587, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.63818359375
Memory cached:  84.0
[I 2023-12-05 02:21:04,533] Trial 52 finished with value: 0.5090683698654175 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2451432475131012, 'log_learning_rate_D': -1.1745489237446587, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.119244575500488
Memory status after this trial: 
Memory allocated:  85.60986328125
Memory cached:  104.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.270911049432611, 'log_learning_rate_D': -1.1591816941771849, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.52734375
Memory cached:  84.0
[I 2023-12-05 02:21:19,357] Trial 53 finished with value: 0.5128384828567505 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.270911049432611, 'log_learning_rate_D': -1.1591816941771849, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.63289499282837
Memory status after this trial: 
Memory allocated:  72.00732421875
Memory cached:  104.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5242655366047746, 'log_learning_rate_D': -1.3629285925375134, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.94189453125
Memory cached:  84.0
[I 2023-12-05 02:21:35,681] Trial 54 finished with value: 0.532230794429779 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5242655366047746, 'log_learning_rate_D': -1.3629285925375134, 'training_batch_size': 6, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.139561891555786
Memory status after this trial: 
Memory allocated:  77.08740234375
Memory cached:  104.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.7228281163341017, 'log_learning_rate_D': -1.018908332589081, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.8232421875
Memory cached:  84.0
[I 2023-12-05 02:21:51,422] Trial 55 finished with value: 0.5229849815368652 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.7228281163341017, 'log_learning_rate_D': -1.018908332589081, 'training_batch_size': 8, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.542503356933594
Memory status after this trial: 
Memory allocated:  103.86083984375
Memory cached:  124.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.9895572596932127, 'log_learning_rate_D': -1.2147658436255822, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.6861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.85498046875
Memory cached:  84.0
[I 2023-12-05 02:22:06,617] Trial 56 finished with value: 0.5100704431533813 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.9895572596932127, 'log_learning_rate_D': -1.2147658436255822, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.985441207885742
Memory status after this trial: 
Memory allocated:  90.49169921875
Memory cached:  104.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.8748361772035413, 'log_learning_rate_D': -1.4506105490929375, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.7132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.11865234375
Memory cached:  84.0
[I 2023-12-05 02:22:22,466] Trial 57 finished with value: 0.5663167834281921 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.8748361772035413, 'log_learning_rate_D': -1.4506105490929375, 'training_batch_size': 6, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.668540954589844
Memory status after this trial: 
Memory allocated:  69.99755859375
Memory cached:  84.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.374962223000744, 'log_learning_rate_D': -1.617532236699776, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.85498046875
Memory cached:  84.0
[I 2023-12-05 02:22:37,820] Trial 58 finished with value: 0.5955677032470703 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.374962223000744, 'log_learning_rate_D': -1.617532236699776, 'training_batch_size': 8, 'training_p': 4}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.144007682800293
Memory status after this trial: 
Memory allocated:  94.54736328125
Memory cached:  124.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.8685344207912813, 'log_learning_rate_D': -1.0126219170271644, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.0224609375
Memory cached:  84.0
[I 2023-12-05 02:22:52,698] Trial 59 finished with value: 0.5100829005241394 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.8685344207912813, 'log_learning_rate_D': -1.0126219170271644, 'training_batch_size': 11, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.672102928161621
Memory status after this trial: 
Memory allocated:  73.51611328125
Memory cached:  84.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.157443385322651, 'log_learning_rate_D': -1.1551816039679959, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.42724609375
Memory cached:  84.0
[I 2023-12-05 02:23:07,237] Trial 60 finished with value: 0.5477575659751892 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.157443385322651, 'log_learning_rate_D': -1.1551816039679959, 'training_batch_size': 7, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.344709873199463
Memory status after this trial: 
Memory allocated:  74.22412109375
Memory cached:  104.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.5786200681730898, 'log_learning_rate_D': -2.812623794215777, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
[I 2023-12-05 02:23:22,437] Trial 61 finished with value: 0.5099512338638306 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.5786200681730898, 'log_learning_rate_D': -2.812623794215777, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.005754947662354
Memory status after this trial: 
Memory allocated:  87.13037109375
Memory cached:  104.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.0460542621110966, 'log_learning_rate_D': -2.8543128556771755, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
[I 2023-12-05 02:23:37,687] Trial 62 finished with value: 0.5102531313896179 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.0460542621110966, 'log_learning_rate_D': -2.8543128556771755, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.049285888671875
Memory status after this trial: 
Memory allocated:  87.13037109375
Memory cached:  104.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.7051450762426352, 'log_learning_rate_D': -3.0935765349748605, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.7373046875
Memory cached:  84.0
[I 2023-12-05 02:23:52,936] Trial 63 finished with value: 0.5105605721473694 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.7051450762426352, 'log_learning_rate_D': -3.0935765349748605, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.050612211227417
Memory status after this trial: 
Memory allocated:  84.38525390625
Memory cached:  124.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3613817952699585, 'log_learning_rate_D': -1.3309873911655894, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.083984375
Memory cached:  84.0
[I 2023-12-05 02:24:07,712] Trial 64 finished with value: 0.5164069533348083 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3613817952699585, 'log_learning_rate_D': -1.3309873911655894, 'training_batch_size': 8, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.602637767791748
Memory status after this trial: 
Memory allocated:  72.17626953125
Memory cached:  104.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5968738411721857, 'log_learning_rate_D': -1.8170132759444024, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.705078125
Memory cached:  84.0
[I 2023-12-05 02:24:24,532] Trial 65 finished with value: 0.5154817700386047 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5968738411721857, 'log_learning_rate_D': -1.8170132759444024, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.621240615844727
Memory status after this trial: 
Memory allocated:  99.98095703125
Memory cached:  124.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9500747531199822, 'log_learning_rate_D': -1.4451590811580912, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.20263671875
Memory cached:  84.0
[I 2023-12-05 02:24:38,964] Trial 66 finished with value: 0.5112661719322205 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9500747531199822, 'log_learning_rate_D': -1.4451590811580912, 'training_batch_size': 9, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.250662088394165
Memory status after this trial: 
Memory allocated:  64.83154296875
Memory cached:  104.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2710184993471696, 'log_learning_rate_D': -1.1005050462198667, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.671875
Memory cached:  84.0
[I 2023-12-05 02:24:53,461] Trial 67 finished with value: 0.6774205565452576 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2710184993471696, 'log_learning_rate_D': -1.1005050462198667, 'training_batch_size': 7, 'training_p': 6}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.322933197021484
Memory status after this trial: 
Memory allocated:  71.77099609375
Memory cached:  104.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8087970733014505, 'log_learning_rate_D': -1.2569187394260568, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.7205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.44384765625
Memory cached:  84.0
[I 2023-12-05 02:25:07,603] Trial 68 finished with value: 0.5336064696311951 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8087970733014505, 'log_learning_rate_D': -1.2569187394260568, 'training_batch_size': 8, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  13.967675685882568
Memory status after this trial: 
Memory allocated:  55.10205078125
Memory cached:  84.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.6515323706339706, 'log_learning_rate_D': -1.5492405811405028, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.8174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.7005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.6063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.5719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.5709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.92724609375
Memory cached:  88.0
[I 2023-12-05 02:25:24,614] Trial 69 finished with value: 0.5092865824699402 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.6515323706339706, 'log_learning_rate_D': -1.5492405811405028, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.79588031768799
Memory status after this trial: 
Memory allocated:  113.62744140625
Memory cached:  146.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.158006600705978, 'log_learning_rate_D': -1.57679959061869, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.8335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.6629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.6674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.6740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.61328125
Memory cached:  104.0
[I 2023-12-05 02:25:41,820] Trial 70 finished with value: 0.6252231001853943 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.158006600705978, 'log_learning_rate_D': -1.57679959061869, 'training_batch_size': 6, 'training_p': 5}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  17.00160241127014
Memory status after this trial: 
Memory allocated:  136.72021484375
Memory cached:  186.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.4343691603556934, 'log_learning_rate_D': -1.1383598896872353, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  10 training error:  tensor(1.0186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.7632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.6919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.5767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.87890625
Memory cached:  104.0
[I 2023-12-05 02:25:59,116] Trial 71 finished with value: 0.5107947587966919 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.4343691603556934, 'log_learning_rate_D': -1.1383598896872353, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  17.08391785621643
Memory status after this trial: 
Memory allocated:  110.37353515625
Memory cached:  144.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.651386084586627, 'log_learning_rate_D': -1.3467479413828887, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.6855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.09765625
Memory cached:  84.0
[I 2023-12-05 02:26:14,712] Trial 72 finished with value: 0.5107506513595581 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.651386084586627, 'log_learning_rate_D': -1.3467479413828887, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.403971433639526
Memory status after this trial: 
Memory allocated:  55.19384765625
Memory cached:  84.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.9250354059752954, 'log_learning_rate_D': -1.698501438029396, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.7197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.22802734375
Memory cached:  84.0
[I 2023-12-05 02:26:29,473] Trial 73 finished with value: 0.6692016124725342 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.9250354059752954, 'log_learning_rate_D': -1.698501438029396, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.553999662399292
Memory status after this trial: 
Memory allocated:  70.19580078125
Memory cached:  84.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.5739482019374984, 'log_learning_rate_D': -1.0009632074901997, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.14013671875
Memory cached:  84.0
[I 2023-12-05 02:26:45,858] Trial 74 finished with value: 0.513081967830658 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.5739482019374984, 'log_learning_rate_D': -1.0009632074901997, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.17834186553955
Memory status after this trial: 
Memory allocated:  68.55712890625
Memory cached:  84.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.799912909093102, 'log_learning_rate_D': -1.5001868677684236, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.8080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.3154296875
Memory cached:  84.0
[I 2023-12-05 02:27:01,307] Trial 75 finished with value: 0.5500048995018005 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.799912909093102, 'log_learning_rate_D': -1.5001868677684236, 'training_batch_size': 7, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.241933584213257
Memory status after this trial: 
Memory allocated:  108.38525390625
Memory cached:  144.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.103800012705369, 'log_learning_rate_D': -1.3267495984778939, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.19873046875
Memory cached:  84.0
[I 2023-12-05 02:27:15,855] Trial 76 finished with value: 0.5122982859611511 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.103800012705369, 'log_learning_rate_D': -1.3267495984778939, 'training_batch_size': 12, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.3553626537323
Memory status after this trial: 
Memory allocated:  63.00146484375
Memory cached:  84.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.444815634674141, 'log_learning_rate_D': -1.1140309468998217, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.7195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.7117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.2685546875
Memory cached:  84.0
[I 2023-12-05 02:27:30,757] Trial 77 finished with value: 0.5235640406608582 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.444815634674141, 'log_learning_rate_D': -1.1140309468998217, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.725208044052124
Memory status after this trial: 
Memory allocated:  80.21142578125
Memory cached:  104.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.9907954956883183, 'log_learning_rate_D': -2.688271305491408, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  20 training error:  tensor(0.7393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  30 training error:  tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  40 training error:  tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  50 training error:  tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  60 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  70 training error:  tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  80 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
	 epoch  90 training error:  tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.90771484375
Memory cached:  124.0
[I 2023-12-05 02:27:48,568] Trial 78 finished with value: 0.5151575207710266 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.9907954956883183, 'log_learning_rate_D': -2.688271305491408, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  17.575913190841675
Memory status after this trial: 
Memory allocated:  157.55419921875
Memory cached:  204.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.323926364086189, 'log_learning_rate_D': -1.876009065298412, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  10 training error:  tensor(1.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  20 training error:  tensor(0.7688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  30 training error:  tensor(0.7802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  40 training error:  tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  50 training error:  tensor(0.6300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  60 training error:  tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  70 training error:  tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  80 training error:  tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
	 epoch  90 training error:  tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.927734375
Memory cached:  104.0
[I 2023-12-05 02:28:03,594] Trial 79 finished with value: 0.5477492213249207 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.323926364086189, 'log_learning_rate_D': -1.876009065298412, 'training_batch_size': 8, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.838351249694824
Memory status after this trial: 
Memory allocated:  98.60302734375
Memory cached:  124.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.321425104740886, 'log_learning_rate_D': -1.6967714326699792, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6123046875
Memory cached:  84.0
[I 2023-12-05 02:28:19,792] Trial 80 finished with value: 0.5114699602127075 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.321425104740886, 'log_learning_rate_D': -1.6967714326699792, 'training_batch_size': 6, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.02159333229065
Memory status after this trial: 
Memory allocated:  75.62255859375
Memory cached:  84.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.486242358142994, 'log_learning_rate_D': -2.074883616563585, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.54345703125
Memory cached:  84.0
[I 2023-12-05 02:28:34,871] Trial 81 finished with value: 0.5108283758163452 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.486242358142994, 'log_learning_rate_D': -2.074883616563585, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.892461776733398
Memory status after this trial: 
Memory allocated:  87.13037109375
Memory cached:  104.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.5726865897270974, 'log_learning_rate_D': -2.4150451557339165, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79345703125
Memory cached:  84.0
[I 2023-12-05 02:28:50,007] Trial 82 finished with value: 0.5106990933418274 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.5726865897270974, 'log_learning_rate_D': -2.4150451557339165, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.9464750289917
Memory status after this trial: 
Memory allocated:  89.22021484375
Memory cached:  104.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.6930631783940506, 'log_learning_rate_D': -2.548795134704401, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.8439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.88134765625
Memory cached:  84.0
[I 2023-12-05 02:29:05,336] Trial 83 finished with value: 0.5104088187217712 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.6930631783940506, 'log_learning_rate_D': -2.548795134704401, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.12891674041748
Memory status after this trial: 
Memory allocated:  103.41650390625
Memory cached:  124.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5436173936717585, 'log_learning_rate_D': -2.8197763647130363, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.6150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.36767578125
Memory cached:  84.0
[I 2023-12-05 02:29:20,609] Trial 84 finished with value: 0.5106945037841797 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5436173936717585, 'log_learning_rate_D': -2.8197763647130363, 'training_batch_size': 8, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  15.07535719871521
Memory status after this trial: 
Memory allocated:  86.35009765625
Memory cached:  104.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.853592923296385, 'log_learning_rate_D': -2.2985633603735236, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.18017578125
Memory cached:  84.0
[I 2023-12-05 02:29:35,731] Trial 85 finished with value: 0.5195521116256714 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.853592923296385, 'log_learning_rate_D': -2.2985633603735236, 'training_batch_size': 7, 'training_p': 2}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  14.915595769882202
Memory status after this trial: 
Memory allocated:  94.35986328125
Memory cached:  124.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.1851167599262173, 'log_learning_rate_D': -2.6184322735148924, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.6426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.31787109375
Memory cached:  84.0
[I 2023-12-05 02:29:52,101] Trial 86 finished with value: 0.5116590857505798 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.1851167599262173, 'log_learning_rate_D': -2.6184322735148924, 'training_batch_size': 6, 'training_p': 3}. Best is trial 36 with value: 0.5074478983879089.
Time for this trial:  16.168755531311035
Memory status after this trial: 
Memory allocated:  81.89111328125
Memory cached:  104.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7353346159263765, 'log_learning_rate_D': -1.2927245360209718, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.7245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.6766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.28173828125
Memory cached:  84.0
[I 2023-12-05 02:30:07,701] Trial 87 finished with value: 0.5046098232269287 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7353346159263765, 'log_learning_rate_D': -1.2927245360209718, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
res:  tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.396363258361816
Memory status after this trial: 
Memory allocated:  49.978515625
Memory cached:  82.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.764180211008945, 'log_learning_rate_D': -1.2230016908546224, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.8107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.83740234375
Memory cached:  82.0
[I 2023-12-05 02:30:23,301] Trial 88 finished with value: 0.5225450396537781 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.764180211008945, 'log_learning_rate_D': -1.2230016908546224, 'training_batch_size': 8, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.420129537582397
Memory status after this trial: 
Memory allocated:  96.35107421875
Memory cached:  124.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.0020887027845267, 'log_learning_rate_D': -1.2841175669177132, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.8151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.6281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.6257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.6254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1025390625
Memory cached:  82.0
[I 2023-12-05 02:30:38,513] Trial 89 finished with value: 0.5410823225975037 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.0020887027845267, 'log_learning_rate_D': -1.2841175669177132, 'training_batch_size': 10, 'training_p': 3}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  14.992197513580322
Memory status after this trial: 
Memory allocated:  99.45947265625
Memory cached:  122.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.88139798946873, 'log_learning_rate_D': -1.4273889662036652, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.7165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.6853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.6139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.642578125
Memory cached:  82.0
[I 2023-12-05 02:30:53,320] Trial 90 finished with value: 0.5769079327583313 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.88139798946873, 'log_learning_rate_D': -1.4273889662036652, 'training_batch_size': 9, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  14.599826097488403
Memory status after this trial: 
Memory allocated:  80.80419921875
Memory cached:  102.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.3909650623056677, 'log_learning_rate_D': -1.1209783221313367, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.6837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.83056640625
Memory cached:  82.0
[I 2023-12-05 02:31:08,231] Trial 91 finished with value: 0.5108636021614075 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.3909650623056677, 'log_learning_rate_D': -1.1209783221313367, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  14.723150730133057
Memory status after this trial: 
Memory allocated:  86.95166015625
Memory cached:  102.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.626831452745676, 'log_learning_rate_D': -2.767532355318876, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.7850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91845703125
Memory cached:  84.0
[I 2023-12-05 02:31:23,646] Trial 92 finished with value: 0.5096511840820312 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.626831452745676, 'log_learning_rate_D': -2.767532355318876, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.20028805732727
Memory status after this trial: 
Memory allocated:  115.36669921875
Memory cached:  144.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7407108683795403, 'log_learning_rate_D': -2.9158697285525337, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  86.0
	 epoch  10 training error:  tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.7217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.6937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.28173828125
Memory cached:  86.0
[I 2023-12-05 02:31:39,317] Trial 93 finished with value: 0.5106528401374817 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7407108683795403, 'log_learning_rate_D': -2.9158697285525337, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.459106206893921
Memory status after this trial: 
Memory allocated:  116.28076171875
Memory cached:  146.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.6615335718036737, 'log_learning_rate_D': -2.7173839434841796, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.5901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.3798828125
Memory cached:  82.0
[I 2023-12-05 02:31:54,798] Trial 94 finished with value: 0.507122814655304 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.6615335718036737, 'log_learning_rate_D': -2.7173839434841796, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.262165069580078
Memory status after this trial: 
Memory allocated:  110.90478515625
Memory cached:  142.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.664509343650408, 'log_learning_rate_D': -1.0781904221988525, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.6324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.091796875
Memory cached:  82.0
[I 2023-12-05 02:32:11,585] Trial 95 finished with value: 0.5120376348495483 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.664509343650408, 'log_learning_rate_D': -1.0781904221988525, 'training_batch_size': 6, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  16.57327961921692
Memory status after this trial: 
Memory allocated:  109.52490234375
Memory cached:  142.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.0624162851749888, 'log_learning_rate_D': -1.3877588149505973, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.6863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.9189453125
Memory cached:  82.0
[I 2023-12-05 02:32:26,746] Trial 96 finished with value: 0.5113324522972107 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.0624162851749888, 'log_learning_rate_D': -1.3877588149505973, 'training_batch_size': 7, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  14.957031726837158
Memory status after this trial: 
Memory allocated:  110.97216796875
Memory cached:  142.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.2367972199944486, 'log_learning_rate_D': -1.566094729827904, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.7515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.7357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.7291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.7248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.7063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.21826171875
Memory cached:  102.0
[I 2023-12-05 02:32:42,735] Trial 97 finished with value: 0.7202398180961609 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.2367972199944486, 'log_learning_rate_D': -1.566094729827904, 'training_batch_size': 8, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.76684832572937
Memory status after this trial: 
Memory allocated:  108.14990234375
Memory cached:  142.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.916500178556257, 'log_learning_rate_D': -1.2242653937966603, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.8060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.7403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.6286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.4453125
Memory cached:  82.0
[I 2023-12-05 02:32:58,065] Trial 98 finished with value: 0.5497104525566101 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.916500178556257, 'log_learning_rate_D': -1.2242653937966603, 'training_batch_size': 7, 'training_p': 3}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  15.120330572128296
Memory status after this trial: 
Memory allocated:  107.69873046875
Memory cached:  144.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.462877341226877, 'log_learning_rate_D': -2.736603248728458, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.7292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.7254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.7124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.5766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.20361328125
Memory cached:  82.0
[I 2023-12-05 02:33:15,308] Trial 99 finished with value: 0.5112863779067993 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.462877341226877, 'log_learning_rate_D': -2.736603248728458, 'training_batch_size': 6, 'training_p': 2}. Best is trial 87 with value: 0.5046098232269287.
Time for this trial:  17.01585626602173
Memory status after this trial: 
Memory allocated:  105.19873046875
Memory cached:  124.0
