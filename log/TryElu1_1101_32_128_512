/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-11-02 16:24:04,103] A new study created in memory with name: no-name-0ce23966-6a5c-44b5-abc0-7af99330e18a
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.82096493749795, 'log_learning_rate_D': -3.686126472740602, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.380859375
Memory cached:  26.0
[I 2023-11-02 16:27:23,085] Trial 0 finished with value: 0.2468709945678711 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.82096493749795, 'log_learning_rate_D': -3.686126472740602, 'training_batch_size': 9, 'training_p': 7}. Best is trial 0 with value: 0.2468709945678711.
Time for this trial:  198.86719799041748
Memory status after this trial: 
Memory allocated:  287.6533203125
Memory cached:  294.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.709644331208496, 'log_learning_rate_D': -2.8788571778182477, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.8464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.6173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.0859375
Memory cached:  42.0
[I 2023-11-02 16:29:59,223] Trial 1 finished with value: 0.2465296983718872 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.709644331208496, 'log_learning_rate_D': -2.8788571778182477, 'training_batch_size': 7, 'training_p': 3}. Best is trial 1 with value: 0.2465296983718872.
Time for this trial:  156.00028228759766
Memory status after this trial: 
Memory allocated:  157.09326171875
Memory cached:  178.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.200842150044968, 'log_learning_rate_D': -4.966933869431607, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.7007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.80859375
Memory cached:  12.0
[I 2023-11-02 16:31:36,486] Trial 2 finished with value: 0.2464831918478012 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.200842150044968, 'log_learning_rate_D': -4.966933869431607, 'training_batch_size': 10, 'training_p': 7}. Best is trial 2 with value: 0.2464831918478012.
Time for this trial:  97.13293409347534
Memory status after this trial: 
Memory allocated:  28.78759765625
Memory cached:  30.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.4047088714764753, 'log_learning_rate_D': -4.752035694789211, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  16.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  22.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  22.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  22.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  24.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  22.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  24.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  22.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7109375
Memory cached:  24.0
[I 2023-11-02 16:34:02,941] Trial 3 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.4047088714764753, 'log_learning_rate_D': -4.752035694789211, 'training_batch_size': 7, 'training_p': 5}. Best is trial 2 with value: 0.2464831918478012.
Time for this trial:  146.3531379699707
Memory status after this trial: 
Memory allocated:  174.05712890625
Memory cached:  180.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.366604941690795, 'log_learning_rate_D': -4.679080212396928, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.8934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.8666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.8347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.7981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1484375
Memory cached:  14.0
[I 2023-11-02 16:36:21,159] Trial 4 finished with value: 0.7253829836845398 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.366604941690795, 'log_learning_rate_D': -4.679080212396928, 'training_batch_size': 12, 'training_p': 5}. Best is trial 2 with value: 0.2464831918478012.
Time for this trial:  138.06203317642212
Memory status after this trial: 
Memory allocated:  92.35498046875
Memory cached:  94.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.950291726412788, 'log_learning_rate_D': -2.4676427786281367, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.9908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.9891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.98828125
Memory cached:  18.0
[I 2023-11-02 16:39:03,168] Trial 5 finished with value: 0.9799526333808899 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.950291726412788, 'log_learning_rate_D': -2.4676427786281367, 'training_batch_size': 7, 'training_p': 4}. Best is trial 2 with value: 0.2464831918478012.
Time for this trial:  161.85455560684204
Memory status after this trial: 
Memory allocated:  143.478515625
Memory cached:  150.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.553267588823152, 'log_learning_rate_D': -4.576771400464104, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.6219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7568359375
Memory cached:  20.0
[I 2023-11-02 16:43:42,142] Trial 6 finished with value: 0.24668271839618683 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.553267588823152, 'log_learning_rate_D': -4.576771400464104, 'training_batch_size': 6, 'training_p': 5}. Best is trial 2 with value: 0.2464831918478012.
Time for this trial:  278.8306043148041
Memory status after this trial: 
Memory allocated:  154.427734375
Memory cached:  160.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.6201735024753114, 'log_learning_rate_D': -1.9483105285904867, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.501953125
Memory cached:  26.0
[I 2023-11-02 16:46:21,204] Trial 7 finished with value: 0.24504585564136505 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.6201735024753114, 'log_learning_rate_D': -1.9483105285904867, 'training_batch_size': 11, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  158.92574334144592
Memory status after this trial: 
Memory allocated:  94.4306640625
Memory cached:  98.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.3184580427587766, 'log_learning_rate_D': -1.3874513256838448, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.587890625
Memory cached:  34.0
[I 2023-11-02 16:48:57,289] Trial 8 finished with value: 0.24613909423351288 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.3184580427587766, 'log_learning_rate_D': -1.3874513256838448, 'training_batch_size': 8, 'training_p': 8}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  155.94412899017334
Memory status after this trial: 
Memory allocated:  185.65234375
Memory cached:  190.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.331244241582642, 'log_learning_rate_D': -2.493581407443177, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.7183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1396484375
Memory cached:  30.0
[I 2023-11-02 16:52:13,420] Trial 9 finished with value: 0.24603906273841858 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.331244241582642, 'log_learning_rate_D': -2.493581407443177, 'training_batch_size': 6, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  195.9632806777954
Memory status after this trial: 
Memory allocated:  106.69091796875
Memory cached:  124.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.4449330591163987, 'log_learning_rate_D': -1.118312241464678, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.7986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  54.0
	 epoch  20 training error:  tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  30 training error:  tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  40 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.98828125
Memory cached:  52.0
[I 2023-11-02 16:55:28,034] Trial 10 finished with value: 0.24606290459632874 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.4449330591163987, 'log_learning_rate_D': -1.118312241464678, 'training_batch_size': 12, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  194.4136254787445
Memory status after this trial: 
Memory allocated:  284.36865234375
Memory cached:  304.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.3817235512388306, 'log_learning_rate_D': -1.9767352786410455, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1640625
Memory cached:  14.0
[I 2023-11-02 16:57:53,415] Trial 11 finished with value: 0.2461363822221756 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.3817235512388306, 'log_learning_rate_D': -1.9767352786410455, 'training_batch_size': 10, 'training_p': 2}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  145.18791699409485
Memory status after this trial: 
Memory allocated:  171.01220703125
Memory cached:  174.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.2340359787000574, 'log_learning_rate_D': -2.078733634171608, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.76953125
Memory cached:  14.0
[I 2023-11-02 16:59:49,593] Trial 12 finished with value: 0.24635489284992218 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.2340359787000574, 'log_learning_rate_D': -2.078733634171608, 'training_batch_size': 11, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  115.9912223815918
Memory status after this trial: 
Memory allocated:  53.01708984375
Memory cached:  56.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.8742826839261193, 'log_learning_rate_D': -3.147974505349912, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.388671875
Memory cached:  12.0
[I 2023-11-02 17:01:44,538] Trial 13 finished with value: 0.2464338093996048 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.8742826839261193, 'log_learning_rate_D': -3.147974505349912, 'training_batch_size': 9, 'training_p': 3}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  114.77150654792786
Memory status after this trial: 
Memory allocated:  93.9208984375
Memory cached:  96.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -1.8431247076243111, 'log_learning_rate_D': -1.6492721512834572, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  44.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  54.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  50.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  50.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.720703125
Memory cached:  52.0
[I 2023-11-02 17:04:43,062] Trial 14 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -1.8431247076243111, 'log_learning_rate_D': -1.6492721512834572, 'training_batch_size': 11, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  178.3317530155182
Memory status after this trial: 
Memory allocated:  288.8701171875
Memory cached:  310.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.673812352288106, 'log_learning_rate_D': -2.3286651226241726, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  20.0
[I 2023-11-02 17:08:27,725] Trial 15 finished with value: 0.2462015450000763 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.673812352288106, 'log_learning_rate_D': -2.3286651226241726, 'training_batch_size': 6, 'training_p': 8}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  224.46561193466187
Memory status after this trial: 
Memory allocated:  88.98193359375
Memory cached:  92.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.8712663846644335, 'log_learning_rate_D': -1.0247795797025074, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  18.0
[I 2023-11-02 17:11:08,188] Trial 16 finished with value: 0.24611687660217285 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.8712663846644335, 'log_learning_rate_D': -1.0247795797025074, 'training_batch_size': 10, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  160.26282477378845
Memory status after this trial: 
Memory allocated:  115.44580078125
Memory cached:  118.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.447807927051287, 'log_learning_rate_D': -1.7843327455307436, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  18.0
[I 2023-11-02 17:12:58,974] Trial 17 finished with value: 0.24641911685466766 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.447807927051287, 'log_learning_rate_D': -1.7843327455307436, 'training_batch_size': 8, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  110.57554197311401
Memory status after this trial: 
Memory allocated:  94.19140625
Memory cached:  96.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.158195756429733, 'log_learning_rate_D': -2.6586228846098012, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.8830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.8061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56640625
Memory cached:  14.0
[I 2023-11-02 17:14:54,009] Trial 18 finished with value: 0.2490597516298294 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.158195756429733, 'log_learning_rate_D': -2.6586228846098012, 'training_batch_size': 11, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  114.86355757713318
Memory status after this trial: 
Memory allocated:  64.478515625
Memory cached:  68.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.1147553813888589, 'log_learning_rate_D': -1.5466566730931186, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  22.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  30.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  28.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  30.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  28.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  28.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  30.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  28.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  28.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.966796875
Memory cached:  30.0
[I 2023-11-02 17:17:58,502] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.1147553813888589, 'log_learning_rate_D': -1.5466566730931186, 'training_batch_size': 8, 'training_p': 2}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  184.2506935596466
Memory status after this trial: 
Memory allocated:  251.78662109375
Memory cached:  260.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.784160674846935, 'log_learning_rate_D': -2.094961226619262, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.9303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.9030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.8871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.8685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.8482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.546875
Memory cached:  20.0
[I 2023-11-02 17:20:45,827] Trial 20 finished with value: 0.8144745230674744 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.784160674846935, 'log_learning_rate_D': -2.094961226619262, 'training_batch_size': 12, 'training_p': 3}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  167.09527277946472
Memory status after this trial: 
Memory allocated:  126.94580078125
Memory cached:  130.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.3527984343568376, 'log_learning_rate_D': -1.073102812702762, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.9503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  20 training error:  tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  30 training error:  tensor(0.3485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  40 training error:  tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9296875
Memory cached:  52.0
[I 2023-11-02 17:24:00,103] Trial 21 finished with value: 0.2472655326128006 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.3527984343568376, 'log_learning_rate_D': -1.073102812702762, 'training_batch_size': 12, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  194.0396604537964
Memory status after this trial: 
Memory allocated:  293.798828125
Memory cached:  314.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.525488921494311, 'log_learning_rate_D': -1.3783964457462092, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  50 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  70 training error:  tensor(1.5505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  80 training error:  tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
	 epoch  90 training error:  tensor(0.3256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.365234375
Memory cached:  64.0
[I 2023-11-02 17:27:14,748] Trial 22 finished with value: 0.255536824464798 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.525488921494311, 'log_learning_rate_D': -1.3783964457462092, 'training_batch_size': 11, 'training_p': 8}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  194.38814568519592
Memory status after this trial: 
Memory allocated:  304.22998046875
Memory cached:  318.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.989413030482892, 'log_learning_rate_D': -1.711335856547302, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  18.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.033203125
Memory cached:  24.0
[I 2023-11-02 17:30:12,398] Trial 23 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.989413030482892, 'log_learning_rate_D': -1.711335856547302, 'training_batch_size': 12, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  177.3854742050171
Memory status after this trial: 
Memory allocated:  145.66943359375
Memory cached:  150.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.794106998289202, 'log_learning_rate_D': -2.2430367495959866, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.5078125
Memory cached:  62.0
[I 2023-11-02 17:33:04,414] Trial 24 finished with value: 0.24624624848365784 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.794106998289202, 'log_learning_rate_D': -2.2430367495959866, 'training_batch_size': 10, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  171.77355980873108
Memory status after this trial: 
Memory allocated:  240.18310546875
Memory cached:  252.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.960027131440936, 'log_learning_rate_D': -1.890468806465016, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.78515625
Memory cached:  22.0
[I 2023-11-02 17:35:56,239] Trial 25 finished with value: 0.246003657579422 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.960027131440936, 'log_learning_rate_D': -1.890468806465016, 'training_batch_size': 11, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  171.5908546447754
Memory status after this trial: 
Memory allocated:  171.740234375
Memory cached:  178.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2179653109068296, 'log_learning_rate_D': -2.503915043910191, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.34375
Memory cached:  22.0
[I 2023-11-02 17:38:46,248] Trial 26 finished with value: 0.24647365510463715 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2179653109068296, 'log_learning_rate_D': -2.503915043910191, 'training_batch_size': 9, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  169.76972436904907
Memory status after this trial: 
Memory allocated:  156.79833984375
Memory cached:  162.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.097139119097653, 'log_learning_rate_D': -1.9710732452441875, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.4901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.60546875
Memory cached:  18.0
[I 2023-11-02 17:41:33,590] Trial 27 finished with value: 0.2460279017686844 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.097139119097653, 'log_learning_rate_D': -1.9710732452441875, 'training_batch_size': 11, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  167.08041191101074
Memory status after this trial: 
Memory allocated:  128.31201171875
Memory cached:  134.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.0568231113134874, 'log_learning_rate_D': -1.8785547584989855, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.6292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.69921875
Memory cached:  18.0
[I 2023-11-02 17:44:21,818] Trial 28 finished with value: 0.24630723893642426 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.0568231113134874, 'log_learning_rate_D': -1.8785547584989855, 'training_batch_size': 11, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  167.98523545265198
Memory status after this trial: 
Memory allocated:  130.05078125
Memory cached:  134.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9079101073560145, 'log_learning_rate_D': -1.8985631061196078, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.146484375
Memory cached:  22.0
[I 2023-11-02 17:47:23,132] Trial 29 finished with value: 0.24630723893642426 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9079101073560145, 'log_learning_rate_D': -1.8985631061196078, 'training_batch_size': 10, 'training_p': 8}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  181.06550931930542
Memory status after this trial: 
Memory allocated:  168.677734375
Memory cached:  174.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.63438819457701, 'log_learning_rate_D': -2.189705403620144, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.947265625
Memory cached:  40.0
[I 2023-11-02 17:50:35,847] Trial 30 finished with value: 0.2462967485189438 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.63438819457701, 'log_learning_rate_D': -2.189705403620144, 'training_batch_size': 11, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  192.45984649658203
Memory status after this trial: 
Memory allocated:  206.119140625
Memory cached:  220.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.4497699795588863, 'log_learning_rate_D': -2.7699531649930327, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.5595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9765625
Memory cached:  20.0
[I 2023-11-02 17:53:23,087] Trial 31 finished with value: 0.24631844460964203 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.4497699795588863, 'log_learning_rate_D': -2.7699531649930327, 'training_batch_size': 9, 'training_p': 7}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  166.99012756347656
Memory status after this trial: 
Memory allocated:  108.16015625
Memory cached:  112.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.8578898302303557, 'log_learning_rate_D': -2.3986197872525836, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.7823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.609375
Memory cached:  20.0
[I 2023-11-02 17:55:55,938] Trial 32 finished with value: 0.24621379375457764 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.8578898302303557, 'log_learning_rate_D': -2.3986197872525836, 'training_batch_size': 11, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  152.62714910507202
Memory status after this trial: 
Memory allocated:  117.18212890625
Memory cached:  120.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.09327988058344, 'log_learning_rate_D': -2.9375921068158464, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.666015625
Memory cached:  20.0
[I 2023-11-02 17:58:17,127] Trial 33 finished with value: 0.2465403527021408 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.09327988058344, 'log_learning_rate_D': -2.9375921068158464, 'training_batch_size': 10, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  140.9745967388153
Memory status after this trial: 
Memory allocated:  75.68798828125
Memory cached:  78.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7139656460102772, 'log_learning_rate_D': -3.1887880528083175, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  22.0
[I 2023-11-02 18:01:06,491] Trial 34 finished with value: 0.24645185470581055 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7139656460102772, 'log_learning_rate_D': -3.1887880528083175, 'training_batch_size': 10, 'training_p': 6}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  169.12682271003723
Memory status after this trial: 
Memory allocated:  186.18701171875
Memory cached:  192.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.0019989303782584, 'log_learning_rate_D': -2.044307462170566, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.365234375
Memory cached:  16.0
[I 2023-11-02 18:03:16,242] Trial 35 finished with value: 0.2462993860244751 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.0019989303782584, 'log_learning_rate_D': -2.044307462170566, 'training_batch_size': 7, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  129.53131747245789
Memory status after this trial: 
Memory allocated:  104.76416015625
Memory cached:  108.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.5181775522236522, 'log_learning_rate_D': -2.663361974363324, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.5362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.75
Memory cached:  12.0
[I 2023-11-02 18:05:12,234] Trial 36 finished with value: 0.2462436705827713 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.5181775522236522, 'log_learning_rate_D': -2.663361974363324, 'training_batch_size': 12, 'training_p': 8}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  115.7813766002655
Memory status after this trial: 
Memory allocated:  48.02294921875
Memory cached:  50.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.180007295052173, 'log_learning_rate_D': -1.8235794837112287, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.9814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.9445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.8616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.6736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.052734375
Memory cached:  26.0
[I 2023-11-02 18:08:05,023] Trial 37 finished with value: 0.24568696320056915 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.180007295052173, 'log_learning_rate_D': -1.8235794837112287, 'training_batch_size': 11, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  172.54752135276794
Memory status after this trial: 
Memory allocated:  158.85693359375
Memory cached:  162.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.9333429467643652, 'log_learning_rate_D': -1.5670350201794991, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7265625
Memory cached:  18.0
[I 2023-11-02 18:10:51,409] Trial 38 finished with value: 0.24574995040893555 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.9333429467643652, 'log_learning_rate_D': -1.5670350201794991, 'training_batch_size': 11, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  166.14506268501282
Memory status after this trial: 
Memory allocated:  109.12890625
Memory cached:  112.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.018882184182523, 'log_learning_rate_D': -1.554163010780813, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.9688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.8727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.759765625
Memory cached:  22.0
[I 2023-11-02 18:13:40,095] Trial 39 finished with value: 0.24680383503437042 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.018882184182523, 'log_learning_rate_D': -1.554163010780813, 'training_batch_size': 12, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  168.42583012580872
Memory status after this trial: 
Memory allocated:  123.1806640625
Memory cached:  126.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.502379117099405, 'log_learning_rate_D': -1.3330767562358983, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.9200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.8522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  22.0
[I 2023-11-02 18:16:27,702] Trial 40 finished with value: 0.245212584733963 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.502379117099405, 'log_learning_rate_D': -1.3330767562358983, 'training_batch_size': 9, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  167.34900045394897
Memory status after this trial: 
Memory allocated:  116.2119140625
Memory cached:  120.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.566057986556521, 'log_learning_rate_D': -1.3830910041148476, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.9588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.8641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.7725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.220703125
Memory cached:  18.0
[I 2023-11-02 18:19:15,639] Trial 41 finished with value: 0.2482372373342514 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.566057986556521, 'log_learning_rate_D': -1.3830910041148476, 'training_batch_size': 9, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  167.6761384010315
Memory status after this trial: 
Memory allocated:  116.2119140625
Memory cached:  120.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.285094677660665, 'log_learning_rate_D': -1.2513699105994343, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.9465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.8673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.7073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.4061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.380859375
Memory cached:  22.0
[I 2023-11-02 18:22:05,113] Trial 42 finished with value: 0.24518845975399017 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.285094677660665, 'log_learning_rate_D': -1.2513699105994343, 'training_batch_size': 8, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  169.19968128204346
Memory status after this trial: 
Memory allocated:  128.13525390625
Memory cached:  132.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.358225072202605, 'log_learning_rate_D': -1.20883572624225, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.8587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.634765625
Memory cached:  22.0
[I 2023-11-02 18:24:58,918] Trial 43 finished with value: 0.24687448143959045 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.358225072202605, 'log_learning_rate_D': -1.20883572624225, 'training_batch_size': 8, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  173.52758312225342
Memory status after this trial: 
Memory allocated:  166.47509765625
Memory cached:  170.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.167433139037378, 'log_learning_rate_D': -1.24272928590232, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.8293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.9928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.58984375
Memory cached:  20.0
[I 2023-11-02 18:27:36,931] Trial 44 finished with value: 0.24747078120708466 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.167433139037378, 'log_learning_rate_D': -1.24272928590232, 'training_batch_size': 8, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  157.75719928741455
Memory status after this trial: 
Memory allocated:  94.25634765625
Memory cached:  96.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.573149320031159, 'log_learning_rate_D': -1.5108464577144927, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.8369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.6961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.95703125
Memory cached:  22.0
[I 2023-11-02 18:30:34,121] Trial 45 finished with value: 0.246246337890625 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.573149320031159, 'log_learning_rate_D': -1.5108464577144927, 'training_batch_size': 7, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  176.93122696876526
Memory status after this trial: 
Memory allocated:  193.001953125
Memory cached:  198.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.927321744236767, 'log_learning_rate_D': -1.6789803738537472, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.9770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.9666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.9528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.9362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.705078125
Memory cached:  24.0
[I 2023-11-02 18:33:15,780] Trial 46 finished with value: 0.9054659008979797 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.927321744236767, 'log_learning_rate_D': -1.6789803738537472, 'training_batch_size': 9, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  161.4007260799408
Memory status after this trial: 
Memory allocated:  119.90625
Memory cached:  124.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.992774075378295, 'log_learning_rate_D': -1.2687620819879195, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.21875
Memory cached:  22.0
[I 2023-11-02 18:36:05,484] Trial 47 finished with value: 0.24668669700622559 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.992774075378295, 'log_learning_rate_D': -1.2687620819879195, 'training_batch_size': 9, 'training_p': 4}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  169.4431426525116
Memory status after this trial: 
Memory allocated:  132.3037109375
Memory cached:  136.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.453369445986855, 'log_learning_rate_D': -1.012887101615854, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  18.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  18.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  20.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57421875
Memory cached:  18.0
[I 2023-11-02 18:38:54,941] Trial 48 finished with value: 0.9999791979789734 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.453369445986855, 'log_learning_rate_D': -1.012887101615854, 'training_batch_size': 8, 'training_p': 3}. Best is trial 7 with value: 0.24504585564136505.
Time for this trial:  169.18755292892456
Memory status after this trial: 
Memory allocated:  134.9482421875
Memory cached:  138.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.712511473609437, 'log_learning_rate_D': -1.3858507681283179, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.7702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.716796875
Memory cached:  22.0
[I 2023-11-02 18:41:27,617] Trial 49 finished with value: 0.24601267278194427 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.712511473609437, 'log_learning_rate_D': -1.3858507681283179, 'training_batch_size': 10, 'training_p': 5}. Best is trial 7 with value: 0.24504585564136505.
[I 2023-11-02 18:41:27,642] A new study created in memory with name: no-name-f9ce47eb-e2b3-40ab-94f9-82bc2e996c9e
Time for this trial:  152.42404460906982
Memory status after this trial: 
Memory allocated:  115.7421875
Memory cached:  120.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.6364186303109833, 'log_learning_rate_D': -1.9048745132276412, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.2967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.0390625
Memory cached:  34.0
[I 2023-11-02 18:44:30,342] Trial 0 finished with value: 0.24591000378131866 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.6364186303109833, 'log_learning_rate_D': -1.9048745132276412, 'training_batch_size': 10, 'training_p': 6}. Best is trial 0 with value: 0.24591000378131866.
Time for this trial:  182.5862877368927
Memory status after this trial: 
Memory allocated:  183.31494140625
Memory cached:  192.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.0352974998960365, 'log_learning_rate_D': -2.3735211718322087, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  20.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.11328125
Memory cached:  18.0
[I 2023-11-02 18:46:29,564] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.0352974998960365, 'log_learning_rate_D': -2.3735211718322087, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 0.24591000378131866.
Time for this trial:  119.09233975410461
Memory status after this trial: 
Memory allocated:  72.7255859375
Memory cached:  76.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.44784538316285, 'log_learning_rate_D': -4.269817653437018, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.8400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.6338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.568359375
Memory cached:  10.0
[I 2023-11-02 18:48:04,636] Trial 2 finished with value: 0.2457425445318222 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.44784538316285, 'log_learning_rate_D': -4.269817653437018, 'training_batch_size': 8, 'training_p': 7}. Best is trial 2 with value: 0.2457425445318222.
Time for this trial:  94.94436979293823
Memory status after this trial: 
Memory allocated:  28.41845703125
Memory cached:  32.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.039853827299224, 'log_learning_rate_D': -3.136893573243261, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.294921875
Memory cached:  46.0
[I 2023-11-02 18:50:54,350] Trial 3 finished with value: 0.2461303472518921 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.039853827299224, 'log_learning_rate_D': -3.136893573243261, 'training_batch_size': 10, 'training_p': 6}. Best is trial 2 with value: 0.2457425445318222.
Time for this trial:  169.58597445487976
Memory status after this trial: 
Memory allocated:  210.158203125
Memory cached:  234.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.2998336368506695, 'log_learning_rate_D': -4.9466117554394415, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.7903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.234375
Memory cached:  16.0
[I 2023-11-02 18:52:57,860] Trial 4 finished with value: 0.24651284515857697 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.2998336368506695, 'log_learning_rate_D': -4.9466117554394415, 'training_batch_size': 8, 'training_p': 4}. Best is trial 2 with value: 0.2457425445318222.
Time for this trial:  123.3509292602539
Memory status after this trial: 
Memory allocated:  130.53076171875
Memory cached:  138.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.7897845450635526, 'log_learning_rate_D': -1.9465598214291777, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  36.0
	 epoch  10 training error:  tensor(2.4824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.4000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.078125
Memory cached:  42.0
[I 2023-11-02 18:55:33,283] Trial 5 finished with value: 0.24518337845802307 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.7897845450635526, 'log_learning_rate_D': -1.9465598214291777, 'training_batch_size': 7, 'training_p': 5}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  155.30335783958435
Memory status after this trial: 
Memory allocated:  220.3388671875
Memory cached:  244.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.8442245208317853, 'log_learning_rate_D': -4.5381291726203, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.177734375
Memory cached:  38.0
[I 2023-11-02 18:58:17,242] Trial 6 finished with value: 0.24652066826820374 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.8442245208317853, 'log_learning_rate_D': -4.5381291726203, 'training_batch_size': 7, 'training_p': 7}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  163.82164311408997
Memory status after this trial: 
Memory allocated:  159.5693359375
Memory cached:  180.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.6445055380250433, 'log_learning_rate_D': -1.6948388874069558, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.7663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.044921875
Memory cached:  10.0
[I 2023-11-02 18:59:48,702] Trial 7 finished with value: 0.24640481173992157 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.6445055380250433, 'log_learning_rate_D': -1.6948388874069558, 'training_batch_size': 12, 'training_p': 8}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  91.32879114151001
Memory status after this trial: 
Memory allocated:  41.65185546875
Memory cached:  46.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.6263052298535219, 'log_learning_rate_D': -4.963801859006381, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  12.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.234375
Memory cached:  16.0
[I 2023-11-02 19:02:24,162] Trial 8 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.6263052298535219, 'log_learning_rate_D': -4.963801859006381, 'training_batch_size': 9, 'training_p': 7}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  155.33410000801086
Memory status after this trial: 
Memory allocated:  141.43798828125
Memory cached:  146.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.2495356804030244, 'log_learning_rate_D': -3.893411513603362, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8828125
Memory cached:  22.0
[I 2023-11-02 19:05:21,206] Trial 9 finished with value: 0.24638095498085022 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.2495356804030244, 'log_learning_rate_D': -3.893411513603362, 'training_batch_size': 10, 'training_p': 8}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  176.90129256248474
Memory status after this trial: 
Memory allocated:  181.96240234375
Memory cached:  190.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.2983810276116836, 'log_learning_rate_D': -1.030972324986191, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  38.0
[I 2023-11-02 19:09:06,109] Trial 10 finished with value: 0.24571466445922852 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.2983810276116836, 'log_learning_rate_D': -1.030972324986191, 'training_batch_size': 6, 'training_p': 4}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  224.67074489593506
Memory status after this trial: 
Memory allocated:  239.23681640625
Memory cached:  258.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.0623773795354134, 'log_learning_rate_D': -1.1808342416114623, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
[I 2023-11-02 19:12:50,702] Trial 11 finished with value: 0.24712884426116943 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.0623773795354134, 'log_learning_rate_D': -1.1808342416114623, 'training_batch_size': 6, 'training_p': 4}. Best is trial 5 with value: 0.24518337845802307.
Time for this trial:  224.4161674976349
Memory status after this trial: 
Memory allocated:  239.23681640625
Memory cached:  258.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.256143666292518, 'log_learning_rate_D': -1.0661960783125646, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.5576171875
Memory cached:  38.0
[I 2023-11-02 19:16:53,052] Trial 12 finished with value: 0.24513185024261475 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.256143666292518, 'log_learning_rate_D': -1.0661960783125646, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  242.15305590629578
Memory status after this trial: 
Memory allocated:  238.02880859375
Memory cached:  256.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.37843604121656, 'log_learning_rate_D': -1.680945538186749, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  20.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  20.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  20.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.0498046875
Memory cached:  18.0
[I 2023-11-02 19:21:38,682] Trial 13 finished with value: 1.0000001192092896 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.37843604121656, 'log_learning_rate_D': -1.680945538186749, 'training_batch_size': 6, 'training_p': 2}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  285.4286894798279
Memory status after this trial: 
Memory allocated:  219.71826171875
Memory cached:  228.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.510223375645145, 'log_learning_rate_D': -2.4638142550373137, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  38.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.705078125
Memory cached:  40.0
[I 2023-11-02 19:24:05,132] Trial 14 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.510223375645145, 'log_learning_rate_D': -2.4638142550373137, 'training_batch_size': 7, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  146.22964310646057
Memory status after this trial: 
Memory allocated:  202.62890625
Memory cached:  220.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.601473153203729, 'log_learning_rate_D': -1.0322349671906437, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.373046875
Memory cached:  38.0
[I 2023-11-02 19:26:47,263] Trial 15 finished with value: 0.2458098977804184 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.601473153203729, 'log_learning_rate_D': -1.0322349671906437, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  161.92020988464355
Memory status after this trial: 
Memory allocated:  154.55224609375
Memory cached:  176.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.9038536030209254, 'log_learning_rate_D': -1.5704138742746225, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  52.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.787109375
Memory cached:  60.0
[I 2023-11-02 19:30:12,515] Trial 16 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.9038536030209254, 'log_learning_rate_D': -1.5704138742746225, 'training_batch_size': 7, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  205.02458882331848
Memory status after this trial: 
Memory allocated:  366.32470703125
Memory cached:  396.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.021163841153987, 'log_learning_rate_D': -2.248645315218268, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  26.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8154296875
Memory cached:  20.0
[I 2023-11-02 19:34:34,483] Trial 17 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.021163841153987, 'log_learning_rate_D': -2.248645315218268, 'training_batch_size': 6, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  261.7513048648834
Memory status after this trial: 
Memory allocated:  165.20166015625
Memory cached:  174.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.623130026178505, 'log_learning_rate_D': -2.882670787643888, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.76171875
Memory cached:  46.0
[I 2023-11-02 19:37:12,382] Trial 18 finished with value: 0.2465250939130783 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.623130026178505, 'log_learning_rate_D': -2.882670787643888, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  157.7046241760254
Memory status after this trial: 
Memory allocated:  233.75341796875
Memory cached:  258.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.9021560547428948, 'log_learning_rate_D': -1.3364285718253563, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  36.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4453125
Memory cached:  42.0
[I 2023-11-02 19:39:43,127] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.9021560547428948, 'log_learning_rate_D': -1.3364285718253563, 'training_batch_size': 8, 'training_p': 6}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  150.50546598434448
Memory status after this trial: 
Memory allocated:  220.6845703125
Memory cached:  240.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.923033944706221, 'log_learning_rate_D': -1.98249603311493, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.9372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.9035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.8544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.6936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  22.0
[I 2023-11-02 19:42:48,771] Trial 20 finished with value: 0.330751895904541 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.923033944706221, 'log_learning_rate_D': -1.98249603311493, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  185.41661643981934
Memory status after this trial: 
Memory allocated:  228.6669921875
Memory cached:  238.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.2244847239252135, 'log_learning_rate_D': -1.011290209674437, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4267578125
Memory cached:  42.0
[I 2023-11-02 19:46:38,266] Trial 21 finished with value: 0.2511661946773529 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.2244847239252135, 'log_learning_rate_D': -1.011290209674437, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  229.27310276031494
Memory status after this trial: 
Memory allocated:  239.23681640625
Memory cached:  258.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.2789194015817538, 'log_learning_rate_D': -1.4117364025936798, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.1728515625
Memory cached:  38.0
[I 2023-11-02 19:50:09,683] Trial 22 finished with value: 0.24619869887828827 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.2789194015817538, 'log_learning_rate_D': -1.4117364025936798, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  211.220627784729
Memory status after this trial: 
Memory allocated:  208.8154296875
Memory cached:  226.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.6350054533981528, 'log_learning_rate_D': -1.2342085218974512, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  16.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.17578125
Memory cached:  22.0
[I 2023-11-02 19:52:30,131] Trial 23 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.6350054533981528, 'log_learning_rate_D': -1.2342085218974512, 'training_batch_size': 7, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  140.2613170146942
Memory status after this trial: 
Memory allocated:  168.17041015625
Memory cached:  176.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.4765362621353444, 'log_learning_rate_D': -1.4006530149880634, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9287109375
Memory cached:  16.0
[I 2023-11-02 19:56:23,734] Trial 24 finished with value: 0.24626581370830536 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.4765362621353444, 'log_learning_rate_D': -1.4006530149880634, 'training_batch_size': 6, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  233.38378477096558
Memory status after this trial: 
Memory allocated:  151.5927734375
Memory cached:  158.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7359586309432595, 'log_learning_rate_D': -1.8438777908390187, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9609375
Memory cached:  38.0
[I 2023-11-02 19:58:43,725] Trial 25 finished with value: 0.24600885808467865 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7359586309432595, 'log_learning_rate_D': -1.8438777908390187, 'training_batch_size': 7, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  139.78590559959412
Memory status after this trial: 
Memory allocated:  206.40625
Memory cached:  228.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.109789448645556, 'log_learning_rate_D': -1.069917953287165, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.8244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  42.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4580078125
Memory cached:  40.0
[I 2023-11-02 20:03:51,822] Trial 26 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.109789448645556, 'log_learning_rate_D': -1.069917953287165, 'training_batch_size': 6, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  307.84142231941223
Memory status after this trial: 
Memory allocated:  274.73974609375
Memory cached:  294.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.9626523758454897, 'log_learning_rate_D': -1.5168368152209375, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6953125
Memory cached:  22.0
[I 2023-11-02 20:06:11,344] Trial 27 finished with value: 0.9983688592910767 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.9626523758454897, 'log_learning_rate_D': -1.5168368152209375, 'training_batch_size': 7, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  139.29972672462463
Memory status after this trial: 
Memory allocated:  133.45556640625
Memory cached:  140.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.4477220076802992, 'log_learning_rate_D': -1.3956044247784625, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.37890625
Memory cached:  24.0
[I 2023-11-02 20:08:48,821] Trial 28 finished with value: 0.24614360928535461 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.4477220076802992, 'log_learning_rate_D': -1.3956044247784625, 'training_batch_size': 8, 'training_p': 6}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  157.25859999656677
Memory status after this trial: 
Memory allocated:  230.24853515625
Memory cached:  240.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.407016721718811, 'log_learning_rate_D': -1.9340138938898535, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  56.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2001953125
Memory cached:  60.0
[I 2023-11-02 20:12:44,729] Trial 29 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.407016721718811, 'log_learning_rate_D': -1.9340138938898535, 'training_batch_size': 6, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  235.69138288497925
Memory status after this trial: 
Memory allocated:  277.11083984375
Memory cached:  312.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.8532784183099353, 'log_learning_rate_D': -1.7179190435337481, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8046875
Memory cached:  18.0
[I 2023-11-02 20:15:18,799] Trial 30 finished with value: 0.2459723949432373 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.8532784183099353, 'log_learning_rate_D': -1.7179190435337481, 'training_batch_size': 9, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  153.86612963676453
Memory status after this trial: 
Memory allocated:  146.29052734375
Memory cached:  152.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.320673434903414, 'log_learning_rate_D': -1.0084231943972077, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.7992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.380859375
Memory cached:  8.0
[I 2023-11-02 20:16:50,974] Trial 31 finished with value: 0.24595613777637482 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.320673434903414, 'log_learning_rate_D': -1.0084231943972077, 'training_batch_size': 8, 'training_p': 7}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  91.98265337944031
Memory status after this trial: 
Memory allocated:  25.93896484375
Memory cached:  30.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.1623248321342636, 'log_learning_rate_D': -2.1427927290128275, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74609375
Memory cached:  14.0
[I 2023-11-02 20:18:40,242] Trial 32 finished with value: 0.24649940431118011 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.1623248321342636, 'log_learning_rate_D': -2.1427927290128275, 'training_batch_size': 7, 'training_p': 6}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  109.08907699584961
Memory status after this trial: 
Memory allocated:  40.81884765625
Memory cached:  44.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.2891217356929152, 'log_learning_rate_D': -2.645507476242854, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.57421875
Memory cached:  16.0
[I 2023-11-02 20:21:00,227] Trial 33 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.2891217356929152, 'log_learning_rate_D': -2.645507476242854, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  139.70166873931885
Memory status after this trial: 
Memory allocated:  83.56201171875
Memory cached:  88.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.8019448255394062, 'log_learning_rate_D': -3.4196588203210205, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.41015625
Memory cached:  14.0
[I 2023-11-02 20:22:34,661] Trial 34 finished with value: 0.24632059037685394 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.8019448255394062, 'log_learning_rate_D': -3.4196588203210205, 'training_batch_size': 8, 'training_p': 6}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  94.24469232559204
Memory status after this trial: 
Memory allocated:  18.11962890625
Memory cached:  22.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.2415339173449316, 'log_learning_rate_D': -2.0941988552912387, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  16.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  16.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.263671875
Memory cached:  14.0
[I 2023-11-02 20:24:15,584] Trial 35 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.2415339173449316, 'log_learning_rate_D': -2.0941988552912387, 'training_batch_size': 8, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  100.74225687980652
Memory status after this trial: 
Memory allocated:  59.07763671875
Memory cached:  64.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.8334114105458257, 'log_learning_rate_D': -1.762952049691797, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.29296875
Memory cached:  20.0
[I 2023-11-02 20:26:21,346] Trial 36 finished with value: 0.2462756633758545 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.8334114105458257, 'log_learning_rate_D': -1.762952049691797, 'training_batch_size': 7, 'training_p': 7}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  125.55026435852051
Memory status after this trial: 
Memory allocated:  142.02734375
Memory cached:  148.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.636641441078764, 'log_learning_rate_D': -2.458286876079206, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.8822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.7534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.73828125
Memory cached:  18.0
[I 2023-11-02 20:29:02,870] Trial 37 finished with value: 0.24593476951122284 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.636641441078764, 'log_learning_rate_D': -2.458286876079206, 'training_batch_size': 9, 'training_p': 8}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  161.2905797958374
Memory status after this trial: 
Memory allocated:  125.1171875
Memory cached:  130.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.155941910790218, 'log_learning_rate_D': -1.2471875858462806, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1650390625
Memory cached:  10.0
[I 2023-11-02 20:31:46,094] Trial 38 finished with value: 0.24883711338043213 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.155941910790218, 'log_learning_rate_D': -1.2471875858462806, 'training_batch_size': 6, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  163.0287802219391
Memory status after this trial: 
Memory allocated:  68.2333984375
Memory cached:  74.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.6016120000171035, 'log_learning_rate_D': -4.406463937234028, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
[I 2023-11-02 20:33:35,566] Trial 39 finished with value: 0.2465706318616867 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.6016120000171035, 'log_learning_rate_D': -4.406463937234028, 'training_batch_size': 8, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  109.26758456230164
Memory status after this trial: 
Memory allocated:  76.49658203125
Memory cached:  82.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.0382754790732833, 'log_learning_rate_D': -3.312257347159412, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0546875
Memory cached:  22.0
[I 2023-11-02 20:35:54,727] Trial 40 finished with value: 0.24632839858531952 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.0382754790732833, 'log_learning_rate_D': -3.312257347159412, 'training_batch_size': 7, 'training_p': 7}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  138.9402310848236
Memory status after this trial: 
Memory allocated:  130.40625
Memory cached:  134.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.5100096321835657, 'log_learning_rate_D': -1.2038877842278004, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.84375
Memory cached:  40.0
[I 2023-11-02 20:38:50,089] Trial 41 finished with value: 0.2457789033651352 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.5100096321835657, 'log_learning_rate_D': -1.2038877842278004, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  175.07888388633728
Memory status after this trial: 
Memory allocated:  158.7548828125
Memory cached:  180.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.295015352354161, 'log_learning_rate_D': -1.2306751975635644, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7001953125
Memory cached:  44.0
[I 2023-11-02 20:44:15,955] Trial 42 finished with value: 0.9975797533988953 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.295015352354161, 'log_learning_rate_D': -1.2306751975635644, 'training_batch_size': 6, 'training_p': 2}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  325.60472774505615
Memory status after this trial: 
Memory allocated:  173.04638671875
Memory cached:  194.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.029918087314693, 'log_learning_rate_D': -1.51585784171926, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  58.0
	 epoch  10 training error:  tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  64.0
	 epoch  50 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  64.0
	 epoch  70 training error:  tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  64.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.8046875
Memory cached:  66.0
[I 2023-11-02 20:47:39,101] Trial 43 finished with value: 0.24584876000881195 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.029918087314693, 'log_learning_rate_D': -1.51585784171926, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  202.87516450881958
Memory status after this trial: 
Memory allocated:  307.037109375
Memory cached:  336.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.469638623074181, 'log_learning_rate_D': -1.5757389611104884, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.42578125
Memory cached:  22.0
[I 2023-11-02 20:50:44,086] Trial 44 finished with value: 0.24601797759532928 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.469638623074181, 'log_learning_rate_D': -1.5757389611104884, 'training_batch_size': 8, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  184.7170112133026
Memory status after this trial: 
Memory allocated:  171.5849609375
Memory cached:  178.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.328511732091351, 'log_learning_rate_D': -1.1697651510078462, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.423828125
Memory cached:  20.0
[I 2023-11-02 20:53:33,980] Trial 45 finished with value: 0.24675710499286652 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.328511732091351, 'log_learning_rate_D': -1.1697651510078462, 'training_batch_size': 7, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  169.63817238807678
Memory status after this trial: 
Memory allocated:  171.67529296875
Memory cached:  178.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.69009463046872, 'log_learning_rate_D': -1.8367187387111856, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  22.0
	 epoch  10 training error:  tensor(23.9884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  24.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  28.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  24.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  28.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  26.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  26.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3466796875
Memory cached:  30.0
[I 2023-11-02 20:58:33,810] Trial 46 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.69009463046872, 'log_learning_rate_D': -1.8367187387111856, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  299.564820766449
Memory status after this trial: 
Memory allocated:  191.4072265625
Memory cached:  198.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.0093792401754365, 'log_learning_rate_D': -1.3151727619943077, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  20 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.474609375
Memory cached:  28.0
[I 2023-11-02 21:01:39,401] Trial 47 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.0093792401754365, 'log_learning_rate_D': -1.3151727619943077, 'training_batch_size': 7, 'training_p': 2}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  185.3455994129181
Memory status after this trial: 
Memory allocated:  226.55419921875
Memory cached:  238.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.730773330444942, 'log_learning_rate_D': -1.6522066398023876, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.9871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.802734375
Memory cached:  42.0
[I 2023-11-02 21:04:21,327] Trial 48 finished with value: 0.9976314902305603 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.730773330444942, 'log_learning_rate_D': -1.6522066398023876, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.24513185024261475.
Time for this trial:  161.68450546264648
Memory status after this trial: 
Memory allocated:  186.23828125
Memory cached:  210.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.3187526018112963, 'log_learning_rate_D': -1.1412965891469034, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.4779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  20 training error:  tensor(1.0190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  60.0
	 epoch  30 training error:  tensor(1.0011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
[I 2023-11-02 21:06:50,053] Trial 49 finished with value: 0.9976121187210083 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.3187526018112963, 'log_learning_rate_D': -1.1412965891469034, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.24513185024261475.
[I 2023-11-02 21:06:50,077] A new study created in memory with name: no-name-99dd5c03-7407-4ba0-8a44-be8261426685
Time for this trial:  148.48830890655518
Memory status after this trial: 
Memory allocated:  198.33935546875
Memory cached:  232.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.0396593510195098, 'log_learning_rate_D': -1.680612805213527, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2265625
Memory cached:  18.0
[I 2023-11-02 21:09:37,349] Trial 0 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.0396593510195098, 'log_learning_rate_D': -1.680612805213527, 'training_batch_size': 11, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  167.1596920490265
Memory status after this trial: 
Memory allocated:  201.00048828125
Memory cached:  214.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.5101075267247084, 'log_learning_rate_D': -4.569625149592623, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  64.0
	 epoch  10 training error:  tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  70.0
	 epoch  20 training error:  tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  70.0
	 epoch  30 training error:  tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  70.0
	 epoch  50 training error:  tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  68.0
	 epoch  60 training error:  tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  70.0
	 epoch  70 training error:  tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  70.0
	 epoch  90 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.041015625
Memory cached:  68.0
[I 2023-11-02 21:12:49,137] Trial 1 finished with value: 0.24635779857635498 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.5101075267247084, 'log_learning_rate_D': -4.569625149592623, 'training_batch_size': 12, 'training_p': 2}. Best is trial 1 with value: 0.24635779857635498.
Time for this trial:  191.64721751213074
Memory status after this trial: 
Memory allocated:  295.32275390625
Memory cached:  320.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.479605696539315, 'log_learning_rate_D': -4.064678803241026, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.8997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  54.0
	 epoch  30 training error:  tensor(0.8516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.8043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.7524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  54.0
	 epoch  60 training error:  tensor(0.6949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  54.0
	 epoch  70 training error:  tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.6435546875
Memory cached:  54.0
[I 2023-11-02 21:16:22,825] Trial 2 finished with value: 0.3131220042705536 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.479605696539315, 'log_learning_rate_D': -4.064678803241026, 'training_batch_size': 6, 'training_p': 8}. Best is trial 1 with value: 0.24635779857635498.
Time for this trial:  213.53940081596375
Memory status after this trial: 
Memory allocated:  227.51220703125
Memory cached:  258.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6797121087502984, 'log_learning_rate_D': -2.6414364218060156, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.9145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.8874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.7510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.224609375
Memory cached:  16.0
[I 2023-11-02 21:18:47,782] Trial 3 finished with value: 0.5546011924743652 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6797121087502984, 'log_learning_rate_D': -2.6414364218060156, 'training_batch_size': 11, 'training_p': 3}. Best is trial 1 with value: 0.24635779857635498.
Time for this trial:  144.82634735107422
Memory status after this trial: 
Memory allocated:  86.537109375
Memory cached:  96.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.110803972962753, 'log_learning_rate_D': -1.164838698632375, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.8296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.17578125
Memory cached:  38.0
[I 2023-11-02 21:21:09,590] Trial 4 finished with value: 0.2457078993320465 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.110803972962753, 'log_learning_rate_D': -1.164838698632375, 'training_batch_size': 12, 'training_p': 5}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  141.65920686721802
Memory status after this trial: 
Memory allocated:  204.3046875
Memory cached:  234.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -1.9676186730232192, 'log_learning_rate_D': -3.9676427251879836, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  12.0
[I 2023-11-02 21:22:37,594] Trial 5 finished with value: 0.2466028779745102 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -1.9676186730232192, 'log_learning_rate_D': -3.9676427251879836, 'training_batch_size': 9, 'training_p': 7}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  87.886385679245
Memory status after this trial: 
Memory allocated:  22.10009765625
Memory cached:  32.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.7075242003756355, 'log_learning_rate_D': -1.7588493406859902, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  54.0
	 epoch  10 training error:  tensor(0.9114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  60.0
	 epoch  20 training error:  tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.8391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.7512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.458984375
Memory cached:  60.0
[I 2023-11-02 21:24:38,186] Trial 6 finished with value: 0.2505098879337311 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.7075242003756355, 'log_learning_rate_D': -1.7588493406859902, 'training_batch_size': 11, 'training_p': 8}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  120.45450973510742
Memory status after this trial: 
Memory allocated:  172.26220703125
Memory cached:  194.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.691888402604842, 'log_learning_rate_D': -1.6200952916435596, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.9720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.9290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.8901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.8327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8564453125
Memory cached:  20.0
[I 2023-11-02 21:29:14,236] Trial 7 finished with value: 0.5970156788825989 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.691888402604842, 'log_learning_rate_D': -1.6200952916435596, 'training_batch_size': 6, 'training_p': 4}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  275.8928701877594
Memory status after this trial: 
Memory allocated:  131.48974609375
Memory cached:  144.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -1.5915703719523293, 'log_learning_rate_D': -2.779717254733939, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  16.0
	 epoch  10 training error:  tensor(37.0292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.697265625
Memory cached:  20.0
[I 2023-11-02 21:31:07,835] Trial 8 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -1.5915703719523293, 'log_learning_rate_D': -2.779717254733939, 'training_batch_size': 7, 'training_p': 6}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  113.46058106422424
Memory status after this trial: 
Memory allocated:  103.86474609375
Memory cached:  116.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.3795767733654416, 'log_learning_rate_D': -3.6148787392535526, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  26.0
	 epoch  20 training error:  tensor(1.1695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.51953125
Memory cached:  22.0
[I 2023-11-02 21:33:59,203] Trial 9 finished with value: 0.24588385224342346 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.3795767733654416, 'log_learning_rate_D': -3.6148787392535526, 'training_batch_size': 8, 'training_p': 2}. Best is trial 4 with value: 0.2457078993320465.
Time for this trial:  171.2293689250946
Memory status after this trial: 
Memory allocated:  204.0400390625
Memory cached:  216.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6437095865792726, 'log_learning_rate_D': -1.0774732198942174, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1640625
Memory cached:  102.0
[I 2023-11-02 21:37:35,616] Trial 10 finished with value: 0.2450779676437378 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6437095865792726, 'log_learning_rate_D': -1.0774732198942174, 'training_batch_size': 10, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  216.1870152950287
Memory status after this trial: 
Memory allocated:  477.11767578125
Memory cached:  518.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6255787724269073, 'log_learning_rate_D': -1.1528907490248135, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  106.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.94140625
Memory cached:  110.0
[I 2023-11-02 21:41:08,812] Trial 11 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6255787724269073, 'log_learning_rate_D': -1.1528907490248135, 'training_batch_size': 10, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  212.97062277793884
Memory status after this trial: 
Memory allocated:  507.54736328125
Memory cached:  546.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.7407300288671244, 'log_learning_rate_D': -1.0247490107022985, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  94.0
	 epoch  10 training error:  tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  20 training error:  tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  30 training error:  tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  40 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  50 training error:  tensor(0.3195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  60 training error:  tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  70 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  80 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
	 epoch  90 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.287109375
Memory cached:  100.0
[I 2023-11-02 21:44:33,863] Trial 12 finished with value: 0.2451932430267334 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.7407300288671244, 'log_learning_rate_D': -1.0247490107022985, 'training_batch_size': 12, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  204.81294107437134
Memory status after this trial: 
Memory allocated:  404.11181640625
Memory cached:  444.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.6862252454171704, 'log_learning_rate_D': -2.2573118395922456, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  86.0
	 epoch  10 training error:  tensor(0.9841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.8042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.419921875
Memory cached:  90.0
[I 2023-11-02 21:48:03,954] Trial 13 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.6862252454171704, 'log_learning_rate_D': -2.2573118395922456, 'training_batch_size': 9, 'training_p': 6}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  209.8097791671753
Memory status after this trial: 
Memory allocated:  430.68017578125
Memory cached:  470.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.388871329459752, 'log_learning_rate_D': -1.0777914419731895, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.650390625
Memory cached:  48.0
[I 2023-11-02 21:51:19,180] Trial 14 finished with value: 0.24633391201496124 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.388871329459752, 'log_learning_rate_D': -1.0777914419731895, 'training_batch_size': 10, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  194.998064994812
Memory status after this trial: 
Memory allocated:  264.81591796875
Memory cached:  296.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.129673528938236, 'log_learning_rate_D': -2.155894552990339, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.5679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3125
Memory cached:  48.0
[I 2023-11-02 21:54:33,412] Trial 15 finished with value: 0.24635742604732513 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.129673528938236, 'log_learning_rate_D': -2.155894552990339, 'training_batch_size': 10, 'training_p': 6}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  193.99624586105347
Memory status after this trial: 
Memory allocated:  238.9912109375
Memory cached:  270.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.1294242857514853, 'log_learning_rate_D': -3.2289968633382484, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.607421875
Memory cached:  42.0
[I 2023-11-02 21:57:47,047] Trial 16 finished with value: 0.24678276479244232 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.1294242857514853, 'log_learning_rate_D': -3.2289968633382484, 'training_batch_size': 12, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  193.3904480934143
Memory status after this trial: 
Memory allocated:  175.20458984375
Memory cached:  206.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.0147186589073156, 'log_learning_rate_D': -1.0735845731497835, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.9157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.55859375
Memory cached:  26.0
[I 2023-11-02 22:00:12,914] Trial 17 finished with value: 0.24632802605628967 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.0147186589073156, 'log_learning_rate_D': -1.0735845731497835, 'training_batch_size': 8, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  145.6195890903473
Memory status after this trial: 
Memory allocated:  117.416015625
Memory cached:  130.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.329239204903801, 'log_learning_rate_D': -2.172909126687638, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.3023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.900390625
Memory cached:  82.0
[I 2023-11-02 22:03:20,789] Trial 18 finished with value: 0.2462301254272461 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.329239204903801, 'log_learning_rate_D': -2.172909126687638, 'training_batch_size': 9, 'training_p': 7}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  187.6519069671631
Memory status after this trial: 
Memory allocated:  349.7099609375
Memory cached:  382.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.769839119513283, 'log_learning_rate_D': -1.6240694999463374, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.626953125
Memory cached:  44.0
[I 2023-11-02 22:06:22,378] Trial 19 finished with value: 0.24611806869506836 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.769839119513283, 'log_learning_rate_D': -1.6240694999463374, 'training_batch_size': 11, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  181.35327458381653
Memory status after this trial: 
Memory allocated:  232.48095703125
Memory cached:  262.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.2830317615548674, 'log_learning_rate_D': -1.5225870693872192, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.7368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.6881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.375
Memory cached:  44.0
[I 2023-11-02 22:09:35,315] Trial 20 finished with value: 0.2461245059967041 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.2830317615548674, 'log_learning_rate_D': -1.5225870693872192, 'training_batch_size': 12, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  192.6934096813202
Memory status after this trial: 
Memory allocated:  249.12451171875
Memory cached:  280.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.8839889585952787, 'log_learning_rate_D': -1.0041546472763847, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  40 training error:  tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.18359375
Memory cached:  46.0
[I 2023-11-02 22:12:17,413] Trial 21 finished with value: 0.24605321884155273 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.8839889585952787, 'log_learning_rate_D': -1.0041546472763847, 'training_batch_size': 12, 'training_p': 6}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  161.86344718933105
Memory status after this trial: 
Memory allocated:  256.93359375
Memory cached:  284.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.1647005568757605, 'log_learning_rate_D': -1.4060585060283284, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.9322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.8150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.6028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.552734375
Memory cached:  46.0
[I 2023-11-02 22:14:55,242] Trial 22 finished with value: 0.24681542813777924 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.1647005568757605, 'log_learning_rate_D': -1.4060585060283284, 'training_batch_size': 11, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  157.60037660598755
Memory status after this trial: 
Memory allocated:  230.384765625
Memory cached:  258.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.2155591265021943, 'log_learning_rate_D': -1.2970372191466355, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.6666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9375
Memory cached:  42.0
[I 2023-11-02 22:17:17,007] Trial 23 finished with value: 0.24601860344409943 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.2155591265021943, 'log_learning_rate_D': -1.2970372191466355, 'training_batch_size': 12, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  141.53262400627136
Memory status after this trial: 
Memory allocated:  217.19189453125
Memory cached:  242.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.175879066565535, 'log_learning_rate_D': -1.9227812614927706, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.9598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.8698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.51171875
Memory cached:  44.0
[I 2023-11-02 22:19:52,749] Trial 24 finished with value: 0.246161088347435 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.175879066565535, 'log_learning_rate_D': -1.9227812614927706, 'training_batch_size': 10, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  155.5380597114563
Memory status after this trial: 
Memory allocated:  202.21923828125
Memory cached:  232.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.932647122186985, 'log_learning_rate_D': -1.3614934456912235, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.6988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.66015625
Memory cached:  40.0
[I 2023-11-02 22:22:34,526] Trial 25 finished with value: 0.24653588235378265 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.932647122186985, 'log_learning_rate_D': -1.3614934456912235, 'training_batch_size': 11, 'training_p': 7}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  161.5021767616272
Memory status after this trial: 
Memory allocated:  184.3251953125
Memory cached:  218.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.4433023709198864, 'log_learning_rate_D': -1.2852445886396575, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  68.0
	 epoch  50 training error:  tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
[I 2023-11-02 22:25:49,057] Trial 26 finished with value: 0.245832160115242 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.4433023709198864, 'log_learning_rate_D': -1.2852445886396575, 'training_batch_size': 8, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  194.29097509384155
Memory status after this trial: 
Memory allocated:  350.7021484375
Memory cached:  388.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.500437062119012, 'log_learning_rate_D': -1.881147982190042, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.11328125
Memory cached:  48.0
[I 2023-11-02 22:28:34,543] Trial 27 finished with value: 0.9975687265396118 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.500437062119012, 'log_learning_rate_D': -1.881147982190042, 'training_batch_size': 12, 'training_p': 6}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  165.2553448677063
Memory status after this trial: 
Memory allocated:  274.33056640625
Memory cached:  302.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.0197496779165247, 'log_learning_rate_D': -1.3746199650695925, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.896484375
Memory cached:  26.0
[I 2023-11-02 22:30:56,026] Trial 28 finished with value: 0.9979690909385681 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.0197496779165247, 'log_learning_rate_D': -1.3746199650695925, 'training_batch_size': 10, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  141.26828527450562
Memory status after this trial: 
Memory allocated:  145.95654296875
Memory cached:  162.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.7158197744054897, 'log_learning_rate_D': -1.0219913562514462, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.53125
Memory cached:  46.0
[I 2023-11-02 22:33:51,745] Trial 29 finished with value: 0.9976723790168762 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.7158197744054897, 'log_learning_rate_D': -1.0219913562514462, 'training_batch_size': 11, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  175.4752321243286
Memory status after this trial: 
Memory allocated:  241.9130859375
Memory cached:  270.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.7373246717638846, 'log_learning_rate_D': -1.6078937532639437, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.5625
Memory cached:  42.0
[I 2023-11-02 22:35:56,743] Trial 30 finished with value: 0.2459956258535385 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.7373246717638846, 'log_learning_rate_D': -1.6078937532639437, 'training_batch_size': 12, 'training_p': 6}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  124.78481912612915
Memory status after this trial: 
Memory allocated:  140.705078125
Memory cached:  168.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.306953554057795, 'log_learning_rate_D': -1.2995592386366557, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  64.0
	 epoch  10 training error:  tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.908203125
Memory cached:  66.0
[I 2023-11-02 22:39:12,340] Trial 31 finished with value: 0.24608607590198517 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.306953554057795, 'log_learning_rate_D': -1.2995592386366557, 'training_batch_size': 8, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  195.3604874610901
Memory status after this trial: 
Memory allocated:  350.7021484375
Memory cached:  388.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.4657907981544835, 'log_learning_rate_D': -1.2737419925485538, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  68.0
	 epoch  30 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.76171875
Memory cached:  66.0
[I 2023-11-02 22:42:24,229] Trial 32 finished with value: 0.24618278443813324 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.4657907981544835, 'log_learning_rate_D': -1.2737419925485538, 'training_batch_size': 7, 'training_p': 2}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  191.65209436416626
Memory status after this trial: 
Memory allocated:  303.43359375
Memory cached:  328.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.4616498390108337, 'log_learning_rate_D': -1.7847734658906689, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  64.0
	 epoch  10 training error:  tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  70.0
	 epoch  30 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  60 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  70 training error:  tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  70.0
	 epoch  90 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.498046875
Memory cached:  68.0
[I 2023-11-02 22:46:00,889] Trial 33 finished with value: 0.24669459462165833 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.4616498390108337, 'log_learning_rate_D': -1.7847734658906689, 'training_batch_size': 9, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  216.39114451408386
Memory status after this trial: 
Memory allocated:  399.728515625
Memory cached:  424.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.963902611553147, 'log_learning_rate_D': -1.469446506332424, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.9959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.9900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.9805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.9644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.9368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.8913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.6962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.748046875
Memory cached:  48.0
[I 2023-11-02 22:49:16,921] Trial 34 finished with value: 0.24830563366413116 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.963902611553147, 'log_learning_rate_D': -1.469446506332424, 'training_batch_size': 7, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  195.76803350448608
Memory status after this trial: 
Memory allocated:  283.14208984375
Memory cached:  314.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.7208391489610957, 'log_learning_rate_D': -1.0123344367474765, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.6460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.95703125
Memory cached:  44.0
[I 2023-11-02 22:52:41,513] Trial 35 finished with value: 0.24636243283748627 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.7208391489610957, 'log_learning_rate_D': -1.0123344367474765, 'training_batch_size': 9, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  204.30126810073853
Memory status after this trial: 
Memory allocated:  362.1435546875
Memory cached:  390.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.9951225819017053, 'log_learning_rate_D': -1.9487280586544973, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.8356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.41015625
Memory cached:  48.0
[I 2023-11-02 22:55:46,607] Trial 36 finished with value: 0.2463866025209427 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.9951225819017053, 'log_learning_rate_D': -1.9487280586544973, 'training_batch_size': 8, 'training_p': 2}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  184.8391101360321
Memory status after this trial: 
Memory allocated:  259.7216796875
Memory cached:  288.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.936996900020878, 'log_learning_rate_D': -1.25903857425144, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.451171875
Memory cached:  42.0
[I 2023-11-02 22:57:50,424] Trial 37 finished with value: 0.24626842141151428 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.936996900020878, 'log_learning_rate_D': -1.25903857425144, 'training_batch_size': 11, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  123.59171295166016
Memory status after this trial: 
Memory allocated:  125.3671875
Memory cached:  154.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.573981324880082, 'log_learning_rate_D': -1.6411644172341342, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4111328125
Memory cached:  24.0
[I 2023-11-02 23:02:40,830] Trial 38 finished with value: 0.24651451408863068 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.573981324880082, 'log_learning_rate_D': -1.6411644172341342, 'training_batch_size': 6, 'training_p': 7}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  290.16994166374207
Memory status after this trial: 
Memory allocated:  235.62548828125
Memory cached:  250.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.996621150345423, 'log_learning_rate_D': -2.440730221919483, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  40.0
	 epoch  10 training error:  tensor(1.6454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.220703125
Memory cached:  46.0
[I 2023-11-02 23:05:40,037] Trial 39 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.996621150345423, 'log_learning_rate_D': -2.440730221919483, 'training_batch_size': 8, 'training_p': 8}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  178.9647250175476
Memory status after this trial: 
Memory allocated:  231.3330078125
Memory cached:  264.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.45885145644529, 'log_learning_rate_D': -1.5005585996955637, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  54.0
	 epoch  10 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.572265625
Memory cached:  58.0
[I 2023-11-02 23:08:07,471] Trial 40 finished with value: 0.2462722510099411 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.45885145644529, 'log_learning_rate_D': -1.5005585996955637, 'training_batch_size': 7, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  147.20041632652283
Memory status after this trial: 
Memory allocated:  237.2060546875
Memory cached:  256.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2449850175711432, 'log_learning_rate_D': -3.302998759207089, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  28.0
	 epoch  80 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.37890625
Memory cached:  28.0
[I 2023-11-02 23:11:02,273] Trial 41 finished with value: 0.24697600305080414 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2449850175711432, 'log_learning_rate_D': -3.302998759207089, 'training_batch_size': 8, 'training_p': 2}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  174.57126832008362
Memory status after this trial: 
Memory allocated:  202.6025390625
Memory cached:  214.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -1.7534960082120774, 'log_learning_rate_D': -1.19499787137828, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.626953125
Memory cached:  26.0
[I 2023-11-02 23:13:41,506] Trial 42 finished with value: 0.2459244281053543 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -1.7534960082120774, 'log_learning_rate_D': -1.19499787137828, 'training_batch_size': 8, 'training_p': 2}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  158.99947118759155
Memory status after this trial: 
Memory allocated:  145.4345703125
Memory cached:  156.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.1598223124826315, 'log_learning_rate_D': -3.7630524662502927, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  18.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  26.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  24.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  26.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  28.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  26.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  26.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  28.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.630859375
Memory cached:  24.0
[I 2023-11-02 23:16:30,606] Trial 43 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.1598223124826315, 'log_learning_rate_D': -3.7630524662502927, 'training_batch_size': 7, 'training_p': 3}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  168.84471130371094
Memory status after this trial: 
Memory allocated:  160.58837890625
Memory cached:  172.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.5308638537859918, 'log_learning_rate_D': -4.917289227899911, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.2123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.41796875
Memory cached:  20.0
[I 2023-11-02 23:18:56,071] Trial 44 finished with value: 0.24750196933746338 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.5308638537859918, 'log_learning_rate_D': -4.917289227899911, 'training_batch_size': 9, 'training_p': 2}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  145.23769164085388
Memory status after this trial: 
Memory allocated:  134.17626953125
Memory cached:  146.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.237522915432022, 'log_learning_rate_D': -1.1750178804480034, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.00390625
Memory cached:  30.0
[I 2023-11-02 23:22:26,547] Trial 45 finished with value: 0.9975637793540955 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.237522915432022, 'log_learning_rate_D': -1.1750178804480034, 'training_batch_size': 9, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  210.1811933517456
Memory status after this trial: 
Memory allocated:  306.25390625
Memory cached:  324.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.602899012593738, 'log_learning_rate_D': -1.7509426735636993, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.697265625
Memory cached:  42.0
[I 2023-11-02 23:24:58,439] Trial 46 finished with value: 0.2458726018667221 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.602899012593738, 'log_learning_rate_D': -1.7509426735636993, 'training_batch_size': 10, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  151.61187052726746
Memory status after this trial: 
Memory allocated:  232.40283203125
Memory cached:  262.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.537488825415534, 'log_learning_rate_D': -1.7721045088754677, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  42.0
	 epoch  10 training error:  tensor(1.3988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.072265625
Memory cached:  48.0
[I 2023-11-02 23:27:30,378] Trial 47 finished with value: 0.2466544657945633 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.537488825415534, 'log_learning_rate_D': -1.7721045088754677, 'training_batch_size': 10, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  151.6979320049286
Memory status after this trial: 
Memory allocated:  230.38134765625
Memory cached:  260.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.790905952453284, 'log_learning_rate_D': -1.5106940695501567, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  20 training error:  tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  50 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.88671875
Memory cached:  60.0
[I 2023-11-02 23:30:23,602] Trial 48 finished with value: 0.2459523230791092 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.790905952453284, 'log_learning_rate_D': -1.5106940695501567, 'training_batch_size': 10, 'training_p': 4}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  172.96923351287842
Memory status after this trial: 
Memory allocated:  295.169921875
Memory cached:  338.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.141573495857184, 'log_learning_rate_D': -1.161788437264819, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.048828125
Memory cached:  46.0
[I 2023-11-02 23:32:59,953] Trial 49 finished with value: 0.24622300267219543 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.141573495857184, 'log_learning_rate_D': -1.161788437264819, 'training_batch_size': 11, 'training_p': 5}. Best is trial 10 with value: 0.2450779676437378.
Time for this trial:  156.11586332321167
Memory status after this trial: 
Memory allocated:  210.62890625
Memory cached:  238.0
