/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-11-01 10:37:20,811] A new study created in memory with name: no-name-c211d91e-ebee-455f-b358-31065854799e
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.3570929283090147, 'log_learning_rate_D': -4.75352995352426, 'training_batch_size': 9, 'training_p': 5}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.59033203125
Memory cached:  42.0
[I 2023-11-01 10:37:39,703] Trial 0 finished with value: 0.2296876460313797 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.3570929283090147, 'log_learning_rate_D': -4.75352995352426, 'training_batch_size': 9, 'training_p': 5}. Best is trial 0 with value: 0.2296876460313797.
Time for this trial:  18.805068492889404
Memory status after this trial: 
Memory allocated:  117.30126953125
Memory cached:  138.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.4413625317885694, 'log_learning_rate_D': -1.2817663334136329, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4853515625
Memory cached:  6.0
[I 2023-11-01 10:37:53,428] Trial 1 finished with value: 0.2296767234802246 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.4413625317885694, 'log_learning_rate_D': -1.2817663334136329, 'training_batch_size': 7, 'training_p': 3}. Best is trial 1 with value: 0.2296767234802246.
Time for this trial:  13.625779151916504
Memory status after this trial: 
Memory allocated:  14.69091796875
Memory cached:  26.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.158394419101536, 'log_learning_rate_D': -1.8833939348090665, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3203125
Memory cached:  12.0
[I 2023-11-01 10:38:10,687] Trial 2 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.158394419101536, 'log_learning_rate_D': -1.8833939348090665, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.2296767234802246.
Time for this trial:  17.16932487487793
Memory status after this trial: 
Memory allocated:  179.74951171875
Memory cached:  194.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.950412052481922, 'log_learning_rate_D': -2.3834842492753294, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.7793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.6138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
[I 2023-11-01 10:38:27,378] Trial 3 finished with value: 0.22886501252651215 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.950412052481922, 'log_learning_rate_D': -2.3834842492753294, 'training_batch_size': 7, 'training_p': 8}. Best is trial 3 with value: 0.22886501252651215.
Time for this trial:  16.592215538024902
Memory status after this trial: 
Memory allocated:  122.45849609375
Memory cached:  130.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1345342384511308, 'log_learning_rate_D': -2.2966538435786026, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  22.0
[I 2023-11-01 10:38:44,506] Trial 4 finished with value: 0.227120041847229 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1345342384511308, 'log_learning_rate_D': -2.2966538435786026, 'training_batch_size': 6, 'training_p': 8}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  17.020081281661987
Memory status after this trial: 
Memory allocated:  37.27490234375
Memory cached:  48.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.6300718987789025, 'log_learning_rate_D': -1.360034683425984, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.3440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3251953125
Memory cached:  6.0
[I 2023-11-01 10:39:00,640] Trial 5 finished with value: 0.230866476893425 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.6300718987789025, 'log_learning_rate_D': -1.360034683425984, 'training_batch_size': 6, 'training_p': 7}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  16.034167051315308
Memory status after this trial: 
Memory allocated:  62.20068359375
Memory cached:  92.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.668886159198669, 'log_learning_rate_D': -1.780711204303039, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.05029296875
Memory cached:  4.0
[I 2023-11-01 10:39:15,463] Trial 6 finished with value: 0.23100964725017548 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.668886159198669, 'log_learning_rate_D': -1.780711204303039, 'training_batch_size': 11, 'training_p': 7}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  14.723236799240112
Memory status after this trial: 
Memory allocated:  49.86279296875
Memory cached:  72.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.233287396352026, 'log_learning_rate_D': -4.635876320402547, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.8857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.6791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.90380859375
Memory cached:  6.0
[I 2023-11-01 10:39:30,320] Trial 7 finished with value: 0.22794170677661896 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.233287396352026, 'log_learning_rate_D': -4.635876320402547, 'training_batch_size': 7, 'training_p': 8}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  14.762304306030273
Memory status after this trial: 
Memory allocated:  38.43505859375
Memory cached:  52.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.903507481188698, 'log_learning_rate_D': -1.1041366245466615, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  20 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  40 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  60 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  80 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.27685546875
Memory cached:  28.0
[I 2023-11-01 10:39:46,761] Trial 8 finished with value: 0.2300095558166504 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.903507481188698, 'log_learning_rate_D': -1.1041366245466615, 'training_batch_size': 6, 'training_p': 5}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  16.33804202079773
Memory status after this trial: 
Memory allocated:  73.16845703125
Memory cached:  88.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.898638099014795, 'log_learning_rate_D': -2.3824730677449835, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.42431640625
Memory cached:  6.0
[I 2023-11-01 10:40:02,881] Trial 9 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.898638099014795, 'log_learning_rate_D': -2.3824730677449835, 'training_batch_size': 10, 'training_p': 3}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  16.011045694351196
Memory status after this trial: 
Memory allocated:  83.26123046875
Memory cached:  96.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.4453716763469995, 'log_learning_rate_D': -3.3840364319053027, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  6.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56494140625
Memory cached:  8.0
[I 2023-11-01 10:40:19,453] Trial 10 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.4453716763469995, 'log_learning_rate_D': -3.3840364319053027, 'training_batch_size': 12, 'training_p': 6}. Best is trial 4 with value: 0.227120041847229.
Time for this trial:  16.400299072265625
Memory status after this trial: 
Memory allocated:  76.21044921875
Memory cached:  104.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.055912498052342, 'log_learning_rate_D': -3.5739697586902053, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.8852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.7952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.6484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
[I 2023-11-01 10:40:36,111] Trial 11 finished with value: 0.22407010197639465 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.055912498052342, 'log_learning_rate_D': -3.5739697586902053, 'training_batch_size': 8, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.442389011383057
Memory status after this trial: 
Memory allocated:  67.97021484375
Memory cached:  96.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9467160367401424, 'log_learning_rate_D': -3.3660769830503936, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
[I 2023-11-01 10:40:53,516] Trial 12 finished with value: 0.22980475425720215 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9467160367401424, 'log_learning_rate_D': -3.3660769830503936, 'training_batch_size': 9, 'training_p': 7}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  17.22793960571289
Memory status after this trial: 
Memory allocated:  80.11083984375
Memory cached:  94.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.8920282482493165, 'log_learning_rate_D': -3.9063990773298873, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.93310546875
Memory cached:  12.0
[I 2023-11-01 10:41:09,425] Trial 13 finished with value: 0.22953426837921143 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.8920282482493165, 'log_learning_rate_D': -3.9063990773298873, 'training_batch_size': 8, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  15.736217737197876
Memory status after this trial: 
Memory allocated:  29.53271484375
Memory cached:  32.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.376116263110782, 'log_learning_rate_D': -2.7248032068850865, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.6415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.84912109375
Memory cached:  12.0
[I 2023-11-01 10:41:25,297] Trial 14 finished with value: 0.2292276918888092 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.376116263110782, 'log_learning_rate_D': -2.7248032068850865, 'training_batch_size': 8, 'training_p': 6}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  15.683552742004395
Memory status after this trial: 
Memory allocated:  29.37744140625
Memory cached:  38.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.6814348891469093, 'log_learning_rate_D': -3.106760483043791, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56005859375
Memory cached:  8.0
[I 2023-11-01 10:41:44,564] Trial 15 finished with value: 0.2252800017595291 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.6814348891469093, 'log_learning_rate_D': -3.106760483043791, 'training_batch_size': 6, 'training_p': 2}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  19.09930992126465
Memory status after this trial: 
Memory allocated:  76.43408203125
Memory cached:  104.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.6851701443869818, 'log_learning_rate_D': -3.9422490448394925, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  20 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  30 training error:  tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  40 training error:  tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.92333984375
Memory cached:  52.0
[I 2023-11-01 10:42:02,082] Trial 16 finished with value: 0.2315019816160202 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.6851701443869818, 'log_learning_rate_D': -3.9422490448394925, 'training_batch_size': 10, 'training_p': 2}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  17.338781118392944
Memory status after this trial: 
Memory allocated:  135.58544921875
Memory cached:  176.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.1349574171914805, 'log_learning_rate_D': -2.965557127581054, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.16357421875
Memory cached:  8.0
[I 2023-11-01 10:42:18,360] Trial 17 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.1349574171914805, 'log_learning_rate_D': -2.965557127581054, 'training_batch_size': 7, 'training_p': 2}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.095258474349976
Memory status after this trial: 
Memory allocated:  50.93701171875
Memory cached:  68.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.4415695328127214, 'log_learning_rate_D': -3.520141821683988, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.087890625
Memory cached:  10.0
[I 2023-11-01 10:42:34,369] Trial 18 finished with value: 0.23050673305988312 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.4415695328127214, 'log_learning_rate_D': -3.520141821683988, 'training_batch_size': 8, 'training_p': 4}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  15.819199562072754
Memory status after this trial: 
Memory allocated:  36.32275390625
Memory cached:  44.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.332665641172419, 'log_learning_rate_D': -2.979448426096034, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.6599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.4360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.490234375
Memory cached:  10.0
[I 2023-11-01 10:42:51,194] Trial 19 finished with value: 0.22933077812194824 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.332665641172419, 'log_learning_rate_D': -2.979448426096034, 'training_batch_size': 10, 'training_p': 4}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.652814626693726
Memory status after this trial: 
Memory allocated:  70.76513671875
Memory cached:  100.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.719386863799463, 'log_learning_rate_D': -4.124837716138716, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.96240234375
Memory cached:  8.0
[I 2023-11-01 10:43:06,257] Trial 20 finished with value: 0.23072181642055511 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.719386863799463, 'log_learning_rate_D': -4.124837716138716, 'training_batch_size': 9, 'training_p': 6}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  14.868320226669312
Memory status after this trial: 
Memory allocated:  11.28173828125
Memory cached:  16.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8898757686201293, 'log_learning_rate_D': -2.5464501610761756, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7578125
Memory cached:  30.0
[I 2023-11-01 10:43:24,647] Trial 21 finished with value: 0.22655268013477325 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8898757686201293, 'log_learning_rate_D': -2.5464501610761756, 'training_batch_size': 6, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  18.197855710983276
Memory status after this trial: 
Memory allocated:  51.02783203125
Memory cached:  72.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9475658251047703, 'log_learning_rate_D': -2.81296515028195, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8818359375
Memory cached:  8.0
[I 2023-11-01 10:43:43,228] Trial 22 finished with value: 0.23484091460704803 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9475658251047703, 'log_learning_rate_D': -2.81296515028195, 'training_batch_size': 6, 'training_p': 7}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  18.385660886764526
Memory status after this trial: 
Memory allocated:  50.60498046875
Memory cached:  72.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.2994094958249995, 'log_learning_rate_D': -3.2968711865931657, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7197265625
Memory cached:  12.0
[I 2023-11-01 10:44:00,022] Trial 23 finished with value: 0.22918477654457092 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.2994094958249995, 'log_learning_rate_D': -3.2968711865931657, 'training_batch_size': 7, 'training_p': 5}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.61984920501709
Memory status after this trial: 
Memory allocated:  56.03173828125
Memory cached:  76.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7334293189368624, 'log_learning_rate_D': -2.663501672272156, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.78369140625
Memory cached:  8.0
[I 2023-11-01 10:44:19,711] Trial 24 finished with value: 0.2759794294834137 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7334293189368624, 'log_learning_rate_D': -2.663501672272156, 'training_batch_size': 6, 'training_p': 3}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  19.494760036468506
Memory status after this trial: 
Memory allocated:  84.72119140625
Memory cached:  98.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2636864286547835, 'log_learning_rate_D': -3.6604927799474165, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4365234375
Memory cached:  8.0
[I 2023-11-01 10:44:36,824] Trial 25 finished with value: 0.22958433628082275 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2636864286547835, 'log_learning_rate_D': -3.6604927799474165, 'training_batch_size': 7, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.897860288619995
Memory status after this trial: 
Memory allocated:  78.64892578125
Memory cached:  108.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9480683057971167, 'log_learning_rate_D': -3.1651012082617123, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34375
Memory cached:  12.0
[I 2023-11-01 10:44:55,636] Trial 26 finished with value: 0.2294197529554367 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9480683057971167, 'log_learning_rate_D': -3.1651012082617123, 'training_batch_size': 6, 'training_p': 7}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  18.60518980026245
Memory status after this trial: 
Memory allocated:  53.60009765625
Memory cached:  74.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.643344327545771, 'log_learning_rate_D': -3.173448164361834, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  20 training error:  tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  40 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  60 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.3017578125
Memory cached:  28.0
[I 2023-11-01 10:45:12,600] Trial 27 finished with value: 0.2297399491071701 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.643344327545771, 'log_learning_rate_D': -3.173448164361834, 'training_batch_size': 8, 'training_p': 6}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.764267921447754
Memory status after this trial: 
Memory allocated:  64.65673828125
Memory cached:  72.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.951633613061401, 'log_learning_rate_D': -3.7145138880025073, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  10 training error:  tensor(8.4643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2294921875
Memory cached:  12.0
[I 2023-11-01 10:45:29,211] Trial 28 finished with value: 0.23196649551391602 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.951633613061401, 'log_learning_rate_D': -3.7145138880025073, 'training_batch_size': 7, 'training_p': 2}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  16.420974493026733
Memory status after this trial: 
Memory allocated:  59.84228515625
Memory cached:  80.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.2073150297570083, 'log_learning_rate_D': -4.441661332189772, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.33447265625
Memory cached:  8.0
[I 2023-11-01 10:45:47,663] Trial 29 finished with value: 0.22954869270324707 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.2073150297570083, 'log_learning_rate_D': -4.441661332189772, 'training_batch_size': 6, 'training_p': 5}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  18.263206958770752
Memory status after this trial: 
Memory allocated:  44.55517578125
Memory cached:  58.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.59386096772868, 'log_learning_rate_D': -4.974373327780501, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0712890625
Memory cached:  8.0
[I 2023-11-01 10:46:03,709] Trial 30 finished with value: 0.22967353463172913 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.59386096772868, 'log_learning_rate_D': -4.974373327780501, 'training_batch_size': 12, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  15.855982065200806
Memory status after this trial: 
Memory allocated:  60.21240234375
Memory cached:  88.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1976405197156272, 'log_learning_rate_D': -2.4274627574398027, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
[I 2023-11-01 10:46:22,208] Trial 31 finished with value: 0.23133516311645508 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1976405197156272, 'log_learning_rate_D': -2.4274627574398027, 'training_batch_size': 6, 'training_p': 8}. Best is trial 11 with value: 0.22407010197639465.
Time for this trial:  18.259145259857178
Memory status after this trial: 
Memory allocated:  37.27490234375
Memory cached:  52.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.4905054007786642, 'log_learning_rate_D': -2.557401656953585, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9072265625
Memory cached:  8.0
[I 2023-11-01 10:46:40,105] Trial 32 finished with value: 0.22297091782093048 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.4905054007786642, 'log_learning_rate_D': -2.557401656953585, 'training_batch_size': 6, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  17.65222716331482
Memory status after this trial: 
Memory allocated:  37.74365234375
Memory cached:  52.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.506532342220816, 'log_learning_rate_D': -3.1149525787688033, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8134765625
Memory cached:  8.0
[I 2023-11-01 10:46:56,187] Trial 33 finished with value: 0.22954781353473663 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.506532342220816, 'log_learning_rate_D': -3.1149525787688033, 'training_batch_size': 7, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  15.892451763153076
Memory status after this trial: 
Memory allocated:  54.88232421875
Memory cached:  76.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7252906866209177, 'log_learning_rate_D': -2.600113105634716, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.6041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7841796875
Memory cached:  10.0
[I 2023-11-01 10:47:12,912] Trial 34 finished with value: 0.22908249497413635 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7252906866209177, 'log_learning_rate_D': -2.600113105634716, 'training_batch_size': 8, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  16.534085035324097
Memory status after this trial: 
Memory allocated:  123.17236328125
Memory cached:  154.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.169113329274949, 'log_learning_rate_D': -2.078587613096996, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.36279296875
Memory cached:  12.0
[I 2023-11-01 10:47:27,621] Trial 35 finished with value: 0.2291344404220581 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.169113329274949, 'log_learning_rate_D': -2.078587613096996, 'training_batch_size': 7, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  14.517890214920044
Memory status after this trial: 
Memory allocated:  19.05615234375
Memory cached:  20.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.48316277988029, 'log_learning_rate_D': -2.872431712615107, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.39794921875
Memory cached:  30.0
[I 2023-11-01 10:47:46,366] Trial 36 finished with value: 0.2310875505208969 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.48316277988029, 'log_learning_rate_D': -2.872431712615107, 'training_batch_size': 6, 'training_p': 4}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  18.53607749938965
Memory status after this trial: 
Memory allocated:  67.70068359375
Memory cached:  94.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8651768846734775, 'log_learning_rate_D': -2.1118649827859057, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  20 training error:  tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  40 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8466796875
Memory cached:  28.0
[I 2023-11-01 10:48:02,020] Trial 37 finished with value: 0.22919054329395294 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8651768846734775, 'log_learning_rate_D': -2.1118649827859057, 'training_batch_size': 7, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  15.452670812606812
Memory status after this trial: 
Memory allocated:  60.23681640625
Memory cached:  68.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.04617912570902, 'log_learning_rate_D': -2.51644820945039, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.10546875
Memory cached:  4.0
[I 2023-11-01 10:48:16,633] Trial 38 finished with value: 0.22982163727283478 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.04617912570902, 'log_learning_rate_D': -2.51644820945039, 'training_batch_size': 6, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  14.4418363571167
Memory status after this trial: 
Memory allocated:  1.84228515625
Memory cached:  4.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.4604761502107095, 'log_learning_rate_D': -2.7921587576606055, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.51123046875
Memory cached:  6.0
[I 2023-11-01 10:48:31,181] Trial 39 finished with value: 0.22981686890125275 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.4604761502107095, 'log_learning_rate_D': -2.7921587576606055, 'training_batch_size': 9, 'training_p': 6}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  14.341586589813232
Memory status after this trial: 
Memory allocated:  22.45361328125
Memory cached:  32.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.3583252947439663, 'log_learning_rate_D': -3.028868763462479, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.14404296875
Memory cached:  2.0
[I 2023-11-01 10:48:45,722] Trial 40 finished with value: 0.22968201339244843 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.3583252947439663, 'log_learning_rate_D': -3.028868763462479, 'training_batch_size': 11, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  14.34635591506958
Memory status after this trial: 
Memory allocated:  31.27197265625
Memory cached:  40.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1968138693753163, 'log_learning_rate_D': -2.3546301775930263, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.923828125
Memory cached:  26.0
[I 2023-11-01 10:49:03,404] Trial 41 finished with value: 0.22696690261363983 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1968138693753163, 'log_learning_rate_D': -2.3546301775930263, 'training_batch_size': 6, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  17.41771650314331
Memory status after this trial: 
Memory allocated:  37.27490234375
Memory cached:  52.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.610850996172032, 'log_learning_rate_D': -2.231885571208121, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  20 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  60 training error:  tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  80 training error:  tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.181640625
Memory cached:  28.0
[I 2023-11-01 10:49:21,684] Trial 42 finished with value: 0.22383205592632294 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.610850996172032, 'log_learning_rate_D': -2.231885571208121, 'training_batch_size': 6, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  18.063440799713135
Memory status after this trial: 
Memory allocated:  66.95654296875
Memory cached:  94.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8229049749221065, 'log_learning_rate_D': -1.8384629701152355, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6943359375
Memory cached:  12.0
[I 2023-11-01 10:49:37,905] Trial 43 finished with value: 0.22953703999519348 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8229049749221065, 'log_learning_rate_D': -1.8384629701152355, 'training_batch_size': 7, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  16.015779972076416
Memory status after this trial: 
Memory allocated:  64.99365234375
Memory cached:  94.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.6387649810337006, 'log_learning_rate_D': -2.595460103311484, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.49462890625
Memory cached:  10.0
[I 2023-11-01 10:49:57,379] Trial 44 finished with value: 0.22931928932666779 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.6387649810337006, 'log_learning_rate_D': -2.595460103311484, 'training_batch_size': 6, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  19.24679470062256
Memory status after this trial: 
Memory allocated:  102.47021484375
Memory cached:  124.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.0367432421069274, 'log_learning_rate_D': -2.1426334296007186, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37890625
Memory cached:  10.0
[I 2023-11-01 10:50:15,033] Trial 45 finished with value: 0.22309322655200958 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.0367432421069274, 'log_learning_rate_D': -2.1426334296007186, 'training_batch_size': 6, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  17.462315559387207
Memory status after this trial: 
Memory allocated:  63.17333984375
Memory cached:  70.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.308757923058446, 'log_learning_rate_D': -1.621251980699188, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.84375
Memory cached:  8.0
[I 2023-11-01 10:50:33,731] Trial 46 finished with value: 0.22694960236549377 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.308757923058446, 'log_learning_rate_D': -1.621251980699188, 'training_batch_size': 6, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  18.495136260986328
Memory status after this trial: 
Memory allocated:  92.57275390625
Memory cached:  106.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.0431219323768937, 'log_learning_rate_D': -2.1631099556734967, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69140625
Memory cached:  6.0
[I 2023-11-01 10:50:49,958] Trial 47 finished with value: 0.2302674502134323 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.0431219323768937, 'log_learning_rate_D': -2.1631099556734967, 'training_batch_size': 7, 'training_p': 3}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  16.03947377204895
Memory status after this trial: 
Memory allocated:  77.88037109375
Memory cached:  90.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.542610265423705, 'log_learning_rate_D': -2.239785555570213, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6650390625
Memory cached:  16.0
[I 2023-11-01 10:51:07,058] Trial 48 finished with value: 0.2303837388753891 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.542610265423705, 'log_learning_rate_D': -2.239785555570213, 'training_batch_size': 8, 'training_p': 8}. Best is trial 32 with value: 0.22297091782093048.
Time for this trial:  16.88655972480774
Memory status after this trial: 
Memory allocated:  107.07958984375
Memory cached:  114.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -4.996586505790113, 'log_learning_rate_D': -1.9785709203877655, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.9205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.8763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.8492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.8179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8759765625
Memory cached:  8.0
[I 2023-11-01 10:51:23,016] Trial 49 finished with value: 0.7633060812950134 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -4.996586505790113, 'log_learning_rate_D': -1.9785709203877655, 'training_batch_size': 7, 'training_p': 7}. Best is trial 32 with value: 0.22297091782093048.
[I 2023-11-01 10:51:23,017] A new study created in memory with name: no-name-6cd0a233-c1b9-4482-8545-63440ac929f3
Time for this trial:  15.765499591827393
Memory status after this trial: 
Memory allocated:  52.24755859375
Memory cached:  66.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.3797103425145028, 'log_learning_rate_D': -3.2247800797004893, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7685546875
Memory cached:  18.0
[I 2023-11-01 10:53:17,442] Trial 0 finished with value: 0.23171578347682953 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.3797103425145028, 'log_learning_rate_D': -3.2247800797004893, 'training_batch_size': 10, 'training_p': 7}. Best is trial 0 with value: 0.23171578347682953.
Time for this trial:  114.31876969337463
Memory status after this trial: 
Memory allocated:  85.27099609375
Memory cached:  88.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.3497854543429764, 'log_learning_rate_D': -3.685980776119709, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  16.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3623046875
Memory cached:  16.0
[I 2023-11-01 10:56:22,063] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.3497854543429764, 'log_learning_rate_D': -3.685980776119709, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.23171578347682953.
Time for this trial:  184.48331093788147
Memory status after this trial: 
Memory allocated:  119.298828125
Memory cached:  122.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.5581611667183517, 'log_learning_rate_D': -2.339835416522552, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  20.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  26.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  28.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  30.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  30.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  26.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  30.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  26.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  26.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5712890625
Memory cached:  26.0
[I 2023-11-01 10:59:39,337] Trial 2 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.5581611667183517, 'log_learning_rate_D': -2.339835416522552, 'training_batch_size': 10, 'training_p': 6}. Best is trial 0 with value: 0.23171578347682953.
Time for this trial:  197.12994742393494
Memory status after this trial: 
Memory allocated:  208.98681640625
Memory cached:  212.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.744476236796169, 'log_learning_rate_D': -1.78857576397853, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.5630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4306640625
Memory cached:  18.0
[I 2023-11-01 11:02:10,910] Trial 3 finished with value: 0.2317526787519455 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.744476236796169, 'log_learning_rate_D': -1.78857576397853, 'training_batch_size': 7, 'training_p': 2}. Best is trial 0 with value: 0.23171578347682953.
Time for this trial:  151.4346296787262
Memory status after this trial: 
Memory allocated:  124.2509765625
Memory cached:  128.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.4868017333376153, 'log_learning_rate_D': -1.760448825556625, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  42.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  44.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  42.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  42.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  44.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  44.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  42.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5205078125
Memory cached:  44.0
[I 2023-11-01 11:04:39,115] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.4868017333376153, 'log_learning_rate_D': -1.760448825556625, 'training_batch_size': 12, 'training_p': 8}. Best is trial 0 with value: 0.23171578347682953.
Time for this trial:  148.04913210868835
Memory status after this trial: 
Memory allocated:  185.00341796875
Memory cached:  200.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.4913460992816487, 'log_learning_rate_D': -2.455355198031981, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5595703125
Memory cached:  48.0
[I 2023-11-01 11:07:44,145] Trial 5 finished with value: 0.22946058213710785 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.4913460992816487, 'log_learning_rate_D': -2.455355198031981, 'training_batch_size': 10, 'training_p': 6}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  184.8848123550415
Memory status after this trial: 
Memory allocated:  238.22900390625
Memory cached:  260.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.740346306247191, 'log_learning_rate_D': -3.2830210186437756, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0908203125
Memory cached:  4.0
[I 2023-11-01 11:09:05,723] Trial 6 finished with value: 0.23356805741786957 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.740346306247191, 'log_learning_rate_D': -3.2830210186437756, 'training_batch_size': 9, 'training_p': 2}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  81.45077347755432
Memory status after this trial: 
Memory allocated:  8.49755859375
Memory cached:  10.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.211259994294368, 'log_learning_rate_D': -2.516800381922915, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3466796875
Memory cached:  38.0
[I 2023-11-01 11:14:19,085] Trial 7 finished with value: 0.2311638444662094 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.211259994294368, 'log_learning_rate_D': -2.516800381922915, 'training_batch_size': 6, 'training_p': 2}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  313.2154748439789
Memory status after this trial: 
Memory allocated:  247.92431640625
Memory cached:  264.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.2014697734543964, 'log_learning_rate_D': -2.8973244755801506, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  16.0
	 epoch  10 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  50 training error:  tensor(1.5808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6591796875
Memory cached:  20.0
[I 2023-11-01 11:16:51,858] Trial 8 finished with value: 0.2395380288362503 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.2014697734543964, 'log_learning_rate_D': -2.8973244755801506, 'training_batch_size': 9, 'training_p': 2}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  152.6300060749054
Memory status after this trial: 
Memory allocated:  126.17919921875
Memory cached:  130.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.173915432857503, 'log_learning_rate_D': -4.464810407487249, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9287109375
Memory cached:  18.0
[I 2023-11-01 11:19:04,129] Trial 9 finished with value: 0.23209011554718018 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.173915432857503, 'log_learning_rate_D': -4.464810407487249, 'training_batch_size': 10, 'training_p': 2}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  132.10952234268188
Memory status after this trial: 
Memory allocated:  110.76416015625
Memory cached:  116.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.942846115121867, 'log_learning_rate_D': -1.0461831219726487, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.6666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5732421875
Memory cached:  44.0
[I 2023-11-01 11:21:55,952] Trial 10 finished with value: 0.22964178025722504 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.942846115121867, 'log_learning_rate_D': -1.0461831219726487, 'training_batch_size': 12, 'training_p': 5}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  171.61636447906494
Memory status after this trial: 
Memory allocated:  307.8330078125
Memory cached:  322.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.731497218721476, 'log_learning_rate_D': -1.2267972466103756, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.7951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.2919921875
Memory cached:  46.0
[I 2023-11-01 11:24:47,624] Trial 11 finished with value: 0.23104505240917206 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.731497218721476, 'log_learning_rate_D': -1.2267972466103756, 'training_batch_size': 12, 'training_p': 5}. Best is trial 5 with value: 0.22946058213710785.
Time for this trial:  171.45809960365295
Memory status after this trial: 
Memory allocated:  307.015625
Memory cached:  322.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.9019846891312895, 'log_learning_rate_D': -1.0130347644650621, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.8140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.6771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9638671875
Memory cached:  24.0
[I 2023-11-01 11:27:33,308] Trial 12 finished with value: 0.22837500274181366 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.9019846891312895, 'log_learning_rate_D': -1.0130347644650621, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  165.48107838630676
Memory status after this trial: 
Memory allocated:  235.36083984375
Memory cached:  240.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.850132583516188, 'log_learning_rate_D': -1.814933355764214, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  20.0
[I 2023-11-01 11:30:20,004] Trial 13 finished with value: 0.23067200183868408 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.850132583516188, 'log_learning_rate_D': -1.814933355764214, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  166.48835039138794
Memory status after this trial: 
Memory allocated:  228.70458984375
Memory cached:  234.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.312442010172206, 'log_learning_rate_D': -1.1829777322508654, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.3513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.5966796875
Memory cached:  42.0
[I 2023-11-01 11:32:55,037] Trial 14 finished with value: 0.22897830605506897 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.312442010172206, 'log_learning_rate_D': -1.1829777322508654, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  154.7954421043396
Memory status after this trial: 
Memory allocated:  187.79443359375
Memory cached:  210.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3209886315557857, 'log_learning_rate_D': -1.1774684601491452, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3310546875
Memory cached:  38.0
[I 2023-11-01 11:35:08,128] Trial 15 finished with value: 0.23017287254333496 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3209886315557857, 'log_learning_rate_D': -1.1774684601491452, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  132.90441799163818
Memory status after this trial: 
Memory allocated:  130.86962890625
Memory cached:  150.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.0908264062055126, 'log_learning_rate_D': -1.0141816668631372, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  34.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.2939453125
Memory cached:  36.0
[I 2023-11-01 11:37:47,566] Trial 16 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.0908264062055126, 'log_learning_rate_D': -1.0141816668631372, 'training_batch_size': 11, 'training_p': 3}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  159.2246458530426
Memory status after this trial: 
Memory allocated:  201.955078125
Memory cached:  222.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.1295345402078105, 'log_learning_rate_D': -1.5667428784246398, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3544921875
Memory cached:  12.0
[I 2023-11-01 11:40:07,406] Trial 17 finished with value: 0.23012962937355042 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.1295345402078105, 'log_learning_rate_D': -1.5667428784246398, 'training_batch_size': 8, 'training_p': 3}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  139.62730169296265
Memory status after this trial: 
Memory allocated:  115.27099609375
Memory cached:  118.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6190197852054715, 'log_learning_rate_D': -2.0267680537230683, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4384765625
Memory cached:  18.0
[I 2023-11-01 11:42:57,573] Trial 18 finished with value: 0.23036503791809082 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6190197852054715, 'log_learning_rate_D': -2.0267680537230683, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  169.94071912765503
Memory status after this trial: 
Memory allocated:  162.75244140625
Memory cached:  168.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.9019520069071727, 'log_learning_rate_D': -1.3381140530017606, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  34.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  40.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  38.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  38.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  38.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  38.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3779296875
Memory cached:  40.0
[I 2023-11-01 11:44:59,381] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.9019520069071727, 'log_learning_rate_D': -1.3381140530017606, 'training_batch_size': 8, 'training_p': 3}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  121.60555744171143
Memory status after this trial: 
Memory allocated:  158.4990234375
Memory cached:  178.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.0650067813653714, 'log_learning_rate_D': -1.4374250491396645, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9951171875
Memory cached:  12.0
[I 2023-11-01 11:47:10,741] Trial 20 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.0650067813653714, 'log_learning_rate_D': -1.4374250491396645, 'training_batch_size': 12, 'training_p': 6}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  131.1592881679535
Memory status after this trial: 
Memory allocated:  50.1259765625
Memory cached:  52.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.4899191907936875, 'log_learning_rate_D': -2.200487213518848, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  62.0
	 epoch  10 training error:  tensor(1.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  70.0
	 epoch  20 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  70.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.9964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.6338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  66.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  68.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  70.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  66.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6748046875
Memory cached:  66.0
[I 2023-11-01 11:50:26,220] Trial 21 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.4899191907936875, 'log_learning_rate_D': -2.200487213518848, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  195.21839833259583
Memory status after this trial: 
Memory allocated:  301.45263671875
Memory cached:  334.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.492808531884625, 'log_learning_rate_D': -1.4868494449431529, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.7861328125
Memory cached:  26.0
[I 2023-11-01 11:53:36,337] Trial 22 finished with value: 0.23009991645812988 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.492808531884625, 'log_learning_rate_D': -1.4868494449431529, 'training_batch_size': 11, 'training_p': 7}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  189.87055134773254
Memory status after this trial: 
Memory allocated:  239.84130859375
Memory cached:  246.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.8976023539110205, 'log_learning_rate_D': -1.9924590631500747, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9599609375
Memory cached:  46.0
[I 2023-11-01 11:56:04,425] Trial 23 finished with value: 0.23089340329170227 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.8976023539110205, 'log_learning_rate_D': -1.9924590631500747, 'training_batch_size': 10, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  147.86034989356995
Memory status after this trial: 
Memory allocated:  176.59619140625
Memory cached:  196.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.524504973737843, 'log_learning_rate_D': -2.489742421127131, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3447265625
Memory cached:  22.0
[I 2023-11-01 11:59:08,417] Trial 24 finished with value: 0.22885452210903168 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.524504973737843, 'log_learning_rate_D': -2.489742421127131, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  183.748877286911
Memory status after this trial: 
Memory allocated:  235.00439453125
Memory cached:  240.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.87580991740123, 'log_learning_rate_D': -1.016129780046083, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0615234375
Memory cached:  40.0
[I 2023-11-01 12:02:17,770] Trial 25 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.87580991740123, 'log_learning_rate_D': -1.016129780046083, 'training_batch_size': 8, 'training_p': 5}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  189.1011300086975
Memory status after this trial: 
Memory allocated:  261.96875
Memory cached:  278.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.0796381488892077, 'log_learning_rate_D': -1.572833242781456, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1162109375
Memory cached:  20.0
[I 2023-11-01 12:05:06,882] Trial 26 finished with value: 0.9982656836509705 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.0796381488892077, 'log_learning_rate_D': -1.572833242781456, 'training_batch_size': 9, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  168.87389707565308
Memory status after this trial: 
Memory allocated:  159.68017578125
Memory cached:  164.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.6096504223078445, 'log_learning_rate_D': -2.6592869777952983, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  36.0
	 epoch  10 training error:  tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.9959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.4638671875
Memory cached:  44.0
[I 2023-11-01 12:08:05,088] Trial 27 finished with value: 0.23613910377025604 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.6096504223078445, 'log_learning_rate_D': -2.6592869777952983, 'training_batch_size': 9, 'training_p': 3}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  177.96406054496765
Memory status after this trial: 
Memory allocated:  274.32666015625
Memory cached:  298.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.189524094057584, 'log_learning_rate_D': -2.0991395016630574, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1298828125
Memory cached:  18.0
[I 2023-11-01 12:10:40,767] Trial 28 finished with value: 0.23013810813426971 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.189524094057584, 'log_learning_rate_D': -2.0991395016630574, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  155.43976140022278
Memory status after this trial: 
Memory allocated:  110.43115234375
Memory cached:  114.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.40645556854264, 'log_learning_rate_D': -1.325808124031832, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  22.0
[I 2023-11-01 12:12:59,416] Trial 29 finished with value: 0.2292451113462448 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.40645556854264, 'log_learning_rate_D': -1.325808124031832, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  138.43858647346497
Memory status after this trial: 
Memory allocated:  132.5078125
Memory cached:  136.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.9764922201237796, 'log_learning_rate_D': -1.6666959946461284, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0654296875
Memory cached:  18.0
[I 2023-11-01 12:15:30,681] Trial 30 finished with value: 0.23070266842842102 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.9764922201237796, 'log_learning_rate_D': -1.6666959946461284, 'training_batch_size': 8, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  151.03888368606567
Memory status after this trial: 
Memory allocated:  126.89208984375
Memory cached:  130.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.2637951972710777, 'log_learning_rate_D': -1.3271865680791126, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1533203125
Memory cached:  14.0
[I 2023-11-01 12:17:49,800] Trial 31 finished with value: 0.2293010801076889 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.2637951972710777, 'log_learning_rate_D': -1.3271865680791126, 'training_batch_size': 10, 'training_p': 8}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  138.90201330184937
Memory status after this trial: 
Memory allocated:  132.5078125
Memory cached:  136.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.6748548712217675, 'log_learning_rate_D': -1.2991665289316678, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2626953125
Memory cached:  16.0
[I 2023-11-01 12:20:11,143] Trial 32 finished with value: 0.2294849008321762 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.6748548712217675, 'log_learning_rate_D': -1.2991665289316678, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  141.1288845539093
Memory status after this trial: 
Memory allocated:  152.84814453125
Memory cached:  158.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.451898430231429, 'log_learning_rate_D': -1.8748540580437603, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6611328125
Memory cached:  18.0
[I 2023-11-01 12:22:30,427] Trial 33 finished with value: 0.2304503470659256 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.451898430231429, 'log_learning_rate_D': -1.8748540580437603, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  139.07258009910583
Memory status after this trial: 
Memory allocated:  141.85791015625
Memory cached:  146.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.886476762449682, 'log_learning_rate_D': -2.199310529241288, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.6044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4169921875
Memory cached:  16.0
[I 2023-11-01 12:25:05,127] Trial 34 finished with value: 0.2316162884235382 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.886476762449682, 'log_learning_rate_D': -2.199310529241288, 'training_batch_size': 9, 'training_p': 6}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  154.45594930648804
Memory status after this trial: 
Memory allocated:  100.9638671875
Memory cached:  102.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.5331026899161393, 'log_learning_rate_D': -1.6155405115532362, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6240234375
Memory cached:  18.0
[I 2023-11-01 12:28:01,852] Trial 35 finished with value: 0.22966884076595306 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.5331026899161393, 'log_learning_rate_D': -1.6155405115532362, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  176.45839667320251
Memory status after this trial: 
Memory allocated:  201.3408203125
Memory cached:  208.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.3877519866654273, 'log_learning_rate_D': -1.8428140542146336, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9521484375
Memory cached:  12.0
[I 2023-11-01 12:29:59,774] Trial 36 finished with value: 0.23047566413879395 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.3877519866654273, 'log_learning_rate_D': -1.8428140542146336, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  117.69887804985046
Memory status after this trial: 
Memory allocated:  81.47900390625
Memory cached:  84.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.852591961692083, 'log_learning_rate_D': -1.2251536481897016, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.7005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4287109375
Memory cached:  18.0
[I 2023-11-01 12:32:29,610] Trial 37 finished with value: 0.22882024943828583 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.852591961692083, 'log_learning_rate_D': -1.2251536481897016, 'training_batch_size': 9, 'training_p': 8}. Best is trial 12 with value: 0.22837500274181366.
Time for this trial:  149.60253429412842
Memory status after this trial: 
Memory allocated:  107.54443359375
Memory cached:  110.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.900608727998767, 'log_learning_rate_D': -1.1701026014970386, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.8748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7470703125
Memory cached:  20.0
[I 2023-11-01 12:35:15,073] Trial 38 finished with value: 0.22650623321533203 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.900608727998767, 'log_learning_rate_D': -1.1701026014970386, 'training_batch_size': 7, 'training_p': 8}. Best is trial 38 with value: 0.22650623321533203.
Time for this trial:  165.21468925476074
Memory status after this trial: 
Memory allocated:  171.0771484375
Memory cached:  174.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.045503508857432, 'log_learning_rate_D': -2.2991741717370617, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4130859375
Memory cached:  18.0
[I 2023-11-01 12:39:19,892] Trial 39 finished with value: 0.23126116394996643 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.045503508857432, 'log_learning_rate_D': -2.2991741717370617, 'training_batch_size': 6, 'training_p': 8}. Best is trial 38 with value: 0.22650623321533203.
Time for this trial:  244.57718062400818
Memory status after this trial: 
Memory allocated:  165.04638671875
Memory cached:  168.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.36036650786345, 'log_learning_rate_D': -1.5295784036847329, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.6807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6416015625
Memory cached:  18.0
[I 2023-11-01 12:42:05,143] Trial 40 finished with value: 0.23039817810058594 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.36036650786345, 'log_learning_rate_D': -1.5295784036847329, 'training_batch_size': 7, 'training_p': 8}. Best is trial 38 with value: 0.22650623321533203.
Time for this trial:  164.9991044998169
Memory status after this trial: 
Memory allocated:  119.96240234375
Memory cached:  122.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.894150948137643, 'log_learning_rate_D': -1.17075346067279, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.7360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5146484375
Memory cached:  20.0
[I 2023-11-01 12:44:39,309] Trial 41 finished with value: 0.2301541417837143 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.894150948137643, 'log_learning_rate_D': -1.17075346067279, 'training_batch_size': 7, 'training_p': 8}. Best is trial 38 with value: 0.22650623321533203.
Time for this trial:  153.91698384284973
Memory status after this trial: 
Memory allocated:  139.0224609375
Memory cached:  142.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.45266921893699, 'log_learning_rate_D': -1.047808810815497, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.9411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4052734375
Memory cached:  14.0
[I 2023-11-01 12:47:09,782] Trial 42 finished with value: 0.9992431998252869 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.45266921893699, 'log_learning_rate_D': -1.047808810815497, 'training_batch_size': 8, 'training_p': 4}. Best is trial 38 with value: 0.22650623321533203.
Time for this trial:  150.22649240493774
Memory status after this trial: 
Memory allocated:  110.91650390625
Memory cached:  114.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.9761860750429845, 'log_learning_rate_D': -1.4190106680044419, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.7530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.6710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0009765625
Memory cached:  18.0
[I 2023-11-01 12:49:57,427] Trial 43 finished with value: 0.22582463920116425 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.9761860750429845, 'log_learning_rate_D': -1.4190106680044419, 'training_batch_size': 9, 'training_p': 8}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  167.39102411270142
Memory status after this trial: 
Memory allocated:  180.6318359375
Memory cached:  184.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -4.911304799974725, 'log_learning_rate_D': -1.6437276283512703, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.1767578125
Memory cached:  46.0
[I 2023-11-01 12:53:09,091] Trial 44 finished with value: 0.2303217500448227 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -4.911304799974725, 'log_learning_rate_D': -1.6437276283512703, 'training_batch_size': 9, 'training_p': 8}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  191.39768648147583
Memory status after this trial: 
Memory allocated:  271.1826171875
Memory cached:  288.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.698398847599918, 'log_learning_rate_D': -1.3905713468580665, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.8017578125
Memory cached:  36.0
[I 2023-11-01 12:58:01,133] Trial 45 finished with value: 0.22920647263526917 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.698398847599918, 'log_learning_rate_D': -1.3905713468580665, 'training_batch_size': 6, 'training_p': 8}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  291.7685627937317
Memory status after this trial: 
Memory allocated:  197.626953125
Memory cached:  216.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.716818279741299, 'log_learning_rate_D': -1.7361677911553102, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.9499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.8851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.5893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9716796875
Memory cached:  24.0
[I 2023-11-01 13:01:01,762] Trial 46 finished with value: 0.22722120583057404 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.716818279741299, 'log_learning_rate_D': -1.7361677911553102, 'training_batch_size': 9, 'training_p': 7}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  180.36512756347656
Memory status after this trial: 
Memory allocated:  225.43359375
Memory cached:  230.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.708824406445817, 'log_learning_rate_D': -1.7465681202722614, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1611328125
Memory cached:  36.0
[I 2023-11-01 13:04:13,610] Trial 47 finished with value: 0.22775495052337646 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.708824406445817, 'log_learning_rate_D': -1.7465681202722614, 'training_batch_size': 7, 'training_p': 7}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  191.58084416389465
Memory status after this trial: 
Memory allocated:  266.3349609375
Memory cached:  272.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.979872456730233, 'log_learning_rate_D': -1.815735857207068, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.9635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.9165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.7776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  28.0
	 epoch  60 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1611328125
Memory cached:  32.0
[I 2023-11-01 13:07:27,388] Trial 48 finished with value: 0.23001964390277863 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.979872456730233, 'log_learning_rate_D': -1.815735857207068, 'training_batch_size': 7, 'training_p': 7}. Best is trial 43 with value: 0.22582463920116425.
Time for this trial:  193.49927616119385
Memory status after this trial: 
Memory allocated:  268.5439453125
Memory cached:  274.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.632303693444999, 'log_learning_rate_D': -1.6966874500009896, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.9286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  28.0
	 epoch  50 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  28.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  28.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.9443359375
Memory cached:  26.0
[I 2023-11-01 13:12:39,609] Trial 49 finished with value: 0.22974836826324463 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.632303693444999, 'log_learning_rate_D': -1.6966874500009896, 'training_batch_size': 6, 'training_p': 7}. Best is trial 43 with value: 0.22582463920116425.
[I 2023-11-01 13:12:39,641] A new study created in memory with name: no-name-951c49d1-3344-4e0e-88c7-e20f9b93b52f
Time for this trial:  311.90999007225037
Memory status after this trial: 
Memory allocated:  228.3681640625
Memory cached:  234.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1726527207370694, 'log_learning_rate_D': -3.3892351299630645, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(5.9924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4326171875
Memory cached:  10.0
[I 2023-11-01 13:16:03,240] Trial 0 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1726527207370694, 'log_learning_rate_D': -3.3892351299630645, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  203.48053908348083
Memory status after this trial: 
Memory allocated:  49.0517578125
Memory cached:  50.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.9540211642020653, 'log_learning_rate_D': -2.5361786306318925, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  62.0
	 epoch  10 training error:  tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.23828125
Memory cached:  64.0
[I 2023-11-01 13:19:13,642] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.9540211642020653, 'log_learning_rate_D': -2.5361786306318925, 'training_batch_size': 8, 'training_p': 7}. Best is trial 0 with value: 1.0.
Time for this trial:  190.25232934951782
Memory status after this trial: 
Memory allocated:  252.578125
Memory cached:  264.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.450969182303236, 'log_learning_rate_D': -3.288021621307584, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.6142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.45703125
Memory cached:  20.0
[I 2023-11-01 13:21:53,618] Trial 2 finished with value: 0.23090746998786926 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.450969182303236, 'log_learning_rate_D': -3.288021621307584, 'training_batch_size': 12, 'training_p': 5}. Best is trial 2 with value: 0.23090746998786926.
Time for this trial:  159.83648204803467
Memory status after this trial: 
Memory allocated:  182.3515625
Memory cached:  188.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.1948706638802604, 'log_learning_rate_D': -4.944932041697978, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.234375
Memory cached:  12.0
[I 2023-11-01 13:23:35,948] Trial 3 finished with value: 0.23234446346759796 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.1948706638802604, 'log_learning_rate_D': -4.944932041697978, 'training_batch_size': 12, 'training_p': 2}. Best is trial 2 with value: 0.23090746998786926.
Time for this trial:  102.19440984725952
Memory status after this trial: 
Memory allocated:  59.6943359375
Memory cached:  62.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.7430564664614905, 'log_learning_rate_D': -1.751761999839776, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.373046875
Memory cached:  66.0
[I 2023-11-01 13:27:12,903] Trial 4 finished with value: 0.22876401245594025 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.7430564664614905, 'log_learning_rate_D': -1.751761999839776, 'training_batch_size': 10, 'training_p': 7}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  216.81499195098877
Memory status after this trial: 
Memory allocated:  339.5048828125
Memory cached:  372.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.59405625816766, 'log_learning_rate_D': -1.604371924191415, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.5989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.94921875
Memory cached:  18.0
[I 2023-11-01 13:29:37,974] Trial 5 finished with value: 0.22939078509807587 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.59405625816766, 'log_learning_rate_D': -1.604371924191415, 'training_batch_size': 7, 'training_p': 7}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  144.90253138542175
Memory status after this trial: 
Memory allocated:  154.7412109375
Memory cached:  160.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.930173386331513, 'log_learning_rate_D': -4.916895986190077, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.591796875
Memory cached:  12.0
[I 2023-11-01 13:31:03,554] Trial 6 finished with value: 0.23295103013515472 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.930173386331513, 'log_learning_rate_D': -4.916895986190077, 'training_batch_size': 11, 'training_p': 3}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  85.44615817070007
Memory status after this trial: 
Memory allocated:  26.3681640625
Memory cached:  28.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -1.4088182822225765, 'log_learning_rate_D': -1.2877304948084074, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  18.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.701171875
Memory cached:  24.0
[I 2023-11-01 13:33:57,319] Trial 7 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -1.4088182822225765, 'log_learning_rate_D': -1.2877304948084074, 'training_batch_size': 12, 'training_p': 2}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  173.6300654411316
Memory status after this trial: 
Memory allocated:  196.2392578125
Memory cached:  200.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.7209987763834573, 'log_learning_rate_D': -2.736865269533217, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  20 training error:  tensor(300.9760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7822265625
Memory cached:  36.0
[I 2023-11-01 13:38:20,483] Trial 8 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.7209987763834573, 'log_learning_rate_D': -2.736865269533217, 'training_batch_size': 6, 'training_p': 2}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  263.0025243759155
Memory status after this trial: 
Memory allocated:  184.06640625
Memory cached:  202.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.189470203565061, 'log_learning_rate_D': -4.125548303386069, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.7430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.5859375
Memory cached:  44.0
[I 2023-11-01 13:41:15,720] Trial 9 finished with value: 0.2318335622549057 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.189470203565061, 'log_learning_rate_D': -4.125548303386069, 'training_batch_size': 12, 'training_p': 7}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  175.07919692993164
Memory status after this trial: 
Memory allocated:  218.068359375
Memory cached:  240.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.462640109927598, 'log_learning_rate_D': -1.8235534421576416, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  58.0
[I 2023-11-01 13:44:13,340] Trial 10 finished with value: 0.22902126610279083 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.462640109927598, 'log_learning_rate_D': -1.8235534421576416, 'training_batch_size': 10, 'training_p': 5}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  177.4047393798828
Memory status after this trial: 
Memory allocated:  313.21533203125
Memory cached:  336.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4998634507523243, 'log_learning_rate_D': -1.9022008923617455, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.921875
Memory cached:  80.0
[I 2023-11-01 13:47:10,520] Trial 11 finished with value: 0.2296757698059082 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4998634507523243, 'log_learning_rate_D': -1.9022008923617455, 'training_batch_size': 10, 'training_p': 5}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  176.97167229652405
Memory status after this trial: 
Memory allocated:  313.21533203125
Memory cached:  336.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.5446891264786693, 'log_learning_rate_D': -2.024826882566206, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.357421875
Memory cached:  44.0
[I 2023-11-01 13:50:07,379] Trial 12 finished with value: 0.22971172630786896 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.5446891264786693, 'log_learning_rate_D': -2.024826882566206, 'training_batch_size': 9, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  176.64233899116516
Memory status after this trial: 
Memory allocated:  292.30078125
Memory cached:  318.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.6068204138592455, 'log_learning_rate_D': -1.1257190012509564, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.763671875
Memory cached:  42.0
[I 2023-11-01 13:52:44,820] Trial 13 finished with value: 0.9999998211860657 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.6068204138592455, 'log_learning_rate_D': -1.1257190012509564, 'training_batch_size': 10, 'training_p': 6}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  157.2284095287323
Memory status after this trial: 
Memory allocated:  247.05224609375
Memory cached:  270.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.940665626282062, 'log_learning_rate_D': -2.095125687331561, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.7444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.962890625
Memory cached:  16.0
[I 2023-11-01 13:55:15,662] Trial 14 finished with value: 0.23324894905090332 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.940665626282062, 'log_learning_rate_D': -2.095125687331561, 'training_batch_size': 10, 'training_p': 4}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  150.62638354301453
Memory status after this trial: 
Memory allocated:  128.982421875
Memory cached:  134.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.775236943370528, 'log_learning_rate_D': -1.0941940915387844, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.9341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.9024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.8321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.7910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.6906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.48046875
Memory cached:  58.0
[I 2023-11-01 13:58:11,386] Trial 15 finished with value: 0.4499532878398895 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.775236943370528, 'log_learning_rate_D': -1.0941940915387844, 'training_batch_size': 9, 'training_p': 6}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  175.48949646949768
Memory status after this trial: 
Memory allocated:  226.17724609375
Memory cached:  238.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.792412238873532, 'log_learning_rate_D': -2.389144862234784, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.580078125
Memory cached:  20.0
[I 2023-11-01 14:01:10,793] Trial 16 finished with value: 0.23268382251262665 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.792412238873532, 'log_learning_rate_D': -2.389144862234784, 'training_batch_size': 8, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  179.16738510131836
Memory status after this trial: 
Memory allocated:  215.736328125
Memory cached:  220.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.8922536070422717, 'log_learning_rate_D': -1.6182190725515584, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9921875
Memory cached:  14.0
[I 2023-11-01 14:03:25,059] Trial 17 finished with value: 0.22907285392284393 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.8922536070422717, 'log_learning_rate_D': -1.6182190725515584, 'training_batch_size': 11, 'training_p': 6}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  134.03203105926514
Memory status after this trial: 
Memory allocated:  127.45458984375
Memory cached:  132.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.49291539931151, 'log_learning_rate_D': -1.501382436398622, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.498046875
Memory cached:  38.0
[I 2023-11-01 14:06:36,401] Trial 18 finished with value: 0.2304675132036209 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.49291539931151, 'log_learning_rate_D': -1.501382436398622, 'training_batch_size': 11, 'training_p': 5}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  191.104900598526
Memory status after this trial: 
Memory allocated:  205.755859375
Memory cached:  226.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.1104949064221623, 'log_learning_rate_D': -2.054211323013951, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71484375
Memory cached:  36.0
[I 2023-11-01 14:09:02,529] Trial 19 finished with value: 0.2297016680240631 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.1104949064221623, 'log_learning_rate_D': -2.054211323013951, 'training_batch_size': 8, 'training_p': 4}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  145.89567017555237
Memory status after this trial: 
Memory allocated:  174.60009765625
Memory cached:  194.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.6142475580333184, 'log_learning_rate_D': -2.9125923041687436, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.671875
Memory cached:  28.0
[I 2023-11-01 14:11:31,039] Trial 20 finished with value: 0.23422765731811523 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.6142475580333184, 'log_learning_rate_D': -2.9125923041687436, 'training_batch_size': 10, 'training_p': 4}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  148.297189950943
Memory status after this trial: 
Memory allocated:  181.88916015625
Memory cached:  190.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.9268859909815665, 'log_learning_rate_D': -1.618495218727051, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9296875
Memory cached:  16.0
[I 2023-11-01 14:13:44,740] Trial 21 finished with value: 0.22974471747875214 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.9268859909815665, 'log_learning_rate_D': -1.618495218727051, 'training_batch_size': 11, 'training_p': 6}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  133.49369359016418
Memory status after this trial: 
Memory allocated:  124.03955078125
Memory cached:  128.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.961301053187617, 'log_learning_rate_D': -1.6484078447419384, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.767578125
Memory cached:  36.0
[I 2023-11-01 14:16:23,162] Trial 22 finished with value: 0.9995579719543457 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.961301053187617, 'log_learning_rate_D': -1.6484078447419384, 'training_batch_size': 11, 'training_p': 6}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  158.20203685760498
Memory status after this trial: 
Memory allocated:  200.36376953125
Memory cached:  220.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.211386091804357, 'log_learning_rate_D': -1.0464882412545111, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.244140625
Memory cached:  22.0
[I 2023-11-01 14:18:51,411] Trial 23 finished with value: 0.22917930781841278 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.211386091804357, 'log_learning_rate_D': -1.0464882412545111, 'training_batch_size': 9, 'training_p': 7}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  148.0189425945282
Memory status after this trial: 
Memory allocated:  124.7060546875
Memory cached:  128.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.2910666102681114, 'log_learning_rate_D': -2.3343291738401404, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.3741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.2940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.513671875
Memory cached:  34.0
[I 2023-11-01 14:21:06,657] Trial 24 finished with value: 0.22951360046863556 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.2910666102681114, 'log_learning_rate_D': -2.3343291738401404, 'training_batch_size': 10, 'training_p': 5}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  135.01852083206177
Memory status after this trial: 
Memory allocated:  212.888671875
Memory cached:  228.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.79758213013448, 'log_learning_rate_D': -1.7133770810035456, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.9765625
Memory cached:  18.0
[I 2023-11-01 14:23:39,972] Trial 25 finished with value: 0.22900085151195526 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.79758213013448, 'log_learning_rate_D': -1.7133770810035456, 'training_batch_size': 11, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  153.09270358085632
Memory status after this trial: 
Memory allocated:  161.2236328125
Memory cached:  168.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.91986888578621, 'log_learning_rate_D': -1.392147683321667, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.447265625
Memory cached:  44.0
[I 2023-11-01 14:26:31,870] Trial 26 finished with value: 0.22998037934303284 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.91986888578621, 'log_learning_rate_D': -1.392147683321667, 'training_batch_size': 10, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  171.66509127616882
Memory status after this trial: 
Memory allocated:  255.12158203125
Memory cached:  272.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.7106107208596493, 'log_learning_rate_D': -1.8545870011598686, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.03125
Memory cached:  44.0
[I 2023-11-01 14:29:16,732] Trial 27 finished with value: 0.22902999818325043 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.7106107208596493, 'log_learning_rate_D': -1.8545870011598686, 'training_batch_size': 9, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  164.6253252029419
Memory status after this trial: 
Memory allocated:  196.09619140625
Memory cached:  218.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.4404253537071106, 'log_learning_rate_D': -2.267174165466869, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.0546875
Memory cached:  20.0
[I 2023-11-01 14:32:20,624] Trial 28 finished with value: 0.22989939153194427 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.4404253537071106, 'log_learning_rate_D': -2.267174165466869, 'training_batch_size': 11, 'training_p': 7}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  183.64374256134033
Memory status after this trial: 
Memory allocated:  225.33837890625
Memory cached:  230.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.2399198812230443, 'log_learning_rate_D': -2.5437261878322444, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.7648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.806640625
Memory cached:  20.0
[I 2023-11-01 14:34:50,152] Trial 29 finished with value: 0.2288062870502472 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.2399198812230443, 'log_learning_rate_D': -2.5437261878322444, 'training_batch_size': 10, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  149.28661465644836
Memory status after this trial: 
Memory allocated:  140.80615234375
Memory cached:  148.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.05895951080948, 'log_learning_rate_D': -2.6440503015631123, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.5808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  8.0
[I 2023-11-01 14:36:52,719] Trial 30 finished with value: 0.23166632652282715 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.05895951080948, 'log_learning_rate_D': -2.6440503015631123, 'training_batch_size': 11, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  122.36555361747742
Memory status after this trial: 
Memory allocated:  38.64599609375
Memory cached:  40.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.338212089300521, 'log_learning_rate_D': -1.8441150525570005, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.8768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.9251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.8385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.7098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30859375
Memory cached:  38.0
[I 2023-11-01 14:39:25,132] Trial 31 finished with value: 0.2330065220594406 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.338212089300521, 'log_learning_rate_D': -1.8441150525570005, 'training_batch_size': 10, 'training_p': 8}. Best is trial 4 with value: 0.22876401245594025.
Time for this trial:  152.18158888816833
Memory status after this trial: 
Memory allocated:  162.85986328125
Memory cached:  184.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.7567887786292946, 'log_learning_rate_D': -2.290870003831522, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.9295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.8900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.7615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.341796875
Memory cached:  62.0
[I 2023-11-01 14:42:12,647] Trial 32 finished with value: 0.22594527900218964 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.7567887786292946, 'log_learning_rate_D': -2.290870003831522, 'training_batch_size': 9, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  167.27352499961853
Memory status after this trial: 
Memory allocated:  237.43701171875
Memory cached:  270.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.8049427148331416, 'log_learning_rate_D': -2.4948900766615476, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.822265625
Memory cached:  18.0
[I 2023-11-01 14:44:42,846] Trial 33 finished with value: 0.2323480099439621 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.8049427148331416, 'log_learning_rate_D': -2.4948900766615476, 'training_batch_size': 8, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  149.93827605247498
Memory status after this trial: 
Memory allocated:  145.951171875
Memory cached:  152.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.274331954007665, 'log_learning_rate_D': -2.2768781362262445, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.9663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.9491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.9206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.8572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.7969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.6805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.482421875
Memory cached:  12.0
[I 2023-11-01 14:47:15,954] Trial 34 finished with value: 0.4919848144054413 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.274331954007665, 'log_learning_rate_D': -2.2768781362262445, 'training_batch_size': 9, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  152.86045217514038
Memory status after this trial: 
Memory allocated:  102.2783203125
Memory cached:  106.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.0550074068951, 'log_learning_rate_D': -3.1844765563835056, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.7956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.7038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.4038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48046875
Memory cached:  58.0
[I 2023-11-01 14:49:57,782] Trial 35 finished with value: 0.231746107339859 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.0550074068951, 'log_learning_rate_D': -3.1844765563835056, 'training_batch_size': 7, 'training_p': 8}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  161.59013652801514
Memory status after this trial: 
Memory allocated:  237.93798828125
Memory cached:  250.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.431674996732223, 'log_learning_rate_D': -2.8540020730434397, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.9455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.9238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.8964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.84375
Memory cached:  20.0
[I 2023-11-01 14:52:51,636] Trial 36 finished with value: 0.6569439768791199 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.431674996732223, 'log_learning_rate_D': -2.8540020730434397, 'training_batch_size': 9, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  173.5913336277008
Memory status after this trial: 
Memory allocated:  138.5146484375
Memory cached:  144.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.7675838642893016, 'log_learning_rate_D': -2.57065578181262, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.8988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.6606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.826171875
Memory cached:  16.0
[I 2023-11-01 14:55:22,827] Trial 37 finished with value: 0.22931699454784393 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.7675838642893016, 'log_learning_rate_D': -2.57065578181262, 'training_batch_size': 12, 'training_p': 8}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  150.9340305328369
Memory status after this trial: 
Memory allocated:  82.841796875
Memory cached:  84.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6798130893054695, 'log_learning_rate_D': -2.1958137926508563, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.7885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.7564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.6955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.6604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.5413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.3595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.384765625
Memory cached:  4.0
[I 2023-11-01 14:57:02,520] Trial 38 finished with value: 0.23094287514686584 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6798130893054695, 'log_learning_rate_D': -2.1958137926508563, 'training_batch_size': 9, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  99.47732710838318
Memory status after this trial: 
Memory allocated:  25.56396484375
Memory cached:  26.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.087896810521716, 'log_learning_rate_D': -1.3096524163798198, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.9912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.9588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.9135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.8264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.0703125
Memory cached:  40.0
[I 2023-11-01 15:00:31,746] Trial 39 finished with value: 0.9981496930122375 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.087896810521716, 'log_learning_rate_D': -1.3096524163798198, 'training_batch_size': 10, 'training_p': 7}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  208.96691274642944
Memory status after this trial: 
Memory allocated:  297.09326171875
Memory cached:  320.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.2690815652087863, 'log_learning_rate_D': -3.048762805534616, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.73828125
Memory cached:  38.0
[I 2023-11-01 15:02:51,037] Trial 40 finished with value: 0.23202143609523773 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.2690815652087863, 'log_learning_rate_D': -3.048762805534616, 'training_batch_size': 7, 'training_p': 8}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  139.05576062202454
Memory status after this trial: 
Memory allocated:  158.154296875
Memory cached:  178.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.450269687937428, 'log_learning_rate_D': -1.8325878213600402, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  20 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  30 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  40 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  50 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  60 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.109375
Memory cached:  54.0
[I 2023-11-01 15:05:41,072] Trial 41 finished with value: 0.22973552346229553 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.450269687937428, 'log_learning_rate_D': -1.8325878213600402, 'training_batch_size': 10, 'training_p': 5}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  169.78554224967957
Memory status after this trial: 
Memory allocated:  259.48779296875
Memory cached:  286.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.614824511661189, 'log_learning_rate_D': -2.0550412220992906, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  58.0
	 epoch  10 training error:  tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.3828125
Memory cached:  66.0
[I 2023-11-01 15:08:36,317] Trial 42 finished with value: 0.22980426251888275 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.614824511661189, 'log_learning_rate_D': -2.0550412220992906, 'training_batch_size': 10, 'training_p': 6}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  174.98379039764404
Memory status after this trial: 
Memory allocated:  281.5029296875
Memory cached:  308.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.1686191443945195, 'log_learning_rate_D': -2.527907762901908, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  54.0
	 epoch  10 training error:  tensor(0.4589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.48828125
Memory cached:  56.0
[I 2023-11-01 15:11:38,411] Trial 43 finished with value: 0.23003415763378143 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.1686191443945195, 'log_learning_rate_D': -2.527907762901908, 'training_batch_size': 11, 'training_p': 8}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  181.82787609100342
Memory status after this trial: 
Memory allocated:  252.7392578125
Memory cached:  286.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.4435387632081618, 'log_learning_rate_D': -1.7343224335277638, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.587890625
Memory cached:  34.0
[I 2023-11-01 15:14:07,996] Trial 44 finished with value: 0.22941282391548157 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.4435387632081618, 'log_learning_rate_D': -1.7343224335277638, 'training_batch_size': 12, 'training_p': 4}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  149.33403134346008
Memory status after this trial: 
Memory allocated:  163.548828125
Memory cached:  184.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.977851192856371, 'log_learning_rate_D': -1.9494354080003307, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.84765625
Memory cached:  42.0
[I 2023-11-01 15:17:26,693] Trial 45 finished with value: 0.23029685020446777 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.977851192856371, 'log_learning_rate_D': -1.9494354080003307, 'training_batch_size': 9, 'training_p': 5}. Best is trial 32 with value: 0.22594527900218964.
Time for this trial:  198.4326627254486
Memory status after this trial: 
Memory allocated:  314.365234375
Memory cached:  330.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.38059577910603, 'log_learning_rate_D': -1.4299350742964776, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  54.0
	 epoch  10 training error:  tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.9410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.8793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.806640625
Memory cached:  58.0
[I 2023-11-01 15:20:10,902] Trial 46 finished with value: 0.22591491043567657 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.38059577910603, 'log_learning_rate_D': -1.4299350742964776, 'training_batch_size': 10, 'training_p': 3}. Best is trial 46 with value: 0.22591491043567657.
Time for this trial:  163.94152235984802
Memory status after this trial: 
Memory allocated:  228.4873046875
Memory cached:  238.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.427459521433946, 'log_learning_rate_D': -1.426113106838353, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.6512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.34375
Memory cached:  18.0
[I 2023-11-01 15:22:59,522] Trial 47 finished with value: 0.22767940163612366 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.427459521433946, 'log_learning_rate_D': -1.426113106838353, 'training_batch_size': 11, 'training_p': 2}. Best is trial 46 with value: 0.22591491043567657.
Time for this trial:  168.3151285648346
Memory status after this trial: 
Memory allocated:  225.2822265625
Memory cached:  232.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.587449492192301, 'log_learning_rate_D': -1.4557198971977687, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.9385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.8960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.7680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.6743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.4193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.798828125
Memory cached:  24.0
[I 2023-11-01 15:25:46,185] Trial 48 finished with value: 0.22205987572669983 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.587449492192301, 'log_learning_rate_D': -1.4557198971977687, 'training_batch_size': 10, 'training_p': 2}. Best is trial 48 with value: 0.22205987572669983.
Time for this trial:  166.39922523498535
Memory status after this trial: 
Memory allocated:  211.50927734375
Memory cached:  218.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.506699919630415, 'log_learning_rate_D': -1.4519923901913787, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.9494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.8789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.5975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.943359375
Memory cached:  22.0
[I 2023-11-01 15:28:31,280] Trial 49 finished with value: 0.22772057354450226 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.506699919630415, 'log_learning_rate_D': -1.4519923901913787, 'training_batch_size': 9, 'training_p': 2}. Best is trial 48 with value: 0.22205987572669983.
[I 2023-11-01 15:28:31,311] A new study created in memory with name: no-name-884dbe73-01a6-4e28-8c0b-d25cd48ca9b7
Time for this trial:  164.8360950946808
Memory status after this trial: 
Memory allocated:  206.49658203125
Memory cached:  212.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.7004800877635877, 'log_learning_rate_D': -4.4028638732079015, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8828125
Memory cached:  16.0
[I 2023-11-01 15:31:44,680] Trial 0 finished with value: 0.23115716874599457 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.7004800877635877, 'log_learning_rate_D': -4.4028638732079015, 'training_batch_size': 6, 'training_p': 8}. Best is trial 0 with value: 0.23115716874599457.
Time for this trial:  193.24528646469116
Memory status after this trial: 
Memory allocated:  103.828125
Memory cached:  106.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.9215111841649914, 'log_learning_rate_D': -4.477417057069013, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1669921875
Memory cached:  18.0
[I 2023-11-01 15:34:29,536] Trial 1 finished with value: 0.2304292768239975 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.9215111841649914, 'log_learning_rate_D': -4.477417057069013, 'training_batch_size': 7, 'training_p': 5}. Best is trial 1 with value: 0.2304292768239975.
Time for this trial:  164.72268295288086
Memory status after this trial: 
Memory allocated:  160.11376953125
Memory cached:  164.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.8536151957826967, 'log_learning_rate_D': -4.64168510587532, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.236328125
Memory cached:  36.0
[I 2023-11-01 15:38:35,311] Trial 2 finished with value: 0.23370032012462616 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.8536151957826967, 'log_learning_rate_D': -4.64168510587532, 'training_batch_size': 6, 'training_p': 3}. Best is trial 1 with value: 0.2304292768239975.
Time for this trial:  245.607684135437
Memory status after this trial: 
Memory allocated:  171.607421875
Memory cached:  190.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.4048339927401061, 'log_learning_rate_D': -4.6629721992892215, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.3155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.009765625
Memory cached:  18.0
[I 2023-11-01 15:42:59,575] Trial 3 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.4048339927401061, 'log_learning_rate_D': -4.6629721992892215, 'training_batch_size': 6, 'training_p': 3}. Best is trial 1 with value: 0.2304292768239975.
Time for this trial:  264.1105766296387
Memory status after this trial: 
Memory allocated:  204.5341796875
Memory cached:  208.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0225355651592491, 'log_learning_rate_D': -1.3184494278610326, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  36.0
	 epoch  20 training error:  tensor(2.7879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9072265625
Memory cached:  34.0
[I 2023-11-01 15:44:57,564] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0225355651592491, 'log_learning_rate_D': -1.3184494278610326, 'training_batch_size': 8, 'training_p': 2}. Best is trial 1 with value: 0.2304292768239975.
Time for this trial:  117.85111474990845
Memory status after this trial: 
Memory allocated:  167.7333984375
Memory cached:  182.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.196275057329545, 'log_learning_rate_D': -1.585791069060794, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  64.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4189453125
Memory cached:  64.0
[I 2023-11-01 15:47:45,665] Trial 5 finished with value: 0.22906675934791565 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.196275057329545, 'log_learning_rate_D': -1.585791069060794, 'training_batch_size': 11, 'training_p': 4}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  167.96819376945496
Memory status after this trial: 
Memory allocated:  280.22802734375
Memory cached:  292.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.809195959038343, 'log_learning_rate_D': -4.883945770384632, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8046875
Memory cached:  12.0
[I 2023-11-01 15:50:55,883] Trial 6 finished with value: 0.23176193237304688 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.809195959038343, 'log_learning_rate_D': -4.883945770384632, 'training_batch_size': 6, 'training_p': 8}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  190.07022190093994
Memory status after this trial: 
Memory allocated:  68.46875
Memory cached:  72.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.3604617997625619, 'log_learning_rate_D': -3.497070310805412, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  16.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6181640625
Memory cached:  14.0
[I 2023-11-01 15:53:02,843] Trial 7 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.3604617997625619, 'log_learning_rate_D': -3.497070310805412, 'training_batch_size': 7, 'training_p': 8}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  126.84025430679321
Memory status after this trial: 
Memory allocated:  117.87109375
Memory cached:  122.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.299541356500961, 'log_learning_rate_D': -3.3972432383694393, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.8858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8076171875
Memory cached:  20.0
[I 2023-11-01 15:56:00,119] Trial 8 finished with value: 0.23300519585609436 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.299541356500961, 'log_learning_rate_D': -3.3972432383694393, 'training_batch_size': 7, 'training_p': 6}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  177.1485779285431
Memory status after this trial: 
Memory allocated:  115.1484375
Memory cached:  118.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.1033515759917965, 'log_learning_rate_D': -3.4553467159756943, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6201171875
Memory cached:  18.0
[I 2023-11-01 15:58:52,153] Trial 9 finished with value: 0.22989724576473236 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.1033515759917965, 'log_learning_rate_D': -3.4553467159756943, 'training_batch_size': 11, 'training_p': 6}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  171.87894892692566
Memory status after this trial: 
Memory allocated:  186.587890625
Memory cached:  190.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.834550371572548, 'log_learning_rate_D': -1.3144653330540186, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9091796875
Memory cached:  36.0
[I 2023-11-01 16:01:21,344] Trial 10 finished with value: 0.22995510697364807 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.834550371572548, 'log_learning_rate_D': -1.3144653330540186, 'training_batch_size': 12, 'training_p': 4}. Best is trial 5 with value: 0.22906675934791565.
Time for this trial:  148.963538646698
Memory status after this trial: 
Memory allocated:  239.169921875
Memory cached:  254.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.718072076118285, 'log_learning_rate_D': -2.170022738056965, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.9144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  64.0
	 epoch  70 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.2041015625
Memory cached:  64.0
[I 2023-11-01 16:04:40,194] Trial 11 finished with value: 0.22894392907619476 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.718072076118285, 'log_learning_rate_D': -2.170022738056965, 'training_batch_size': 11, 'training_p': 6}. Best is trial 11 with value: 0.22894392907619476.
Time for this trial:  198.62623047828674
Memory status after this trial: 
Memory allocated:  350.546875
Memory cached:  366.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.9663094357175765, 'log_learning_rate_D': -1.9238028612589506, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.9883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.9664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.9354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.8895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.8216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.4032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.3271484375
Memory cached:  46.0
[I 2023-11-01 16:07:48,197] Trial 12 finished with value: 0.22162218391895294 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.9663094357175765, 'log_learning_rate_D': -1.9238028612589506, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  187.7612853050232
Memory status after this trial: 
Memory allocated:  268.52734375
Memory cached:  284.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.940012461282586, 'log_learning_rate_D': -2.041781011402569, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  46.0
	 epoch  10 training error:  tensor(0.9599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  54.0
	 epoch  20 training error:  tensor(0.8877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.7449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.1416015625
Memory cached:  52.0
[I 2023-11-01 16:11:01,248] Trial 13 finished with value: 0.22735317051410675 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.940012461282586, 'log_learning_rate_D': -2.041781011402569, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  192.80332589149475
Memory status after this trial: 
Memory allocated:  298.8076171875
Memory cached:  322.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.840502936811397, 'log_learning_rate_D': -2.191560701136219, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.8995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.8070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9833984375
Memory cached:  22.0
[I 2023-11-01 16:13:45,539] Trial 14 finished with value: 0.22970688343048096 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.840502936811397, 'log_learning_rate_D': -2.191560701136219, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  164.06586170196533
Memory status after this trial: 
Memory allocated:  195.107421875
Memory cached:  202.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.456746563599438, 'log_learning_rate_D': -2.1775162756600177, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.9268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1259765625
Memory cached:  26.0
[I 2023-11-01 16:16:47,135] Trial 15 finished with value: 0.230549618601799 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.456746563599438, 'log_learning_rate_D': -2.1775162756600177, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  181.3603081703186
Memory status after this trial: 
Memory allocated:  196.9892578125
Memory cached:  204.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.895016228200055, 'log_learning_rate_D': -2.6481057294466317, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  58.0
	 epoch  10 training error:  tensor(0.9319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.8569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.6399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9931640625
Memory cached:  62.0
[I 2023-11-01 16:19:51,342] Trial 16 finished with value: 0.23085308074951172 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.895016228200055, 'log_learning_rate_D': -2.6481057294466317, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  183.9838466644287
Memory status after this trial: 
Memory allocated:  272.59228515625
Memory cached:  284.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.395829930256804, 'log_learning_rate_D': -1.8167484794162374, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.9220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.8087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.6404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5498046875
Memory cached:  38.0
[I 2023-11-01 16:22:45,944] Trial 17 finished with value: 0.227934792637825 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.395829930256804, 'log_learning_rate_D': -1.8167484794162374, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  174.3382453918457
Memory status after this trial: 
Memory allocated:  214.28271484375
Memory cached:  234.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.28988105523013, 'log_learning_rate_D': -1.1945580133517975, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.8336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
[I 2023-11-01 16:25:44,432] Trial 18 finished with value: 0.22754354774951935 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.28988105523013, 'log_learning_rate_D': -1.1945580133517975, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  178.26526618003845
Memory status after this trial: 
Memory allocated:  243.36328125
Memory cached:  264.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.482198227754258, 'log_learning_rate_D': -2.6515891856875387, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.6446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9052734375
Memory cached:  38.0
[I 2023-11-01 16:28:32,373] Trial 19 finished with value: 0.23315317928791046 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.482198227754258, 'log_learning_rate_D': -2.6515891856875387, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  167.69878888130188
Memory status after this trial: 
Memory allocated:  169.05419921875
Memory cached:  188.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.917537077487242, 'log_learning_rate_D': -1.8338910892486175, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.9301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.8972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.8624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.8248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.7837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.7385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7353515625
Memory cached:  12.0
[I 2023-11-01 16:31:00,940] Trial 20 finished with value: 0.6132760047912598 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.917537077487242, 'log_learning_rate_D': -1.8338910892486175, 'training_batch_size': 8, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  148.30788207054138
Memory status after this trial: 
Memory allocated:  69.90087890625
Memory cached:  72.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.271389163025936, 'log_learning_rate_D': -1.0906998145090334, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0712890625
Memory cached:  42.0
[I 2023-11-01 16:33:59,731] Trial 21 finished with value: 0.2300897091627121 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.271389163025936, 'log_learning_rate_D': -1.0906998145090334, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  178.5404510498047
Memory status after this trial: 
Memory allocated:  243.36328125
Memory cached:  264.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.426841686275524, 'log_learning_rate_D': -1.0073296353662688, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.3173828125
Memory cached:  42.0
[I 2023-11-01 16:37:14,589] Trial 22 finished with value: 0.2288016825914383 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.426841686275524, 'log_learning_rate_D': -1.0073296353662688, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  194.6108808517456
Memory status after this trial: 
Memory allocated:  321.01123046875
Memory cached:  338.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.542342905116534, 'log_learning_rate_D': -1.5518414237011386, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.9095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  28.0
	 epoch  20 training error:  tensor(0.7021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  28.0
	 epoch  30 training error:  tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2294921875
Memory cached:  26.0
[I 2023-11-01 16:39:55,752] Trial 23 finished with value: 0.22852876782417297 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.542342905116534, 'log_learning_rate_D': -1.5518414237011386, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  160.91962480545044
Memory status after this trial: 
Memory allocated:  169.4208984375
Memory cached:  174.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.218749310060723, 'log_learning_rate_D': -1.7671128431901106, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.7171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1279296875
Memory cached:  46.0
[I 2023-11-01 16:42:58,338] Trial 24 finished with value: 0.22890260815620422 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.218749310060723, 'log_learning_rate_D': -1.7671128431901106, 'training_batch_size': 11, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  182.35194277763367
Memory status after this trial: 
Memory allocated:  264.16015625
Memory cached:  286.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.047835136606068, 'log_learning_rate_D': -1.3603913699464116, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0732421875
Memory cached:  40.0
[I 2023-11-01 16:45:46,722] Trial 25 finished with value: 0.22964034974575043 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.047835136606068, 'log_learning_rate_D': -1.3603913699464116, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  168.10256433486938
Memory status after this trial: 
Memory allocated:  162.9560546875
Memory cached:  182.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.989324611862022, 'log_learning_rate_D': -1.9656939874020234, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.9383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.9038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.8833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.8608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.8358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.8080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3935546875
Memory cached:  20.0
[I 2023-11-01 16:48:06,081] Trial 26 finished with value: 0.7610855102539062 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.989324611862022, 'log_learning_rate_D': -1.9656939874020234, 'training_batch_size': 8, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  139.11236333847046
Memory status after this trial: 
Memory allocated:  99.53466796875
Memory cached:  102.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.8505594369971528, 'log_learning_rate_D': -1.0203960701121453, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2568359375
Memory cached:  42.0
[I 2023-11-01 16:51:21,956] Trial 27 finished with value: 0.2295713722705841 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.8505594369971528, 'log_learning_rate_D': -1.0203960701121453, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  195.6079225540161
Memory status after this trial: 
Memory allocated:  250.59521484375
Memory cached:  272.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.612019411455024, 'log_learning_rate_D': -1.5448091839153697, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.7923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.5582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.0380859375
Memory cached:  38.0
[I 2023-11-01 16:54:13,530] Trial 28 finished with value: 0.22930467128753662 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.612019411455024, 'log_learning_rate_D': -1.5448091839153697, 'training_batch_size': 11, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  171.30051589012146
Memory status after this trial: 
Memory allocated:  201.93798828125
Memory cached:  224.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.9496306098909626, 'log_learning_rate_D': -2.4920613622329952, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  20.0
[I 2023-11-01 16:56:29,241] Trial 29 finished with value: 0.22897468507289886 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.9496306098909626, 'log_learning_rate_D': -2.4920613622329952, 'training_batch_size': 9, 'training_p': 8}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  135.4883828163147
Memory status after this trial: 
Memory allocated:  157.31787109375
Memory cached:  162.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.5789768990817907, 'log_learning_rate_D': -3.015515075782265, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.4970703125
Memory cached:  42.0
[I 2023-11-01 16:59:08,313] Trial 30 finished with value: 0.2314668446779251 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.5789768990817907, 'log_learning_rate_D': -3.015515075782265, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  158.84461069107056
Memory status after this trial: 
Memory allocated:  244.36767578125
Memory cached:  262.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.362597852817696, 'log_learning_rate_D': -1.8893392039082388, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.7774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5908203125
Memory cached:  42.0
[I 2023-11-01 17:02:09,062] Trial 31 finished with value: 0.22745418548583984 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.362597852817696, 'log_learning_rate_D': -1.8893392039082388, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  180.50180578231812
Memory status after this trial: 
Memory allocated:  221.07080078125
Memory cached:  240.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.715759938007698, 'log_learning_rate_D': -1.968943150526247, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.9422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.8898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.8307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.7606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.6736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.5626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.4178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0244140625
Memory cached:  24.0
[I 2023-11-01 17:05:16,071] Trial 32 finished with value: 0.2274821251630783 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.715759938007698, 'log_learning_rate_D': -1.968943150526247, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  186.76131653785706
Memory status after this trial: 
Memory allocated:  216.69287109375
Memory cached:  224.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.69489483297743, 'log_learning_rate_D': -2.0118563241438836, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.8262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.7420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.6959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.6463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.5927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2685546875
Memory cached:  20.0
[I 2023-11-01 17:08:02,351] Trial 33 finished with value: 0.49224424362182617 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.69489483297743, 'log_learning_rate_D': -2.0118563241438836, 'training_batch_size': 11, 'training_p': 8}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  166.02921056747437
Memory status after this trial: 
Memory allocated:  177.46240234375
Memory cached:  182.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.353473661374105, 'log_learning_rate_D': -2.36454722650744, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.7940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.5556640625
Memory cached:  40.0
[I 2023-11-01 17:11:11,505] Trial 34 finished with value: 0.23110614717006683 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.353473661374105, 'log_learning_rate_D': -2.36454722650744, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  188.89664220809937
Memory status after this trial: 
Memory allocated:  224.12548828125
Memory cached:  246.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.6903503769193415, 'log_learning_rate_D': -1.745540777782617, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.4708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6943359375
Memory cached:  40.0
[I 2023-11-01 17:13:59,042] Trial 35 finished with value: 0.23047633469104767 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.6903503769193415, 'log_learning_rate_D': -1.745540777782617, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  167.2694706916809
Memory status after this trial: 
Memory allocated:  177.44091796875
Memory cached:  196.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.943034864086794, 'log_learning_rate_D': -1.9591025589757902, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.8853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.8481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.8046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.7530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.4521484375
Memory cached:  20.0
[I 2023-11-01 17:17:03,646] Trial 36 finished with value: 0.381664514541626 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.943034864086794, 'log_learning_rate_D': -1.9591025589757902, 'training_batch_size': 12, 'training_p': 8}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  184.34160494804382
Memory status after this trial: 
Memory allocated:  193.20849609375
Memory cached:  198.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.283046513702261, 'log_learning_rate_D': -1.4765654401748778, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.7640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6435546875
Memory cached:  36.0
[I 2023-11-01 17:19:32,998] Trial 37 finished with value: 0.23358285427093506 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.283046513702261, 'log_learning_rate_D': -1.4765654401748778, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  149.10910320281982
Memory status after this trial: 
Memory allocated:  162.30517578125
Memory cached:  180.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.687137398299314, 'log_learning_rate_D': -1.676830143430375, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.8547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.4306640625
Memory cached:  40.0
[I 2023-11-01 17:22:29,003] Trial 38 finished with value: 0.23017339408397675 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.687137398299314, 'log_learning_rate_D': -1.676830143430375, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  175.75423526763916
Memory status after this trial: 
Memory allocated:  249.56884765625
Memory cached:  270.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.997395397174467, 'log_learning_rate_D': -2.3537066972545113, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.8960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.7209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.6177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7255859375
Memory cached:  16.0
[I 2023-11-01 17:25:12,692] Trial 39 finished with value: 0.23132768273353577 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.997395397174467, 'log_learning_rate_D': -2.3537066972545113, 'training_batch_size': 9, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  163.43549513816833
Memory status after this trial: 
Memory allocated:  153.3916015625
Memory cached:  158.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.0016344985221854, 'log_learning_rate_D': -1.4211682181042584, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.8039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0322265625
Memory cached:  42.0
[I 2023-11-01 17:28:10,942] Trial 40 finished with value: 0.2302979975938797 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.0016344985221854, 'log_learning_rate_D': -1.4211682181042584, 'training_batch_size': 8, 'training_p': 3}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  177.98964309692383
Memory status after this trial: 
Memory allocated:  215.04248046875
Memory cached:  234.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.7904175218686893, 'log_learning_rate_D': -1.209472722181743, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.9150390625
Memory cached:  18.0
[I 2023-11-01 17:31:07,633] Trial 41 finished with value: 0.22958020865917206 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.7904175218686893, 'log_learning_rate_D': -1.209472722181743, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  176.4241931438446
Memory status after this trial: 
Memory allocated:  142.9775390625
Memory cached:  146.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.5127353966494725, 'log_learning_rate_D': -1.2423461177448045, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.8519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.6955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3349609375
Memory cached:  24.0
[I 2023-11-01 17:33:39,389] Trial 42 finished with value: 0.22850120067596436 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.5127353966494725, 'log_learning_rate_D': -1.2423461177448045, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  151.50306057929993
Memory status after this trial: 
Memory allocated:  120.955078125
Memory cached:  124.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.172301703095924, 'log_learning_rate_D': -1.559384613239709, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2275390625
Memory cached:  40.0
[I 2023-11-01 17:36:58,290] Trial 43 finished with value: 0.22910480201244354 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.172301703095924, 'log_learning_rate_D': -1.559384613239709, 'training_batch_size': 11, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  198.64081811904907
Memory status after this trial: 
Memory allocated:  267.4609375
Memory cached:  288.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.797981817021215, 'log_learning_rate_D': -1.6727827840532312, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  20 training error:  tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  30 training error:  tensor(1.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  40 training error:  tensor(1.0165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.9227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.8300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.7842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8681640625
Memory cached:  12.0
[I 2023-11-01 17:38:57,239] Trial 44 finished with value: 0.7200724482536316 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.797981817021215, 'log_learning_rate_D': -1.6727827840532312, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  118.71496534347534
Memory status after this trial: 
Memory allocated:  90.74169921875
Memory cached:  92.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.349796613617492, 'log_learning_rate_D': -1.9253640847150364, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.1591796875
Memory cached:  38.0
[I 2023-11-01 17:42:02,513] Trial 45 finished with value: 0.22908754646778107 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.349796613617492, 'log_learning_rate_D': -1.9253640847150364, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  185.00224995613098
Memory status after this trial: 
Memory allocated:  212.66064453125
Memory cached:  232.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.771799490670178, 'log_learning_rate_D': -2.101671212963087, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5712890625
Memory cached:  18.0
[I 2023-11-01 17:44:57,060] Trial 46 finished with value: 0.2308100014925003 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.771799490670178, 'log_learning_rate_D': -2.101671212963087, 'training_batch_size': 11, 'training_p': 8}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  174.26703190803528
Memory status after this trial: 
Memory allocated:  190.98046875
Memory cached:  196.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.556905363415185, 'log_learning_rate_D': -1.3077017097989505, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.7392578125
Memory cached:  44.0
[I 2023-11-01 17:47:48,377] Trial 47 finished with value: 0.2293126881122589 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.556905363415185, 'log_learning_rate_D': -1.3077017097989505, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  171.04772806167603
Memory status after this trial: 
Memory allocated:  214.67822265625
Memory cached:  234.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.14941314682628, 'log_learning_rate_D': -1.8441392629259523, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.7743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.0576171875
Memory cached:  46.0
[I 2023-11-01 17:50:57,751] Trial 48 finished with value: 0.23012547194957733 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.14941314682628, 'log_learning_rate_D': -1.8441392629259523, 'training_batch_size': 11, 'training_p': 6}. Best is trial 12 with value: 0.22162218391895294.
Time for this trial:  189.0963101387024
Memory status after this trial: 
Memory allocated:  254.42333984375
Memory cached:  272.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.8650245042719273, 'log_learning_rate_D': -2.098377090885905, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.9365234375
Memory cached:  24.0
[I 2023-11-01 17:53:46,241] Trial 49 finished with value: 0.22933761775493622 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.8650245042719273, 'log_learning_rate_D': -2.098377090885905, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.22162218391895294.
[I 2023-11-01 17:53:46,270] A new study created in memory with name: no-name-02e402fa-aafd-4c34-aee3-50e5a983ae57
Time for this trial:  168.2198691368103
Memory status after this trial: 
Memory allocated:  189.09912109375
Memory cached:  196.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.081440298506403, 'log_learning_rate_D': -2.8422790607480253, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5087890625
Memory cached:  16.0
[I 2023-11-01 17:56:30,796] Trial 0 finished with value: 0.23650221526622772 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.081440298506403, 'log_learning_rate_D': -2.8422790607480253, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 0.23650221526622772.
Time for this trial:  164.409672498703
Memory status after this trial: 
Memory allocated:  107.6181640625
Memory cached:  110.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.620839691945051, 'log_learning_rate_D': -4.8393133859478645, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.9347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.9022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.8669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.8287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.7877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.673828125
Memory cached:  12.0
[I 2023-11-01 18:00:02,628] Trial 1 finished with value: 0.6713571548461914 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.620839691945051, 'log_learning_rate_D': -4.8393133859478645, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 0.23650221526622772.
Time for this trial:  211.68171977996826
Memory status after this trial: 
Memory allocated:  123.509765625
Memory cached:  126.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8418623062801336, 'log_learning_rate_D': -2.835812329235789, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.0322265625
Memory cached:  40.0
[I 2023-11-01 18:02:16,169] Trial 2 finished with value: 0.23269176483154297 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8418623062801336, 'log_learning_rate_D': -2.835812329235789, 'training_batch_size': 9, 'training_p': 5}. Best is trial 2 with value: 0.23269176483154297.
Time for this trial:  133.41100215911865
Memory status after this trial: 
Memory allocated:  203.61376953125
Memory cached:  222.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.162281598360618, 'log_learning_rate_D': -4.832236394138642, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.8858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.7054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5849609375
Memory cached:  20.0
[I 2023-11-01 18:04:49,823] Trial 3 finished with value: 0.2312134951353073 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.162281598360618, 'log_learning_rate_D': -4.832236394138642, 'training_batch_size': 10, 'training_p': 2}. Best is trial 3 with value: 0.2312134951353073.
Time for this trial:  153.51797747612
Memory status after this trial: 
Memory allocated:  84.72412109375
Memory cached:  86.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.8346898758263612, 'log_learning_rate_D': -1.2889992269685258, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.3549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  54.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.869140625
Memory cached:  56.0
[I 2023-11-01 18:09:27,608] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.8346898758263612, 'log_learning_rate_D': -1.2889992269685258, 'training_batch_size': 6, 'training_p': 8}. Best is trial 3 with value: 0.2312134951353073.
Time for this trial:  277.59783935546875
Memory status after this trial: 
Memory allocated:  241.5673828125
Memory cached:  264.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.998814062411414, 'log_learning_rate_D': -1.8101329557841983, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  50 training error:  tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.91796875
Memory cached:  60.0
[I 2023-11-01 18:13:56,537] Trial 5 finished with value: 0.23302526772022247 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.998814062411414, 'log_learning_rate_D': -1.8101329557841983, 'training_batch_size': 6, 'training_p': 2}. Best is trial 3 with value: 0.2312134951353073.
Time for this trial:  268.7604033946991
Memory status after this trial: 
Memory allocated:  278.54443359375
Memory cached:  310.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.453823915532045, 'log_learning_rate_D': -4.929082098218578, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8935546875
Memory cached:  22.0
[I 2023-11-01 18:16:42,393] Trial 6 finished with value: 0.23485873639583588 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.453823915532045, 'log_learning_rate_D': -4.929082098218578, 'training_batch_size': 9, 'training_p': 3}. Best is trial 3 with value: 0.2312134951353073.
Time for this trial:  165.70913338661194
Memory status after this trial: 
Memory allocated:  204.12548828125
Memory cached:  210.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.381088350041265, 'log_learning_rate_D': -1.4004670420580219, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2080078125
Memory cached:  18.0
[I 2023-11-01 18:19:06,604] Trial 7 finished with value: 0.9980669021606445 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.381088350041265, 'log_learning_rate_D': -1.4004670420580219, 'training_batch_size': 7, 'training_p': 4}. Best is trial 3 with value: 0.2312134951353073.
Time for this trial:  144.06140065193176
Memory status after this trial: 
Memory allocated:  90.521484375
Memory cached:  92.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.8646100490690447, 'log_learning_rate_D': -4.637354163496289, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.7666015625
Memory cached:  40.0
[I 2023-11-01 18:21:44,467] Trial 8 finished with value: 0.23014603555202484 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.8646100490690447, 'log_learning_rate_D': -4.637354163496289, 'training_batch_size': 10, 'training_p': 2}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  157.71479606628418
Memory status after this trial: 
Memory allocated:  202.22705078125
Memory cached:  222.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.402529290900795, 'log_learning_rate_D': -2.695974067766952, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  38.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  42.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  36.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  38.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.375
Memory cached:  40.0
[I 2023-11-01 18:27:00,610] Trial 9 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.402529290900795, 'log_learning_rate_D': -2.695974067766952, 'training_batch_size': 6, 'training_p': 3}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  315.9806263446808
Memory status after this trial: 
Memory allocated:  263.33984375
Memory cached:  280.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.337906598148967, 'log_learning_rate_D': -3.973110431002034, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4560546875
Memory cached:  18.0
[I 2023-11-01 18:28:54,845] Trial 10 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.337906598148967, 'log_learning_rate_D': -3.973110431002034, 'training_batch_size': 12, 'training_p': 7}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  114.01057171821594
Memory status after this trial: 
Memory allocated:  87.6328125
Memory cached:  92.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.760788076309639, 'log_learning_rate_D': -4.160079349205068, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  16.0
[I 2023-11-01 18:31:13,329] Trial 11 finished with value: 0.23183004558086395 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.760788076309639, 'log_learning_rate_D': -4.160079349205068, 'training_batch_size': 11, 'training_p': 2}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  138.27849054336548
Memory status after this trial: 
Memory allocated:  140.43896484375
Memory cached:  142.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.815296873906375, 'log_learning_rate_D': -4.126673359898739, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5380859375
Memory cached:  46.0
[I 2023-11-01 18:34:37,470] Trial 12 finished with value: 0.23105894029140472 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.815296873906375, 'log_learning_rate_D': -4.126673359898739, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  203.90164756774902
Memory status after this trial: 
Memory allocated:  298.56787109375
Memory cached:  318.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.469187603155839, 'log_learning_rate_D': -3.9098128320689067, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.8017578125
Memory cached:  66.0
[I 2023-11-01 18:37:58,466] Trial 13 finished with value: 0.23405984044075012 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.469187603155839, 'log_learning_rate_D': -3.9098128320689067, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  200.7463014125824
Memory status after this trial: 
Memory allocated:  288.77099609375
Memory cached:  302.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.4454225670214207, 'log_learning_rate_D': -3.527048252172163, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.2919921875
Memory cached:  22.0
[I 2023-11-01 18:40:57,335] Trial 14 finished with value: 0.23442088067531586 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.4454225670214207, 'log_learning_rate_D': -3.527048252172163, 'training_batch_size': 12, 'training_p': 4}. Best is trial 8 with value: 0.23014603555202484.
Time for this trial:  178.59100341796875
Memory status after this trial: 
Memory allocated:  237.5625
Memory cached:  246.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.767432275110002, 'log_learning_rate_D': -4.377852732804672, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.8458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.0087890625
Memory cached:  24.0
[I 2023-11-01 18:43:52,723] Trial 15 finished with value: 0.228799968957901 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.767432275110002, 'log_learning_rate_D': -4.377852732804672, 'training_batch_size': 10, 'training_p': 5}. Best is trial 15 with value: 0.228799968957901.
Time for this trial:  175.15426898002625
Memory status after this trial: 
Memory allocated:  218.71826171875
Memory cached:  226.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.963473288334879, 'log_learning_rate_D': -4.500862217318455, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.8845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.7482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.6019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
[I 2023-11-01 18:46:16,974] Trial 16 finished with value: 0.22553257644176483 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.963473288334879, 'log_learning_rate_D': -4.500862217318455, 'training_batch_size': 10, 'training_p': 6}. Best is trial 16 with value: 0.22553257644176483.
Time for this trial:  144.03251838684082
Memory status after this trial: 
Memory allocated:  148.93994140625
Memory cached:  154.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.837691340710527, 'log_learning_rate_D': -4.4194922065401965, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.8639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.7831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  14.0
[I 2023-11-01 18:48:41,507] Trial 17 finished with value: 0.22198548913002014 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.837691340710527, 'log_learning_rate_D': -4.4194922065401965, 'training_batch_size': 10, 'training_p': 6}. Best is trial 17 with value: 0.22198548913002014.
Time for this trial:  144.31748843193054
Memory status after this trial: 
Memory allocated:  148.93994140625
Memory cached:  154.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.91183835882498, 'log_learning_rate_D': -3.4253873988416013, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  34.0
	 epoch  10 training error:  tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.9527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.9229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.8899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.8035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3486328125
Memory cached:  40.0
[I 2023-11-01 18:51:04,272] Trial 18 finished with value: 0.5319718718528748 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.91183835882498, 'log_learning_rate_D': -3.4253873988416013, 'training_batch_size': 8, 'training_p': 6}. Best is trial 17 with value: 0.22198548913002014.
Time for this trial:  142.54649138450623
Memory status after this trial: 
Memory allocated:  140.2509765625
Memory cached:  160.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.376501178492908, 'log_learning_rate_D': -4.408136423076013, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.8992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.7675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3955078125
Memory cached:  16.0
[I 2023-11-01 18:53:14,212] Trial 19 finished with value: 0.2219141572713852 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.376501178492908, 'log_learning_rate_D': -4.408136423076013, 'training_batch_size': 8, 'training_p': 7}. Best is trial 19 with value: 0.2219141572713852.
Time for this trial:  129.73033809661865
Memory status after this trial: 
Memory allocated:  99.37158203125
Memory cached:  104.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.395652326858753, 'log_learning_rate_D': -4.997231610711841, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.6866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.6431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.5999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.4730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.3455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7705078125
Memory cached:  14.0
[I 2023-11-01 18:55:14,768] Trial 20 finished with value: 0.253100723028183 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.395652326858753, 'log_learning_rate_D': -4.997231610711841, 'training_batch_size': 8, 'training_p': 8}. Best is trial 19 with value: 0.2219141572713852.
Time for this trial:  120.35015058517456
Memory status after this trial: 
Memory allocated:  73.578125
Memory cached:  78.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.988753335430025, 'log_learning_rate_D': -4.392153392908036, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.9260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.8889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.8514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.8133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.7332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.6499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7587890625
Memory cached:  22.0
[I 2023-11-01 18:57:26,925] Trial 21 finished with value: 0.5713903903961182 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.988753335430025, 'log_learning_rate_D': -4.392153392908036, 'training_batch_size': 9, 'training_p': 7}. Best is trial 19 with value: 0.2219141572713852.
Time for this trial:  131.94770097732544
Memory status after this trial: 
Memory allocated:  112.17578125
Memory cached:  116.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.406864691086702, 'log_learning_rate_D': -4.512995701594125, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.9224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.8066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.6694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.9716796875
Memory cached:  34.0
[I 2023-11-01 18:59:54,292] Trial 22 finished with value: 0.22661252319812775 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.406864691086702, 'log_learning_rate_D': -4.512995701594125, 'training_batch_size': 10, 'training_p': 6}. Best is trial 19 with value: 0.2219141572713852.
Time for this trial:  147.1516625881195
Memory status after this trial: 
Memory allocated:  171.52490234375
Memory cached:  190.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.568908902036496, 'log_learning_rate_D': -3.703229922133864, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.8912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.7863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.7246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.6587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0029296875
Memory cached:  14.0
[I 2023-11-01 19:02:07,799] Trial 23 finished with value: 0.326033353805542 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.568908902036496, 'log_learning_rate_D': -3.703229922133864, 'training_batch_size': 9, 'training_p': 7}. Best is trial 19 with value: 0.2219141572713852.
Time for this trial:  133.2855966091156
Memory status after this trial: 
Memory allocated:  68.736328125
Memory cached:  72.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.942509467824215, 'log_learning_rate_D': -4.4674467836038785, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.7992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.7153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1416015625
Memory cached:  16.0
[I 2023-11-01 19:04:18,421] Trial 24 finished with value: 0.22081008553504944 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.942509467824215, 'log_learning_rate_D': -4.4674467836038785, 'training_batch_size': 7, 'training_p': 6}. Best is trial 24 with value: 0.22081008553504944.
Time for this trial:  130.38466954231262
Memory status after this trial: 
Memory allocated:  99.7744140625
Memory cached:  104.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.18958261566001, 'log_learning_rate_D': -4.181893045210429, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.8797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.5554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7724609375
Memory cached:  12.0
[I 2023-11-01 19:06:16,178] Trial 25 finished with value: 0.22056566178798676 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.18958261566001, 'log_learning_rate_D': -4.181893045210429, 'training_batch_size': 7, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  117.54412746429443
Memory status after this trial: 
Memory allocated:  55.9248046875
Memory cached:  58.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.177446956103629, 'log_learning_rate_D': -3.2951129542876405, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.8439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.7735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.6998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.6217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.5393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  12.0
[I 2023-11-01 19:08:13,880] Trial 26 finished with value: 0.22769370675086975 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.177446956103629, 'log_learning_rate_D': -3.2951129542876405, 'training_batch_size': 7, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  117.49303221702576
Memory status after this trial: 
Memory allocated:  51.74169921875
Memory cached:  54.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.167367423946836, 'log_learning_rate_D': -3.8307349981444174, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.8748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.8161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.7851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.7541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.7237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.6940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4697265625
Memory cached:  10.0
[I 2023-11-01 19:09:56,122] Trial 27 finished with value: 0.6234685778617859 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.167367423946836, 'log_learning_rate_D': -3.8307349981444174, 'training_batch_size': 7, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  102.05230355262756
Memory status after this trial: 
Memory allocated:  22.32861328125
Memory cached:  24.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.583590420815288, 'log_learning_rate_D': -4.0963842047900645, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(1.0249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.8927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.8580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.7850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.7460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2607421875
Memory cached:  8.0
[I 2023-11-01 19:11:41,655] Trial 28 finished with value: 0.6755580902099609 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.583590420815288, 'log_learning_rate_D': -4.0963842047900645, 'training_batch_size': 7, 'training_p': 8}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  105.33770871162415
Memory status after this trial: 
Memory allocated:  42.1337890625
Memory cached:  44.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.001119841564416, 'log_learning_rate_D': -3.6628444046851714, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7431640625
Memory cached:  16.0
[I 2023-11-01 19:14:05,967] Trial 29 finished with value: 0.2322356253862381 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.001119841564416, 'log_learning_rate_D': -3.6628444046851714, 'training_batch_size': 8, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  144.09386563301086
Memory status after this trial: 
Memory allocated:  122.5009765625
Memory cached:  126.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.328687237950612, 'log_learning_rate_D': -4.229302868272455, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.2346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  20 training error:  tensor(1.2232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  30 training error:  tensor(1.2111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(1.1976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(1.1822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(1.1640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  70 training error:  tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  80 training error:  tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
	 epoch  90 training error:  tensor(1.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  10.0
[I 2023-11-01 19:16:08,149] Trial 30 finished with value: 1.0624802112579346 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.328687237950612, 'log_learning_rate_D': -4.229302868272455, 'training_batch_size': 7, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  121.93859004974365
Memory status after this trial: 
Memory allocated:  38.08056640625
Memory cached:  40.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.755156917458568, 'log_learning_rate_D': -4.613859542050874, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.7311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.7138671875
Memory cached:  36.0
[I 2023-11-01 19:18:36,109] Trial 31 finished with value: 0.22941775619983673 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.755156917458568, 'log_learning_rate_D': -4.613859542050874, 'training_batch_size': 8, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  147.74456334114075
Memory status after this trial: 
Memory allocated:  185.54296875
Memory cached:  200.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.635154699953305, 'log_learning_rate_D': -4.719526715341367, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.8960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.6883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.4181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2744140625
Memory cached:  10.0
[I 2023-11-01 19:20:33,979] Trial 32 finished with value: 0.22981201112270355 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.635154699953305, 'log_learning_rate_D': -4.719526715341367, 'training_batch_size': 7, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  117.63260817527771
Memory status after this trial: 
Memory allocated:  61.91796875
Memory cached:  64.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.726334573629002, 'log_learning_rate_D': -4.316455554967086, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.8186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.6907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2900390625
Memory cached:  14.0
[I 2023-11-01 19:22:46,021] Trial 33 finished with value: 0.22975365817546844 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.726334573629002, 'log_learning_rate_D': -4.316455554967086, 'training_batch_size': 8, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  131.8335382938385
Memory status after this trial: 
Memory allocated:  110.57421875
Memory cached:  114.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.455648733571346, 'log_learning_rate_D': -4.716948070734064, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.9170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.8423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.6467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7431640625
Memory cached:  40.0
[I 2023-11-01 19:25:00,201] Trial 34 finished with value: 0.2353595793247223 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.455648733571346, 'log_learning_rate_D': -4.716948070734064, 'training_batch_size': 9, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  133.96707201004028
Memory status after this trial: 
Memory allocated:  133.94091796875
Memory cached:  152.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.964033090414494, 'log_learning_rate_D': -4.982501433489313, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.8494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.8005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.7504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.6989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.6457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.681640625
Memory cached:  10.0
[I 2023-11-01 19:28:36,168] Trial 35 finished with value: 0.3200790584087372 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.964033090414494, 'log_learning_rate_D': -4.982501433489313, 'training_batch_size': 6, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  215.73743200302124
Memory status after this trial: 
Memory allocated:  57.9365234375
Memory cached:  60.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.272500584254429, 'log_learning_rate_D': -4.35080541892381, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.7563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.6034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1455078125
Memory cached:  16.0
[I 2023-11-01 19:30:31,861] Trial 36 finished with value: 0.24168388545513153 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.272500584254429, 'log_learning_rate_D': -4.35080541892381, 'training_batch_size': 7, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  115.47238874435425
Memory status after this trial: 
Memory allocated:  43.697265625
Memory cached:  46.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.60680013711862, 'log_learning_rate_D': -4.736861298835962, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.6894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1044921875
Memory cached:  20.0
[I 2023-11-01 19:32:54,093] Trial 37 finished with value: 0.2306644767522812 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.60680013711862, 'log_learning_rate_D': -4.736861298835962, 'training_batch_size': 8, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  142.0030665397644
Memory status after this trial: 
Memory allocated:  129.30859375
Memory cached:  134.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.033372084391187, 'log_learning_rate_D': -4.004279969023091, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  12.0
[I 2023-11-01 19:37:04,281] Trial 38 finished with value: 0.23248468339443207 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.033372084391187, 'log_learning_rate_D': -4.004279969023091, 'training_batch_size': 6, 'training_p': 5}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  249.9513623714447
Memory status after this trial: 
Memory allocated:  99.95068359375
Memory cached:  102.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.797634016415264, 'log_learning_rate_D': -4.507226272908664, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.8853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.8684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.8514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.8342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.8168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.7993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.7817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.7639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.7462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3564453125
Memory cached:  14.0
[I 2023-11-01 19:38:57,824] Trial 39 finished with value: 0.699500560760498 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.797634016415264, 'log_learning_rate_D': -4.507226272908664, 'training_batch_size': 9, 'training_p': 8}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  113.2785153388977
Memory status after this trial: 
Memory allocated:  79.86669921875
Memory cached:  82.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.4513073709413415, 'log_learning_rate_D': -4.803023286897313, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6611328125
Memory cached:  38.0
[I 2023-11-01 19:41:30,350] Trial 40 finished with value: 0.2302011102437973 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.4513073709413415, 'log_learning_rate_D': -4.803023286897313, 'training_batch_size': 8, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  152.2916910648346
Memory status after this trial: 
Memory allocated:  154.9921875
Memory cached:  174.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.983483546353277, 'log_learning_rate_D': -4.529136108818472, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.9615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.8596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.6880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5439453125
Memory cached:  22.0
[I 2023-11-01 19:43:54,844] Trial 41 finished with value: 0.3550693392753601 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.983483546353277, 'log_learning_rate_D': -4.529136108818472, 'training_batch_size': 10, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  144.2529056072235
Memory status after this trial: 
Memory allocated:  148.93994140625
Memory cached:  154.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.796220451442901, 'log_learning_rate_D': -4.243450042943541, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.7815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.6156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9130859375
Memory cached:  18.0
[I 2023-11-01 19:46:11,552] Trial 42 finished with value: 0.22876472771167755 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.796220451442901, 'log_learning_rate_D': -4.243450042943541, 'training_batch_size': 10, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  136.49636149406433
Memory status after this trial: 
Memory allocated:  140.5283203125
Memory cached:  146.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.564745241514911, 'log_learning_rate_D': -4.466846871887139, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.2509765625
Memory cached:  38.0
[I 2023-11-01 19:48:33,592] Trial 43 finished with value: 0.23070628941059113 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.564745241514911, 'log_learning_rate_D': -4.466846871887139, 'training_batch_size': 11, 'training_p': 6}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  141.8194181919098
Memory status after this trial: 
Memory allocated:  182.95263671875
Memory cached:  204.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.820562882160788, 'log_learning_rate_D': -4.828356290867778, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.8347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.7582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6357421875
Memory cached:  20.0
[I 2023-11-01 19:51:07,116] Trial 44 finished with value: 0.22321239113807678 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.820562882160788, 'log_learning_rate_D': -4.828356290867778, 'training_batch_size': 9, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  153.29282426834106
Memory status after this trial: 
Memory allocated:  133.29296875
Memory cached:  138.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.276101780775491, 'log_learning_rate_D': -4.892779217042203, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.5988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8837890625
Memory cached:  18.0
[I 2023-11-01 19:53:35,881] Trial 45 finished with value: 0.22886991500854492 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.276101780775491, 'log_learning_rate_D': -4.892779217042203, 'training_batch_size': 9, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  148.52248668670654
Memory status after this trial: 
Memory allocated:  143.91015625
Memory cached:  148.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.783641924899334, 'log_learning_rate_D': -4.07929286713006, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.8500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.6372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6181640625
Memory cached:  16.0
[I 2023-11-01 19:56:14,618] Trial 46 finished with value: 0.2380537986755371 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.783641924899334, 'log_learning_rate_D': -4.07929286713006, 'training_batch_size': 7, 'training_p': 8}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  158.44833374023438
Memory status after this trial: 
Memory allocated:  141.36328125
Memory cached:  146.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.53247576063509, 'log_learning_rate_D': -4.79995196514975, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.548828125
Memory cached:  24.0
[I 2023-11-01 20:01:00,433] Trial 47 finished with value: 0.22913971543312073 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.53247576063509, 'log_learning_rate_D': -4.79995196514975, 'training_batch_size': 6, 'training_p': 7}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  285.5417289733887
Memory status after this trial: 
Memory allocated:  149.4697265625
Memory cached:  154.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.015959795381914, 'log_learning_rate_D': -4.231068300104549, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  20 training error:  tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  30 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  50 training error:  tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  60 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  80 training error:  tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
	 epoch  90 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.2548828125
Memory cached:  86.0
[I 2023-11-01 20:03:59,697] Trial 48 finished with value: 0.23425479233264923 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.015959795381914, 'log_learning_rate_D': -4.231068300104549, 'training_batch_size': 8, 'training_p': 3}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  179.00561499595642
Memory status after this trial: 
Memory allocated:  359.177734375
Memory cached:  382.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.341973149840071, 'log_learning_rate_D': -4.661903811176887, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.8853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.8419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.7959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.7472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.6972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.6443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.5879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2451171875
Memory cached:  14.0
[I 2023-11-01 20:06:10,747] Trial 49 finished with value: 0.5100451111793518 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.341973149840071, 'log_learning_rate_D': -4.661903811176887, 'training_batch_size': 9, 'training_p': 4}. Best is trial 25 with value: 0.22056566178798676.
Time for this trial:  130.80078649520874
Memory status after this trial: 
Memory allocated:  71.33447265625
Memory cached:  74.0
