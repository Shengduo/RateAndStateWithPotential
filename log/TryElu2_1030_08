/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-10-30 16:07:29,919] A new study created in memory with name: no-name-a7918d43-2214-42f6-ae1a-a9a78380f195
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.978268693908947, 'log_learning_rate_D': -2.1549582192602923, 'training_batch_size': 7, 'training_p': 5}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.67529296875
Memory cached:  4.0
[I 2023-10-30 16:07:47,969] Trial 0 finished with value: 0.22657151520252228 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.978268693908947, 'log_learning_rate_D': -2.1549582192602923, 'training_batch_size': 7, 'training_p': 5}. Best is trial 0 with value: 0.22657151520252228.
Time for this trial:  17.955779790878296
Memory status after this trial: 
Memory allocated:  60.22607421875
Memory cached:  88.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.535715755013258, 'log_learning_rate_D': -3.727136111609687, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  2.0
[I 2023-10-30 16:08:03,576] Trial 1 finished with value: 0.22552898526191711 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.535715755013258, 'log_learning_rate_D': -3.727136111609687, 'training_batch_size': 6, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.504514694213867
Memory status after this trial: 
Memory allocated:  13.92822265625
Memory cached:  16.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.979261630805434, 'log_learning_rate_D': -4.740105003355571, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.9412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90869140625
Memory cached:  4.0
[I 2023-10-30 16:08:19,775] Trial 2 finished with value: 0.22615042328834534 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.979261630805434, 'log_learning_rate_D': -4.740105003355571, 'training_batch_size': 8, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.108612537384033
Memory status after this trial: 
Memory allocated:  80.04345703125
Memory cached:  94.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.177862426336531, 'log_learning_rate_D': -2.481912523264523, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(20.0913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1953125
Memory cached:  6.0
[I 2023-10-30 16:08:36,278] Trial 3 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.177862426336531, 'log_learning_rate_D': -2.481912523264523, 'training_batch_size': 6, 'training_p': 5}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.406697273254395
Memory status after this trial: 
Memory allocated:  70.97509765625
Memory cached:  84.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.2339081682717792, 'log_learning_rate_D': -1.1396130131036415, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.48291015625
Memory cached:  6.0
[W 2023-10-30 16:08:36,998] Trial 4 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.2339081682717792, 'log_learning_rate_D': -1.1396130131036415, 'training_batch_size': 10, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:08:36,999] Trial 4 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  0.6312742233276367
Memory status after this trial: 
Memory allocated:  134.08740234375
Memory cached:  148.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.6983274779667004, 'log_learning_rate_D': -2.7394310537193727, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  20 training error:  tensor(2.6637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.03515625
Memory cached:  10.0
[I 2023-10-30 16:08:53,321] Trial 5 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.6983274779667004, 'log_learning_rate_D': -2.7394310537193727, 'training_batch_size': 11, 'training_p': 6}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.224691152572632
Memory status after this trial: 
Memory allocated:  64.07470703125
Memory cached:  72.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.261646773311522, 'log_learning_rate_D': -4.3594941993907135, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.5885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  8.0
[I 2023-10-30 16:09:09,694] Trial 6 finished with value: 0.2267376184463501 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.261646773311522, 'log_learning_rate_D': -4.3594941993907135, 'training_batch_size': 10, 'training_p': 5}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.283564805984497
Memory status after this trial: 
Memory allocated:  73.27490234375
Memory cached:  86.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.8186683610699315, 'log_learning_rate_D': -3.068524399971629, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.8644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.70263671875
Memory cached:  4.0
[I 2023-10-30 16:09:25,034] Trial 7 finished with value: 0.22719846665859222 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.8186683610699315, 'log_learning_rate_D': -3.068524399971629, 'training_batch_size': 8, 'training_p': 5}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.229364395141602
Memory status after this trial: 
Memory allocated:  22.50146484375
Memory cached:  30.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.4252418402438565, 'log_learning_rate_D': -1.7949178157697063, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9140625
Memory cached:  10.0
[W 2023-10-30 16:09:25,797] Trial 8 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.4252418402438565, 'log_learning_rate_D': -1.7949178157697063, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:09:25,798] Trial 8 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  0.6445720195770264
Memory status after this trial: 
Memory allocated:  82.29443359375
Memory cached:  98.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.315677155659855, 'log_learning_rate_D': -3.8320956443806495, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.7064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.552734375
Memory cached:  8.0
[I 2023-10-30 16:09:42,361] Trial 9 finished with value: 0.22679825127124786 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.315677155659855, 'log_learning_rate_D': -3.8320956443806495, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.46036195755005
Memory status after this trial: 
Memory allocated:  87.06005859375
Memory cached:  108.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.609900381266771, 'log_learning_rate_D': -1.2669336663748627, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.76171875
Memory cached:  8.0
[I 2023-10-30 16:09:59,856] Trial 10 finished with value: 0.9901200532913208 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.609900381266771, 'log_learning_rate_D': -1.2669336663748627, 'training_batch_size': 10, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.392242908477783
Memory status after this trial: 
Memory allocated:  108.10205078125
Memory cached:  114.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.3428476585758897, 'log_learning_rate_D': -1.7322574366982293, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.98828125
Memory cached:  4.0
[I 2023-10-30 16:10:17,071] Trial 11 finished with value: 0.22993002831935883 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.3428476585758897, 'log_learning_rate_D': -1.7322574366982293, 'training_batch_size': 6, 'training_p': 6}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.105911254882812
Memory status after this trial: 
Memory allocated:  60.06005859375
Memory cached:  68.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.0720634649848149, 'log_learning_rate_D': -3.783655993619188, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(19.4458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  4.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59912109375
Memory cached:  2.0
[I 2023-10-30 16:10:32,575] Trial 12 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.0720634649848149, 'log_learning_rate_D': -3.783655993619188, 'training_batch_size': 6, 'training_p': 2}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.357929229736328
Memory status after this trial: 
Memory allocated:  4.41162109375
Memory cached:  6.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.8745379048954733, 'log_learning_rate_D': -4.864696685080601, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.6480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.37060546875
Memory cached:  2.0
[I 2023-10-30 16:10:48,843] Trial 13 finished with value: 0.22601643204689026 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.8745379048954733, 'log_learning_rate_D': -4.864696685080601, 'training_batch_size': 8, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.114344596862793
Memory status after this trial: 
Memory allocated:  62.20068359375
Memory cached:  90.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.7373646787745445, 'log_learning_rate_D': -4.573064215129868, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.9873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.9296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.5672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.80224609375
Memory cached:  4.0
[I 2023-10-30 16:11:03,978] Trial 14 finished with value: 0.22661414742469788 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.7373646787745445, 'log_learning_rate_D': -4.573064215129868, 'training_batch_size': 12, 'training_p': 3}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.982601404190063
Memory status after this trial: 
Memory allocated:  24.37255859375
Memory cached:  34.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.921018703359006, 'log_learning_rate_D': -4.927290530443205, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  10 training error:  tensor(1.0073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  20 training error:  tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  30 training error:  tensor(1.0040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  40 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  50 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.57861328125
Memory cached:  2.0
[I 2023-10-30 16:11:18,327] Trial 15 finished with value: 0.9911400079727173 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.921018703359006, 'log_learning_rate_D': -4.927290530443205, 'training_batch_size': 7, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.192928791046143
Memory status after this trial: 
Memory allocated:  6.99853515625
Memory cached:  8.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.7726566667597723, 'log_learning_rate_D': -4.0139094639781785, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.9762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.9139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.6822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.302734375
Memory cached:  2.0
[I 2023-10-30 16:11:33,981] Trial 16 finished with value: 0.22717319428920746 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.7726566667597723, 'log_learning_rate_D': -4.0139094639781785, 'training_batch_size': 9, 'training_p': 3}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.497536420822144
Memory status after this trial: 
Memory allocated:  24.37255859375
Memory cached:  34.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.289828592647393, 'log_learning_rate_D': -3.287411920230486, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.9567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.9316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.9168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.8806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.8580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.8316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.26171875
Memory cached:  4.0
[I 2023-10-30 16:11:48,935] Trial 17 finished with value: 0.7664092779159546 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.289828592647393, 'log_learning_rate_D': -3.287411920230486, 'training_batch_size': 7, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.795071363449097
Memory status after this trial: 
Memory allocated:  7.83740234375
Memory cached:  10.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.4132608841086833, 'log_learning_rate_D': -4.993087527273404, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
[I 2023-10-30 16:12:04,630] Trial 18 finished with value: 0.22607724368572235 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.4132608841086833, 'log_learning_rate_D': -4.993087527273404, 'training_batch_size': 9, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.555266380310059
Memory status after this trial: 
Memory allocated:  43.52099609375
Memory cached:  66.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.3932462566866946, 'log_learning_rate_D': -3.433321394721542, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.9717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.9693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.9668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.9642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.9614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5068359375
Memory cached:  8.0
[I 2023-10-30 16:12:19,193] Trial 19 finished with value: 0.957467257976532 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.3932462566866946, 'log_learning_rate_D': -3.433321394721542, 'training_batch_size': 7, 'training_p': 2}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.40204644203186
Memory status after this trial: 
Memory allocated:  3.55712890625
Memory cached:  8.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.383885072677839, 'log_learning_rate_D': -4.325544400483052, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.33935546875
Memory cached:  6.0
[I 2023-10-30 16:12:34,854] Trial 20 finished with value: 0.22656980156898499 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.383885072677839, 'log_learning_rate_D': -4.325544400483052, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.515782833099365
Memory status after this trial: 
Memory allocated:  44.39501953125
Memory cached:  66.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.6979400018326576, 'log_learning_rate_D': -4.0668138724691225, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12353515625
Memory cached:  2.0
[I 2023-10-30 16:12:49,249] Trial 21 finished with value: 0.226528599858284 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.6979400018326576, 'log_learning_rate_D': -4.0668138724691225, 'training_batch_size': 10, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.234251499176025
Memory status after this trial: 
Memory allocated:  13.92822265625
Memory cached:  16.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.0188939292071835, 'log_learning_rate_D': -3.5726484786078987, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.27099609375
Memory cached:  2.0
[I 2023-10-30 16:13:06,493] Trial 22 finished with value: 0.22624468803405762 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.0188939292071835, 'log_learning_rate_D': -3.5726484786078987, 'training_batch_size': 6, 'training_p': 6}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.07868480682373
Memory status after this trial: 
Memory allocated:  65.64990234375
Memory cached:  92.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.406822771903882, 'log_learning_rate_D': -4.890498740729822, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4990234375
Memory cached:  6.0
[I 2023-10-30 16:13:22,049] Trial 23 finished with value: 0.22671642899513245 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.406822771903882, 'log_learning_rate_D': -4.890498740729822, 'training_batch_size': 9, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.400538921356201
Memory status after this trial: 
Memory allocated:  43.52099609375
Memory cached:  66.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.203629928307553, 'log_learning_rate_D': -4.411969117837078, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5615234375
Memory cached:  4.0
[I 2023-10-30 16:13:38,020] Trial 24 finished with value: 0.226676806807518 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.203629928307553, 'log_learning_rate_D': -4.411969117837078, 'training_batch_size': 9, 'training_p': 3}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.820262432098389
Memory status after this trial: 
Memory allocated:  44.40673828125
Memory cached:  64.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.4459294314833366, 'log_learning_rate_D': -4.8456759225089225, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
[I 2023-10-30 16:13:54,812] Trial 25 finished with value: 0.22606447339057922 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.4459294314833366, 'log_learning_rate_D': -4.8456759225089225, 'training_batch_size': 9, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.636901140213013
Memory status after this trial: 
Memory allocated:  114.32763671875
Memory cached:  144.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.9070361659768373, 'log_learning_rate_D': -4.590701410265618, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4140625
Memory cached:  4.0
[I 2023-10-30 16:14:11,371] Trial 26 finished with value: 0.22630086541175842 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.9070361659768373, 'log_learning_rate_D': -4.590701410265618, 'training_batch_size': 11, 'training_p': 3}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.41066837310791
Memory status after this trial: 
Memory allocated:  114.32763671875
Memory cached:  144.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.6166494464637022, 'log_learning_rate_D': -4.275356316147323, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.11767578125
Memory cached:  18.0
[I 2023-10-30 16:14:26,062] Trial 27 finished with value: 0.2261323481798172 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.6166494464637022, 'log_learning_rate_D': -4.275356316147323, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.534199237823486
Memory status after this trial: 
Memory allocated:  21.21923828125
Memory cached:  26.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.04431976868273, 'log_learning_rate_D': -4.107632376517942, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.9822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.9579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.8916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.6964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4921875
Memory cached:  8.0
[I 2023-10-30 16:14:42,105] Trial 28 finished with value: 0.22664885222911835 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.04431976868273, 'log_learning_rate_D': -4.107632376517942, 'training_batch_size': 10, 'training_p': 5}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.881351232528687
Memory status after this trial: 
Memory allocated:  45.77880859375
Memory cached:  68.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.588314858065271, 'log_learning_rate_D': -4.681103500050433, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.32861328125
Memory cached:  6.0
[I 2023-10-30 16:14:56,996] Trial 29 finished with value: 0.22668026387691498 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.588314858065271, 'log_learning_rate_D': -4.681103500050433, 'training_batch_size': 7, 'training_p': 6}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.727316617965698
Memory status after this trial: 
Memory allocated:  12.17333984375
Memory cached:  14.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.0509000227331153, 'log_learning_rate_D': -3.7065635635931873, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.7110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  4.0
[I 2023-10-30 16:15:13,046] Trial 30 finished with value: 0.2268085926771164 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.0509000227331153, 'log_learning_rate_D': -3.7065635635931873, 'training_batch_size': 11, 'training_p': 3}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.89584469795227
Memory status after this trial: 
Memory allocated:  62.66845703125
Memory cached:  90.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.072617832811175, 'log_learning_rate_D': -4.522348101598137, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.9815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.8508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  2.0
[I 2023-10-30 16:15:27,572] Trial 31 finished with value: 0.22617533802986145 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.072617832811175, 'log_learning_rate_D': -4.522348101598137, 'training_batch_size': 9, 'training_p': 4}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  14.356728076934814
Memory status after this trial: 
Memory allocated:  13.89794921875
Memory cached:  16.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.5799356807345846, 'log_learning_rate_D': -3.9830167191447576, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
[I 2023-10-30 16:15:43,118] Trial 32 finished with value: 0.22561870515346527 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.5799356807345846, 'log_learning_rate_D': -3.9830167191447576, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.377307176589966
Memory status after this trial: 
Memory allocated:  46.70751953125
Memory cached:  68.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.595052240925248, 'log_learning_rate_D': -3.97233031050268, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.9268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5595703125
Memory cached:  6.0
[I 2023-10-30 16:15:58,854] Trial 33 finished with value: 0.22685082256793976 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.595052240925248, 'log_learning_rate_D': -3.97233031050268, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.565111637115479
Memory status after this trial: 
Memory allocated:  46.70751953125
Memory cached:  68.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.972948555987423, 'log_learning_rate_D': -4.789500928350539, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.8924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3388671875
Memory cached:  6.0
[I 2023-10-30 16:16:15,691] Trial 34 finished with value: 0.22673813998699188 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.972948555987423, 'log_learning_rate_D': -4.789500928350539, 'training_batch_size': 8, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.665062189102173
Memory status after this trial: 
Memory allocated:  112.96728515625
Memory cached:  142.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.9608869673733507, 'log_learning_rate_D': -4.718851924559138, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7333984375
Memory cached:  4.0
[I 2023-10-30 16:16:33,106] Trial 35 finished with value: 0.23585939407348633 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.9608869673733507, 'log_learning_rate_D': -4.718851924559138, 'training_batch_size': 6, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.256542682647705
Memory status after this trial: 
Memory allocated:  65.06201171875
Memory cached:  72.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.806975888240766, 'log_learning_rate_D': -4.181444055824888, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  6.0
[I 2023-10-30 16:16:51,207] Trial 36 finished with value: 0.22598977386951447 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.806975888240766, 'log_learning_rate_D': -4.181444055824888, 'training_batch_size': 6, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.928980112075806
Memory status after this trial: 
Memory allocated:  118.74560546875
Memory cached:  148.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.814898863329644, 'log_learning_rate_D': -4.273875485757116, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.8987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  22.0
[I 2023-10-30 16:17:08,123] Trial 37 finished with value: 0.22673094272613525 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.814898863329644, 'log_learning_rate_D': -4.273875485757116, 'training_batch_size': 6, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  16.70582675933838
Memory status after this trial: 
Memory allocated:  31.79638671875
Memory cached:  42.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.245520314131281, 'log_learning_rate_D': -3.4874214204517826, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  2.0
[I 2023-10-30 16:17:24,223] Trial 38 finished with value: 0.22715432941913605 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.245520314131281, 'log_learning_rate_D': -3.4874214204517826, 'training_batch_size': 6, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.910568952560425
Memory status after this trial: 
Memory allocated:  13.92822265625
Memory cached:  16.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.238955782415532, 'log_learning_rate_D': -3.157588702750383, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.8806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.390625
Memory cached:  40.0
[I 2023-10-30 16:17:43,080] Trial 39 finished with value: 0.22676384449005127 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.238955782415532, 'log_learning_rate_D': -3.157588702750383, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  18.648176908493042
Memory status after this trial: 
Memory allocated:  187.90576171875
Memory cached:  218.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.85315867017289, 'log_learning_rate_D': -3.832481414272384, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.7986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96630859375
Memory cached:  40.0
[I 2023-10-30 16:18:01,382] Trial 40 finished with value: 0.2263617366552353 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.85315867017289, 'log_learning_rate_D': -3.832481414272384, 'training_batch_size': 6, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  18.12582039833069
Memory status after this trial: 
Memory allocated:  90.48291015625
Memory cached:  100.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5872623814560667, 'log_learning_rate_D': -2.863112050686955, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4658203125
Memory cached:  12.0
[I 2023-10-30 16:18:18,923] Trial 41 finished with value: 0.22598980367183685 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5872623814560667, 'log_learning_rate_D': -2.863112050686955, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.365582942962646
Memory status after this trial: 
Memory allocated:  136.81884765625
Memory cached:  152.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5805127538268122, 'log_learning_rate_D': -2.696628058239443, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  20 training error:  tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  50 training error:  tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.77734375
Memory cached:  60.0
[I 2023-10-30 16:18:37,255] Trial 42 finished with value: 0.22857682406902313 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5805127538268122, 'log_learning_rate_D': -2.696628058239443, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  18.150220155715942
Memory status after this trial: 
Memory allocated:  163.18896484375
Memory cached:  206.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.143454243533891, 'log_learning_rate_D': -2.7796200716276935, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.8910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.83984375
Memory cached:  12.0
[I 2023-10-30 16:18:55,003] Trial 43 finished with value: 0.2266726940870285 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.143454243533891, 'log_learning_rate_D': -2.7796200716276935, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.561588287353516
Memory status after this trial: 
Memory allocated:  130.94189453125
Memory cached:  146.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.629630532039353, 'log_learning_rate_D': -2.955715038232653, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.9609375
Memory cached:  10.0
[I 2023-10-30 16:19:12,343] Trial 44 finished with value: 0.2261027842760086 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.629630532039353, 'log_learning_rate_D': -2.955715038232653, 'training_batch_size': 8, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.14599061012268
Memory status after this trial: 
Memory allocated:  107.59619140625
Memory cached:  136.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.881608354274132, 'log_learning_rate_D': -3.6664648678509404, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.439453125
Memory cached:  8.0
[I 2023-10-30 16:19:31,707] Trial 45 finished with value: 0.2278430461883545 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.881608354274132, 'log_learning_rate_D': -3.6664648678509404, 'training_batch_size': 6, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  19.147323846817017
Memory status after this trial: 
Memory allocated:  126.57568359375
Memory cached:  158.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.1679346885904653, 'log_learning_rate_D': -4.45229419055712, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2158203125
Memory cached:  18.0
[I 2023-10-30 16:19:49,222] Trial 46 finished with value: 0.22642123699188232 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.1679346885904653, 'log_learning_rate_D': -4.45229419055712, 'training_batch_size': 8, 'training_p': 7}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  17.334801197052002
Memory status after this trial: 
Memory allocated:  119.51123046875
Memory cached:  142.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.474464859509574, 'log_learning_rate_D': -3.3084668919954496, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.9902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.9501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.7705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.76123046875
Memory cached:  6.0
[I 2023-10-30 16:20:07,504] Trial 47 finished with value: 0.22626729309558868 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.474464859509574, 'log_learning_rate_D': -3.3084668919954496, 'training_batch_size': 6, 'training_p': 6}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  18.06452751159668
Memory status after this trial: 
Memory allocated:  75.10791015625
Memory cached:  90.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.02048161469989, 'log_learning_rate_D': -3.880065475063778, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.9946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.9900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.9815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.9634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.9207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.5645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.73876953125
Memory cached:  2.0
[I 2023-10-30 16:20:23,088] Trial 48 finished with value: 0.22643354535102844 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.02048161469989, 'log_learning_rate_D': -3.880065475063778, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.22552898526191711.
Time for this trial:  15.395511388778687
Memory status after this trial: 
Memory allocated:  20.89013671875
Memory cached:  22.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.7561394849372034, 'log_learning_rate_D': -4.133165514069198, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.5660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.75341796875
Memory cached:  4.0
[I 2023-10-30 16:20:42,501] Trial 49 finished with value: 0.22700409591197968 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.7561394849372034, 'log_learning_rate_D': -4.133165514069198, 'training_batch_size': 6, 'training_p': 5}. Best is trial 1 with value: 0.22552898526191711.
[I 2023-10-30 16:20:42,501] A new study created in memory with name: no-name-16e296f3-6f16-4c62-8ff3-3217e1c07727
Time for this trial:  19.226654767990112
Memory status after this trial: 
Memory allocated:  100.75146484375
Memory cached:  106.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.687651977883706, 'log_learning_rate_D': -2.2349200599896575, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  16.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6083984375
Memory cached:  20.0
[I 2023-10-30 16:23:00,753] Trial 0 finished with value: 0.999991238117218 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.687651977883706, 'log_learning_rate_D': -2.2349200599896575, 'training_batch_size': 12, 'training_p': 5}. Best is trial 0 with value: 0.999991238117218.
Time for this trial:  138.1433482170105
Memory status after this trial: 
Memory allocated:  124.712890625
Memory cached:  128.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8006463654869314, 'log_learning_rate_D': -4.672358903198418, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1201171875
Memory cached:  20.0
[I 2023-10-30 16:25:19,387] Trial 1 finished with value: 0.22659710049629211 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8006463654869314, 'log_learning_rate_D': -4.672358903198418, 'training_batch_size': 8, 'training_p': 6}. Best is trial 1 with value: 0.22659710049629211.
Time for this trial:  138.48427844047546
Memory status after this trial: 
Memory allocated:  176.8388671875
Memory cached:  180.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.9749075576794297, 'log_learning_rate_D': -2.343773299438873, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.7552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.0849609375
Memory cached:  4.0
[I 2023-10-30 16:26:43,738] Trial 2 finished with value: 0.22630071640014648 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.9749075576794297, 'log_learning_rate_D': -2.343773299438873, 'training_batch_size': 7, 'training_p': 8}. Best is trial 2 with value: 0.22630071640014648.
Time for this trial:  84.2190592288971
Memory status after this trial: 
Memory allocated:  6.90234375
Memory cached:  8.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.6675615694413972, 'log_learning_rate_D': -3.4924774085801977, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.7265625
Memory cached:  16.0
[W 2023-10-30 16:26:49,747] Trial 3 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.6675615694413972, 'log_learning_rate_D': -3.4924774085801977, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:26:49,747] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.872002124786377
Memory status after this trial: 
Memory allocated:  175.900390625
Memory cached:  182.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.3416468381169486, 'log_learning_rate_D': -3.1902255423284203, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.8309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.8062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.7632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.6021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.2099609375
Memory cached:  14.0
[I 2023-10-30 16:28:42,085] Trial 4 finished with value: 0.36557134985923767 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.3416468381169486, 'log_learning_rate_D': -3.1902255423284203, 'training_batch_size': 10, 'training_p': 6}. Best is trial 2 with value: 0.22630071640014648.
Time for this trial:  112.20549750328064
Memory status after this trial: 
Memory allocated:  107.9111328125
Memory cached:  112.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.076964239134008, 'log_learning_rate_D': -3.1509208656860235, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5244140625
Memory cached:  16.0
[I 2023-10-30 16:30:14,407] Trial 5 finished with value: 0.22611753642559052 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.076964239134008, 'log_learning_rate_D': -3.1509208656860235, 'training_batch_size': 9, 'training_p': 4}. Best is trial 5 with value: 0.22611753642559052.
Time for this trial:  92.19792366027832
Memory status after this trial: 
Memory allocated:  71.26708984375
Memory cached:  72.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.858857901637945, 'log_learning_rate_D': -2.762296584050278, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.9322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4814453125
Memory cached:  14.0
[I 2023-10-30 16:32:12,292] Trial 6 finished with value: 0.9952247738838196 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.858857901637945, 'log_learning_rate_D': -2.762296584050278, 'training_batch_size': 12, 'training_p': 6}. Best is trial 5 with value: 0.22611753642559052.
Time for this trial:  117.77477979660034
Memory status after this trial: 
Memory allocated:  85.3046875
Memory cached:  88.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.065516149597702, 'log_learning_rate_D': -2.3669662255604753, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  12.0
	 epoch  20 training error:  tensor(1.2230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1162109375
Memory cached:  10.0
[I 2023-10-30 16:33:56,575] Trial 7 finished with value: 0.9984920620918274 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.065516149597702, 'log_learning_rate_D': -2.3669662255604753, 'training_batch_size': 11, 'training_p': 4}. Best is trial 5 with value: 0.22611753642559052.
Time for this trial:  104.15303301811218
Memory status after this trial: 
Memory allocated:  90.5517578125
Memory cached:  94.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.5449533048231583, 'log_learning_rate_D': -1.5983628499284368, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.7377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.3840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1962890625
Memory cached:  18.0
[I 2023-10-30 16:35:51,739] Trial 8 finished with value: 0.22491002082824707 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.5449533048231583, 'log_learning_rate_D': -1.5983628499284368, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  115.0385992527008
Memory status after this trial: 
Memory allocated:  104.263671875
Memory cached:  108.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.731396109783132, 'log_learning_rate_D': -3.296397825630285, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  14.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  16.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  14.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  14.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  20.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  16.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  14.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7314453125
Memory cached:  14.0
[I 2023-10-30 16:37:50,812] Trial 9 finished with value: 0.9999929666519165 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.731396109783132, 'log_learning_rate_D': -3.296397825630285, 'training_batch_size': 7, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  118.92051935195923
Memory status after this trial: 
Memory allocated:  100.3486328125
Memory cached:  104.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.571728312186044, 'log_learning_rate_D': -1.5942507941988358, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7021484375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7021484375
Memory cached:  14.0
[W 2023-10-30 16:38:07,873] Trial 10 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.571728312186044, 'log_learning_rate_D': -1.5942507941988358, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:38:07,874] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  16.92660403251648
Memory status after this trial: 
Memory allocated:  75.1689453125
Memory cached:  78.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.8708918169223097, 'log_learning_rate_D': -4.087033765632395, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.9417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.4833984375
Memory cached:  30.0
[I 2023-10-30 16:39:53,286] Trial 11 finished with value: 0.22661519050598145 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.8708918169223097, 'log_learning_rate_D': -4.087033765632395, 'training_batch_size': 9, 'training_p': 8}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  105.26966857910156
Memory status after this trial: 
Memory allocated:  127.7099609375
Memory cached:  146.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.2438979173713998, 'log_learning_rate_D': -1.148707111304949, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  12.0
[W 2023-10-30 16:39:58,532] Trial 12 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.2438979173713998, 'log_learning_rate_D': -1.148707111304949, 'training_batch_size': 6, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:39:58,533] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.0416295528411865
Memory status after this trial: 
Memory allocated:  128.38916015625
Memory cached:  132.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.2433960788262381, 'log_learning_rate_D': -1.0115239652374832, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
[W 2023-10-30 16:40:05,859] Trial 13 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.2433960788262381, 'log_learning_rate_D': -1.0115239652374832, 'training_batch_size': 6, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:40:05,860] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.102721452713013
Memory status after this trial: 
Memory allocated:  128.38916015625
Memory cached:  132.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.4873260988599197, 'log_learning_rate_D': -1.1889404489871627, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  16.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  16.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  16.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.908203125
Memory cached:  14.0
[I 2023-10-30 16:43:40,417] Trial 14 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.4873260988599197, 'log_learning_rate_D': -1.1889404489871627, 'training_batch_size': 6, 'training_p': 2}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  214.3737449645996
Memory status after this trial: 
Memory allocated:  128.38916015625
Memory cached:  132.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.771964465014875, 'log_learning_rate_D': -1.0303575238851699, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  30.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.3623046875
Memory cached:  40.0
[I 2023-10-30 16:45:34,607] Trial 15 finished with value: 0.9975601434707642 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.771964465014875, 'log_learning_rate_D': -1.0303575238851699, 'training_batch_size': 9, 'training_p': 2}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  114.00910878181458
Memory status after this trial: 
Memory allocated:  112.79248046875
Memory cached:  132.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4514309748334204, 'log_learning_rate_D': -1.5302923038892444, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7880859375
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.0384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7880859375
Memory cached:  8.0
[W 2023-10-30 16:45:50,902] Trial 16 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4514309748334204, 'log_learning_rate_D': -1.5302923038892444, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:45:50,903] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  16.12370800971985
Memory status after this trial: 
Memory allocated:  100.67138671875
Memory cached:  102.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.423281420172651, 'log_learning_rate_D': -1.801124798472717, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
[I 2023-10-30 16:47:42,719] Trial 17 finished with value: 0.22614483535289764 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.423281420172651, 'log_learning_rate_D': -1.801124798472717, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  111.63380861282349
Memory status after this trial: 
Memory allocated:  102.66162109375
Memory cached:  106.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.418643161391523, 'log_learning_rate_D': -3.4913203641173647, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2939453125
Memory cached:  20.0
[I 2023-10-30 16:49:34,780] Trial 18 finished with value: 0.2284320443868637 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.418643161391523, 'log_learning_rate_D': -3.4913203641173647, 'training_batch_size': 10, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  111.8889582157135
Memory status after this trial: 
Memory allocated:  105.337890625
Memory cached:  108.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0945727951832374, 'log_learning_rate_D': -1.6121183008620656, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.2568359375
Memory cached:  14.0
[W 2023-10-30 16:49:39,579] Trial 19 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0945727951832374, 'log_learning_rate_D': -1.6121183008620656, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 16:49:39,580] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.575045108795166
Memory status after this trial: 
Memory allocated:  111.29248046875
Memory cached:  116.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.3758413128792952, 'log_learning_rate_D': -1.7264824647090173, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2060546875
Memory cached:  14.0
[I 2023-10-30 16:51:54,854] Trial 20 finished with value: 0.2267255336046219 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.3758413128792952, 'log_learning_rate_D': -1.7264824647090173, 'training_batch_size': 8, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  135.0912492275238
Memory status after this trial: 
Memory allocated:  152.78271484375
Memory cached:  158.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -4.035091649756421, 'log_learning_rate_D': -3.7396488346226713, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.9841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.9726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.9528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.8630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
[I 2023-10-30 16:53:24,787] Trial 21 finished with value: 0.7558779716491699 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -4.035091649756421, 'log_learning_rate_D': -3.7396488346226713, 'training_batch_size': 10, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  89.76187443733215
Memory status after this trial: 
Memory allocated:  50.61376953125
Memory cached:  52.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.331702563727746, 'log_learning_rate_D': -2.782786266087615, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.7104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3984375
Memory cached:  6.0
[I 2023-10-30 16:56:33,107] Trial 22 finished with value: 0.22553539276123047 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.331702563727746, 'log_learning_rate_D': -2.782786266087615, 'training_batch_size': 6, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  188.12995386123657
Memory status after this trial: 
Memory allocated:  27.5517578125
Memory cached:  28.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.6242161491963127, 'log_learning_rate_D': -2.7824769083948535, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.8064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.6603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.6361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.6123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
	 epoch  90 training error:  tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.546875
Memory cached:  6.0
[I 2023-10-30 16:59:43,210] Trial 23 finished with value: 1.1129049062728882 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.6242161491963127, 'log_learning_rate_D': -2.7824769083948535, 'training_batch_size': 6, 'training_p': 7}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  189.9111111164093
Memory status after this trial: 
Memory allocated:  40.14599609375
Memory cached:  42.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.21186181229523, 'log_learning_rate_D': -1.5136063675298788, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  16.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  14.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  14.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  18.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  16.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6513671875
Memory cached:  18.0
[I 2023-10-30 17:01:52,105] Trial 24 finished with value: 0.999993622303009 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.21186181229523, 'log_learning_rate_D': -1.5136063675298788, 'training_batch_size': 7, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  128.7121684551239
Memory status after this trial: 
Memory allocated:  97.1552734375
Memory cached:  100.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.189426887886803, 'log_learning_rate_D': -2.094210996137889, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.7085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.6585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.6105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1484375
Memory cached:  14.0
[I 2023-10-30 17:05:04,193] Trial 25 finished with value: 0.3620240092277527 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.189426887886803, 'log_learning_rate_D': -2.094210996137889, 'training_batch_size': 6, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  191.86579751968384
Memory status after this trial: 
Memory allocated:  77.4208984375
Memory cached:  80.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.68493499651609, 'log_learning_rate_D': -2.738539595710193, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.8214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.5807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.8749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
	 epoch  90 training error:  tensor(19.5920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.5126953125
Memory cached:  34.0
[I 2023-10-30 17:07:12,786] Trial 26 finished with value: 36.983436584472656 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.68493499651609, 'log_learning_rate_D': -2.738539595710193, 'training_batch_size': 7, 'training_p': 2}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  128.39370226860046
Memory status after this trial: 
Memory allocated:  116.70849609375
Memory cached:  134.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.104148924346222, 'log_learning_rate_D': -3.042912135103127, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7392578125
Memory cached:  10.0
[I 2023-10-30 17:08:43,518] Trial 27 finished with value: 0.2266579419374466 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.104148924346222, 'log_learning_rate_D': -3.042912135103127, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  90.54115390777588
Memory status after this trial: 
Memory allocated:  65.29052734375
Memory cached:  66.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.858820350167502, 'log_learning_rate_D': -2.561096140753734, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5322265625
Memory cached:  8.0
[I 2023-10-30 17:10:26,105] Trial 28 finished with value: 0.22650885581970215 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.858820350167502, 'log_learning_rate_D': -2.561096140753734, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  102.40165567398071
Memory status after this trial: 
Memory allocated:  34.35693359375
Memory cached:  36.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.421675183852381, 'log_learning_rate_D': -1.9457484665517444, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.4928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.1689453125
Memory cached:  24.0
[I 2023-10-30 17:12:15,691] Trial 29 finished with value: 0.9994478225708008 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.421675183852381, 'log_learning_rate_D': -1.9457484665517444, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  109.39262557029724
Memory status after this trial: 
Memory allocated:  91.25634765625
Memory cached:  96.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.0056157670474475, 'log_learning_rate_D': -2.9907646413637052, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2275390625
Memory cached:  10.0
[I 2023-10-30 17:13:42,122] Trial 30 finished with value: 0.22610770165920258 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.0056157670474475, 'log_learning_rate_D': -2.9907646413637052, 'training_batch_size': 8, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  86.23622226715088
Memory status after this trial: 
Memory allocated:  34.06787109375
Memory cached:  36.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0552346753155615, 'log_learning_rate_D': -1.4687181578444668, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.6455078125
Memory cached:  14.0
[I 2023-10-30 17:15:30,438] Trial 31 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0552346753155615, 'log_learning_rate_D': -1.4687181578444668, 'training_batch_size': 7, 'training_p': 7}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  108.12818479537964
Memory status after this trial: 
Memory allocated:  79.26806640625
Memory cached:  82.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.5337152775494802, 'log_learning_rate_D': -2.1176151102645284, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4296875
Memory cached:  6.0
[I 2023-10-30 17:18:08,987] Trial 32 finished with value: 0.2265760451555252 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.5337152775494802, 'log_learning_rate_D': -2.1176151102645284, 'training_batch_size': 6, 'training_p': 6}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  158.34850788116455
Memory status after this trial: 
Memory allocated:  46.14404296875
Memory cached:  48.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.059200783713753, 'log_learning_rate_D': -2.4644190859033053, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.1689453125
Memory cached:  6.0
[I 2023-10-30 17:19:55,055] Trial 33 finished with value: 0.2264637053012848 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.059200783713753, 'log_learning_rate_D': -2.4644190859033053, 'training_batch_size': 8, 'training_p': 7}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  105.87858963012695
Memory status after this trial: 
Memory allocated:  60.6962890625
Memory cached:  62.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.0060819352671597, 'log_learning_rate_D': -2.889217812826341, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  10.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7939453125
Memory cached:  12.0
[I 2023-10-30 17:21:56,736] Trial 34 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.0060819352671597, 'log_learning_rate_D': -2.889217812826341, 'training_batch_size': 7, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  121.48862099647522
Memory status after this trial: 
Memory allocated:  57.193359375
Memory cached:  58.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.329583226511549, 'log_learning_rate_D': -2.068454512175618, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0517578125
Memory cached:  16.0
[I 2023-10-30 17:24:15,990] Trial 35 finished with value: 0.999943196773529 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.329583226511549, 'log_learning_rate_D': -2.068454512175618, 'training_batch_size': 11, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  139.04459309577942
Memory status after this trial: 
Memory allocated:  69.46728515625
Memory cached:  72.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.379006071736606, 'log_learning_rate_D': -2.1988939331174473, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  26.0
	 epoch  10 training error:  tensor(1.4094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1044921875
Memory cached:  34.0
[I 2023-10-30 17:26:12,046] Trial 36 finished with value: 0.9983011484146118 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.379006071736606, 'log_learning_rate_D': -2.1988939331174473, 'training_batch_size': 8, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  115.85394024848938
Memory status after this trial: 
Memory allocated:  133.9541015625
Memory cached:  148.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.1485179886770087, 'log_learning_rate_D': -3.0721568312248984, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.9894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.9773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.9484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.1416015625
Memory cached:  6.0
[I 2023-10-30 17:27:40,902] Trial 37 finished with value: 0.23156578838825226 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.1485179886770087, 'log_learning_rate_D': -3.0721568312248984, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  88.66128969192505
Memory status after this trial: 
Memory allocated:  18.78076171875
Memory cached:  20.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.9821594048294466, 'log_learning_rate_D': -2.601916600983908, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2392578125
Memory cached:  10.0
[I 2023-10-30 17:29:11,457] Trial 38 finished with value: 0.22745537757873535 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.9821594048294466, 'log_learning_rate_D': -2.601916600983908, 'training_batch_size': 10, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  90.37324166297913
Memory status after this trial: 
Memory allocated:  36.80810546875
Memory cached:  38.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.565524989371373, 'log_learning_rate_D': -3.557615654677381, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3447265625
Memory cached:  16.0
[I 2023-10-30 17:30:48,043] Trial 39 finished with value: 0.2262851744890213 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.565524989371373, 'log_learning_rate_D': -3.557615654677381, 'training_batch_size': 8, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  96.41628980636597
Memory status after this trial: 
Memory allocated:  87.60498046875
Memory cached:  90.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.710968915960586, 'log_learning_rate_D': -2.936154159014154, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.5410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2431640625
Memory cached:  6.0
[I 2023-10-30 17:32:25,122] Trial 40 finished with value: 0.22768822312355042 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.710968915960586, 'log_learning_rate_D': -2.936154159014154, 'training_batch_size': 9, 'training_p': 6}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  96.8879075050354
Memory status after this trial: 
Memory allocated:  27.36962890625
Memory cached:  28.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.281668271179991, 'log_learning_rate_D': -2.3482470253343353, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.8056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.3175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3916015625
Memory cached:  12.0
[I 2023-10-30 17:33:58,370] Trial 41 finished with value: 0.2261752337217331 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.281668271179991, 'log_learning_rate_D': -2.3482470253343353, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  93.07139134407043
Memory status after this trial: 
Memory allocated:  57.39208984375
Memory cached:  58.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.032522805752993, 'log_learning_rate_D': -3.137057743561169, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.6040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7255859375
Memory cached:  16.0
[I 2023-10-30 17:35:38,963] Trial 42 finished with value: 0.22624240815639496 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.032522805752993, 'log_learning_rate_D': -3.137057743561169, 'training_batch_size': 8, 'training_p': 6}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  100.41375374794006
Memory status after this trial: 
Memory allocated:  50.94287109375
Memory cached:  54.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.495659416967814, 'log_learning_rate_D': -2.674394837802933, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.9780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.7797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.3840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1943359375
Memory cached:  16.0
[I 2023-10-30 17:37:53,918] Trial 43 finished with value: 0.24328532814979553 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.495659416967814, 'log_learning_rate_D': -2.674394837802933, 'training_batch_size': 7, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  134.74755954742432
Memory status after this trial: 
Memory allocated:  146.37060546875
Memory cached:  150.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.7947197167276365, 'log_learning_rate_D': -3.23652668890861, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.9902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.5882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7626953125
Memory cached:  8.0
[I 2023-10-30 17:39:25,181] Trial 44 finished with value: 0.3496299684047699 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.7947197167276365, 'log_learning_rate_D': -3.23652668890861, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  91.07958483695984
Memory status after this trial: 
Memory allocated:  41.8310546875
Memory cached:  44.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.158301898204466, 'log_learning_rate_D': -2.3160289773851535, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1474609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1474609375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1474609375
Memory cached:  12.0
[W 2023-10-30 17:39:48,522] Trial 45 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.158301898204466, 'log_learning_rate_D': -2.3160289773851535, 'training_batch_size': 12, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 17:39:48,523] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  23.163008213043213
Memory status after this trial: 
Memory allocated:  82.919921875
Memory cached:  86.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.2708817888221535, 'log_learning_rate_D': -2.429966160662259, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  10.0
[W 2023-10-30 17:40:08,933] Trial 46 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.2708817888221535, 'log_learning_rate_D': -2.429966160662259, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 17:40:08,934] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  20.22117805480957
Memory status after this trial: 
Memory allocated:  82.919921875
Memory cached:  86.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2369705665656983, 'log_learning_rate_D': -2.357662079260159, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  12.0
[I 2023-10-30 17:43:07,756] Trial 47 finished with value: 0.2283337116241455 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2369705665656983, 'log_learning_rate_D': -2.357662079260159, 'training_batch_size': 6, 'training_p': 5}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  178.61925172805786
Memory status after this trial: 
Memory allocated:  82.919921875
Memory cached:  86.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7026559132385777, 'log_learning_rate_D': -2.8904329112436837, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3837890625
Memory cached:  10.0
[I 2023-10-30 17:44:52,843] Trial 48 finished with value: 0.22701476514339447 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7026559132385777, 'log_learning_rate_D': -2.8904329112436837, 'training_batch_size': 10, 'training_p': 4}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  104.88719916343689
Memory status after this trial: 
Memory allocated:  40.28125
Memory cached:  42.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.757781327252354, 'log_learning_rate_D': -1.9180223933587217, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  16.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  14.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3505859375
Memory cached:  18.0
[I 2023-10-30 17:46:47,518] Trial 49 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.757781327252354, 'log_learning_rate_D': -1.9180223933587217, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 0.22491002082824707.
Time for this trial:  114.4622323513031
Memory status after this trial: 
Memory allocated:  102.66162109375
Memory cached:  106.0
