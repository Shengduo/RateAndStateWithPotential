/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2024-03-30 12:09:08,505] Using an existing study with name 'my_study1' instead of creating a new one.
Cuda is available:  True
Device is:  cuda
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial0216_combined_800.pt
Vs.shape:  torch.Size([800, 100])
thetas.shape:  torch.Size([800, 100])
fs.shape:  torch.Size([800, 100])
ts.shape:  torch.Size([800, 100])
Xs.shape:  torch.Size([800, 100])
No pruned database has been founded.
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -2.3145832491851697, 'log_learning_rate_D': -1.8703962742640803, 'log_learning_rate_D_dagger': -2.5829995543125874, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(2.0590, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.1143, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.7019, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.5881, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.5340, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.5035, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.4778, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  10.0
[W 2024-03-30 12:12:09,908] Trial 1 failed with parameters: {'log_learning_rate': -2.3145832491851697, 'log_learning_rate_D': -1.8703962742640803, 'log_learning_rate_D_dagger': -2.5829995543125874, 'training_batch_size': 9, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 12:12:09,909] Trial 1 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  179.153480052948
Memory status after this trial: 
Memory allocated:  6.400390625
Memory cached:  12.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.1480186612646746, 'log_learning_rate_D': -1.003377136535113, 'log_learning_rate_D_dagger': -2.1620094636883223, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.6303, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.54931640625
Memory cached:  6.0
[W 2024-03-30 12:12:24,508] Trial 2 failed with parameters: {'log_learning_rate': -4.1480186612646746, 'log_learning_rate_D': -1.003377136535113, 'log_learning_rate_D_dagger': -2.1620094636883223, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2024-03-30 12:12:24,509] Trial 2 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  14.313059329986572
Memory status after this trial: 
Memory allocated:  6.400390625
Memory cached:  8.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -2.178224313566093, 'log_learning_rate_D': -2.8325773176674582, 'log_learning_rate_D_dagger': -3.003691175134671, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7924, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.2777, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  20 training error:  tensor(1.0619, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9016, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.7721, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.6963, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.6623, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.6250, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.5955, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.5693, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  100 training error:  tensor(0.5458, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  110 training error:  tensor(0.5248, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  120 training error:  tensor(0.5057, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  130 training error:  tensor(0.4882, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  140 training error:  tensor(0.4720, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  150 training error:  tensor(0.4570, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  160 training error:  tensor(0.4430, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  170 training error:  tensor(0.4300, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  180 training error:  tensor(0.4182, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
	 epoch  190 training error:  tensor(0.4076, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74462890625
Memory cached:  12.0
[I 2024-03-30 12:17:29,957] Trial 3 finished with value: 0.30006882548332214 and parameters: {'log_learning_rate': -2.178224313566093, 'log_learning_rate_D': -2.8325773176674582, 'log_learning_rate_D_dagger': -3.003691175134671, 'training_batch_size': 12, 'training_p': 3}. Best is trial 3 with value: 0.30006882548332214.
res:  tensor(0.3001, grad_fn=<ToCopyBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  305.2379744052887
Memory status after this trial: 
Memory allocated:  6.400390625
Memory cached:  10.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -1.0735922476072304, 'log_learning_rate_D': -3.4443543487130883, 'log_learning_rate_D_dagger': -1.8700575064838136, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2628, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3557, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3355, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.4067, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.3315, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.4726, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2905, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2860, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2627, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.5459, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  100 training error:  tensor(0.2584, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
	 epoch  110 training error:  tensor(0.3891, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  12.0
[W 2024-03-30 12:43:07,285] Trial 4 failed with parameters: {'log_learning_rate': -1.0735922476072304, 'log_learning_rate_D': -3.4443543487130883, 'log_learning_rate_D_dagger': -1.8700575064838136, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2024-03-30 12:43:07,285] Trial 4 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  1536.95374917984
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  14.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -2.3271622091785087, 'log_learning_rate_D': -4.284826633025315, 'log_learning_rate_D_dagger': -3.6193313717822866, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.9104, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  10 training error:  tensor(1.6317, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.4798, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  30 training error:  tensor(1.4157, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  40 training error:  tensor(1.3724, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  50 training error:  tensor(1.3265, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  60 training error:  tensor(1.2834, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  70 training error:  tensor(1.2435, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  80 training error:  tensor(1.2049, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  90 training error:  tensor(1.1679, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  100 training error:  tensor(1.1326, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  110 training error:  tensor(1.0989, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  120 training error:  tensor(1.0669, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  130 training error:  tensor(1.0365, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  140 training error:  tensor(1.0078, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  150 training error:  tensor(0.9807, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  160 training error:  tensor(0.9551, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  170 training error:  tensor(0.9311, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.9084, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.8869, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
[I 2024-03-30 12:48:21,391] Trial 5 finished with value: 0.510338306427002 and parameters: {'log_learning_rate': -2.3271622091785087, 'log_learning_rate_D': -4.284826633025315, 'log_learning_rate_D_dagger': -3.6193313717822866, 'training_batch_size': 10, 'training_p': 4}. Best is trial 3 with value: 0.30006882548332214.
Time for this trial:  313.8696994781494
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  20.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -1.6782164687725132, 'log_learning_rate_D': -3.73127590778042, 'log_learning_rate_D_dagger': -2.655636107342951, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(2.0879, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  10 training error:  tensor(1.4710, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  20 training error:  tensor(1.1298, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.8466, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.6904, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.6186, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.5743, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.5462, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.5249, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.5081, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.4949, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  110 training error:  tensor(0.4840, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  120 training error:  tensor(0.4750, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  130 training error:  tensor(0.4671, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  140 training error:  tensor(0.4601, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  150 training error:  tensor(0.4538, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  160 training error:  tensor(0.4479, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  170 training error:  tensor(0.4423, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.4370, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.4319, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
[I 2024-03-30 12:53:41,144] Trial 6 finished with value: 0.2612544298171997 and parameters: {'log_learning_rate': -1.6782164687725132, 'log_learning_rate_D': -3.73127590778042, 'log_learning_rate_D_dagger': -2.655636107342951, 'training_batch_size': 12, 'training_p': 7}. Best is trial 6 with value: 0.2612544298171997.
res:  tensor(0.2613, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3001, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  319.5522198677063
Memory status after this trial: 
Memory allocated:  6.400390625
Memory cached:  20.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.662202928059234, 'log_learning_rate_D': -2.7787862082546035, 'log_learning_rate_D_dagger': -3.0135899747465764, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.8845, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  10 training error:  tensor(1.1964, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.8787, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.6813, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.5711, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.5193, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.4890, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.4678, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.4526, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.4411, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  100 training error:  tensor(0.4302, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  110 training error:  tensor(0.4215, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  120 training error:  tensor(0.4154, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  130 training error:  tensor(0.4053, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  140 training error:  tensor(0.3989, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
	 epoch  150 training error:  tensor(0.3943, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  20.0
[W 2024-03-30 13:04:59,857] Trial 7 failed with parameters: {'log_learning_rate': -4.662202928059234, 'log_learning_rate_D': -2.7787862082546035, 'log_learning_rate_D_dagger': -3.0135899747465764, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2024-03-30 13:04:59,858] Trial 7 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  678.5031957626343
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  20.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.759356230354218, 'log_learning_rate_D': -4.298238540897489, 'log_learning_rate_D_dagger': -2.2192604408902734, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0908, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.3383, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.3035, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.3277, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2825, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2700, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2557, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.3089, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2558, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2785, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  100 training error:  tensor(0.2516, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  110 training error:  tensor(0.2600, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  120 training error:  tensor(0.2713, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  130 training error:  tensor(0.2395, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  140 training error:  tensor(0.2422, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  150 training error:  tensor(0.2428, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  160 training error:  tensor(0.2976, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  170 training error:  tensor(0.2396, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  180 training error:  tensor(0.2479, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
	 epoch  190 training error:  tensor(0.2699, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  20.0
[I 2024-03-30 13:50:34,279] Trial 8 finished with value: 0.20375733077526093 and parameters: {'log_learning_rate': -4.759356230354218, 'log_learning_rate_D': -4.298238540897489, 'log_learning_rate_D_dagger': -2.2192604408902734, 'training_batch_size': 6, 'training_p': 3}. Best is trial 8 with value: 0.20375733077526093.
res:  tensor(0.2038, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.2613, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  2733.994966983795
Memory status after this trial: 
Memory allocated:  6.6494140625
Memory cached:  18.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -3.4116264809137737, 'log_learning_rate_D': -2.8329209578201495, 'log_learning_rate_D_dagger': -1.8495089943003937, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4540, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4589, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3596, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2907, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 13:58:30,682] Trial 9 failed with parameters: {'log_learning_rate': -3.4116264809137737, 'log_learning_rate_D': -2.8329209578201495, 'log_learning_rate_D_dagger': -1.8495089943003937, 'training_batch_size': 6, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2024-03-30 13:58:30,682] Trial 9 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  476.011492729187
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -3.661919997536391, 'log_learning_rate_D': -3.0774603200752613, 'log_learning_rate_D_dagger': -1.127062005773626, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(2.0454, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  10 training error:  tensor(5.9545, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  20 training error:  tensor(1.4629, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  30 training error:  tensor(1.3254, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
[W 2024-03-30 13:59:33,671] Trial 10 failed with parameters: {'log_learning_rate': -3.661919997536391, 'log_learning_rate_D': -3.0774603200752613, 'log_learning_rate_D_dagger': -1.127062005773626, 'training_batch_size': 12, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2024-03-30 13:59:33,671] Trial 10 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  62.763221979141235
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  22.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -1.9020895629548074, 'log_learning_rate_D': -4.918870182945489, 'log_learning_rate_D_dagger': -1.1618221923817713, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(5.5167, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(2.7631, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(1.3791, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(1.1705, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.6820, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(1.0876, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(1.8229, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(1.1938, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(1.3040, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(1.9790, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  100 training error:  tensor(1.5652, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  110 training error:  tensor(1.3672, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  120 training error:  tensor(1.4071, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  130 training error:  tensor(1.6219, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  140 training error:  tensor(2.0603, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  150 training error:  tensor(1.4998, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  160 training error:  tensor(1.2443, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  170 training error:  tensor(1.7978, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  180 training error:  tensor(1.9748, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  190 training error:  tensor(1.5945, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
[I 2024-03-30 14:09:30,818] Trial 11 finished with value: 1.9506734609603882 and parameters: {'log_learning_rate': -1.9020895629548074, 'log_learning_rate_D': -4.918870182945489, 'log_learning_rate_D_dagger': -1.1618221923817713, 'training_batch_size': 9, 'training_p': 2}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  596.9073870182037
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  18.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -2.482147553952724, 'log_learning_rate_D': -4.79147271047834, 'log_learning_rate_D_dagger': -4.717021748805896, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.9079, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(1.8339, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(1.7686, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(1.7098, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(1.6583, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(1.6124, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(1.5732, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(1.5393, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(1.5098, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(1.4844, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  100 training error:  tensor(1.4625, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  110 training error:  tensor(1.4430, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  120 training error:  tensor(1.4256, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  130 training error:  tensor(1.4099, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  140 training error:  tensor(1.3957, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  150 training error:  tensor(1.3823, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  160 training error:  tensor(1.3698, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  170 training error:  tensor(1.3579, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  180 training error:  tensor(1.3465, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  190 training error:  tensor(1.3354, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
[I 2024-03-30 14:23:57,895] Trial 12 finished with value: 0.9706525802612305 and parameters: {'log_learning_rate': -2.482147553952724, 'log_learning_rate_D': -4.79147271047834, 'log_learning_rate_D_dagger': -4.717021748805896, 'training_batch_size': 8, 'training_p': 4}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  866.8146090507507
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  18.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -2.064998752152285, 'log_learning_rate_D': -3.4179222248353547, 'log_learning_rate_D_dagger': -3.284674294056521, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5807, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(1.0629, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8660, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.6671, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.5327, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.5000, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.4706, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.4475, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.4277, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.4103, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.3952, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  110 training error:  tensor(0.3819, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  120 training error:  tensor(0.3704, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  130 training error:  tensor(0.3602, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  140 training error:  tensor(0.3514, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  150 training error:  tensor(0.3437, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  160 training error:  tensor(0.3369, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  170 training error:  tensor(0.3309, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.3256, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.3208, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
[I 2024-03-30 14:33:56,841] Trial 13 finished with value: 0.31669801473617554 and parameters: {'log_learning_rate': -2.064998752152285, 'log_learning_rate_D': -3.4179222248353547, 'log_learning_rate_D_dagger': -3.284674294056521, 'training_batch_size': 9, 'training_p': 2}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  598.6816892623901
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  18.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -1.0849717309547975, 'log_learning_rate_D': -2.381123108987757, 'log_learning_rate_D_dagger': -2.165198350085275, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.6590, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4663, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3500, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3204, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3166, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3161, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.3104, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.3042, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2819, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2686, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.3015, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
[W 2024-03-30 14:41:32,641] Trial 14 failed with parameters: {'log_learning_rate': -1.0849717309547975, 'log_learning_rate_D': -2.381123108987757, 'log_learning_rate_D_dagger': -2.165198350085275, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2024-03-30 14:41:32,641] Trial 14 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  455.55574226379395
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  18.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.272539466873177, 'log_learning_rate_D': -4.0355420933069155, 'log_learning_rate_D_dagger': -3.296492264488119, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.6603, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.8574, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6247, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.4912, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.4404, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.4128, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.3969, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.3844, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.3742, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.3658, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.3573, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  110 training error:  tensor(0.3498, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  120 training error:  tensor(0.3410, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  130 training error:  tensor(0.3360, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  140 training error:  tensor(0.3330, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  150 training error:  tensor(0.3223, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  160 training error:  tensor(0.3185, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  170 training error:  tensor(0.3124, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.3123, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.3045, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[I 2024-03-30 15:27:07,609] Trial 15 finished with value: 0.2199150174856186 and parameters: {'log_learning_rate': -4.272539466873177, 'log_learning_rate_D': -4.0355420933069155, 'log_learning_rate_D_dagger': -3.296492264488119, 'training_batch_size': 6, 'training_p': 4}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  2734.594888687134
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -3.292992112786437, 'log_learning_rate_D': -4.52276107427468, 'log_learning_rate_D_dagger': -1.740255387242955, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.9890, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  20.0
	 epoch  10 training error:  tensor(1.1069, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.7671, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.5275, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.4444, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.4655, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.3920, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.3891, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.3873, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.3902, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  100 training error:  tensor(0.3918, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  110 training error:  tensor(0.3901, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  120 training error:  tensor(0.3786, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  130 training error:  tensor(0.3984, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  140 training error:  tensor(0.3873, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  150 training error:  tensor(0.3895, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  160 training error:  tensor(0.3865, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
	 epoch  170 training error:  tensor(0.3824, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  22.0
	 epoch  180 training error:  tensor(0.3808, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  26.0
	 epoch  190 training error:  tensor(0.3795, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.650390625
Memory cached:  24.0
[I 2024-03-30 15:32:36,847] Trial 16 finished with value: 0.26326942443847656 and parameters: {'log_learning_rate': -3.292992112786437, 'log_learning_rate_D': -4.52276107427468, 'log_learning_rate_D_dagger': -1.740255387242955, 'training_batch_size': 11, 'training_p': 5}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  328.8768198490143
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  20.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -1.2426828037091355, 'log_learning_rate_D': -4.9630352333742165, 'log_learning_rate_D_dagger': -1.419122759667185, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(5.5187, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(2.0683, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(1.1793, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(1.1311, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.6845, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(1.0685, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.9498, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.5499, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.6853, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.6375, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.9657, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  110 training error:  tensor(0.8081, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  120 training error:  tensor(0.6659, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  130 training error:  tensor(1.0751, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  140 training error:  tensor(0.8897, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  150 training error:  tensor(0.9291, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  160 training error:  tensor(0.8768, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  170 training error:  tensor(1.0274, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.6775, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.9203, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.455078125
Memory cached:  18.0
[I 2024-03-30 15:47:00,536] Trial 17 finished with value: 1.0797230005264282 and parameters: {'log_learning_rate': -1.2426828037091355, 'log_learning_rate_D': -4.9630352333742165, 'log_learning_rate_D_dagger': -1.419122759667185, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 0.20375733077526093.
Time for this trial:  863.4287552833557
Memory status after this trial: 
Memory allocated:  12.30615234375
Memory cached:  18.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9859116076002055, 'log_learning_rate_D': -1.924148258191822, 'log_learning_rate_D_dagger': -2.152922965644088, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6526, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 15:48:50,733] Trial 18 failed with parameters: {'log_learning_rate': -4.9859116076002055, 'log_learning_rate_D': -1.924148258191822, 'log_learning_rate_D_dagger': -2.152922965644088, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 15:48:50,733] Trial 18 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.8065013885498
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.938606658863083, 'log_learning_rate_D': -2.4377122117318537, 'log_learning_rate_D_dagger': -2.166518603942559, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7022, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.5325, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.4065, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.3747, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3719, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.4367, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.3334, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.3291, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.3304, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.3395, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  100 training error:  tensor(0.4042, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  110 training error:  tensor(0.3239, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  120 training error:  tensor(0.3186, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  130 training error:  tensor(0.3488, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  140 training error:  tensor(0.2985, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  150 training error:  tensor(0.3264, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  160 training error:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  170 training error:  tensor(0.3042, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  180 training error:  tensor(0.3699, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  190 training error:  tensor(0.3161, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:34:22,037] Trial 19 failed with parameters: {'log_learning_rate': -4.938606658863083, 'log_learning_rate_D': -2.4377122117318537, 'log_learning_rate_D_dagger': -2.166518603942559, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:34:22,038] Trial 19 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  2730.850267648697
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.871122183535188, 'log_learning_rate_D': -1.9418094193786368, 'log_learning_rate_D_dagger': -2.1642192480001765, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4655, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:35:44,095] Trial 20 failed with parameters: {'log_learning_rate': -4.871122183535188, 'log_learning_rate_D': -1.9418094193786368, 'log_learning_rate_D_dagger': -2.1642192480001765, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:35:44,096] Trial 20 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.58010244369507
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.863109779821631, 'log_learning_rate_D': -1.959408735092424, 'log_learning_rate_D_dagger': -2.0489702443185984, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7057, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:37:18,921] Trial 21 failed with parameters: {'log_learning_rate': -4.863109779821631, 'log_learning_rate_D': -1.959408735092424, 'log_learning_rate_D_dagger': -2.0489702443185984, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:37:18,921] Trial 21 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.46472477912903
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.989346823778078, 'log_learning_rate_D': -1.8543087576092558, 'log_learning_rate_D_dagger': -2.101951738237901, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5563, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:38:41,449] Trial 22 failed with parameters: {'log_learning_rate': -4.989346823778078, 'log_learning_rate_D': -1.8543087576092558, 'log_learning_rate_D_dagger': -2.101951738237901, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:38:41,449] Trial 22 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.99030065536499
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.621712326303903, 'log_learning_rate_D': -2.253934096214112, 'log_learning_rate_D_dagger': -2.2201611619628787, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7650, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:40:57,550] Trial 23 failed with parameters: {'log_learning_rate': -4.621712326303903, 'log_learning_rate_D': -2.253934096214112, 'log_learning_rate_D_dagger': -2.2201611619628787, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:40:57,551] Trial 23 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  135.70849990844727
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.781103458939612, 'log_learning_rate_D': -1.9276918358579556, 'log_learning_rate_D_dagger': -2.082647762630777, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6134, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:42:46,393] Trial 24 failed with parameters: {'log_learning_rate': -4.781103458939612, 'log_learning_rate_D': -1.9276918358579556, 'log_learning_rate_D_dagger': -2.082647762630777, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:42:46,394] Trial 24 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.4116849899292
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.993157220426827, 'log_learning_rate_D': -1.894808368565064, 'log_learning_rate_D_dagger': -2.1474661311072905, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7923, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:44:35,964] Trial 25 failed with parameters: {'log_learning_rate': -4.993157220426827, 'log_learning_rate_D': -1.894808368565064, 'log_learning_rate_D_dagger': -2.1474661311072905, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:44:35,964] Trial 25 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.15826177597046
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.94622558539839, 'log_learning_rate_D': -1.9362460972055282, 'log_learning_rate_D_dagger': -2.1253475434324622, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5666, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:45:58,414] Trial 26 failed with parameters: {'log_learning_rate': -4.94622558539839, 'log_learning_rate_D': -1.9362460972055282, 'log_learning_rate_D_dagger': -2.1253475434324622, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:45:58,415] Trial 26 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.03786015510559
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.907061392685171, 'log_learning_rate_D': -1.9192764335506123, 'log_learning_rate_D_dagger': -2.102933322359778, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7172, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:47:34,061] Trial 27 failed with parameters: {'log_learning_rate': -4.907061392685171, 'log_learning_rate_D': -1.9192764335506123, 'log_learning_rate_D_dagger': -2.102933322359778, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:47:34,062] Trial 27 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.2218382358551
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.896750358234379, 'log_learning_rate_D': -1.6790568262672707, 'log_learning_rate_D_dagger': -2.1581483155830554, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6285, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:48:56,515] Trial 28 failed with parameters: {'log_learning_rate': -4.896750358234379, 'log_learning_rate_D': -1.6790568262672707, 'log_learning_rate_D_dagger': -2.1581483155830554, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:48:56,515] Trial 28 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.05933547019958
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.930835782045569, 'log_learning_rate_D': -1.6339767134584178, 'log_learning_rate_D_dagger': -2.3191055641652882, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6739, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:50:32,556] Trial 29 failed with parameters: {'log_learning_rate': -4.930835782045569, 'log_learning_rate_D': -1.6339767134584178, 'log_learning_rate_D_dagger': -2.3191055641652882, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:50:32,557] Trial 29 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.58768367767334
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.980835650988963, 'log_learning_rate_D': -2.0036054342250855, 'log_learning_rate_D_dagger': -2.116810020479747, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7639, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:52:21,290] Trial 30 failed with parameters: {'log_learning_rate': -4.980835650988963, 'log_learning_rate_D': -2.0036054342250855, 'log_learning_rate_D_dagger': -2.116810020479747, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:52:21,291] Trial 30 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.3185715675354
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.921060691209016, 'log_learning_rate_D': -1.8845903004132176, 'log_learning_rate_D_dagger': -1.9340259698769982, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5512, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:53:43,470] Trial 31 failed with parameters: {'log_learning_rate': -4.921060691209016, 'log_learning_rate_D': -1.8845903004132176, 'log_learning_rate_D_dagger': -1.9340259698769982, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:53:43,470] Trial 31 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.81126141548157
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.948674930651894, 'log_learning_rate_D': -1.9973600670647813, 'log_learning_rate_D_dagger': -2.1531308584433915, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6743, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:55:19,281] Trial 32 failed with parameters: {'log_learning_rate': -4.948674930651894, 'log_learning_rate_D': -1.9973600670647813, 'log_learning_rate_D_dagger': -2.1531308584433915, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:55:19,282] Trial 32 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.44726300239563
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.950166486773992, 'log_learning_rate_D': -1.9596772313878699, 'log_learning_rate_D_dagger': -2.10283258137793, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6818, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:56:55,349] Trial 33 failed with parameters: {'log_learning_rate': -4.950166486773992, 'log_learning_rate_D': -1.9596772313878699, 'log_learning_rate_D_dagger': -2.10283258137793, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:56:55,349] Trial 33 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.69387936592102
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.840844565396578, 'log_learning_rate_D': -2.046162322074239, 'log_learning_rate_D_dagger': -2.082702144925116, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5617, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 16:58:31,566] Trial 34 failed with parameters: {'log_learning_rate': -4.840844565396578, 'log_learning_rate_D': -2.046162322074239, 'log_learning_rate_D_dagger': -2.082702144925116, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 16:58:31,567] Trial 34 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.83645629882812
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.988727541954032, 'log_learning_rate_D': -1.8862340727972193, 'log_learning_rate_D_dagger': -2.1732274923240005, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5977, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:00:20,931] Trial 35 failed with parameters: {'log_learning_rate': -4.988727541954032, 'log_learning_rate_D': -1.8862340727972193, 'log_learning_rate_D_dagger': -2.1732274923240005, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:00:20,931] Trial 35 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.95988154411316
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.942097065580056, 'log_learning_rate_D': -1.653878557994915, 'log_learning_rate_D_dagger': -2.1684958320802377, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7820, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:01:42,786] Trial 36 failed with parameters: {'log_learning_rate': -4.942097065580056, 'log_learning_rate_D': -1.653878557994915, 'log_learning_rate_D_dagger': -2.1684958320802377, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:01:42,786] Trial 36 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.46443176269531
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.979189027551908, 'log_learning_rate_D': -1.8818405973249543, 'log_learning_rate_D_dagger': -2.1209819919911648, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5472, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:03:18,268] Trial 37 failed with parameters: {'log_learning_rate': -4.979189027551908, 'log_learning_rate_D': -1.8818405973249543, 'log_learning_rate_D_dagger': -2.1209819919911648, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:03:18,269] Trial 37 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.11610817909241
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.974993596248136, 'log_learning_rate_D': -1.291223777393637, 'log_learning_rate_D_dagger': -2.154753209124318, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5810, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:04:40,426] Trial 38 failed with parameters: {'log_learning_rate': -4.974993596248136, 'log_learning_rate_D': -1.291223777393637, 'log_learning_rate_D_dagger': -2.154753209124318, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:04:40,426] Trial 38 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.7158522605896
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.948265997905579, 'log_learning_rate_D': -1.9200385650007075, 'log_learning_rate_D_dagger': -2.1118971588956357, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7554, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:06:16,306] Trial 39 failed with parameters: {'log_learning_rate': -4.948265997905579, 'log_learning_rate_D': -1.9200385650007075, 'log_learning_rate_D_dagger': -2.1118971588956357, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:06:16,306] Trial 39 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.5116138458252
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.816002313918697, 'log_learning_rate_D': -1.921580058576887, 'log_learning_rate_D_dagger': -2.287653419743693, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6306, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:07:52,434] Trial 40 failed with parameters: {'log_learning_rate': -4.816002313918697, 'log_learning_rate_D': -1.921580058576887, 'log_learning_rate_D_dagger': -2.287653419743693, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:07:52,435] Trial 40 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.77082633972168
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.999919480002537, 'log_learning_rate_D': -1.7550566365712705, 'log_learning_rate_D_dagger': -2.0932989635473174, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6042, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:09:15,069] Trial 41 failed with parameters: {'log_learning_rate': -4.999919480002537, 'log_learning_rate_D': -1.7550566365712705, 'log_learning_rate_D_dagger': -2.0932989635473174, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:09:15,070] Trial 41 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.25815033912659
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.568450996682351, 'log_learning_rate_D': -1.724186736167813, 'log_learning_rate_D_dagger': -2.115784591572508, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6755, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:10:37,679] Trial 42 failed with parameters: {'log_learning_rate': -4.568450996682351, 'log_learning_rate_D': -1.724186736167813, 'log_learning_rate_D_dagger': -2.115784591572508, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:10:37,679] Trial 42 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.23833537101746
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.817000665928045, 'log_learning_rate_D': -1.931123778699503, 'log_learning_rate_D_dagger': -2.1983913264787516, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6801, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:12:13,709] Trial 43 failed with parameters: {'log_learning_rate': -4.817000665928045, 'log_learning_rate_D': -1.931123778699503, 'log_learning_rate_D_dagger': -2.1983913264787516, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:12:13,710] Trial 43 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.60443830490112
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.913802391341356, 'log_learning_rate_D': -1.870609875032689, 'log_learning_rate_D_dagger': -2.0894228132991737, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5034, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:13:35,937] Trial 44 failed with parameters: {'log_learning_rate': -4.913802391341356, 'log_learning_rate_D': -1.870609875032689, 'log_learning_rate_D_dagger': -2.0894228132991737, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:13:35,938] Trial 44 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.8425521850586
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.763668064595365, 'log_learning_rate_D': -1.8010481495120167, 'log_learning_rate_D_dagger': -2.162319330004016, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5721, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:14:58,172] Trial 45 failed with parameters: {'log_learning_rate': -4.763668064595365, 'log_learning_rate_D': -1.8010481495120167, 'log_learning_rate_D_dagger': -2.162319330004016, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:14:58,173] Trial 45 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.87477159500122
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.935061942452387, 'log_learning_rate_D': -2.145506179445941, 'log_learning_rate_D_dagger': -2.0093555407547146, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5695, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:16:47,147] Trial 46 failed with parameters: {'log_learning_rate': -4.935061942452387, 'log_learning_rate_D': -2.145506179445941, 'log_learning_rate_D_dagger': -2.0093555407547146, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:16:47,147] Trial 46 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.57178974151611
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.905937955993052, 'log_learning_rate_D': -1.920030026547996, 'log_learning_rate_D_dagger': -2.243807271757128, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6138, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:18:23,204] Trial 47 failed with parameters: {'log_learning_rate': -4.905937955993052, 'log_learning_rate_D': -1.920030026547996, 'log_learning_rate_D_dagger': -2.243807271757128, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:18:23,204] Trial 47 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.64024114608765
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.84100779442695, 'log_learning_rate_D': -1.9656864009470927, 'log_learning_rate_D_dagger': -2.10407855754074, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6420, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:19:58,531] Trial 48 failed with parameters: {'log_learning_rate': -4.84100779442695, 'log_learning_rate_D': -1.9656864009470927, 'log_learning_rate_D_dagger': -2.10407855754074, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:19:58,531] Trial 48 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.95559167861938
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.994388573408336, 'log_learning_rate_D': -2.042610529869168, 'log_learning_rate_D_dagger': -2.087039817735154, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5257, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:21:33,867] Trial 49 failed with parameters: {'log_learning_rate': -4.994388573408336, 'log_learning_rate_D': -2.042610529869168, 'log_learning_rate_D_dagger': -2.087039817735154, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:21:33,867] Trial 49 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.87172222137451
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.871535920015006, 'log_learning_rate_D': -1.8417939505874235, 'log_learning_rate_D_dagger': -2.232770616694981, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7778, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:23:22,397] Trial 50 failed with parameters: {'log_learning_rate': -4.871535920015006, 'log_learning_rate_D': -1.8417939505874235, 'log_learning_rate_D_dagger': -2.232770616694981, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:23:22,397] Trial 50 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.15629696846008
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.99542453656059, 'log_learning_rate_D': -1.8359767119561505, 'log_learning_rate_D_dagger': -2.0837758996802593, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6505, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:24:44,645] Trial 51 failed with parameters: {'log_learning_rate': -4.99542453656059, 'log_learning_rate_D': -1.8359767119561505, 'log_learning_rate_D_dagger': -2.0837758996802593, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:24:44,646] Trial 51 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.7920594215393
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.956988339471735, 'log_learning_rate_D': -1.62838952919275, 'log_learning_rate_D_dagger': -2.3476495880981716, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7176, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:26:47,172] Trial 52 failed with parameters: {'log_learning_rate': -4.956988339471735, 'log_learning_rate_D': -1.62838952919275, 'log_learning_rate_D_dagger': -2.3476495880981716, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:26:47,173] Trial 52 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.07514500617981
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9534192077657755, 'log_learning_rate_D': -1.8355776730613114, 'log_learning_rate_D_dagger': -1.983204054799692, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6579, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:28:09,621] Trial 53 failed with parameters: {'log_learning_rate': -4.9534192077657755, 'log_learning_rate_D': -1.8355776730613114, 'log_learning_rate_D_dagger': -1.983204054799692, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:28:09,622] Trial 53 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.11078572273254
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.7392835481713345, 'log_learning_rate_D': -1.9357204447985255, 'log_learning_rate_D_dagger': -2.2992322955497047, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5745, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:29:59,209] Trial 54 failed with parameters: {'log_learning_rate': -4.7392835481713345, 'log_learning_rate_D': -1.9357204447985255, 'log_learning_rate_D_dagger': -2.2992322955497047, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:29:59,209] Trial 54 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.18964958190918
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.784248849790688, 'log_learning_rate_D': -2.041772168833649, 'log_learning_rate_D_dagger': -2.1617734619364195, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6435, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:31:48,012] Trial 55 failed with parameters: {'log_learning_rate': -4.784248849790688, 'log_learning_rate_D': -2.041772168833649, 'log_learning_rate_D_dagger': -2.1617734619364195, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:31:48,013] Trial 55 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.27443623542786
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.897030269361613, 'log_learning_rate_D': -1.9881427085825112, 'log_learning_rate_D_dagger': -2.1513767318752364, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5327, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:33:23,746] Trial 56 failed with parameters: {'log_learning_rate': -4.897030269361613, 'log_learning_rate_D': -1.9881427085825112, 'log_learning_rate_D_dagger': -2.1513767318752364, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:33:23,746] Trial 56 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.28911209106445
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9183305755097235, 'log_learning_rate_D': -1.7640332815273725, 'log_learning_rate_D_dagger': -2.2097182754336093, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7292, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:35:12,763] Trial 57 failed with parameters: {'log_learning_rate': -4.9183305755097235, 'log_learning_rate_D': -1.7640332815273725, 'log_learning_rate_D_dagger': -2.2097182754336093, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:35:12,764] Trial 57 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.63718175888062
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.775325933366733, 'log_learning_rate_D': -1.8092611151425464, 'log_learning_rate_D_dagger': -2.1971976967710645, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6757, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:36:48,664] Trial 58 failed with parameters: {'log_learning_rate': -4.775325933366733, 'log_learning_rate_D': -1.8092611151425464, 'log_learning_rate_D_dagger': -2.1971976967710645, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:36:48,664] Trial 58 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.32196044921875
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.4636526356421475, 'log_learning_rate_D': -1.5390707588839452, 'log_learning_rate_D_dagger': -2.1943284469775444, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5518, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:38:10,477] Trial 59 failed with parameters: {'log_learning_rate': -4.4636526356421475, 'log_learning_rate_D': -1.5390707588839452, 'log_learning_rate_D_dagger': -2.1943284469775444, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:38:10,478] Trial 59 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.43742752075195
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.560106030814358, 'log_learning_rate_D': -2.0041755262271517, 'log_learning_rate_D_dagger': -2.1992600179702624, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5653, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:39:59,437] Trial 60 failed with parameters: {'log_learning_rate': -4.560106030814358, 'log_learning_rate_D': -2.0041755262271517, 'log_learning_rate_D_dagger': -2.1992600179702624, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:39:59,438] Trial 60 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.59919118881226
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.855650068378935, 'log_learning_rate_D': -1.8115283690946957, 'log_learning_rate_D_dagger': -2.315647303722524, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6436, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:41:35,547] Trial 61 failed with parameters: {'log_learning_rate': -4.855650068378935, 'log_learning_rate_D': -1.8115283690946957, 'log_learning_rate_D_dagger': -2.315647303722524, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:41:35,548] Trial 61 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.75309610366821
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.922425748935541, 'log_learning_rate_D': -2.024619328927991, 'log_learning_rate_D_dagger': -2.0589848509590096, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5322, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:43:12,059] Trial 62 failed with parameters: {'log_learning_rate': -4.922425748935541, 'log_learning_rate_D': -2.024619328927991, 'log_learning_rate_D_dagger': -2.0589848509590096, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:43:12,060] Trial 62 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  96.08650207519531
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.934456909555061, 'log_learning_rate_D': -1.9011602238708227, 'log_learning_rate_D_dagger': -2.058589360623382, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4637, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:44:34,235] Trial 63 failed with parameters: {'log_learning_rate': -4.934456909555061, 'log_learning_rate_D': -1.9011602238708227, 'log_learning_rate_D_dagger': -2.058589360623382, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:44:34,236] Trial 63 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.77541637420654
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.888697654917692, 'log_learning_rate_D': -1.9393422304866381, 'log_learning_rate_D_dagger': -2.2209973139255528, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6934, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:46:22,544] Trial 64 failed with parameters: {'log_learning_rate': -4.888697654917692, 'log_learning_rate_D': -1.9393422304866381, 'log_learning_rate_D_dagger': -2.2209973139255528, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:46:22,544] Trial 64 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  107.94692969322205
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9785694138960785, 'log_learning_rate_D': -1.6267788366585156, 'log_learning_rate_D_dagger': -2.1392788051730243, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5642, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:47:30,950] Trial 65 failed with parameters: {'log_learning_rate': -4.9785694138960785, 'log_learning_rate_D': -1.6267788366585156, 'log_learning_rate_D_dagger': -2.1392788051730243, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:47:30,951] Trial 65 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  67.90637373924255
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.987445512721761, 'log_learning_rate_D': -1.5819169817812488, 'log_learning_rate_D_dagger': -2.096963922594138, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5376, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:48:53,677] Trial 66 failed with parameters: {'log_learning_rate': -4.987445512721761, 'log_learning_rate_D': -1.5819169817812488, 'log_learning_rate_D_dagger': -2.096963922594138, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:48:53,677] Trial 66 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.30991077423096
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.977729060357015, 'log_learning_rate_D': -1.408888020317867, 'log_learning_rate_D_dagger': -2.1823922863389402, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4714, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:50:16,042] Trial 67 failed with parameters: {'log_learning_rate': -4.977729060357015, 'log_learning_rate_D': -1.408888020317867, 'log_learning_rate_D_dagger': -2.1823922863389402, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:50:16,042] Trial 67 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.01233005523682
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.906376725604902, 'log_learning_rate_D': -1.9286691664327607, 'log_learning_rate_D_dagger': -2.133968272210163, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6176, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:51:50,690] Trial 68 failed with parameters: {'log_learning_rate': -4.906376725604902, 'log_learning_rate_D': -1.9286691664327607, 'log_learning_rate_D_dagger': -2.133968272210163, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:51:50,690] Trial 68 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.25219130516052
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.828740203512808, 'log_learning_rate_D': -1.9414901922506673, 'log_learning_rate_D_dagger': -2.1273706727614945, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5743, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:53:26,130] Trial 69 failed with parameters: {'log_learning_rate': -4.828740203512808, 'log_learning_rate_D': -1.9414901922506673, 'log_learning_rate_D_dagger': -2.1273706727614945, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:53:26,130] Trial 69 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.05982303619385
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.997862992634381, 'log_learning_rate_D': -1.970985978688657, 'log_learning_rate_D_dagger': -2.036744909827342, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5715, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:55:01,462] Trial 70 failed with parameters: {'log_learning_rate': -4.997862992634381, 'log_learning_rate_D': -1.970985978688657, 'log_learning_rate_D_dagger': -2.036744909827342, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:55:01,463] Trial 70 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.8532202243805
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.645709190326191, 'log_learning_rate_D': -2.005433247398427, 'log_learning_rate_D_dagger': -2.2414143830624367, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6477, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:56:37,476] Trial 71 failed with parameters: {'log_learning_rate': -4.645709190326191, 'log_learning_rate_D': -2.005433247398427, 'log_learning_rate_D_dagger': -2.2414143830624367, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:56:37,476] Trial 71 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.45949649810791
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.852008863292298, 'log_learning_rate_D': -2.025967738955492, 'log_learning_rate_D_dagger': -2.134508599655784, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8963, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 17:58:26,413] Trial 72 failed with parameters: {'log_learning_rate': -4.852008863292298, 'log_learning_rate_D': -2.025967738955492, 'log_learning_rate_D_dagger': -2.134508599655784, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 17:58:26,414] Trial 72 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.48411726951599
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.762481755561156, 'log_learning_rate_D': -2.126196443638608, 'log_learning_rate_D_dagger': -2.12795807426139, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7910, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:00:29,557] Trial 73 failed with parameters: {'log_learning_rate': -4.762481755561156, 'log_learning_rate_D': -2.126196443638608, 'log_learning_rate_D_dagger': -2.12795807426139, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:00:29,558] Trial 73 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.74583435058594
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.987489353082549, 'log_learning_rate_D': -1.9281450453762292, 'log_learning_rate_D_dagger': -2.163348426629462, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6289, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:02:05,359] Trial 74 failed with parameters: {'log_learning_rate': -4.987489353082549, 'log_learning_rate_D': -1.9281450453762292, 'log_learning_rate_D_dagger': -2.163348426629462, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:02:05,359] Trial 74 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.42523145675659
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.977349893319139, 'log_learning_rate_D': -1.7768054727268066, 'log_learning_rate_D_dagger': -2.1601665704292423, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7014, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:03:41,327] Trial 75 failed with parameters: {'log_learning_rate': -4.977349893319139, 'log_learning_rate_D': -1.7768054727268066, 'log_learning_rate_D_dagger': -2.1601665704292423, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:03:41,327] Trial 75 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.52700781822205
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.922606166365748, 'log_learning_rate_D': -1.912613196761392, 'log_learning_rate_D_dagger': -2.1571774439570843, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6200, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:05:30,600] Trial 76 failed with parameters: {'log_learning_rate': -4.922606166365748, 'log_learning_rate_D': -1.912613196761392, 'log_learning_rate_D_dagger': -2.1571774439570843, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:05:30,600] Trial 76 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.8171534538269
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.845324244862374, 'log_learning_rate_D': -2.1743319285537774, 'log_learning_rate_D_dagger': -2.1244648510946544, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6114, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:07:19,536] Trial 77 failed with parameters: {'log_learning_rate': -4.845324244862374, 'log_learning_rate_D': -2.1743319285537774, 'log_learning_rate_D_dagger': -2.1244648510946544, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:07:19,536] Trial 77 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.56212711334229
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.891765908975968, 'log_learning_rate_D': -2.1341706462421635, 'log_learning_rate_D_dagger': -2.1830860903069724, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6235, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:09:08,399] Trial 78 failed with parameters: {'log_learning_rate': -4.891765908975968, 'log_learning_rate_D': -2.1341706462421635, 'log_learning_rate_D_dagger': -2.1830860903069724, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:09:08,400] Trial 78 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.47299265861511
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.982869444064487, 'log_learning_rate_D': -2.053703168006195, 'log_learning_rate_D_dagger': -2.145477626327436, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6579, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:10:43,822] Trial 79 failed with parameters: {'log_learning_rate': -4.982869444064487, 'log_learning_rate_D': -2.053703168006195, 'log_learning_rate_D_dagger': -2.145477626327436, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:10:43,822] Trial 79 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.93123483657837
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.833631175107642, 'log_learning_rate_D': -1.693690742928064, 'log_learning_rate_D_dagger': -2.1316342008162756, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6168, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:12:05,736] Trial 80 failed with parameters: {'log_learning_rate': -4.833631175107642, 'log_learning_rate_D': -1.693690742928064, 'log_learning_rate_D_dagger': -2.1316342008162756, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:12:05,736] Trial 80 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.53204536437988
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9820938051526955, 'log_learning_rate_D': -1.8277595126424941, 'log_learning_rate_D_dagger': -2.0744531942220643, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5895, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:13:41,573] Trial 81 failed with parameters: {'log_learning_rate': -4.9820938051526955, 'log_learning_rate_D': -1.8277595126424941, 'log_learning_rate_D_dagger': -2.0744531942220643, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:13:41,573] Trial 81 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.4330587387085
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.932751014358417, 'log_learning_rate_D': -1.871547518770054, 'log_learning_rate_D_dagger': -2.308388359223834, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6831, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:15:31,959] Trial 82 failed with parameters: {'log_learning_rate': -4.932751014358417, 'log_learning_rate_D': -1.871547518770054, 'log_learning_rate_D_dagger': -2.308388359223834, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:15:31,959] Trial 82 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.96796321868896
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.841084756403182, 'log_learning_rate_D': -1.966437771196801, 'log_learning_rate_D_dagger': -2.0657369938302312, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7054, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:16:54,043] Trial 83 failed with parameters: {'log_learning_rate': -4.841084756403182, 'log_learning_rate_D': -1.966437771196801, 'log_learning_rate_D_dagger': -2.0657369938302312, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:16:54,043] Trial 83 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.69056177139282
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.868639554573714, 'log_learning_rate_D': -1.94406694112479, 'log_learning_rate_D_dagger': -2.1269695032639087, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6613, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:18:29,841] Trial 84 failed with parameters: {'log_learning_rate': -4.868639554573714, 'log_learning_rate_D': -1.94406694112479, 'log_learning_rate_D_dagger': -2.1269695032639087, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:18:29,842] Trial 84 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.38454747200012
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.8823876101804355, 'log_learning_rate_D': -1.1249637296157653, 'log_learning_rate_D_dagger': -2.226771814277792, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5826, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:20:05,202] Trial 85 failed with parameters: {'log_learning_rate': -4.8823876101804355, 'log_learning_rate_D': -1.1249637296157653, 'log_learning_rate_D_dagger': -2.226771814277792, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:20:05,202] Trial 85 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.0222418308258
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.916510580578528, 'log_learning_rate_D': -2.1062379185485125, 'log_learning_rate_D_dagger': -2.1597413162614596, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6369, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:21:41,157] Trial 86 failed with parameters: {'log_learning_rate': -4.916510580578528, 'log_learning_rate_D': -2.1062379185485125, 'log_learning_rate_D_dagger': -2.1597413162614596, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:21:41,158] Trial 86 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.54212856292725
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.853187950022254, 'log_learning_rate_D': -1.8196662177047984, 'log_learning_rate_D_dagger': -2.164642584244948, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5926, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:23:03,327] Trial 87 failed with parameters: {'log_learning_rate': -4.853187950022254, 'log_learning_rate_D': -1.8196662177047984, 'log_learning_rate_D_dagger': -2.164642584244948, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:23:03,328] Trial 87 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.79234647750854
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.977667797459066, 'log_learning_rate_D': -1.937193056629725, 'log_learning_rate_D_dagger': -2.145122266584568, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7060, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:24:38,862] Trial 88 failed with parameters: {'log_learning_rate': -4.977667797459066, 'log_learning_rate_D': -1.937193056629725, 'log_learning_rate_D_dagger': -2.145122266584568, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:24:38,863] Trial 88 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.16730260848999
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.815166524269053, 'log_learning_rate_D': -1.9392363757362991, 'log_learning_rate_D_dagger': -2.0343434265890825, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7824, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:26:14,803] Trial 89 failed with parameters: {'log_learning_rate': -4.815166524269053, 'log_learning_rate_D': -1.9392363757362991, 'log_learning_rate_D_dagger': -2.0343434265890825, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:26:14,804] Trial 89 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.53898000717163
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.895030262666575, 'log_learning_rate_D': -2.0494582533147256, 'log_learning_rate_D_dagger': -2.043848871913338, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6898, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:27:50,193] Trial 90 failed with parameters: {'log_learning_rate': -4.895030262666575, 'log_learning_rate_D': -2.0494582533147256, 'log_learning_rate_D_dagger': -2.043848871913338, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:27:50,193] Trial 90 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.97263073921204
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.893355207940299, 'log_learning_rate_D': -1.939356526058822, 'log_learning_rate_D_dagger': -2.12174290706973, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7391, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:29:26,367] Trial 91 failed with parameters: {'log_learning_rate': -4.893355207940299, 'log_learning_rate_D': -1.939356526058822, 'log_learning_rate_D_dagger': -2.12174290706973, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:29:26,367] Trial 91 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.6980345249176
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.770602410676946, 'log_learning_rate_D': -1.96655260673547, 'log_learning_rate_D_dagger': -2.3229434849742954, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7763, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:31:15,772] Trial 92 failed with parameters: {'log_learning_rate': -4.770602410676946, 'log_learning_rate_D': -1.96655260673547, 'log_learning_rate_D_dagger': -2.3229434849742954, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:31:15,772] Trial 92 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.02101469039917
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.811032644158315, 'log_learning_rate_D': -1.9543952730261234, 'log_learning_rate_D_dagger': -2.2020990930221376, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8346, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:33:04,319] Trial 93 failed with parameters: {'log_learning_rate': -4.811032644158315, 'log_learning_rate_D': -1.9543952730261234, 'log_learning_rate_D_dagger': -2.2020990930221376, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:33:04,320] Trial 93 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.11843490600586
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.871194417966207, 'log_learning_rate_D': -2.0635066634313235, 'log_learning_rate_D_dagger': -2.1758438061361067, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7734, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:35:07,452] Trial 94 failed with parameters: {'log_learning_rate': -4.871194417966207, 'log_learning_rate_D': -2.0635066634313235, 'log_learning_rate_D_dagger': -2.1758438061361067, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:35:07,453] Trial 94 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.73216152191162
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.974809031584354, 'log_learning_rate_D': -2.0149540701631303, 'log_learning_rate_D_dagger': -2.1896885169573106, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5064, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:36:43,220] Trial 95 failed with parameters: {'log_learning_rate': -4.974809031584354, 'log_learning_rate_D': -2.0149540701631303, 'log_learning_rate_D_dagger': -2.1896885169573106, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:36:43,221] Trial 95 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.37419056892395
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.933637149672185, 'log_learning_rate_D': -1.9368487147617737, 'log_learning_rate_D_dagger': -2.213629031122872, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7099, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:38:19,221] Trial 96 failed with parameters: {'log_learning_rate': -4.933637149672185, 'log_learning_rate_D': -1.9368487147617737, 'log_learning_rate_D_dagger': -2.213629031122872, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:38:19,221] Trial 96 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.56644558906555
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.543663412374905, 'log_learning_rate_D': -1.8198032162326752, 'log_learning_rate_D_dagger': -2.085990715528452, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5527, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:39:41,570] Trial 97 failed with parameters: {'log_learning_rate': -4.543663412374905, 'log_learning_rate_D': -1.8198032162326752, 'log_learning_rate_D_dagger': -2.085990715528452, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:39:41,571] Trial 97 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.9599392414093
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.89101278332253, 'log_learning_rate_D': -1.6893913801957012, 'log_learning_rate_D_dagger': -2.2366674226113346, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7341, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:41:04,088] Trial 98 failed with parameters: {'log_learning_rate': -4.89101278332253, 'log_learning_rate_D': -1.6893913801957012, 'log_learning_rate_D_dagger': -2.2366674226113346, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:41:04,089] Trial 98 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.17023015022278
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9370756081344345, 'log_learning_rate_D': -1.9319120934646379, 'log_learning_rate_D_dagger': -2.0882715751353014, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5689, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:42:39,725] Trial 99 failed with parameters: {'log_learning_rate': -4.9370756081344345, 'log_learning_rate_D': -1.9319120934646379, 'log_learning_rate_D_dagger': -2.0882715751353014, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:42:39,725] Trial 99 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.08841753005981
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  100   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.927807255444536, 'log_learning_rate_D': -1.9228640634641758, 'log_learning_rate_D_dagger': -2.288721149630055, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5673, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:44:15,187] Trial 100 failed with parameters: {'log_learning_rate': -4.927807255444536, 'log_learning_rate_D': -1.9228640634641758, 'log_learning_rate_D_dagger': -2.288721149630055, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:44:15,187] Trial 100 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.00614809989929
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  101   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9731057886192644, 'log_learning_rate_D': -1.700055294566432, 'log_learning_rate_D_dagger': -2.1208272558156587, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5367, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:45:23,556] Trial 101 failed with parameters: {'log_learning_rate': -4.9731057886192644, 'log_learning_rate_D': -1.700055294566432, 'log_learning_rate_D_dagger': -2.1208272558156587, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:45:23,557] Trial 101 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  67.9518256187439
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  102   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.940759671773664, 'log_learning_rate_D': -2.05355306062131, 'log_learning_rate_D_dagger': -2.1396858411911515, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7082, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:47:26,152] Trial 102 failed with parameters: {'log_learning_rate': -4.940759671773664, 'log_learning_rate_D': -2.05355306062131, 'log_learning_rate_D_dagger': -2.1396858411911515, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:47:26,153] Trial 102 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.19240355491638
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  103   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.8586297039263195, 'log_learning_rate_D': -1.8799520176039768, 'log_learning_rate_D_dagger': -2.2897626261574606, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6744, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:49:28,576] Trial 103 failed with parameters: {'log_learning_rate': -4.8586297039263195, 'log_learning_rate_D': -1.8799520176039768, 'log_learning_rate_D_dagger': -2.2897626261574606, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:49:28,576] Trial 103 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.04499959945679
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  104   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9509217563283245, 'log_learning_rate_D': -1.9018989532627768, 'log_learning_rate_D_dagger': -2.0443794510684605, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7242, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:51:04,086] Trial 104 failed with parameters: {'log_learning_rate': -4.9509217563283245, 'log_learning_rate_D': -1.9018989532627768, 'log_learning_rate_D_dagger': -2.0443794510684605, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:51:04,086] Trial 104 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.15112733840942
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  105   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.970364607263988, 'log_learning_rate_D': -1.7064388414716776, 'log_learning_rate_D_dagger': -1.8615645341289562, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.9221, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:52:27,049] Trial 105 failed with parameters: {'log_learning_rate': -4.970364607263988, 'log_learning_rate_D': -1.7064388414716776, 'log_learning_rate_D_dagger': -1.8615645341289562, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:52:27,050] Trial 105 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.58271765708923
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  106   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.769091216898291, 'log_learning_rate_D': -2.1803636835497295, 'log_learning_rate_D_dagger': -2.1943561782708123, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5938, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:54:16,172] Trial 106 failed with parameters: {'log_learning_rate': -4.769091216898291, 'log_learning_rate_D': -2.1803636835497295, 'log_learning_rate_D_dagger': -2.1943561782708123, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:54:16,173] Trial 106 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.70252227783203
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  107   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.709865994769293, 'log_learning_rate_D': -1.9170499677039725, 'log_learning_rate_D_dagger': -1.9377784872673955, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8149, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:55:38,343] Trial 107 failed with parameters: {'log_learning_rate': -4.709865994769293, 'log_learning_rate_D': -1.9170499677039725, 'log_learning_rate_D_dagger': -1.9377784872673955, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:55:38,343] Trial 107 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.73784303665161
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  108   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.902699138741192, 'log_learning_rate_D': -1.7348227045683418, 'log_learning_rate_D_dagger': -2.148342648321508, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7258, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:57:00,623] Trial 108 failed with parameters: {'log_learning_rate': -4.902699138741192, 'log_learning_rate_D': -1.7348227045683418, 'log_learning_rate_D_dagger': -2.148342648321508, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:57:00,624] Trial 108 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.9056146144867
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  109   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.835228906682761, 'log_learning_rate_D': -1.8436155448278186, 'log_learning_rate_D_dagger': -2.092728178136979, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5626, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 18:58:22,775] Trial 109 failed with parameters: {'log_learning_rate': -4.835228906682761, 'log_learning_rate_D': -1.8436155448278186, 'log_learning_rate_D_dagger': -2.092728178136979, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 18:58:22,776] Trial 109 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.78605055809021
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  110   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.856943234513958, 'log_learning_rate_D': -2.1623097925176893, 'log_learning_rate_D_dagger': -2.1448273541308547, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6151, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:00:11,359] Trial 110 failed with parameters: {'log_learning_rate': -4.856943234513958, 'log_learning_rate_D': -2.1623097925176893, 'log_learning_rate_D_dagger': -2.1448273541308547, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:00:11,359] Trial 110 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.17224884033203
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  111   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.726508218271887, 'log_learning_rate_D': -1.8978622134597338, 'log_learning_rate_D_dagger': -2.1931185809583122, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7038, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:02:00,617] Trial 111 failed with parameters: {'log_learning_rate': -4.726508218271887, 'log_learning_rate_D': -1.8978622134597338, 'log_learning_rate_D_dagger': -2.1931185809583122, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:02:00,617] Trial 111 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.84014534950256
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  112   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.923394780841911, 'log_learning_rate_D': -1.8701232733837059, 'log_learning_rate_D_dagger': -2.1631566774644932, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5144, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:03:22,777] Trial 112 failed with parameters: {'log_learning_rate': -4.923394780841911, 'log_learning_rate_D': -1.8701232733837059, 'log_learning_rate_D_dagger': -2.1631566774644932, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:03:22,777] Trial 112 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.753897190094
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  113   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.978190302614966, 'log_learning_rate_D': -2.0155534746551185, 'log_learning_rate_D_dagger': -2.1311712455233813, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6029, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:04:58,147] Trial 113 failed with parameters: {'log_learning_rate': -4.978190302614966, 'log_learning_rate_D': -2.0155534746551185, 'log_learning_rate_D_dagger': -2.1311712455233813, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:04:58,148] Trial 113 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.9040322303772
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  114   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.952535621953629, 'log_learning_rate_D': -1.758505795361057, 'log_learning_rate_D_dagger': -2.138953665697566, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7416, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:06:20,198] Trial 114 failed with parameters: {'log_learning_rate': -4.952535621953629, 'log_learning_rate_D': -1.758505795361057, 'log_learning_rate_D_dagger': -2.138953665697566, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:06:20,198] Trial 114 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.63761687278748
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  115   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.966187600591621, 'log_learning_rate_D': -1.8163513573206047, 'log_learning_rate_D_dagger': -2.095598617323879, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3943, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:07:55,804] Trial 115 failed with parameters: {'log_learning_rate': -4.966187600591621, 'log_learning_rate_D': -1.8163513573206047, 'log_learning_rate_D_dagger': -2.095598617323879, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:07:55,804] Trial 115 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.19681739807129
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  116   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.848409351951141, 'log_learning_rate_D': -1.8838869879887534, 'log_learning_rate_D_dagger': -2.016159809944864, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5711, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:09:17,724] Trial 116 failed with parameters: {'log_learning_rate': -4.848409351951141, 'log_learning_rate_D': -1.8838869879887534, 'log_learning_rate_D_dagger': -2.016159809944864, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:09:17,724] Trial 116 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.50286722183228
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  117   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.956580266732634, 'log_learning_rate_D': -1.7253426694276386, 'log_learning_rate_D_dagger': -2.1484912004023764, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7128, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:10:40,058] Trial 117 failed with parameters: {'log_learning_rate': -4.956580266732634, 'log_learning_rate_D': -1.7253426694276386, 'log_learning_rate_D_dagger': -2.1484912004023764, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:10:40,058] Trial 117 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.9699604511261
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  118   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.634475305629529, 'log_learning_rate_D': -1.9666403058319717, 'log_learning_rate_D_dagger': -2.135282611330264, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6568, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:12:15,742] Trial 118 failed with parameters: {'log_learning_rate': -4.634475305629529, 'log_learning_rate_D': -1.9666403058319717, 'log_learning_rate_D_dagger': -2.135282611330264, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:12:15,742] Trial 118 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.15462636947632
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  119   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.854841782325876, 'log_learning_rate_D': -1.9256962154018007, 'log_learning_rate_D_dagger': -2.2593383480313123, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6680, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:13:51,083] Trial 119 failed with parameters: {'log_learning_rate': -4.854841782325876, 'log_learning_rate_D': -1.9256962154018007, 'log_learning_rate_D_dagger': -2.2593383480313123, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:13:51,084] Trial 119 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.99006676673889
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  120   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.998551413720813, 'log_learning_rate_D': -2.100501115840792, 'log_learning_rate_D_dagger': -1.8425860203716466, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.9215, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:15:39,695] Trial 120 failed with parameters: {'log_learning_rate': -4.998551413720813, 'log_learning_rate_D': -2.100501115840792, 'log_learning_rate_D_dagger': -1.8425860203716466, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:15:39,695] Trial 120 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.12257242202759
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  121   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.368303466527509, 'log_learning_rate_D': -1.9075064268512225, 'log_learning_rate_D_dagger': -2.116526515877328, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5772, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:17:01,714] Trial 121 failed with parameters: {'log_learning_rate': -4.368303466527509, 'log_learning_rate_D': -1.9075064268512225, 'log_learning_rate_D_dagger': -2.116526515877328, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:17:01,715] Trial 121 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.5669629573822
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  122   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.865292554031173, 'log_learning_rate_D': -1.9407305619718063, 'log_learning_rate_D_dagger': -2.1651098814860252, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6541, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:18:37,310] Trial 122 failed with parameters: {'log_learning_rate': -4.865292554031173, 'log_learning_rate_D': -1.9407305619718063, 'log_learning_rate_D_dagger': -2.1651098814860252, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:18:37,311] Trial 122 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.14726853370667
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  123   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.524074333749784, 'log_learning_rate_D': -1.8250413756185258, 'log_learning_rate_D_dagger': -2.214858258511425, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6552, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:20:12,472] Trial 123 failed with parameters: {'log_learning_rate': -4.524074333749784, 'log_learning_rate_D': -1.8250413756185258, 'log_learning_rate_D_dagger': -2.214858258511425, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:20:12,472] Trial 123 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.7913064956665
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  124   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9774667652718305, 'log_learning_rate_D': -2.4157081114772403, 'log_learning_rate_D_dagger': -2.1722196911654454, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7238, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:22:41,681] Trial 124 failed with parameters: {'log_learning_rate': -4.9774667652718305, 'log_learning_rate_D': -2.4157081114772403, 'log_learning_rate_D_dagger': -2.1722196911654454, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:22:41,682] Trial 124 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  148.84746551513672
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  125   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.930961850970352, 'log_learning_rate_D': -1.9442378401043112, 'log_learning_rate_D_dagger': -2.1529199198541096, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5027, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:24:17,003] Trial 125 failed with parameters: {'log_learning_rate': -4.930961850970352, 'log_learning_rate_D': -1.9442378401043112, 'log_learning_rate_D_dagger': -2.1529199198541096, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:24:17,004] Trial 125 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.8781681060791
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  126   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.825934451105239, 'log_learning_rate_D': -2.001142242845907, 'log_learning_rate_D_dagger': -2.1346128710018615, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7070, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:26:04,478] Trial 126 failed with parameters: {'log_learning_rate': -4.825934451105239, 'log_learning_rate_D': -2.001142242845907, 'log_learning_rate_D_dagger': -2.1346128710018615, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:26:04,478] Trial 126 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  107.04084658622742
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  127   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.8095158873208845, 'log_learning_rate_D': -1.834784088695403, 'log_learning_rate_D_dagger': -2.185310405633259, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6782, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:27:26,256] Trial 127 failed with parameters: {'log_learning_rate': -4.8095158873208845, 'log_learning_rate_D': -1.834784088695403, 'log_learning_rate_D_dagger': -2.185310405633259, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:27:26,256] Trial 127 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.34737467765808
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  128   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.972873333568541, 'log_learning_rate_D': -1.9853827439087475, 'log_learning_rate_D_dagger': -2.2670781478486215, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4377, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:29:01,832] Trial 128 failed with parameters: {'log_learning_rate': -4.972873333568541, 'log_learning_rate_D': -1.9853827439087475, 'log_learning_rate_D_dagger': -2.2670781478486215, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:29:01,832] Trial 128 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.15669202804565
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  129   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.849548094829364, 'log_learning_rate_D': -2.003396248162712, 'log_learning_rate_D_dagger': -2.183417807242308, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6672, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:30:37,778] Trial 129 failed with parameters: {'log_learning_rate': -4.849548094829364, 'log_learning_rate_D': -2.003396248162712, 'log_learning_rate_D_dagger': -2.183417807242308, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:30:37,779] Trial 129 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.56245827674866
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  130   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.956114636725987, 'log_learning_rate_D': -1.7249284457423344, 'log_learning_rate_D_dagger': -2.134303072410286, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6259, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:31:59,628] Trial 130 failed with parameters: {'log_learning_rate': -4.956114636725987, 'log_learning_rate_D': -1.7249284457423344, 'log_learning_rate_D_dagger': -2.134303072410286, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:31:59,629] Trial 130 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.48334646224976
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  131   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.84809613272251, 'log_learning_rate_D': -1.9055036821706537, 'log_learning_rate_D_dagger': -2.2274169348254236, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6111, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:33:34,979] Trial 131 failed with parameters: {'log_learning_rate': -4.84809613272251, 'log_learning_rate_D': -1.9055036821706537, 'log_learning_rate_D_dagger': -2.2274169348254236, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:33:34,979] Trial 131 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.96488857269287
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  132   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.974207580489386, 'log_learning_rate_D': -2.1308174529378574, 'log_learning_rate_D_dagger': -2.1457272642594427, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4762, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:35:10,189] Trial 132 failed with parameters: {'log_learning_rate': -4.974207580489386, 'log_learning_rate_D': -2.1308174529378574, 'log_learning_rate_D_dagger': -2.1457272642594427, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:35:10,190] Trial 132 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.76326203346252
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  133   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.991400246698512, 'log_learning_rate_D': -2.106799216894155, 'log_learning_rate_D_dagger': -2.113637727192111, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6051, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:36:45,494] Trial 133 failed with parameters: {'log_learning_rate': -4.991400246698512, 'log_learning_rate_D': -2.106799216894155, 'log_learning_rate_D_dagger': -2.113637727192111, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:36:45,494] Trial 133 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.9536657333374
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  134   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.979286174273895, 'log_learning_rate_D': -1.9865081950700945, 'log_learning_rate_D_dagger': -2.093004825646261, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8109, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:38:34,984] Trial 134 failed with parameters: {'log_learning_rate': -4.979286174273895, 'log_learning_rate_D': -1.9865081950700945, 'log_learning_rate_D_dagger': -2.093004825646261, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:38:34,985] Trial 134 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.01576781272888
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  135   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9313525963089395, 'log_learning_rate_D': -1.9069747625170197, 'log_learning_rate_D_dagger': -2.3232290729147733, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8053, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:40:37,856] Trial 135 failed with parameters: {'log_learning_rate': -4.9313525963089395, 'log_learning_rate_D': -1.9069747625170197, 'log_learning_rate_D_dagger': -2.3232290729147733, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:40:37,857] Trial 135 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.50968599319458
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  136   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.756241885425672, 'log_learning_rate_D': -1.9302594541114462, 'log_learning_rate_D_dagger': -2.1000419523119396, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6736, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:42:13,847] Trial 136 failed with parameters: {'log_learning_rate': -4.756241885425672, 'log_learning_rate_D': -1.9302594541114462, 'log_learning_rate_D_dagger': -2.1000419523119396, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:42:13,847] Trial 136 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.5745997428894
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  137   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.944226632501353, 'log_learning_rate_D': -1.9531950220946497, 'log_learning_rate_D_dagger': -2.0339255475886264, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5788, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:43:35,947] Trial 137 failed with parameters: {'log_learning_rate': -4.944226632501353, 'log_learning_rate_D': -1.9531950220946497, 'log_learning_rate_D_dagger': -2.0339255475886264, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:43:35,947] Trial 137 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.7648937702179
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  138   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.951360760922886, 'log_learning_rate_D': -1.7963308020057323, 'log_learning_rate_D_dagger': -2.0778516221999763, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5770, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:44:58,637] Trial 138 failed with parameters: {'log_learning_rate': -4.951360760922886, 'log_learning_rate_D': -1.7963308020057323, 'log_learning_rate_D_dagger': -2.0778516221999763, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:44:58,638] Trial 138 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.32147669792175
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  139   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.732188174768465, 'log_learning_rate_D': -1.9335821840936473, 'log_learning_rate_D_dagger': -2.130049361027816, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6140, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:46:33,769] Trial 139 failed with parameters: {'log_learning_rate': -4.732188174768465, 'log_learning_rate_D': -1.9335821840936473, 'log_learning_rate_D_dagger': -2.130049361027816, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:46:33,769] Trial 139 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.73271632194519
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  140   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.859397557877299, 'log_learning_rate_D': -1.2147393664004866, 'log_learning_rate_D_dagger': -2.299530259684326, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6400, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:48:36,113] Trial 140 failed with parameters: {'log_learning_rate': -4.859397557877299, 'log_learning_rate_D': -1.2147393664004866, 'log_learning_rate_D_dagger': -2.299530259684326, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:48:36,114] Trial 140 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  121.8790180683136
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  141   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.983405193353749, 'log_learning_rate_D': -1.8396516633488282, 'log_learning_rate_D_dagger': -2.1517188050596268, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6696, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:50:11,617] Trial 141 failed with parameters: {'log_learning_rate': -4.983405193353749, 'log_learning_rate_D': -1.8396516633488282, 'log_learning_rate_D_dagger': -2.1517188050596268, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:50:11,617] Trial 141 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.11916971206665
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  142   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.783813519897171, 'log_learning_rate_D': -1.9860909948901382, 'log_learning_rate_D_dagger': -2.1216817988158163, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6609, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:52:00,481] Trial 142 failed with parameters: {'log_learning_rate': -4.783813519897171, 'log_learning_rate_D': -1.9860909948901382, 'log_learning_rate_D_dagger': -2.1216817988158163, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:52:00,482] Trial 142 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.3967649936676
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  143   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.988520635732128, 'log_learning_rate_D': -1.890460591593472, 'log_learning_rate_D_dagger': -2.1909727157651218, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7531, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:53:49,371] Trial 143 failed with parameters: {'log_learning_rate': -4.988520635732128, 'log_learning_rate_D': -1.890460591593472, 'log_learning_rate_D_dagger': -2.1909727157651218, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:53:49,371] Trial 143 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.53719282150269
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  144   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.607508208232545, 'log_learning_rate_D': -1.9593263093694047, 'log_learning_rate_D_dagger': -2.123897817844476, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5040, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:55:11,492] Trial 144 failed with parameters: {'log_learning_rate': -4.607508208232545, 'log_learning_rate_D': -1.9593263093694047, 'log_learning_rate_D_dagger': -2.123897817844476, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:55:11,493] Trial 144 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.67626667022705
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  145   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.953517202927143, 'log_learning_rate_D': -2.0244060864066213, 'log_learning_rate_D_dagger': -2.180931452560934, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7140, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:57:00,153] Trial 145 failed with parameters: {'log_learning_rate': -4.953517202927143, 'log_learning_rate_D': -2.0244060864066213, 'log_learning_rate_D_dagger': -2.180931452560934, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:57:00,153] Trial 145 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.14189577102661
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  146   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9662888121352085, 'log_learning_rate_D': -1.868602887460347, 'log_learning_rate_D_dagger': -2.1195793587383553, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7141, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:58:35,148] Trial 146 failed with parameters: {'log_learning_rate': -4.9662888121352085, 'log_learning_rate_D': -1.868602887460347, 'log_learning_rate_D_dagger': -2.1195793587383553, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:58:35,149] Trial 146 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.63824939727783
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  147   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.765478629587062, 'log_learning_rate_D': -1.6831782130513773, 'log_learning_rate_D_dagger': -2.20920431368597, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6193, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 19:59:57,118] Trial 147 failed with parameters: {'log_learning_rate': -4.765478629587062, 'log_learning_rate_D': -1.6831782130513773, 'log_learning_rate_D_dagger': -2.20920431368597, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 19:59:57,118] Trial 147 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.58322882652283
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  148   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.979973367948758, 'log_learning_rate_D': -1.7025780676438091, 'log_learning_rate_D_dagger': -1.9656411306091224, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5699, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:01:05,576] Trial 148 failed with parameters: {'log_learning_rate': -4.979973367948758, 'log_learning_rate_D': -1.7025780676438091, 'log_learning_rate_D_dagger': -1.9656411306091224, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:01:05,577] Trial 148 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  68.06868553161621
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  149   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.901473469573898, 'log_learning_rate_D': -2.0365920875194004, 'log_learning_rate_D_dagger': -2.059286359377291, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7834, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:03:07,644] Trial 149 failed with parameters: {'log_learning_rate': -4.901473469573898, 'log_learning_rate_D': -2.0365920875194004, 'log_learning_rate_D_dagger': -2.059286359377291, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:03:07,644] Trial 149 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  121.73011660575867
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  150   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.786511437544033, 'log_learning_rate_D': -1.47374910909108, 'log_learning_rate_D_dagger': -2.1272717982238505, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6274, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:04:30,301] Trial 150 failed with parameters: {'log_learning_rate': -4.786511437544033, 'log_learning_rate_D': -1.47374910909108, 'log_learning_rate_D_dagger': -2.1272717982238505, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:04:30,302] Trial 150 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.26205110549927
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  151   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.698480318121614, 'log_learning_rate_D': -1.7728021458638703, 'log_learning_rate_D_dagger': -2.0672657351614916, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6805, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:05:52,461] Trial 151 failed with parameters: {'log_learning_rate': -4.698480318121614, 'log_learning_rate_D': -1.7728021458638703, 'log_learning_rate_D_dagger': -2.0672657351614916, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:05:52,461] Trial 151 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.77991151809692
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  152   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.882940230730511, 'log_learning_rate_D': -1.763180021654788, 'log_learning_rate_D_dagger': -2.132155196176731, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5901, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:07:14,216] Trial 152 failed with parameters: {'log_learning_rate': -4.882940230730511, 'log_learning_rate_D': -1.763180021654788, 'log_learning_rate_D_dagger': -2.132155196176731, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:07:14,216] Trial 152 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.4046242237091
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  153   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.965829799117751, 'log_learning_rate_D': -1.8240353969966727, 'log_learning_rate_D_dagger': -2.170030697197142, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6264, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:08:36,974] Trial 153 failed with parameters: {'log_learning_rate': -4.965829799117751, 'log_learning_rate_D': -1.8240353969966727, 'log_learning_rate_D_dagger': -2.170030697197142, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:08:36,974] Trial 153 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.37544369697571
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  154   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.661424316515366, 'log_learning_rate_D': -2.0716094801624703, 'log_learning_rate_D_dagger': -2.2381833518216983, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5323, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:10:12,903] Trial 154 failed with parameters: {'log_learning_rate': -4.661424316515366, 'log_learning_rate_D': -2.0716094801624703, 'log_learning_rate_D_dagger': -2.2381833518216983, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:10:12,903] Trial 154 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.54485034942627
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  155   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.756088311817277, 'log_learning_rate_D': -1.8806185857284583, 'log_learning_rate_D_dagger': -2.274364945152785, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6302, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:11:48,546] Trial 155 failed with parameters: {'log_learning_rate': -4.756088311817277, 'log_learning_rate_D': -1.8806185857284583, 'log_learning_rate_D_dagger': -2.274364945152785, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:11:48,546] Trial 155 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.22605895996094
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  156   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.6952980716472625, 'log_learning_rate_D': -2.1058224643077397, 'log_learning_rate_D_dagger': -2.157922075651862, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4803, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:13:24,096] Trial 156 failed with parameters: {'log_learning_rate': -4.6952980716472625, 'log_learning_rate_D': -2.1058224643077397, 'log_learning_rate_D_dagger': -2.157922075651862, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:13:24,096] Trial 156 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.11271929740906
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  157   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.855231530649023, 'log_learning_rate_D': -1.7808244682446284, 'log_learning_rate_D_dagger': -2.267250743266287, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6563, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:14:59,761] Trial 157 failed with parameters: {'log_learning_rate': -4.855231530649023, 'log_learning_rate_D': -1.7808244682446284, 'log_learning_rate_D_dagger': -2.267250743266287, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:14:59,762] Trial 157 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.27172040939331
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  158   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.919209043285889, 'log_learning_rate_D': -1.9453444880351558, 'log_learning_rate_D_dagger': -2.0726766143635196, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6830, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:16:49,168] Trial 158 failed with parameters: {'log_learning_rate': -4.919209043285889, 'log_learning_rate_D': -1.9453444880351558, 'log_learning_rate_D_dagger': -2.0726766143635196, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:16:49,168] Trial 158 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.04462790489197
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  159   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.952596737729225, 'log_learning_rate_D': -1.8331487394549968, 'log_learning_rate_D_dagger': -2.0574625627384444, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6240, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:18:12,176] Trial 159 failed with parameters: {'log_learning_rate': -4.952596737729225, 'log_learning_rate_D': -1.8331487394549968, 'log_learning_rate_D_dagger': -2.0574625627384444, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:18:12,177] Trial 159 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.66264271736145
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  160   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.754331183287747, 'log_learning_rate_D': -1.9078606505107518, 'log_learning_rate_D_dagger': -2.1871385422159904, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6675, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:19:48,631] Trial 160 failed with parameters: {'log_learning_rate': -4.754331183287747, 'log_learning_rate_D': -1.9078606505107518, 'log_learning_rate_D_dagger': -2.1871385422159904, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:19:48,632] Trial 160 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  96.0326452255249
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  161   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.98792888341214, 'log_learning_rate_D': -2.4319996663239163, 'log_learning_rate_D_dagger': -2.1622957323671295, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.9786, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4742, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:22:45,633] Trial 161 failed with parameters: {'log_learning_rate': -4.98792888341214, 'log_learning_rate_D': -2.4319996663239163, 'log_learning_rate_D_dagger': -2.1622957323671295, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:22:45,634] Trial 161 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  176.58001446723938
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  162   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9340590578269286, 'log_learning_rate_D': -2.0478741152288684, 'log_learning_rate_D_dagger': -2.1214084622806544, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7246, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:24:34,785] Trial 162 failed with parameters: {'log_learning_rate': -4.9340590578269286, 'log_learning_rate_D': -2.0478741152288684, 'log_learning_rate_D_dagger': -2.1214084622806544, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:24:34,785] Trial 162 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.78930401802063
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  163   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.797834361095838, 'log_learning_rate_D': -1.8162630844171264, 'log_learning_rate_D_dagger': -2.1530110486085676, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5424, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:26:10,429] Trial 163 failed with parameters: {'log_learning_rate': -4.797834361095838, 'log_learning_rate_D': -1.8162630844171264, 'log_learning_rate_D_dagger': -2.1530110486085676, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:26:10,429] Trial 163 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.13426804542542
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  164   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.721420308774475, 'log_learning_rate_D': -1.9839775558918094, 'log_learning_rate_D_dagger': -2.048635044589816, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5345, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:27:32,293] Trial 164 failed with parameters: {'log_learning_rate': -4.721420308774475, 'log_learning_rate_D': -1.9839775558918094, 'log_learning_rate_D_dagger': -2.048635044589816, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:27:32,294] Trial 164 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.50824427604675
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  165   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.980741110858107, 'log_learning_rate_D': -1.9519390540510795, 'log_learning_rate_D_dagger': -2.1999554245856263, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6874, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:29:08,061] Trial 165 failed with parameters: {'log_learning_rate': -4.980741110858107, 'log_learning_rate_D': -1.9519390540510795, 'log_learning_rate_D_dagger': -2.1999554245856263, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:29:08,061] Trial 165 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.23523831367493
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  166   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.921455488200715, 'log_learning_rate_D': -1.8792749358327168, 'log_learning_rate_D_dagger': -2.229597383385314, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6287, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:30:30,335] Trial 166 failed with parameters: {'log_learning_rate': -4.921455488200715, 'log_learning_rate_D': -1.8792749358327168, 'log_learning_rate_D_dagger': -2.229597383385314, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:30:30,336] Trial 166 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.90128087997437
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  167   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9007282435648545, 'log_learning_rate_D': -1.9526940555540961, 'log_learning_rate_D_dagger': -2.1487654091630666, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7353, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:32:19,480] Trial 167 failed with parameters: {'log_learning_rate': -4.9007282435648545, 'log_learning_rate_D': -1.9526940555540961, 'log_learning_rate_D_dagger': -2.1487654091630666, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:32:19,481] Trial 167 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.7543089389801
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  168   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9477709722038234, 'log_learning_rate_D': -1.8300228578955462, 'log_learning_rate_D_dagger': -2.030575743407476, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7285, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:33:54,679] Trial 168 failed with parameters: {'log_learning_rate': -4.9477709722038234, 'log_learning_rate_D': -1.8300228578955462, 'log_learning_rate_D_dagger': -2.030575743407476, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:33:54,680] Trial 168 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.78397130966187
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  169   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.853337401360368, 'log_learning_rate_D': -1.704414360593221, 'log_learning_rate_D_dagger': -2.000540945215269, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5713, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:35:16,557] Trial 169 failed with parameters: {'log_learning_rate': -4.853337401360368, 'log_learning_rate_D': -1.704414360593221, 'log_learning_rate_D_dagger': -2.000540945215269, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:35:16,558] Trial 169 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.55611276626587
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  170   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.985632350022749, 'log_learning_rate_D': -1.8748841770015137, 'log_learning_rate_D_dagger': -2.1320943105778083, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6044, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:36:38,555] Trial 170 failed with parameters: {'log_learning_rate': -4.985632350022749, 'log_learning_rate_D': -1.8748841770015137, 'log_learning_rate_D_dagger': -2.1320943105778083, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:36:38,556] Trial 170 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.58154487609863
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  171   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.719053753319011, 'log_learning_rate_D': -2.0345851287077457, 'log_learning_rate_D_dagger': -2.136609897210805, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5949, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:38:14,634] Trial 171 failed with parameters: {'log_learning_rate': -4.719053753319011, 'log_learning_rate_D': -2.0345851287077457, 'log_learning_rate_D_dagger': -2.136609897210805, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:38:14,634] Trial 171 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.70441603660583
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  172   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.82050448708555, 'log_learning_rate_D': -1.7444467977814955, 'log_learning_rate_D_dagger': -2.359595548861544, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6852, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:40:03,586] Trial 172 failed with parameters: {'log_learning_rate': -4.82050448708555, 'log_learning_rate_D': -1.7444467977814955, 'log_learning_rate_D_dagger': -2.359595548861544, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:40:03,586] Trial 172 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.58065438270569
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  173   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.845597251460854, 'log_learning_rate_D': -1.9905181020686928, 'log_learning_rate_D_dagger': -2.1664419391677456, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6802, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:41:52,414] Trial 173 failed with parameters: {'log_learning_rate': -4.845597251460854, 'log_learning_rate_D': -1.9905181020686928, 'log_learning_rate_D_dagger': -2.1664419391677456, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:41:52,414] Trial 173 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.30285024642944
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  174   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.907825211115919, 'log_learning_rate_D': -1.831634641846363, 'log_learning_rate_D_dagger': -1.9869686676672185, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6680, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:43:14,915] Trial 174 failed with parameters: {'log_learning_rate': -4.907825211115919, 'log_learning_rate_D': -1.831634641846363, 'log_learning_rate_D_dagger': -1.9869686676672185, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:43:14,916] Trial 174 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  82.15315580368042
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  175   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.93337640349436, 'log_learning_rate_D': -2.0550381222685723, 'log_learning_rate_D_dagger': -2.1224661171791457, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6801, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:45:04,378] Trial 175 failed with parameters: {'log_learning_rate': -4.93337640349436, 'log_learning_rate_D': -2.0550381222685723, 'log_learning_rate_D_dagger': -2.1224661171791457, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:45:04,378] Trial 175 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.8508038520813
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  176   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.936962100147159, 'log_learning_rate_D': -1.634275876808354, 'log_learning_rate_D_dagger': -2.016746811360253, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5051, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:46:13,093] Trial 176 failed with parameters: {'log_learning_rate': -4.936962100147159, 'log_learning_rate_D': -1.634275876808354, 'log_learning_rate_D_dagger': -2.016746811360253, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:46:13,094] Trial 176 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  68.3492443561554
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  177   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.86701496652227, 'log_learning_rate_D': -2.020672363965706, 'log_learning_rate_D_dagger': -2.1410162770456482, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5945, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:47:49,848] Trial 177 failed with parameters: {'log_learning_rate': -4.86701496652227, 'log_learning_rate_D': -2.020672363965706, 'log_learning_rate_D_dagger': -2.1410162770456482, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:47:49,848] Trial 177 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  96.35216093063354
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  178   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.96552273090113, 'log_learning_rate_D': -1.8798917347613875, 'log_learning_rate_D_dagger': -2.188269649800197, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6446, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:49:38,766] Trial 178 failed with parameters: {'log_learning_rate': -4.96552273090113, 'log_learning_rate_D': -1.8798917347613875, 'log_learning_rate_D_dagger': -2.188269649800197, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:49:38,767] Trial 178 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.51930928230286
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  179   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.922021783385945, 'log_learning_rate_D': -1.8389802472203263, 'log_learning_rate_D_dagger': -2.3349448181796424, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6510, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:51:14,304] Trial 179 failed with parameters: {'log_learning_rate': -4.922021783385945, 'log_learning_rate_D': -1.8389802472203263, 'log_learning_rate_D_dagger': -2.3349448181796424, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:51:14,305] Trial 179 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.9445321559906
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  180   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.979099338270062, 'log_learning_rate_D': -2.088859179624724, 'log_learning_rate_D_dagger': -2.0830595685537117, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5273, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:53:17,201] Trial 180 failed with parameters: {'log_learning_rate': -4.979099338270062, 'log_learning_rate_D': -2.088859179624724, 'log_learning_rate_D_dagger': -2.0830595685537117, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:53:17,201] Trial 180 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  122.52935409545898
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  181   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.9439048784720985, 'log_learning_rate_D': -1.896479879058984, 'log_learning_rate_D_dagger': -2.208158612240959, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7657, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:54:52,734] Trial 181 failed with parameters: {'log_learning_rate': -4.9439048784720985, 'log_learning_rate_D': -1.896479879058984, 'log_learning_rate_D_dagger': -2.208158612240959, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:54:52,735] Trial 181 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.01771664619446
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  182   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.993844924985588, 'log_learning_rate_D': -1.6396848818713252, 'log_learning_rate_D_dagger': -2.0637845089480247, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6849, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.4382, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3496, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 20:59:51,581] Trial 182 failed with parameters: {'log_learning_rate': -4.993844924985588, 'log_learning_rate_D': -1.6396848818713252, 'log_learning_rate_D_dagger': -2.0637845089480247, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 20:59:51,581] Trial 182 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  298.30000948905945
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  183   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.966891266828322, 'log_learning_rate_D': -1.796309197119737, 'log_learning_rate_D_dagger': -2.090617722923497, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5582, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:01:13,855] Trial 183 failed with parameters: {'log_learning_rate': -4.966891266828322, 'log_learning_rate_D': -1.796309197119737, 'log_learning_rate_D_dagger': -2.090617722923497, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:01:13,856] Trial 183 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.90343618392944
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  184   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.824114413164518, 'log_learning_rate_D': -1.9635169116676359, 'log_learning_rate_D_dagger': -2.182387278229893, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.4563, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:02:49,482] Trial 184 failed with parameters: {'log_learning_rate': -4.824114413164518, 'log_learning_rate_D': -1.9635169116676359, 'log_learning_rate_D_dagger': -2.182387278229893, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:02:49,482] Trial 184 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.20091962814331
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  185   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.747380843336639, 'log_learning_rate_D': -1.873414931917381, 'log_learning_rate_D_dagger': -2.22714697714765, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4682, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:04:11,495] Trial 185 failed with parameters: {'log_learning_rate': -4.747380843336639, 'log_learning_rate_D': -1.873414931917381, 'log_learning_rate_D_dagger': -2.22714697714765, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:04:11,495] Trial 185 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.68065690994263
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  186   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.891656955878246, 'log_learning_rate_D': -2.070942138270887, 'log_learning_rate_D_dagger': -2.1464503844124456, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6126, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:06:00,596] Trial 186 failed with parameters: {'log_learning_rate': -4.891656955878246, 'log_learning_rate_D': -2.070942138270887, 'log_learning_rate_D_dagger': -2.1464503844124456, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:06:00,597] Trial 186 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.64675283432007
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  187   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.915489189641392, 'log_learning_rate_D': -1.9668862994442962, 'log_learning_rate_D_dagger': -2.023208004057757, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6891, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:07:22,625] Trial 187 failed with parameters: {'log_learning_rate': -4.915489189641392, 'log_learning_rate_D': -1.9668862994442962, 'log_learning_rate_D_dagger': -2.023208004057757, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:07:22,625] Trial 187 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.4706392288208
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  188   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.585814052265178, 'log_learning_rate_D': -1.868126670415247, 'log_learning_rate_D_dagger': -2.1903321588984372, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6439, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:08:57,805] Trial 188 failed with parameters: {'log_learning_rate': -4.585814052265178, 'log_learning_rate_D': -1.868126670415247, 'log_learning_rate_D_dagger': -2.1903321588984372, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:08:57,805] Trial 188 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.80379128456116
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  189   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.970230779473537, 'log_learning_rate_D': -1.9194043944542623, 'log_learning_rate_D_dagger': -2.1992712323462156, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7430, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:10:33,166] Trial 189 failed with parameters: {'log_learning_rate': -4.970230779473537, 'log_learning_rate_D': -1.9194043944542623, 'log_learning_rate_D_dagger': -2.1992712323462156, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:10:33,167] Trial 189 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.87612748146057
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  190   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.909700314105234, 'log_learning_rate_D': -1.8097341224770926, 'log_learning_rate_D_dagger': -2.150618967245727, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7221, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:11:55,339] Trial 190 failed with parameters: {'log_learning_rate': -4.909700314105234, 'log_learning_rate_D': -1.8097341224770926, 'log_learning_rate_D_dagger': -2.150618967245727, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:11:55,340] Trial 190 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.73514986038208
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  191   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.782718494587784, 'log_learning_rate_D': -1.9499139659639235, 'log_learning_rate_D_dagger': -2.1414624237189703, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6625, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:13:30,601] Trial 191 failed with parameters: {'log_learning_rate': -4.782718494587784, 'log_learning_rate_D': -1.9499139659639235, 'log_learning_rate_D_dagger': -2.1414624237189703, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:13:30,602] Trial 191 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.77468371391296
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  192   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.6936640854497655, 'log_learning_rate_D': -2.0907014052129815, 'log_learning_rate_D_dagger': -2.1535681370548474, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6688, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:15:19,073] Trial 192 failed with parameters: {'log_learning_rate': -4.6936640854497655, 'log_learning_rate_D': -2.0907014052129815, 'log_learning_rate_D_dagger': -2.1535681370548474, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:15:19,073] Trial 192 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.10038042068481
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  193   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.7783399646602795, 'log_learning_rate_D': -1.8983057895805127, 'log_learning_rate_D_dagger': -2.2441289301479364, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7198, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:17:08,107] Trial 193 failed with parameters: {'log_learning_rate': -4.7783399646602795, 'log_learning_rate_D': -1.8983057895805127, 'log_learning_rate_D_dagger': -2.2441289301479364, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:17:08,108] Trial 193 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  108.57811260223389
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  194   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.88546801187566, 'log_learning_rate_D': -1.4512153855019547, 'log_learning_rate_D_dagger': -2.0716987145107177, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5266, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:18:17,064] Trial 194 failed with parameters: {'log_learning_rate': -4.88546801187566, 'log_learning_rate_D': -1.4512153855019547, 'log_learning_rate_D_dagger': -2.0716987145107177, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:18:17,064] Trial 194 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  68.55009484291077
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  195   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.910548423081999, 'log_learning_rate_D': -1.7661389884855696, 'log_learning_rate_D_dagger': -2.259078322857251, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7027, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:19:52,404] Trial 195 failed with parameters: {'log_learning_rate': -4.910548423081999, 'log_learning_rate_D': -1.7661389884855696, 'log_learning_rate_D_dagger': -2.259078322857251, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:19:52,404] Trial 195 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  94.95012521743774
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  196   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.950866290025183, 'log_learning_rate_D': -1.8185145162754548, 'log_learning_rate_D_dagger': -2.186322962486434, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5685, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:21:14,596] Trial 196 failed with parameters: {'log_learning_rate': -4.950866290025183, 'log_learning_rate_D': -1.8185145162754548, 'log_learning_rate_D_dagger': -2.186322962486434, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:21:14,596] Trial 196 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  81.75926804542542
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  197   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.913147548908604, 'log_learning_rate_D': -1.7437522538182684, 'log_learning_rate_D_dagger': -2.356192191029685, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6845, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:22:50,631] Trial 197 failed with parameters: {'log_learning_rate': -4.913147548908604, 'log_learning_rate_D': -1.7437522538182684, 'log_learning_rate_D_dagger': -2.356192191029685, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:22:50,632] Trial 197 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.670893907547
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  198   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.656905774826568, 'log_learning_rate_D': -2.0678290555854693, 'log_learning_rate_D_dagger': -2.1027000742026516, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6398, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:24:40,388] Trial 198 failed with parameters: {'log_learning_rate': -4.656905774826568, 'log_learning_rate_D': -2.0678290555854693, 'log_learning_rate_D_dagger': -2.1027000742026516, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:24:40,388] Trial 198 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  109.41112041473389
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  199   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.761188611396589, 'log_learning_rate_D': -1.9030978310159585, 'log_learning_rate_D_dagger': -1.9842615993081498, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6048, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:26:16,779] Trial 199 failed with parameters: {'log_learning_rate': -4.761188611396589, 'log_learning_rate_D': -1.9030978310159585, 'log_learning_rate_D_dagger': -1.9842615993081498, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:26:16,779] Trial 199 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  96.00476384162903
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
--------------------  Trial  200   --------------------
Start timing: 
Parameters: 
{'log_learning_rate': -4.573299740184726, 'log_learning_rate_D': -1.867642891672677, 'log_learning_rate_D_dagger': -2.1192554173049674, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7506, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  6.6796875
Memory cached:  18.0
[W 2024-03-30 21:27:52,503] Trial 200 failed with parameters: {'log_learning_rate': -4.573299740184726, 'log_learning_rate_D': -1.867642891672677, 'log_learning_rate_D_dagger': -2.1192554173049674, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2024-03-30 21:27:52,503] Trial 200 failed with value tensor(nan, grad_fn=<ToCopyBackward0>).
Time for this trial:  95.33760452270508
Memory status after this trial: 
Memory allocated:  12.55517578125
Memory cached:  18.0
