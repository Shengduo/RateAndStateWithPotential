/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-11-03 21:55:19,643] A new study created in memory with name: no-name-c3052cbc-1f16-4b95-a536-08008aeb68a9
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.602758599374746, 'log_learning_rate_D': -2.2586165970865193, 'training_batch_size': 6, 'training_p': 7}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.8957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.73095703125
Memory cached:  2.0
[I 2023-11-03 21:55:39,328] Trial 0 finished with value: 0.08878528326749802 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.602758599374746, 'log_learning_rate_D': -2.2586165970865193, 'training_batch_size': 6, 'training_p': 7}. Best is trial 0 with value: 0.08878528326749802.
Time for this trial:  19.564164638519287
Memory status after this trial: 
Memory allocated:  35.53369140625
Memory cached:  50.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.461297747725036, 'log_learning_rate_D': -3.355563459825692, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  46.0
	 epoch  10 training error:  tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.78076171875
Memory cached:  48.0
[I 2023-11-03 21:55:58,667] Trial 1 finished with value: 0.031066138297319412 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.461297747725036, 'log_learning_rate_D': -3.355563459825692, 'training_batch_size': 7, 'training_p': 3}. Best is trial 1 with value: 0.031066138297319412.
Time for this trial:  19.234654426574707
Memory status after this trial: 
Memory allocated:  149.87255859375
Memory cached:  168.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.460067459923868, 'log_learning_rate_D': -4.138804231797724, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.8984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.7681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.6306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.06298828125
Memory cached:  6.0
[I 2023-11-03 21:56:15,251] Trial 2 finished with value: 0.025889886543154716 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.460067459923868, 'log_learning_rate_D': -4.138804231797724, 'training_batch_size': 10, 'training_p': 3}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  16.48262858390808
Memory status after this trial: 
Memory allocated:  39.58349609375
Memory cached:  54.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.214197743685158, 'log_learning_rate_D': -4.575900277100249, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  10 training error:  tensor(0.8257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.509765625
Memory cached:  26.0
[I 2023-11-03 21:56:31,491] Trial 3 finished with value: 0.035370808094739914 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.214197743685158, 'log_learning_rate_D': -4.575900277100249, 'training_batch_size': 11, 'training_p': 6}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  16.133728504180908
Memory status after this trial: 
Memory allocated:  30.11279296875
Memory cached:  46.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.4581485973640196, 'log_learning_rate_D': -3.5952797034664914, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.7508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.6937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.6682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.759765625
Memory cached:  8.0
[I 2023-11-03 21:56:49,484] Trial 4 finished with value: 0.11306082457304001 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.4581485973640196, 'log_learning_rate_D': -3.5952797034664914, 'training_batch_size': 10, 'training_p': 7}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  17.884363412857056
Memory status after this trial: 
Memory allocated:  120.58056640625
Memory cached:  150.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9176079535938566, 'log_learning_rate_D': -1.9726738390147753, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.93359375
Memory cached:  24.0
[I 2023-11-03 21:57:07,181] Trial 5 finished with value: 0.03448861837387085 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9176079535938566, 'log_learning_rate_D': -1.9726738390147753, 'training_batch_size': 8, 'training_p': 6}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  17.58568549156189
Memory status after this trial: 
Memory allocated:  123.65185546875
Memory cached:  162.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.194082272716996, 'log_learning_rate_D': -4.112024832933255, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.263671875
Memory cached:  4.0
[I 2023-11-03 21:57:23,511] Trial 6 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.194082272716996, 'log_learning_rate_D': -4.112024832933255, 'training_batch_size': 11, 'training_p': 6}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  16.225591897964478
Memory status after this trial: 
Memory allocated:  45.85107421875
Memory cached:  62.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0639315812826022, 'log_learning_rate_D': -1.5617755101386872, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  62.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7900390625
Memory cached:  64.0
[I 2023-11-03 21:57:42,583] Trial 7 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0639315812826022, 'log_learning_rate_D': -1.5617755101386872, 'training_batch_size': 9, 'training_p': 4}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  18.967130184173584
Memory status after this trial: 
Memory allocated:  180.52880859375
Memory cached:  198.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.5975702160847347, 'log_learning_rate_D': -1.4198392570040501, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.26904296875
Memory cached:  8.0
[I 2023-11-03 21:58:00,954] Trial 8 finished with value: 0.03287147730588913 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.5975702160847347, 'log_learning_rate_D': -1.4198392570040501, 'training_batch_size': 12, 'training_p': 6}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  18.27365231513977
Memory status after this trial: 
Memory allocated:  119.74462890625
Memory cached:  134.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -4.775772507592578, 'log_learning_rate_D': -3.3425850607502188, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.8569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.7872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.6949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.0029296875
Memory cached:  10.0
[I 2023-11-03 21:58:18,975] Trial 9 finished with value: 0.2065633088350296 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -4.775772507592578, 'log_learning_rate_D': -3.3425850607502188, 'training_batch_size': 8, 'training_p': 4}. Best is trial 2 with value: 0.025889886543154716.
Time for this trial:  17.929046630859375
Memory status after this trial: 
Memory allocated:  88.07763671875
Memory cached:  102.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.780636238548731, 'log_learning_rate_D': -4.729279966707018, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.0242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.0185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
[I 2023-11-03 21:58:34,075] Trial 10 finished with value: 0.021226320415735245 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.780636238548731, 'log_learning_rate_D': -4.729279966707018, 'training_batch_size': 10, 'training_p': 2}. Best is trial 10 with value: 0.021226320415735245.
Time for this trial:  14.94433045387268
Memory status after this trial: 
Memory allocated:  5.27392578125
Memory cached:  6.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.837645706775048, 'log_learning_rate_D': -4.940559282052834, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.7946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.35888671875
Memory cached:  26.0
[I 2023-11-03 21:58:49,253] Trial 11 finished with value: 0.023538785055279732 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.837645706775048, 'log_learning_rate_D': -4.940559282052834, 'training_batch_size': 10, 'training_p': 2}. Best is trial 10 with value: 0.021226320415735245.
Time for this trial:  15.01112961769104
Memory status after this trial: 
Memory allocated:  5.27392578125
Memory cached:  6.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.6716981742813655, 'log_learning_rate_D': -4.934698955468703, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.375
Memory cached:  26.0
[I 2023-11-03 21:59:04,486] Trial 12 finished with value: 0.03495323657989502 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.6716981742813655, 'log_learning_rate_D': -4.934698955468703, 'training_batch_size': 10, 'training_p': 2}. Best is trial 10 with value: 0.021226320415735245.
Time for this trial:  15.062944173812866
Memory status after this trial: 
Memory allocated:  5.27392578125
Memory cached:  6.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.6399251460270747, 'log_learning_rate_D': -4.95463647551925, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.6113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.341796875
Memory cached:  22.0
[I 2023-11-03 21:59:19,631] Trial 13 finished with value: 0.02204369567334652 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.6399251460270747, 'log_learning_rate_D': -4.95463647551925, 'training_batch_size': 9, 'training_p': 2}. Best is trial 10 with value: 0.021226320415735245.
Time for this trial:  14.976233720779419
Memory status after this trial: 
Memory allocated:  6.99853515625
Memory cached:  8.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4978697302857733, 'log_learning_rate_D': -4.244198307292685, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.86376953125
Memory cached:  2.0
[I 2023-11-03 21:59:35,038] Trial 14 finished with value: 0.01958342455327511 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4978697302857733, 'log_learning_rate_D': -4.244198307292685, 'training_batch_size': 9, 'training_p': 2}. Best is trial 14 with value: 0.01958342455327511.
Time for this trial:  15.220885038375854
Memory status after this trial: 
Memory allocated:  10.44775390625
Memory cached:  12.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.989131659632626, 'log_learning_rate_D': -4.101480240740311, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.6957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.6009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.4122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.271484375
Memory cached:  2.0
[I 2023-11-03 21:59:50,704] Trial 15 finished with value: 0.2568824887275696 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.989131659632626, 'log_learning_rate_D': -4.101480240740311, 'training_batch_size': 8, 'training_p': 4}. Best is trial 14 with value: 0.01958342455327511.
Time for this trial:  15.49324655532837
Memory status after this trial: 
Memory allocated:  17.40966796875
Memory cached:  20.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.285074634372715, 'log_learning_rate_D': -2.5669810360014926, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.53857421875
Memory cached:  6.0
[I 2023-11-03 22:00:06,653] Trial 16 finished with value: 0.017751911655068398 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.285074634372715, 'log_learning_rate_D': -2.5669810360014926, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  15.788525104522705
Memory status after this trial: 
Memory allocated:  19.01123046875
Memory cached:  26.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.159127786253971, 'log_learning_rate_D': -2.7169154898354133, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.56494140625
Memory cached:  2.0
[I 2023-11-03 22:00:22,557] Trial 17 finished with value: 0.01831597089767456 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.159127786253971, 'log_learning_rate_D': -2.7169154898354133, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  15.71966814994812
Memory status after this trial: 
Memory allocated:  31.99072265625
Memory cached:  46.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1840920929626337, 'log_learning_rate_D': -2.659588910586618, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62890625
Memory cached:  4.0
[I 2023-11-03 22:00:39,108] Trial 18 finished with value: 0.0258795116096735 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1840920929626337, 'log_learning_rate_D': -2.659588910586618, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  16.364185094833374
Memory status after this trial: 
Memory allocated:  46.16650390625
Memory cached:  68.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.175253750860288, 'log_learning_rate_D': -1.0050586693407735, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  6.0
[I 2023-11-03 22:00:56,515] Trial 19 finished with value: 0.038117703050374985 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.175253750860288, 'log_learning_rate_D': -1.0050586693407735, 'training_batch_size': 12, 'training_p': 5}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  17.22661018371582
Memory status after this trial: 
Memory allocated:  68.12451171875
Memory cached:  76.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.1716974059414746, 'log_learning_rate_D': -2.798732982770206, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5732421875
Memory cached:  6.0
[I 2023-11-03 22:01:13,686] Trial 20 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.1716974059414746, 'log_learning_rate_D': -2.798732982770206, 'training_batch_size': 11, 'training_p': 5}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  16.981566905975342
Memory status after this trial: 
Memory allocated:  59.60009765625
Memory cached:  68.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.3916365808075173, 'log_learning_rate_D': -2.4735422902007373, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0537109375
Memory cached:  8.0
[I 2023-11-03 22:01:29,942] Trial 21 finished with value: 0.01986106112599373 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.3916365808075173, 'log_learning_rate_D': -2.4735422902007373, 'training_batch_size': 11, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  16.02476215362549
Memory status after this trial: 
Memory allocated:  15.66943359375
Memory cached:  18.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.94188393807893, 'log_learning_rate_D': -3.0244732667414485, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6953125
Memory cached:  2.0
[I 2023-11-03 22:01:46,106] Trial 22 finished with value: 0.019367678090929985 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.94188393807893, 'log_learning_rate_D': -3.0244732667414485, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  15.970647811889648
Memory status after this trial: 
Memory allocated:  24.24853515625
Memory cached:  32.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9447996588514638, 'log_learning_rate_D': -2.7544402383307975, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.482421875
Memory cached:  6.0
[I 2023-11-03 22:02:02,334] Trial 23 finished with value: 0.022548530250787735 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9447996588514638, 'log_learning_rate_D': -2.7544402383307975, 'training_batch_size': 12, 'training_p': 4}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  16.020289659500122
Memory status after this trial: 
Memory allocated:  22.46142578125
Memory cached:  30.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.017437980544984, 'log_learning_rate_D': -3.0504487644653513, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.0246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.0231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.01513671875
Memory cached:  4.0
[I 2023-11-03 22:02:18,815] Trial 24 finished with value: 0.023759637027978897 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.017437980544984, 'log_learning_rate_D': -3.0504487644653513, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  16.301984310150146
Memory status after this trial: 
Memory allocated:  45.72900390625
Memory cached:  60.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2846202788150496, 'log_learning_rate_D': -3.0429677071716696, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
[I 2023-11-03 22:02:36,281] Trial 25 finished with value: 0.019006038084626198 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2846202788150496, 'log_learning_rate_D': -3.0429677071716696, 'training_batch_size': 11, 'training_p': 4}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  17.29027271270752
Memory status after this trial: 
Memory allocated:  73.30419921875
Memory cached:  88.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3883722247840735, 'log_learning_rate_D': -2.0913488437827508, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8349609375
Memory cached:  12.0
[I 2023-11-03 22:02:54,434] Trial 26 finished with value: 0.023892974480986595 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3883722247840735, 'log_learning_rate_D': -2.0913488437827508, 'training_batch_size': 11, 'training_p': 8}. Best is trial 16 with value: 0.017751911655068398.
Time for this trial:  17.965667247772217
Memory status after this trial: 
Memory allocated:  91.99169921875
Memory cached:  112.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.897319959403934, 'log_learning_rate_D': -2.409193166397104, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4404296875
Memory cached:  8.0
[I 2023-11-03 22:03:11,738] Trial 27 finished with value: 0.017602866515517235 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.897319959403934, 'log_learning_rate_D': -2.409193166397104, 'training_batch_size': 11, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.117841243743896
Memory status after this trial: 
Memory allocated:  64.54931640625
Memory cached:  72.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.968048020694585, 'log_learning_rate_D': -2.4565706738735487, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  46.0
	 epoch  10 training error:  tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.48095703125
Memory cached:  48.0
[I 2023-11-03 22:03:30,490] Trial 28 finished with value: 0.02106942981481552 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.968048020694585, 'log_learning_rate_D': -2.4565706738735487, 'training_batch_size': 12, 'training_p': 5}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  18.557855129241943
Memory status after this trial: 
Memory allocated:  150.06298828125
Memory cached:  176.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5997422818948155, 'log_learning_rate_D': -2.267897436073172, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.890625
Memory cached:  8.0
[I 2023-11-03 22:03:49,729] Trial 29 finished with value: 0.04211392626166344 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5997422818948155, 'log_learning_rate_D': -2.267897436073172, 'training_batch_size': 6, 'training_p': 5}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  19.061036586761475
Memory status after this trial: 
Memory allocated:  102.21337890625
Memory cached:  130.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.161730790721824, 'log_learning_rate_D': -1.985030506763036, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.7005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  40 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  70 training error:  tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.0232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.0232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.72705078125
Memory cached:  4.0
[I 2023-11-03 22:04:05,719] Trial 30 finished with value: 0.022368689998984337 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.161730790721824, 'log_learning_rate_D': -1.985030506763036, 'training_batch_size': 11, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  15.767534255981445
Memory status after this trial: 
Memory allocated:  21.77685546875
Memory cached:  30.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2807243836406994, 'log_learning_rate_D': -2.3861098844933046, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.58740234375
Memory cached:  8.0
[I 2023-11-03 22:04:23,290] Trial 31 finished with value: 0.03201071172952652 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2807243836406994, 'log_learning_rate_D': -2.3861098844933046, 'training_batch_size': 11, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.373910188674927
Memory status after this trial: 
Memory allocated:  73.30419921875
Memory cached:  88.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.137307189020353, 'log_learning_rate_D': -2.892748509191108, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.75
Memory cached:  8.0
[I 2023-11-03 22:04:40,534] Trial 32 finished with value: 0.02442651055753231 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.137307189020353, 'log_learning_rate_D': -2.892748509191108, 'training_batch_size': 12, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.058439016342163
Memory status after this trial: 
Memory allocated:  58.75439453125
Memory cached:  80.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.4474928692630047, 'log_learning_rate_D': -2.5368020408087766, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.33056640625
Memory cached:  62.0
[I 2023-11-03 22:04:58,915] Trial 33 finished with value: 0.021200045943260193 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.4474928692630047, 'log_learning_rate_D': -2.5368020408087766, 'training_batch_size': 11, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  18.174708366394043
Memory status after this trial: 
Memory allocated:  134.50634765625
Memory cached:  164.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.773590441420896, 'log_learning_rate_D': -3.2038551487003133, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7294921875
Memory cached:  8.0
[I 2023-11-03 22:05:18,206] Trial 34 finished with value: 0.02037954330444336 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.773590441420896, 'log_learning_rate_D': -3.2038551487003133, 'training_batch_size': 10, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  19.09388542175293
Memory status after this trial: 
Memory allocated:  137.21142578125
Memory cached:  152.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.311056420127902, 'log_learning_rate_D': -2.659858119407242, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.08349609375
Memory cached:  6.0
[I 2023-11-03 22:05:36,285] Trial 35 finished with value: 0.020625976845622063 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.311056420127902, 'log_learning_rate_D': -2.659858119407242, 'training_batch_size': 11, 'training_p': 5}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.886051177978516
Memory status after this trial: 
Memory allocated:  100.75341796875
Memory cached:  106.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.976837686890522, 'log_learning_rate_D': -2.985951691992805, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.71240234375
Memory cached:  8.0
[I 2023-11-03 22:05:54,291] Trial 36 finished with value: 0.020395314320921898 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.976837686890522, 'log_learning_rate_D': -2.985951691992805, 'training_batch_size': 12, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.823289155960083
Memory status after this trial: 
Memory allocated:  114.17919921875
Memory cached:  140.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.763830747353296, 'log_learning_rate_D': -3.6225575896442175, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5146484375
Memory cached:  2.0
[I 2023-11-03 22:06:10,787] Trial 37 finished with value: 0.039323996752500534 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.763830747353296, 'log_learning_rate_D': -3.6225575896442175, 'training_batch_size': 11, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.300721645355225
Memory status after this trial: 
Memory allocated:  38.89013671875
Memory cached:  54.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.507772313908303, 'log_learning_rate_D': -2.651996740496402, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.7219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.041015625
Memory cached:  6.0
[I 2023-11-03 22:06:27,233] Trial 38 finished with value: 0.032746974378824234 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.507772313908303, 'log_learning_rate_D': -2.651996740496402, 'training_batch_size': 10, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.249481916427612
Memory status after this trial: 
Memory allocated:  35.71923828125
Memory cached:  50.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.737718753574625, 'log_learning_rate_D': -2.210508346048755, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.99755859375
Memory cached:  44.0
[I 2023-11-03 22:06:45,957] Trial 39 finished with value: 0.06498952955007553 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.737718753574625, 'log_learning_rate_D': -2.210508346048755, 'training_batch_size': 12, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  18.522356271743774
Memory status after this trial: 
Memory allocated:  137.86181640625
Memory cached:  168.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.0736199480095423, 'log_learning_rate_D': -1.8265655106001883, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.60302734375
Memory cached:  10.0
[I 2023-11-03 22:07:05,000] Trial 40 finished with value: 0.04818775877356529 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.0736199480095423, 'log_learning_rate_D': -1.8265655106001883, 'training_batch_size': 11, 'training_p': 5}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  18.809561729431152
Memory status after this trial: 
Memory allocated:  147.36279296875
Memory cached:  164.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9720942321497583, 'log_learning_rate_D': -3.0034874101711106, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6640625
Memory cached:  6.0
[I 2023-11-03 22:07:21,279] Trial 41 finished with value: 0.017715811729431152 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.9720942321497583, 'log_learning_rate_D': -3.0034874101711106, 'training_batch_size': 12, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.079152822494507
Memory status after this trial: 
Memory allocated:  22.52392578125
Memory cached:  30.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.2933671515840373, 'log_learning_rate_D': -3.1937303721649126, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7041015625
Memory cached:  6.0
[I 2023-11-03 22:07:38,571] Trial 42 finished with value: 0.019055737182497978 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.2933671515840373, 'log_learning_rate_D': -3.1937303721649126, 'training_batch_size': 12, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.088825464248657
Memory status after this trial: 
Memory allocated:  49.14990234375
Memory cached:  68.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.493467089463573, 'log_learning_rate_D': -2.8757169823517947, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.34228515625
Memory cached:  2.0
[I 2023-11-03 22:07:55,404] Trial 43 finished with value: 0.019744595512747765 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.493467089463573, 'log_learning_rate_D': -2.8757169823517947, 'training_batch_size': 12, 'training_p': 2}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.61002469062805
Memory status after this trial: 
Memory allocated:  34.81494140625
Memory cached:  44.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.0002631957409047, 'log_learning_rate_D': -2.2889752243312396, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6669921875
Memory cached:  8.0
[I 2023-11-03 22:08:12,683] Trial 44 finished with value: 0.017817510291934013 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.0002631957409047, 'log_learning_rate_D': -2.2889752243312396, 'training_batch_size': 11, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.05723738670349
Memory status after this trial: 
Memory allocated:  19.86767578125
Memory cached:  28.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.4823831747674507, 'log_learning_rate_D': -2.288964153558253, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.48046875
Memory cached:  6.0
[I 2023-11-03 22:08:29,138] Trial 45 finished with value: 0.018396029248833656 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.4823831747674507, 'log_learning_rate_D': -2.288964153558253, 'training_batch_size': 12, 'training_p': 3}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.25951337814331
Memory status after this trial: 
Memory allocated:  9.55224609375
Memory cached:  12.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.8341656867820846, 'log_learning_rate_D': -2.596746646532222, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.94970703125
Memory cached:  6.0
[I 2023-11-03 22:08:46,019] Trial 46 finished with value: 0.04555192589759827 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.8341656867820846, 'log_learning_rate_D': -2.596746646532222, 'training_batch_size': 10, 'training_p': 2}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.673975944519043
Memory status after this trial: 
Memory allocated:  43.52099609375
Memory cached:  64.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.00018259763447, 'log_learning_rate_D': -2.3738545220284686, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.36328125
Memory cached:  6.0
[I 2023-11-03 22:09:03,679] Trial 47 finished with value: 0.021019933745265007 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.00018259763447, 'log_learning_rate_D': -2.3738545220284686, 'training_batch_size': 12, 'training_p': 4}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  17.435314416885376
Memory status after this trial: 
Memory allocated:  64.15380859375
Memory cached:  92.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.597264712180727, 'log_learning_rate_D': -2.156227368334478, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.04931640625
Memory cached:  6.0
[I 2023-11-03 22:09:20,137] Trial 48 finished with value: 0.017604121938347816 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.597264712180727, 'log_learning_rate_D': -2.156227368334478, 'training_batch_size': 7, 'training_p': 2}. Best is trial 27 with value: 0.017602866515517235.
Time for this trial:  16.234490633010864
Memory status after this trial: 
Memory allocated:  10.40966796875
Memory cached:  12.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.189669736340152, 'log_learning_rate_D': -2.1405703424696685, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6171875
Memory cached:  8.0
[I 2023-11-03 22:09:36,740] Trial 49 finished with value: 0.028072837740182877 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.189669736340152, 'log_learning_rate_D': -2.1405703424696685, 'training_batch_size': 7, 'training_p': 2}. Best is trial 27 with value: 0.017602866515517235.
[I 2023-11-03 22:09:36,741] A new study created in memory with name: no-name-c4ba1127-7807-4a65-a35b-155212a02654
Time for this trial:  16.381476402282715
Memory status after this trial: 
Memory allocated:  10.40966796875
Memory cached:  14.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.5767371445511285, 'log_learning_rate_D': -3.2760571088782826, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  52.0
	 epoch  20 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.0259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7763671875
Memory cached:  50.0
[I 2023-11-03 22:12:40,488] Trial 0 finished with value: 0.01793208345770836 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.5767371445511285, 'log_learning_rate_D': -3.2760571088782826, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 0.01793208345770836.
Time for this trial:  183.62614917755127
Memory status after this trial: 
Memory allocated:  261.75439453125
Memory cached:  280.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.5717824979665007, 'log_learning_rate_D': -1.0015929721301418, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.3603515625
Memory cached:  46.0
[I 2023-11-03 22:18:00,201] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.5717824979665007, 'log_learning_rate_D': -1.0015929721301418, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 0.01793208345770836.
Time for this trial:  319.5543761253357
Memory status after this trial: 
Memory allocated:  251.9072265625
Memory cached:  276.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.2214582948950992, 'log_learning_rate_D': -4.986406619212067, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6103515625
Memory cached:  8.0
[W 2023-11-03 22:18:08,596] Trial 2 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.2214582948950992, 'log_learning_rate_D': -4.986406619212067, 'training_batch_size': 7, 'training_p': 7} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV.py", line 339, in objective
    avg_training_loss = train1Epoch(trainDataLoader, Loss, myWD, params['training_p'])
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV.py", line 208, in train1Epoch
    loss.backward()
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[W 2023-11-03 22:18:08,598] Trial 2 failed with value None.
Traceback (most recent call last):
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV.py", line 384, in <module>
    this_study.optimize(myOpt.objective, n_trials=50)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/study.py", line 442, in optimize
    _optimize(
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 251, in _run_trial
    raise func_err
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV.py", line 339, in objective
    avg_training_loss = train1Epoch(trainDataLoader, Loss, myWD, params['training_p'])
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV.py", line 208, in train1Epoch
    loss.backward()
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
