/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-11-28 22:06:25,899] A new study created in memory with name: no-name-fb6d2b04-9e07-4012-8333-3baf04b43992
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1108_bigDRS_Burigede.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -4.486027903493216, 'log_learning_rate_D': -4.1956028393199665, 'log_learning_rate_D_dagger': -3.241041033361396, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(9.6722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  210.0
	 epoch  10 training error:  tensor(26.4723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  414.0
	 epoch  20 training error:  tensor(15.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  396.0
	 epoch  30 training error:  tensor(7.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  394.0
	 epoch  40 training error:  tensor(10.8010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  402.0
	 epoch  50 training error:  tensor(5.6101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  398.0
	 epoch  60 training error:  tensor(13.1853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  402.0
	 epoch  70 training error:  tensor(9.1915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  406.0
	 epoch  80 training error:  tensor(7.3501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  404.0
	 epoch  90 training error:  tensor(6.6657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.3837890625
Memory cached:  402.0
[I 2023-11-28 22:12:58,257] Trial 0 finished with value: 5.096315383911133 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -4.486027903493216, 'log_learning_rate_D': -4.1956028393199665, 'log_learning_rate_D_dagger': -3.241041033361396, 'training_batch_size': 8, 'training_p': 8}. Best is trial 0 with value: 5.096315383911133.
Time for this trial:  392.2406346797943
Memory status after this trial: 
Memory allocated:  402.9560546875
Memory cached:  424.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -2.3981127049515245, 'log_learning_rate_D': -2.3301935709849735, 'log_learning_rate_D_dagger': -1.5561143208668988, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(9.3166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.12109375
Memory cached:  240.0
	 epoch  10 training error:  tensor(3.2350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.12109375
Memory cached:  360.0
	 epoch  20 training error:  tensor(2.2228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.12109375
Memory cached:  364.0
	 epoch  30 training error:  tensor(2.1410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.12109375
Memory cached:  358.0
	 epoch  40 training error:  tensor(4.2061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.12109375
Memory cached:  384.0
[W 2023-11-28 22:18:57,148] Trial 1 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -2.3981127049515245, 'log_learning_rate_D': -2.3301935709849735, 'log_learning_rate_D_dagger': -1.5561143208668988, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 22:18:57,149] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  358.68180084228516
Memory status after this trial: 
Memory allocated:  408.85498046875
Memory cached:  438.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.945493604873295, 'log_learning_rate_D': -4.0717110659663165, 'log_learning_rate_D_dagger': -3.1817819780379275, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.8549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  156.0
	 epoch  10 training error:  tensor(2.2144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  264.0
	 epoch  20 training error:  tensor(2.1799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  252.0
	 epoch  30 training error:  tensor(2.3454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  254.0
	 epoch  40 training error:  tensor(2.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  266.0
	 epoch  50 training error:  tensor(2.4147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  266.0
	 epoch  60 training error:  tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  272.0
	 epoch  70 training error:  tensor(2.2755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  274.0
	 epoch  80 training error:  tensor(2.4914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  278.0
	 epoch  90 training error:  tensor(2.2738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.626953125
Memory cached:  268.0
[I 2023-11-28 22:22:41,611] Trial 2 finished with value: 1.7333393096923828 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.945493604873295, 'log_learning_rate_D': -4.0717110659663165, 'log_learning_rate_D_dagger': -3.1817819780379275, 'training_batch_size': 9, 'training_p': 6}. Best is trial 2 with value: 1.7333393096923828.
Time for this trial:  224.28183436393738
Memory status after this trial: 
Memory allocated:  228.5810546875
Memory cached:  244.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.5923601174381696, 'log_learning_rate_D': -3.4910614105838054, 'log_learning_rate_D_dagger': -4.587581563430475, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  202.0
	 epoch  10 training error:  tensor(1.2493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  352.0
	 epoch  20 training error:  tensor(1.8383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  356.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  364.0
	 epoch  40 training error:  tensor(1.3923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  350.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  366.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  346.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  362.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  350.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1591796875
Memory cached:  358.0
[I 2023-11-28 22:28:29,999] Trial 3 finished with value: 4.721348762512207 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.5923601174381696, 'log_learning_rate_D': -3.4910614105838054, 'log_learning_rate_D_dagger': -4.587581563430475, 'training_batch_size': 9, 'training_p': 2}. Best is trial 2 with value: 1.7333393096923828.
Time for this trial:  348.2355463504791
Memory status after this trial: 
Memory allocated:  311.826171875
Memory cached:  322.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.761135962404005, 'log_learning_rate_D': -3.1528505015902626, 'log_learning_rate_D_dagger': -4.528204508452681, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.9235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  90.0
	 epoch  10 training error:  tensor(1.9034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  134.0
	 epoch  20 training error:  tensor(1.6473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  130.0
	 epoch  30 training error:  tensor(1.5582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  130.0
	 epoch  40 training error:  tensor(1.5567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  138.0
	 epoch  50 training error:  tensor(1.5068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  130.0
	 epoch  60 training error:  tensor(1.3584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  126.0
	 epoch  70 training error:  tensor(1.3797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  130.0
	 epoch  80 training error:  tensor(1.4269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  128.0
	 epoch  90 training error:  tensor(1.4210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.611328125
Memory cached:  128.0
[I 2023-11-28 22:35:06,283] Trial 4 finished with value: 1.1843699216842651 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.761135962404005, 'log_learning_rate_D': -3.1528505015902626, 'log_learning_rate_D_dagger': -4.528204508452681, 'training_batch_size': 6, 'training_p': 3}. Best is trial 4 with value: 1.1843699216842651.
Time for this trial:  396.11138367652893
Memory status after this trial: 
Memory allocated:  88.818359375
Memory cached:  122.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.3276539772364577, 'log_learning_rate_D': -4.22213385505345, 'log_learning_rate_D_dagger': -2.1492958411197045, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(5.6024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  212.0
	 epoch  10 training error:  tensor(1.1923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  314.0
	 epoch  20 training error:  tensor(1.6572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  314.0
	 epoch  30 training error:  tensor(1.3434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  320.0
	 epoch  40 training error:  tensor(1.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  330.0
	 epoch  50 training error:  tensor(1.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  326.0
	 epoch  60 training error:  tensor(1.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  322.0
	 epoch  70 training error:  tensor(1.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  310.0
	 epoch  80 training error:  tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  318.0
	 epoch  90 training error:  tensor(1.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.25390625
Memory cached:  316.0
[I 2023-11-28 22:44:05,726] Trial 5 finished with value: 1.018223762512207 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.3276539772364577, 'log_learning_rate_D': -4.22213385505345, 'log_learning_rate_D_dagger': -2.1492958411197045, 'training_batch_size': 6, 'training_p': 5}. Best is trial 5 with value: 1.018223762512207.
Time for this trial:  539.2908766269684
Memory status after this trial: 
Memory allocated:  315.814453125
Memory cached:  342.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.577436146049329, 'log_learning_rate_D': -3.7960855795459976, 'log_learning_rate_D_dagger': -1.9144830138149778, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  122.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  156.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  170.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  160.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  174.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  156.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  164.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  160.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  162.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.76220703125
Memory cached:  160.0
[I 2023-11-28 22:51:27,462] Trial 6 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.577436146049329, 'log_learning_rate_D': -3.7960855795459976, 'log_learning_rate_D_dagger': -1.9144830138149778, 'training_batch_size': 6, 'training_p': 2}. Best is trial 6 with value: 1.0.
Time for this trial:  441.54829382896423
Memory status after this trial: 
Memory allocated:  208.2578125
Memory cached:  214.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -1.9177491751981823, 'log_learning_rate_D': -3.4928790474170985, 'log_learning_rate_D_dagger': -2.4703200239147085, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(18.3505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  152.0
	 epoch  10 training error:  tensor(10.3791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  328.0
	 epoch  20 training error:  tensor(7.9779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  318.0
	 epoch  30 training error:  tensor(7.6662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  332.0
	 epoch  40 training error:  tensor(7.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  334.0
	 epoch  50 training error:  tensor(7.6884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  328.0
	 epoch  60 training error:  tensor(7.5858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  332.0
	 epoch  70 training error:  tensor(7.7768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  324.0
	 epoch  80 training error:  tensor(7.6144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  338.0
	 epoch  90 training error:  tensor(7.7937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.234375
Memory cached:  324.0
[I 2023-11-28 22:57:15,819] Trial 7 finished with value: 15.558056831359863 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -1.9177491751981823, 'log_learning_rate_D': -3.4928790474170985, 'log_learning_rate_D_dagger': -2.4703200239147085, 'training_batch_size': 7, 'training_p': 2}. Best is trial 6 with value: 1.0.
Time for this trial:  348.2010028362274
Memory status after this trial: 
Memory allocated:  296.22412109375
Memory cached:  304.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.6778282080545788, 'log_learning_rate_D': -1.853494527713858, 'log_learning_rate_D_dagger': -1.6159532893593882, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(20.6360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  96.0
	 epoch  10 training error:  tensor(1.7124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  120.0
	 epoch  20 training error:  tensor(1.9705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  116.0
	 epoch  30 training error:  tensor(2.4913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  122.0
	 epoch  40 training error:  tensor(2.4919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  120.0
	 epoch  50 training error:  tensor(5.4610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  126.0
	 epoch  60 training error:  tensor(5.7031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  120.0
	 epoch  70 training error:  tensor(6.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  116.0
	 epoch  80 training error:  tensor(4.4795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  120.0
	 epoch  90 training error:  tensor(59.2255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.46728515625
Memory cached:  122.0
[I 2023-11-28 23:01:50,301] Trial 8 finished with value: 38.46145248413086 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.6778282080545788, 'log_learning_rate_D': -1.853494527713858, 'log_learning_rate_D_dagger': -1.6159532893593882, 'training_batch_size': 8, 'training_p': 2}. Best is trial 6 with value: 1.0.
Time for this trial:  274.3023090362549
Memory status after this trial: 
Memory allocated:  65.9609375
Memory cached:  102.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.984933812024202, 'log_learning_rate_D': -3.1488944225915927, 'log_learning_rate_D_dagger': -1.1322650431389047, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(13.5651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.18701171875
Memory cached:  222.0
[W 2023-11-28 23:02:00,385] Trial 9 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.984933812024202, 'log_learning_rate_D': -3.1488944225915927, 'log_learning_rate_D_dagger': -1.1322650431389047, 'training_batch_size': 10, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:02:00,386] Trial 9 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  9.908579349517822
Memory status after this trial: 
Memory allocated:  526.09033203125
Memory cached:  556.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -4.912408095426481, 'log_learning_rate_D': -2.8444671913437785, 'log_learning_rate_D_dagger': -3.387991721374289, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(17.4488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.8876953125
Memory cached:  186.0
[W 2023-11-28 23:02:10,098] Trial 10 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -4.912408095426481, 'log_learning_rate_D': -2.8444671913437785, 'log_learning_rate_D_dagger': -3.387991721374289, 'training_batch_size': 11, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:02:10,099] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  9.533399820327759
Memory status after this trial: 
Memory allocated:  333.98291015625
Memory cached:  356.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -2.170158551202077, 'log_learning_rate_D': -1.1574402607055085, 'log_learning_rate_D_dagger': -1.2451100741085641, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(18.7510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  180.0
	 epoch  10 training error:  tensor(6.9074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  322.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  314.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  322.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  332.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  332.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  322.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  328.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  328.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.49560546875
Memory cached:  328.0
[I 2023-11-28 23:08:13,689] Trial 11 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -2.170158551202077, 'log_learning_rate_D': -1.1574402607055085, 'log_learning_rate_D_dagger': -1.2451100741085641, 'training_batch_size': 8, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  363.39952063560486
Memory status after this trial: 
Memory allocated:  295.98974609375
Memory cached:  312.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -4.567915810776835, 'log_learning_rate_D': -2.5592577677980715, 'log_learning_rate_D_dagger': -1.6102996832129994, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(31.7577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  122.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  170.0
	 epoch  20 training error:  tensor(1.8293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  176.0
	 epoch  30 training error:  tensor(1.3013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  170.0
	 epoch  40 training error:  tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  174.0
	 epoch  50 training error:  tensor(5.9654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  176.0
	 epoch  60 training error:  tensor(2.1568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  178.0
	 epoch  70 training error:  tensor(4.1971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  174.0
	 epoch  80 training error:  tensor(4.1826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  172.0
	 epoch  90 training error:  tensor(4.1172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.56689453125
Memory cached:  174.0
[I 2023-11-28 23:12:53,675] Trial 12 finished with value: 4.0245680809021 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -4.567915810776835, 'log_learning_rate_D': -2.5592577677980715, 'log_learning_rate_D_dagger': -1.6102996832129994, 'training_batch_size': 9, 'training_p': 4}. Best is trial 6 with value: 1.0.
Time for this trial:  279.8103985786438
Memory status after this trial: 
Memory allocated:  103.7646484375
Memory cached:  150.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.5839946899176702, 'log_learning_rate_D': -4.817700950578117, 'log_learning_rate_D_dagger': -1.047632646451847, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(3.9630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40869140625
Memory cached:  218.0
	 epoch  10 training error:  tensor(4.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40869140625
Memory cached:  406.0
[W 2023-11-28 23:14:13,889] Trial 13 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.5839946899176702, 'log_learning_rate_D': -4.817700950578117, 'log_learning_rate_D_dagger': -1.047632646451847, 'training_batch_size': 11, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:14:13,890] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  79.94913530349731
Memory status after this trial: 
Memory allocated:  474.78125
Memory cached:  496.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0907640149460927, 'log_learning_rate_D': -4.884845588797386, 'log_learning_rate_D_dagger': -1.033882939777361, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(8.9168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.150390625
Memory cached:  168.0
[W 2023-11-28 23:14:29,117] Trial 14 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0907640149460927, 'log_learning_rate_D': -4.884845588797386, 'log_learning_rate_D_dagger': -1.033882939777361, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:14:29,118] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  14.920675277709961
Memory status after this trial: 
Memory allocated:  456.6796875
Memory cached:  474.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0078904227576564, 'log_learning_rate_D': -4.956374707318105, 'log_learning_rate_D_dagger': -1.1321639970317965, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(10.2043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40234375
Memory cached:  224.0
	 epoch  10 training error:  tensor(4.5037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40234375
Memory cached:  378.0
	 epoch  20 training error:  tensor(5.8767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40234375
Memory cached:  384.0
	 epoch  30 training error:  tensor(4.4661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.40234375
Memory cached:  368.0
[W 2023-11-28 23:17:04,656] Trial 15 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0078904227576564, 'log_learning_rate_D': -4.956374707318105, 'log_learning_rate_D_dagger': -1.1321639970317965, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:17:04,658] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  155.22901701927185
Memory status after this trial: 
Memory allocated:  475.2177734375
Memory cached:  496.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0927353274421074, 'log_learning_rate_D': -4.7299482165080615, 'log_learning_rate_D_dagger': -1.0450566972154922, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(5.9135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.63671875
Memory cached:  190.0
[W 2023-11-28 23:17:15,725] Trial 16 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0927353274421074, 'log_learning_rate_D': -4.7299482165080615, 'log_learning_rate_D_dagger': -1.0450566972154922, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:17:15,726] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  10.750285387039185
Memory status after this trial: 
Memory allocated:  471.71875
Memory cached:  482.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.745540588071933, 'log_learning_rate_D': -4.710215577099138, 'log_learning_rate_D_dagger': -2.414515487328881, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(7.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  232.0
	 epoch  10 training error:  tensor(1.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  408.0
	 epoch  20 training error:  tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  410.0
	 epoch  30 training error:  tensor(1.0234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  408.0
	 epoch  40 training error:  tensor(1.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  398.0
	 epoch  50 training error:  tensor(1.0179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  408.0
	 epoch  60 training error:  tensor(1.0087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  400.0
	 epoch  70 training error:  tensor(1.0205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  380.0
	 epoch  80 training error:  tensor(1.5003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  416.0
	 epoch  90 training error:  tensor(2.4441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.37939453125
Memory cached:  406.0
[I 2023-11-28 23:24:07,258] Trial 17 finished with value: 1.7255760431289673 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.745540588071933, 'log_learning_rate_D': -4.710215577099138, 'log_learning_rate_D_dagger': -2.414515487328881, 'training_batch_size': 12, 'training_p': 4}. Best is trial 6 with value: 1.0.
Time for this trial:  411.17489671707153
Memory status after this trial: 
Memory allocated:  471.7255859375
Memory cached:  492.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.3566404494053863, 'log_learning_rate_D': -1.0215007728525576, 'log_learning_rate_D_dagger': -1.12592304899895, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(4.3268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  128.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  236.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  246.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  244.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  230.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  240.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  244.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  240.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  248.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  250.0
[I 2023-11-28 23:28:30,717] Trial 18 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.3566404494053863, 'log_learning_rate_D': -1.0215007728525576, 'log_learning_rate_D_dagger': -1.12592304899895, 'training_batch_size': 11, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  263.20060086250305
Memory status after this trial: 
Memory allocated:  182.4111328125
Memory cached:  200.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.1909362709366411, 'log_learning_rate_D': -2.1016908593064976, 'log_learning_rate_D_dagger': -1.0332723275230755, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  144.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  250.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  254.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  248.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  252.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  244.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  240.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  252.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  242.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.62548828125
Memory cached:  242.0
[I 2023-11-28 23:33:18,456] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.1909362709366411, 'log_learning_rate_D': -2.1016908593064976, 'log_learning_rate_D_dagger': -1.0332723275230755, 'training_batch_size': 7, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  287.48472785949707
Memory status after this trial: 
Memory allocated:  168.83544921875
Memory cached:  194.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -2.3721859315216927, 'log_learning_rate_D': -1.2494296157628484, 'log_learning_rate_D_dagger': -1.7110738758898616, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(14.5752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  130.0
	 epoch  10 training error:  tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  214.0
	 epoch  20 training error:  tensor(1.0222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  220.0
	 epoch  30 training error:  tensor(1.0152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  218.0
	 epoch  40 training error:  tensor(1.0118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  244.0
	 epoch  50 training error:  tensor(1.0106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  224.0
	 epoch  60 training error:  tensor(1.0086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  218.0
	 epoch  70 training error:  tensor(1.0063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  220.0
	 epoch  80 training error:  tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  216.0
	 epoch  90 training error:  tensor(1.0034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.609375
Memory cached:  216.0
[I 2023-11-28 23:37:53,004] Trial 20 finished with value: 1.0010887384414673 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -2.3721859315216927, 'log_learning_rate_D': -1.2494296157628484, 'log_learning_rate_D_dagger': -1.7110738758898616, 'training_batch_size': 7, 'training_p': 6}. Best is trial 6 with value: 1.0.
Time for this trial:  274.29771423339844
Memory status after this trial: 
Memory allocated:  154.9814453125
Memory cached:  176.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.869258180855802, 'log_learning_rate_D': -2.73857431496284, 'log_learning_rate_D_dagger': -1.237452903938277, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(6.5555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  142.0
	 epoch  10 training error:  tensor(31.6736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  288.0
	 epoch  20 training error:  tensor(38.1490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  270.0
	 epoch  30 training error:  tensor(34.9722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  272.0
	 epoch  40 training error:  tensor(34.1413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  288.0
	 epoch  50 training error:  tensor(33.7573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  276.0
	 epoch  60 training error:  tensor(33.7836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  290.0
	 epoch  70 training error:  tensor(34.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  278.0
	 epoch  80 training error:  tensor(34.5965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  280.0
	 epoch  90 training error:  tensor(33.9006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.96728515625
Memory cached:  276.0
[I 2023-11-28 23:43:21,282] Trial 21 finished with value: 24.48533821105957 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.869258180855802, 'log_learning_rate_D': -2.73857431496284, 'log_learning_rate_D_dagger': -1.237452903938277, 'training_batch_size': 10, 'training_p': 6}. Best is trial 6 with value: 1.0.
Time for this trial:  327.9954240322113
Memory status after this trial: 
Memory allocated:  238.15576171875
Memory cached:  244.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.8416724603736898, 'log_learning_rate_D': -1.8460535101567102, 'log_learning_rate_D_dagger': -2.1014711352745543, 'training_batch_size': 6, 'training_p': 7}
[W 2023-11-28 23:43:29,309] Trial 22 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.8416724603736898, 'log_learning_rate_D': -1.8460535101567102, 'log_learning_rate_D_dagger': -2.1014711352745543, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:43:29,310] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.750239849090576
Memory status after this trial: 
Memory allocated:  229.8583984375
Memory cached:  246.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.7265122524778136, 'log_learning_rate_D': -1.6553560331504864, 'log_learning_rate_D_dagger': -1.991089659792629, 'training_batch_size': 6, 'training_p': 7}
[W 2023-11-28 23:43:37,396] Trial 23 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.7265122524778136, 'log_learning_rate_D': -1.6553560331504864, 'log_learning_rate_D_dagger': -1.991089659792629, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:43:37,397] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.798020362854004
Memory status after this trial: 
Memory allocated:  230.662109375
Memory cached:  246.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.011753736791956, 'log_learning_rate_D': -1.7954230119731391, 'log_learning_rate_D_dagger': -1.9287121655429385, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(3.9124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  168.0
[W 2023-11-28 23:43:51,614] Trial 24 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.011753736791956, 'log_learning_rate_D': -1.7954230119731391, 'log_learning_rate_D_dagger': -1.9287121655429385, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:43:51,615] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  13.900794267654419
Memory status after this trial: 
Memory allocated:  229.8583984375
Memory cached:  246.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.024732207596161, 'log_learning_rate_D': -1.702138876942729, 'log_learning_rate_D_dagger': -2.0600839285740014, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(3.8278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.22705078125
Memory cached:  142.0
	 epoch  10 training error:  tensor(3.8537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.22705078125
Memory cached:  202.0
	 epoch  20 training error:  tensor(3.9379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.22705078125
Memory cached:  204.0
[W 2023-11-28 23:46:24,578] Trial 25 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.024732207596161, 'log_learning_rate_D': -1.702138876942729, 'log_learning_rate_D_dagger': -2.0600839285740014, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:46:24,579] Trial 25 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  152.6631636619568
Memory status after this trial: 
Memory allocated:  168.03076171875
Memory cached:  172.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.0108853726380946, 'log_learning_rate_D': -1.6152719814865915, 'log_learning_rate_D_dagger': -2.009915382766513, 'training_batch_size': 6, 'training_p': 7}
[W 2023-11-28 23:46:32,830] Trial 26 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.0108853726380946, 'log_learning_rate_D': -1.6152719814865915, 'log_learning_rate_D_dagger': -2.009915382766513, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:46:32,831] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.955910921096802
Memory status after this trial: 
Memory allocated:  284.1962890625
Memory cached:  310.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.036942284562428, 'log_learning_rate_D': -1.848214082085368, 'log_learning_rate_D_dagger': -2.009368945860406, 'training_batch_size': 6, 'training_p': 7}
[W 2023-11-28 23:46:40,941] Trial 27 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.036942284562428, 'log_learning_rate_D': -1.848214082085368, 'log_learning_rate_D_dagger': -2.009368945860406, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:46:40,942] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.828493356704712
Memory status after this trial: 
Memory allocated:  229.8583984375
Memory cached:  246.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.015957818653602, 'log_learning_rate_D': -1.6393479857520188, 'log_learning_rate_D_dagger': -2.060527889286872, 'training_batch_size': 6, 'training_p': 7}
[W 2023-11-28 23:46:48,164] Trial 28 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.015957818653602, 'log_learning_rate_D': -1.6393479857520188, 'log_learning_rate_D_dagger': -2.060527889286872, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-11-28 23:46:48,164] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.95790958404541
Memory status after this trial: 
Memory allocated:  159.0517578125
Memory cached:  162.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.1264799046751133, 'log_learning_rate_D': -1.7063743415380042, 'log_learning_rate_D_dagger': -1.9491675343768717, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(3.2097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  170.0
	 epoch  10 training error:  tensor(6.8089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  264.0
	 epoch  20 training error:  tensor(14.0828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  270.0
	 epoch  30 training error:  tensor(7.5270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  256.0
	 epoch  40 training error:  tensor(7.6722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  264.0
	 epoch  50 training error:  tensor(8.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  258.0
	 epoch  60 training error:  tensor(7.3249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  268.0
	 epoch  70 training error:  tensor(8.3981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  252.0
	 epoch  80 training error:  tensor(7.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  260.0
	 epoch  90 training error:  tensor(8.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.27099609375
Memory cached:  252.0
[I 2023-11-28 23:57:00,996] Trial 29 finished with value: 5.625985622406006 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.1264799046751133, 'log_learning_rate_D': -1.7063743415380042, 'log_learning_rate_D_dagger': -1.9491675343768717, 'training_batch_size': 6, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  612.5373690128326
Memory status after this trial: 
Memory allocated:  229.8583984375
Memory cached:  246.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.571935992263302, 'log_learning_rate_D': -2.37707454657271, 'log_learning_rate_D_dagger': -2.648243760421982, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(9.4869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  158.0
	 epoch  10 training error:  tensor(4.3420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  316.0
	 epoch  20 training error:  tensor(7.4615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  324.0
	 epoch  30 training error:  tensor(6.6693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  324.0
	 epoch  40 training error:  tensor(5.1030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  318.0
	 epoch  50 training error:  tensor(3.9680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  300.0
	 epoch  60 training error:  tensor(3.3938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  308.0
	 epoch  70 training error:  tensor(3.1726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  308.0
	 epoch  80 training error:  tensor(3.1528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  320.0
	 epoch  90 training error:  tensor(3.1807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.91064453125
Memory cached:  304.0
[I 2023-11-29 00:02:00,769] Trial 30 finished with value: 3.946057081222534 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.571935992263302, 'log_learning_rate_D': -2.37707454657271, 'log_learning_rate_D_dagger': -2.648243760421982, 'training_batch_size': 8, 'training_p': 4}. Best is trial 6 with value: 1.0.
Time for this trial:  299.5097270011902
Memory status after this trial: 
Memory allocated:  250.494140625
Memory cached:  256.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -1.0226932751525646, 'log_learning_rate_D': -1.384868955838446, 'log_learning_rate_D_dagger': -1.4450687985717594, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(6.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  192.0
	 epoch  10 training error:  tensor(1.6689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  336.0
	 epoch  20 training error:  tensor(1.2296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  338.0
	 epoch  30 training error:  tensor(4.2248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  324.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  326.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  336.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  344.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  332.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  340.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.29833984375
Memory cached:  344.0
[I 2023-11-29 00:07:01,986] Trial 31 finished with value: 3.0520405769348145 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -1.0226932751525646, 'log_learning_rate_D': -1.384868955838446, 'log_learning_rate_D_dagger': -1.4450687985717594, 'training_batch_size': 10, 'training_p': 5}. Best is trial 6 with value: 1.0.
Time for this trial:  300.97122144699097
Memory status after this trial: 
Memory allocated:  274.3095703125
Memory cached:  286.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.5750685289243074, 'log_learning_rate_D': -3.0100049875356683, 'log_learning_rate_D_dagger': -2.0641653275712093, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(15.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  152.0
	 epoch  10 training error:  tensor(20.6142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  282.0
	 epoch  20 training error:  tensor(20.3181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  282.0
	 epoch  30 training error:  tensor(21.3443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  282.0
	 epoch  40 training error:  tensor(22.1974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  274.0
	 epoch  50 training error:  tensor(22.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  278.0
	 epoch  60 training error:  tensor(22.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  286.0
	 epoch  70 training error:  tensor(22.3755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  282.0
	 epoch  80 training error:  tensor(22.6253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  278.0
	 epoch  90 training error:  tensor(22.5218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.64453125
Memory cached:  282.0
[I 2023-11-29 00:12:49,360] Trial 32 finished with value: 25.224767684936523 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.5750685289243074, 'log_learning_rate_D': -3.0100049875356683, 'log_learning_rate_D_dagger': -2.0641653275712093, 'training_batch_size': 7, 'training_p': 3}. Best is trial 6 with value: 1.0.
Time for this trial:  347.11327481269836
Memory status after this trial: 
Memory allocated:  262.6533203125
Memory cached:  270.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -3.3048858678681343, 'log_learning_rate_D': -1.5122003311804404, 'log_learning_rate_D_dagger': -1.052925549943486, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(3.1889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  130.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  210.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  206.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  192.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  206.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  204.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  200.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  206.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  204.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.53857421875
Memory cached:  208.0
[I 2023-11-29 00:16:10,480] Trial 33 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -3.3048858678681343, 'log_learning_rate_D': -1.5122003311804404, 'log_learning_rate_D_dagger': -1.052925549943486, 'training_batch_size': 8, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  200.88682985305786
Memory status after this trial: 
Memory allocated:  148.529296875
Memory cached:  172.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -2.066099902024457, 'log_learning_rate_D': -2.071850830705565, 'log_learning_rate_D_dagger': -1.513669622443865, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(6.2832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  164.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  278.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  290.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  290.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  286.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  294.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  296.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  302.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  280.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.55126953125
Memory cached:  292.0
[I 2023-11-29 00:22:08,058] Trial 34 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -2.066099902024457, 'log_learning_rate_D': -2.071850830705565, 'log_learning_rate_D_dagger': -1.513669622443865, 'training_batch_size': 10, 'training_p': 3}. Best is trial 6 with value: 1.0.
Time for this trial:  357.32183504104614
Memory status after this trial: 
Memory allocated:  253.46142578125
Memory cached:  260.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.3828323645209304, 'log_learning_rate_D': -1.2758738525314532, 'log_learning_rate_D_dagger': -1.0582913270900958, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  136.0
	 epoch  10 training error:  tensor(19.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  240.0
	 epoch  20 training error:  tensor(10.1797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  222.0
	 epoch  30 training error:  tensor(78.8890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  222.0
	 epoch  40 training error:  tensor(55.2408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  226.0
	 epoch  50 training error:  tensor(97.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  226.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  226.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  226.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  240.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.29248046875
Memory cached:  232.0
[I 2023-11-29 00:26:31,685] Trial 35 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.3828323645209304, 'log_learning_rate_D': -1.2758738525314532, 'log_learning_rate_D_dagger': -1.0582913270900958, 'training_batch_size': 12, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  263.3517806529999
Memory status after this trial: 
Memory allocated:  182.4111328125
Memory cached:  186.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.5829345349477655, 'log_learning_rate_D': -1.0557168342391514, 'log_learning_rate_D_dagger': -1.42013225994521, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(3.2418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  122.0
	 epoch  10 training error:  tensor(2.2037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  140.0
	 epoch  20 training error:  tensor(1.4713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  148.0
	 epoch  30 training error:  tensor(1.4464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  144.0
	 epoch  40 training error:  tensor(1.4616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  148.0
[W 2023-11-29 00:28:12,829] Trial 36 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.5829345349477655, 'log_learning_rate_D': -1.0557168342391514, 'log_learning_rate_D_dagger': -1.42013225994521, 'training_batch_size': 11, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-11-29 00:28:12,829] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  100.91498064994812
Memory status after this trial: 
Memory allocated:  93.1416015625
Memory cached:  122.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.5115000751260235, 'log_learning_rate_D': -1.0021102407347966, 'log_learning_rate_D_dagger': -1.3536590487294013, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(5.6963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  114.0
	 epoch  10 training error:  tensor(1.4551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  144.0
	 epoch  20 training error:  tensor(5.1739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  138.0
	 epoch  30 training error:  tensor(11.3787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  140.0
	 epoch  40 training error:  tensor(8.8590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  142.0
	 epoch  50 training error:  tensor(8.5314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  142.0
	 epoch  60 training error:  tensor(8.5387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  146.0
	 epoch  70 training error:  tensor(8.8295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  142.0
	 epoch  80 training error:  tensor(9.4056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  138.0
	 epoch  90 training error:  tensor(8.7180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7275390625
Memory cached:  142.0
[I 2023-11-29 00:32:11,543] Trial 37 finished with value: 5.480250835418701 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.5115000751260235, 'log_learning_rate_D': -1.0021102407347966, 'log_learning_rate_D_dagger': -1.3536590487294013, 'training_batch_size': 12, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  238.48681807518005
Memory status after this trial: 
Memory allocated:  93.1416015625
Memory cached:  118.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.997704645082248, 'log_learning_rate_D': -1.0212022812577526, 'log_learning_rate_D_dagger': -1.8293864711053662, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(3.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  126.0
	 epoch  10 training error:  tensor(33.1686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  202.0
	 epoch  20 training error:  tensor(49.6603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  206.0
	 epoch  30 training error:  tensor(57.3552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  204.0
	 epoch  40 training error:  tensor(60.9266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  196.0
	 epoch  50 training error:  tensor(62.4383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  204.0
	 epoch  60 training error:  tensor(62.4625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  196.0
	 epoch  70 training error:  tensor(63.6065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  204.0
	 epoch  80 training error:  tensor(61.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  198.0
	 epoch  90 training error:  tensor(63.3414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.92138671875
Memory cached:  202.0
[I 2023-11-29 00:36:26,590] Trial 38 finished with value: 26.39131736755371 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.997704645082248, 'log_learning_rate_D': -1.0212022812577526, 'log_learning_rate_D_dagger': -1.8293864711053662, 'training_batch_size': 11, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  254.8138837814331
Memory status after this trial: 
Memory allocated:  134.16845703125
Memory cached:  174.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.936005238727245, 'log_learning_rate_D': -1.6975459862325954, 'log_learning_rate_D_dagger': -1.2833097517364298, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  126.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  188.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  186.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  194.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  184.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  186.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  190.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  194.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  192.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9091796875
Memory cached:  190.0
[I 2023-11-29 00:40:56,893] Trial 39 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.936005238727245, 'log_learning_rate_D': -1.6975459862325954, 'log_learning_rate_D_dagger': -1.2833097517364298, 'training_batch_size': 11, 'training_p': 6}. Best is trial 6 with value: 1.0.
Time for this trial:  270.0483703613281
Memory status after this trial: 
Memory allocated:  131.2724609375
Memory cached:  162.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.311580099743146, 'log_learning_rate_D': -1.5312060735143609, 'log_learning_rate_D_dagger': -1.753463778662189, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(10.9838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  144.0
	 epoch  10 training error:  tensor(2.3001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  216.0
	 epoch  20 training error:  tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  226.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  226.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  232.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  226.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  228.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  234.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  230.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.005859375
Memory cached:  226.0
[I 2023-11-29 00:45:01,676] Trial 40 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.311580099743146, 'log_learning_rate_D': -1.5312060735143609, 'log_learning_rate_D_dagger': -1.753463778662189, 'training_batch_size': 11, 'training_p': 5}. Best is trial 6 with value: 1.0.
Time for this trial:  244.55394411087036
Memory status after this trial: 
Memory allocated:  150.26513671875
Memory cached:  184.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -2.6106371962471795, 'log_learning_rate_D': -2.0161241385097712, 'log_learning_rate_D_dagger': -1.4286767151751507, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(24.5333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  142.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  278.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  274.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  292.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  292.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  294.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  280.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  290.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  278.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.95751953125
Memory cached:  298.0
[I 2023-11-29 00:50:27,909] Trial 41 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -2.6106371962471795, 'log_learning_rate_D': -2.0161241385097712, 'log_learning_rate_D_dagger': -1.4286767151751507, 'training_batch_size': 10, 'training_p': 7}. Best is trial 6 with value: 1.0.
Time for this trial:  325.97218799591064
Memory status after this trial: 
Memory allocated:  227.744140625
Memory cached:  236.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.7830809947236217, 'log_learning_rate_D': -2.3695188801916567, 'log_learning_rate_D_dagger': -2.083590560629702, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  126.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  228.0
	 epoch  20 training error:  tensor(1.1624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  234.0
	 epoch  30 training error:  tensor(1.4856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  222.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  234.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  220.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  226.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  230.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  238.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.828125
Memory cached:  236.0
[I 2023-11-29 00:58:14,629] Trial 42 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.7830809947236217, 'log_learning_rate_D': -2.3695188801916567, 'log_learning_rate_D_dagger': -2.083590560629702, 'training_batch_size': 6, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  466.4667856693268
Memory status after this trial: 
Memory allocated:  200.96435546875
Memory cached:  204.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.2485055812489136, 'log_learning_rate_D': -1.0474780014037577, 'log_learning_rate_D_dagger': -1.0070251917812179, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(2.1573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  168.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  296.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  304.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  294.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  298.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  296.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  296.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  296.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  296.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.71435546875
Memory cached:  300.0
[I 2023-11-29 01:02:52,526] Trial 43 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.2485055812489136, 'log_learning_rate_D': -1.0474780014037577, 'log_learning_rate_D_dagger': -1.0070251917812179, 'training_batch_size': 7, 'training_p': 5}. Best is trial 6 with value: 1.0.
Time for this trial:  277.66087675094604
Memory status after this trial: 
Memory allocated:  284.4990234375
Memory cached:  306.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.129771666788736, 'log_learning_rate_D': -1.4976183681576098, 'log_learning_rate_D_dagger': -2.845965004687824, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(14.7154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.43408203125
Memory cached:  170.0
[W 2023-11-29 01:03:05,600] Trial 44 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.129771666788736, 'log_learning_rate_D': -1.4976183681576098, 'log_learning_rate_D_dagger': -2.845965004687824, 'training_batch_size': 8, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-11-29 01:03:05,601] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  12.801977157592773
Memory status after this trial: 
Memory allocated:  306.9560546875
Memory cached:  316.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.1058541181370325, 'log_learning_rate_D': -1.3532750441690846, 'log_learning_rate_D_dagger': -2.7471001799985864, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(15.3836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  166.0
	 epoch  10 training error:  tensor(10.8502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  308.0
	 epoch  20 training error:  tensor(10.7401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  314.0
	 epoch  30 training error:  tensor(11.0131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  318.0
	 epoch  40 training error:  tensor(11.1449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  318.0
	 epoch  50 training error:  tensor(10.8599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  322.0
	 epoch  60 training error:  tensor(11.1675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  318.0
	 epoch  70 training error:  tensor(11.4276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  318.0
	 epoch  80 training error:  tensor(10.6731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  318.0
	 epoch  90 training error:  tensor(11.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.95849609375
Memory cached:  330.0
[I 2023-11-29 01:09:08,512] Trial 45 finished with value: 6.156885147094727 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.1058541181370325, 'log_learning_rate_D': -1.3532750441690846, 'log_learning_rate_D_dagger': -2.7471001799985864, 'training_batch_size': 8, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  362.58734226226807
Memory status after this trial: 
Memory allocated:  296.3662109375
Memory cached:  304.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.7637834780699264, 'log_learning_rate_D': -1.7001851973786626, 'log_learning_rate_D_dagger': -1.848952165156141, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(21.8860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  176.0
	 epoch  10 training error:  tensor(9.7569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  328.0
	 epoch  20 training error:  tensor(9.4147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  326.0
	 epoch  30 training error:  tensor(9.6157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  310.0
	 epoch  40 training error:  tensor(9.6474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  306.0
	 epoch  50 training error:  tensor(9.3252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  324.0
	 epoch  60 training error:  tensor(9.4425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  326.0
	 epoch  70 training error:  tensor(8.8686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  326.0
	 epoch  80 training error:  tensor(9.4531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  332.0
	 epoch  90 training error:  tensor(9.4077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.15869140625
Memory cached:  322.0
[I 2023-11-29 01:15:02,312] Trial 46 finished with value: 5.771938323974609 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.7637834780699264, 'log_learning_rate_D': -1.7001851973786626, 'log_learning_rate_D_dagger': -1.848952165156141, 'training_batch_size': 9, 'training_p': 6}. Best is trial 6 with value: 1.0.
Time for this trial:  353.5003411769867
Memory status after this trial: 
Memory allocated:  247.20654296875
Memory cached:  268.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.2367027958562715, 'log_learning_rate_D': -2.0785504566850572, 'log_learning_rate_D_dagger': -1.2225994546867094, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  148.0
	 epoch  10 training error:  tensor(5.8131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  254.0
	 epoch  20 training error:  tensor(7.6216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  256.0
	 epoch  30 training error:  tensor(8.4062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  258.0
	 epoch  40 training error:  tensor(8.5425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  256.0
	 epoch  50 training error:  tensor(8.7855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  256.0
	 epoch  60 training error:  tensor(8.8120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  248.0
	 epoch  70 training error:  tensor(8.9047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  246.0
	 epoch  80 training error:  tensor(8.6865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  250.0
	 epoch  90 training error:  tensor(8.7341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.64111328125
Memory cached:  248.0
[I 2023-11-29 01:19:50,586] Trial 47 finished with value: 7.447071075439453 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.2367027958562715, 'log_learning_rate_D': -2.0785504566850572, 'log_learning_rate_D_dagger': -1.2225994546867094, 'training_batch_size': 7, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  287.9933216571808
Memory status after this trial: 
Memory allocated:  169.52001953125
Memory cached:  192.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.4486781804134459, 'log_learning_rate_D': -1.4882735281110557, 'log_learning_rate_D_dagger': -1.0033789648109868, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  166.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  274.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  274.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  266.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  280.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  272.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  268.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  272.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  272.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.11865234375
Memory cached:  276.0
[I 2023-11-29 01:25:07,508] Trial 48 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.4486781804134459, 'log_learning_rate_D': -1.4882735281110557, 'log_learning_rate_D_dagger': -1.0033789648109868, 'training_batch_size': 8, 'training_p': 8}. Best is trial 6 with value: 1.0.
Time for this trial:  316.6307144165039
Memory status after this trial: 
Memory allocated:  179.744140625
Memory cached:  192.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.7885591459233492, 'log_learning_rate_D': -1.2006474350732443, 'log_learning_rate_D_dagger': -1.3665625414003244, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  162.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  276.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  280.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  266.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  284.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  278.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  278.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  290.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  280.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.01318359375
Memory cached:  272.0
[I 2023-11-29 01:30:04,943] Trial 49 finished with value: 1.4816464185714722 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.7885591459233492, 'log_learning_rate_D': -1.2006474350732443, 'log_learning_rate_D_dagger': -1.3665625414003244, 'training_batch_size': 7, 'training_p': 7}. Best is trial 6 with value: 1.0.
[I 2023-11-29 01:30:04,989] A new study created in memory with name: no-name-fa97673e-9ebb-4779-8027-9fb8a7022a3c
Time for this trial:  297.1673958301544
Memory status after this trial: 
Memory allocated:  227.0048828125
Memory cached:  232.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.8846829753544587, 'log_learning_rate_D': -1.1958979535734917, 'log_learning_rate_D_dagger': -1.0532971063419394, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(15.8737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  140.0
	 epoch  10 training error:  tensor(38.7142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  228.0
	 epoch  20 training error:  tensor(50.8224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  230.0
	 epoch  30 training error:  tensor(48.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  228.0
	 epoch  40 training error:  tensor(45.6216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  230.0
	 epoch  50 training error:  tensor(42.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  228.0
	 epoch  60 training error:  tensor(44.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  230.0
	 epoch  70 training error:  tensor(43.6913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  230.0
	 epoch  80 training error:  tensor(38.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  238.0
	 epoch  90 training error:  tensor(36.4152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.94140625
Memory cached:  226.0
[I 2023-11-29 01:34:34,031] Trial 0 finished with value: 37.51882553100586 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.8846829753544587, 'log_learning_rate_D': -1.1958979535734917, 'log_learning_rate_D_dagger': -1.0532971063419394, 'training_batch_size': 12, 'training_p': 5}. Best is trial 0 with value: 37.51882553100586.
Time for this trial:  268.9215569496155
Memory status after this trial: 
Memory allocated:  124.685546875
Memory cached:  170.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.0663537453240024, 'log_learning_rate_D': -1.0324643097558601, 'log_learning_rate_D_dagger': -3.289500336404264, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.9560546875
Memory cached:  222.0
[W 2023-11-29 01:34:44,729] Trial 1 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.0663537453240024, 'log_learning_rate_D': -1.0324643097558601, 'log_learning_rate_D_dagger': -3.289500336404264, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-11-29 01:34:44,730] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  10.532757043838501
Memory status after this trial: 
Memory allocated:  359.48583984375
Memory cached:  378.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -4.963848628054684, 'log_learning_rate_D': -1.197831463212844, 'log_learning_rate_D_dagger': -2.9973934788818073, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(5.7489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.05029296875
Memory cached:  162.0
[W 2023-11-29 01:34:53,217] Trial 2 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -4.963848628054684, 'log_learning_rate_D': -1.197831463212844, 'log_learning_rate_D_dagger': -2.9973934788818073, 'training_batch_size': 12, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-11-29 01:34:53,218] Trial 2 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.325919151306152
Memory status after this trial: 
Memory allocated:  273.78125
Memory cached:  284.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.651104301961458, 'log_learning_rate_D': -4.062123785819333, 'log_learning_rate_D_dagger': -4.353261928211583, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(3.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  152.0
	 epoch  10 training error:  tensor(2.6800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  276.0
	 epoch  20 training error:  tensor(2.1629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  270.0
	 epoch  30 training error:  tensor(2.2981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  280.0
	 epoch  40 training error:  tensor(2.2941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  284.0
	 epoch  50 training error:  tensor(2.4915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  278.0
	 epoch  60 training error:  tensor(2.4825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  272.0
	 epoch  70 training error:  tensor(2.4936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  276.0
	 epoch  80 training error:  tensor(2.4881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  278.0
	 epoch  90 training error:  tensor(2.5463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.64453125
Memory cached:  286.0
[I 2023-11-29 01:40:29,510] Trial 3 finished with value: 2.044386625289917 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.651104301961458, 'log_learning_rate_D': -4.062123785819333, 'log_learning_rate_D_dagger': -4.353261928211583, 'training_batch_size': 11, 'training_p': 8}. Best is trial 3 with value: 2.044386625289917.
Time for this trial:  336.1266186237335
Memory status after this trial: 
Memory allocated:  219.3310546875
Memory cached:  226.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -2.54188895570736, 'log_learning_rate_D': -2.4531803161593086, 'log_learning_rate_D_dagger': -3.5663304360301913, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(9.3668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  180.0
	 epoch  10 training error:  tensor(7.0311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  338.0
	 epoch  20 training error:  tensor(7.1387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  358.0
	 epoch  30 training error:  tensor(7.2215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  356.0
	 epoch  40 training error:  tensor(7.4446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  352.0
	 epoch  50 training error:  tensor(7.6300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  338.0
	 epoch  60 training error:  tensor(7.2161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  344.0
	 epoch  70 training error:  tensor(7.5441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  350.0
	 epoch  80 training error:  tensor(7.4298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  352.0
	 epoch  90 training error:  tensor(7.3505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.91357421875
Memory cached:  340.0
[I 2023-11-29 01:47:43,299] Trial 4 finished with value: 9.103761672973633 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -2.54188895570736, 'log_learning_rate_D': -2.4531803161593086, 'log_learning_rate_D_dagger': -3.5663304360301913, 'training_batch_size': 11, 'training_p': 5}. Best is trial 3 with value: 2.044386625289917.
Time for this trial:  433.6090052127838
Memory status after this trial: 
Memory allocated:  413.41015625
Memory cached:  436.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.472194197232751, 'log_learning_rate_D': -3.2664092752766627, 'log_learning_rate_D_dagger': -3.2643705410954533, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(4.1630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  190.0
	 epoch  10 training error:  tensor(6.8543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  370.0
	 epoch  20 training error:  tensor(7.4777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  346.0
	 epoch  30 training error:  tensor(5.4946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  354.0
	 epoch  40 training error:  tensor(4.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  344.0
	 epoch  50 training error:  tensor(3.9555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  358.0
	 epoch  60 training error:  tensor(5.0536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  360.0
	 epoch  70 training error:  tensor(4.8999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  350.0
	 epoch  80 training error:  tensor(4.8017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  348.0
	 epoch  90 training error:  tensor(4.6677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.12646484375
Memory cached:  346.0
[I 2023-11-29 01:53:15,628] Trial 5 finished with value: 5.741950035095215 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.472194197232751, 'log_learning_rate_D': -3.2664092752766627, 'log_learning_rate_D_dagger': -3.2643705410954533, 'training_batch_size': 10, 'training_p': 4}. Best is trial 3 with value: 2.044386625289917.
Time for this trial:  332.1046578884125
Memory status after this trial: 
Memory allocated:  295.7314453125
Memory cached:  308.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.157518950603288, 'log_learning_rate_D': -2.8371855697601696, 'log_learning_rate_D_dagger': -3.61559856293953, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  190.0
	 epoch  10 training error:  tensor(1.2329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  368.0
	 epoch  20 training error:  tensor(1.5396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  368.0
	 epoch  30 training error:  tensor(1.5195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  358.0
	 epoch  40 training error:  tensor(1.4198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  362.0
	 epoch  50 training error:  tensor(1.4731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  356.0
	 epoch  60 training error:  tensor(1.5516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  370.0
	 epoch  70 training error:  tensor(1.5118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  362.0
	 epoch  80 training error:  tensor(1.6304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  370.0
	 epoch  90 training error:  tensor(1.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.29541015625
Memory cached:  362.0
[I 2023-11-29 01:59:19,353] Trial 6 finished with value: 1.6440120935440063 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.157518950603288, 'log_learning_rate_D': -2.8371855697601696, 'log_learning_rate_D_dagger': -3.61559856293953, 'training_batch_size': 12, 'training_p': 2}. Best is trial 6 with value: 1.6440120935440063.
Time for this trial:  363.53679060935974
Memory status after this trial: 
Memory allocated:  320.28125
Memory cached:  342.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.604555479577895, 'log_learning_rate_D': -2.569838833589964, 'log_learning_rate_D_dagger': -3.275123912552055, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(32.4273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  188.0
	 epoch  10 training error:  tensor(5.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  354.0
	 epoch  20 training error:  tensor(9.9207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  352.0
	 epoch  30 training error:  tensor(7.5012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  368.0
	 epoch  40 training error:  tensor(6.2294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  358.0
	 epoch  50 training error:  tensor(5.0439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  358.0
	 epoch  60 training error:  tensor(4.8707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  352.0
	 epoch  70 training error:  tensor(4.4143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  346.0
	 epoch  80 training error:  tensor(3.9660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  344.0
	 epoch  90 training error:  tensor(3.8412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.56884765625
Memory cached:  360.0
[I 2023-11-29 02:05:31,622] Trial 7 finished with value: 4.179859161376953 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.604555479577895, 'log_learning_rate_D': -2.569838833589964, 'log_learning_rate_D_dagger': -3.275123912552055, 'training_batch_size': 10, 'training_p': 4}. Best is trial 6 with value: 1.6440120935440063.
Time for this trial:  372.0799787044525
Memory status after this trial: 
Memory allocated:  378.67626953125
Memory cached:  400.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.125898116557682, 'log_learning_rate_D': -3.732113022757302, 'log_learning_rate_D_dagger': -1.09611106904201, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  138.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  208.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  210.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  202.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  196.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  204.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  208.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  204.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  214.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5478515625
Memory cached:  214.0
[I 2023-11-29 02:09:00,925] Trial 8 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.125898116557682, 'log_learning_rate_D': -3.732113022757302, 'log_learning_rate_D_dagger': -1.09611106904201, 'training_batch_size': 8, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  209.11341953277588
Memory status after this trial: 
Memory allocated:  106.41259765625
Memory cached:  152.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.5094056117357013, 'log_learning_rate_D': -1.899646803033686, 'log_learning_rate_D_dagger': -4.1493571526826, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(23.2288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  170.0
	 epoch  10 training error:  tensor(24.8504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  280.0
	 epoch  20 training error:  tensor(24.4879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  266.0
	 epoch  30 training error:  tensor(31.1153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  282.0
	 epoch  40 training error:  tensor(33.3519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  278.0
	 epoch  50 training error:  tensor(26.9882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  288.0
	 epoch  60 training error:  tensor(24.7763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  274.0
	 epoch  70 training error:  tensor(27.1672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  282.0
	 epoch  80 training error:  tensor(24.8188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  284.0
	 epoch  90 training error:  tensor(23.8110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.85546875
Memory cached:  268.0
[I 2023-11-29 02:18:53,423] Trial 9 finished with value: 18.27512550354004 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.5094056117357013, 'log_learning_rate_D': -1.899646803033686, 'log_learning_rate_D_dagger': -4.1493571526826, 'training_batch_size': 6, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  592.3019104003906
Memory status after this trial: 
Memory allocated:  268.57861328125
Memory cached:  274.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.7349278410343176, 'log_learning_rate_D': -2.7563071335275464, 'log_learning_rate_D_dagger': -2.4524372917261963, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(2.7396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  180.0
	 epoch  10 training error:  tensor(1.8757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  350.0
	 epoch  20 training error:  tensor(1.6712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  340.0
	 epoch  30 training error:  tensor(1.4621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  350.0
	 epoch  40 training error:  tensor(5.9826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  348.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  350.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  344.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  348.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  362.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.4296875
Memory cached:  366.0
[I 2023-11-29 02:24:12,108] Trial 10 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.7349278410343176, 'log_learning_rate_D': -2.7563071335275464, 'log_learning_rate_D_dagger': -2.4524372917261963, 'training_batch_size': 12, 'training_p': 8}. Best is trial 8 with value: 1.0.
Time for this trial:  318.46569061279297
Memory status after this trial: 
Memory allocated:  288.5185546875
Memory cached:  306.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.3361815166895843, 'log_learning_rate_D': -3.036826306847239, 'log_learning_rate_D_dagger': -4.843586881339, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(2.1486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  126.0
	 epoch  10 training error:  tensor(1.9157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  208.0
	 epoch  20 training error:  tensor(3.8018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  208.0
	 epoch  30 training error:  tensor(1.9641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  210.0
	 epoch  40 training error:  tensor(1.8792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  202.0
	 epoch  50 training error:  tensor(1.8336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  202.0
	 epoch  60 training error:  tensor(2.3238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  206.0
	 epoch  70 training error:  tensor(1.9433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  206.0
	 epoch  80 training error:  tensor(2.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  208.0
	 epoch  90 training error:  tensor(2.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.20703125
Memory cached:  204.0
[I 2023-11-29 02:32:51,598] Trial 11 finished with value: 1.9252442121505737 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.3361815166895843, 'log_learning_rate_D': -3.036826306847239, 'log_learning_rate_D_dagger': -4.843586881339, 'training_batch_size': 6, 'training_p': 7}. Best is trial 8 with value: 1.0.
Time for this trial:  519.2646210193634
Memory status after this trial: 
Memory allocated:  151.31298828125
Memory cached:  176.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.0378434282746642, 'log_learning_rate_D': -4.947357353103511, 'log_learning_rate_D_dagger': -1.1045885080279019, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  168.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  244.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  242.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  240.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  234.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  236.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  250.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  232.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  238.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.50390625
Memory cached:  254.0
[I 2023-11-29 02:36:27,114] Trial 12 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.0378434282746642, 'log_learning_rate_D': -4.947357353103511, 'log_learning_rate_D_dagger': -1.1045885080279019, 'training_batch_size': 8, 'training_p': 2}. Best is trial 8 with value: 1.0.
Time for this trial:  215.28030586242676
Memory status after this trial: 
Memory allocated:  161.9462890625
Memory cached:  178.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -4.536012554382593, 'log_learning_rate_D': -3.7032853169623685, 'log_learning_rate_D_dagger': -2.0018478668805653, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(2.1017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  154.0
	 epoch  10 training error:  tensor(1.9499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  298.0
	 epoch  20 training error:  tensor(2.4461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  304.0
	 epoch  30 training error:  tensor(4.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  294.0
	 epoch  40 training error:  tensor(4.4056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  288.0
	 epoch  50 training error:  tensor(5.4359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  308.0
	 epoch  60 training error:  tensor(4.3750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  296.0
	 epoch  70 training error:  tensor(3.1756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  308.0
	 epoch  80 training error:  tensor(2.9569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  320.0
	 epoch  90 training error:  tensor(3.9542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.12744140625
Memory cached:  304.0
[I 2023-11-29 02:41:25,666] Trial 13 finished with value: 3.6972413063049316 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -4.536012554382593, 'log_learning_rate_D': -3.7032853169623685, 'log_learning_rate_D_dagger': -2.0018478668805653, 'training_batch_size': 8, 'training_p': 8}. Best is trial 8 with value: 1.0.
Time for this trial:  298.3189356327057
Memory status after this trial: 
Memory allocated:  246.62255859375
Memory cached:  252.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.1185465748186045, 'log_learning_rate_D': -3.9608154409903165, 'log_learning_rate_D_dagger': -2.3585996028050094, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(6.5279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  158.0
	 epoch  10 training error:  tensor(4.1995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  294.0
	 epoch  20 training error:  tensor(3.8270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  306.0
	 epoch  30 training error:  tensor(3.0143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  314.0
	 epoch  40 training error:  tensor(18.1218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  312.0
	 epoch  50 training error:  tensor(9.7826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  302.0
	 epoch  60 training error:  tensor(8.3108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  288.0
	 epoch  70 training error:  tensor(9.0105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  292.0
	 epoch  80 training error:  tensor(9.0930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  294.0
	 epoch  90 training error:  tensor(9.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.52685546875
Memory cached:  308.0
[I 2023-11-29 02:46:16,938] Trial 14 finished with value: 6.6554083824157715 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.1185465748186045, 'log_learning_rate_D': -3.9608154409903165, 'log_learning_rate_D_dagger': -2.3585996028050094, 'training_batch_size': 8, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  291.0100932121277
Memory status after this trial: 
Memory allocated:  205.345703125
Memory cached:  220.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.9422140284767293, 'log_learning_rate_D': -3.5096036417694956, 'log_learning_rate_D_dagger': -2.3991122920458965, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(2.8044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  138.0
	 epoch  10 training error:  tensor(1.3803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  190.0
	 epoch  20 training error:  tensor(1.0937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  194.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  196.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  200.0
	 epoch  50 training error:  tensor(1.2721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  192.0
	 epoch  60 training error:  tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  196.0
	 epoch  70 training error:  tensor(1.0391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  190.0
	 epoch  80 training error:  tensor(1.0356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  192.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  200.0
[I 2023-11-29 02:50:08,876] Trial 15 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.9422140284767293, 'log_learning_rate_D': -3.5096036417694956, 'log_learning_rate_D_dagger': -2.3991122920458965, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  231.6944136619568
Memory status after this trial: 
Memory allocated:  102.14599609375
Memory cached:  146.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.943353910827423, 'log_learning_rate_D': -4.458649398576164, 'log_learning_rate_D_dagger': -1.6282147235453368, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(3.2085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  168.0
	 epoch  10 training error:  tensor(16.6789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  330.0
	 epoch  20 training error:  tensor(14.7099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  342.0
	 epoch  30 training error:  tensor(15.7183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  352.0
	 epoch  40 training error:  tensor(13.0912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  358.0
	 epoch  50 training error:  tensor(11.2720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  342.0
	 epoch  60 training error:  tensor(9.5389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  350.0
	 epoch  70 training error:  tensor(8.8450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  350.0
	 epoch  80 training error:  tensor(8.0324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  352.0
	 epoch  90 training error:  tensor(6.9137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.9287109375
Memory cached:  350.0
[I 2023-11-29 02:55:30,771] Trial 16 finished with value: 4.610215663909912 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.943353910827423, 'log_learning_rate_D': -4.458649398576164, 'log_learning_rate_D_dagger': -1.6282147235453368, 'training_batch_size': 7, 'training_p': 7}. Best is trial 8 with value: 1.0.
Time for this trial:  321.64826107025146
Memory status after this trial: 
Memory allocated:  309.45068359375
Memory cached:  328.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -3.2329986600728686, 'log_learning_rate_D': -3.3711571016593784, 'log_learning_rate_D_dagger': -2.7189830922822047, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  140.0
	 epoch  10 training error:  tensor(2.8916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  210.0
	 epoch  20 training error:  tensor(2.6799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  210.0
	 epoch  30 training error:  tensor(2.8624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  218.0
	 epoch  40 training error:  tensor(2.6092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  212.0
	 epoch  50 training error:  tensor(2.8611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  216.0
	 epoch  60 training error:  tensor(2.7137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  210.0
	 epoch  70 training error:  tensor(2.4717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  210.0
	 epoch  80 training error:  tensor(2.5167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  210.0
	 epoch  90 training error:  tensor(2.7273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.57958984375
Memory cached:  208.0
[I 2023-11-29 02:59:43,746] Trial 17 finished with value: 2.6262314319610596 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -3.2329986600728686, 'log_learning_rate_D': -3.3711571016593784, 'log_learning_rate_D_dagger': -2.7189830922822047, 'training_batch_size': 9, 'training_p': 3}. Best is trial 8 with value: 1.0.
Time for this trial:  252.73007726669312
Memory status after this trial: 
Memory allocated:  112.03515625
Memory cached:  154.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.8992475353558453, 'log_learning_rate_D': -2.123873648869418, 'log_learning_rate_D_dagger': -1.6292999895783202, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.7331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  150.0
	 epoch  10 training error:  tensor(2.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  252.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  242.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  250.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  236.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  252.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  260.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  260.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  252.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  244.0
[I 2023-11-29 03:03:33,869] Trial 18 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.8992475353558453, 'log_learning_rate_D': -2.123873648869418, 'log_learning_rate_D_dagger': -1.6292999895783202, 'training_batch_size': 7, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  229.89560556411743
Memory status after this trial: 
Memory allocated:  160.24365234375
Memory cached:  182.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.878769729030956, 'log_learning_rate_D': -2.9767760276199757, 'log_learning_rate_D_dagger': -2.706673941716582, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(2.7567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  102.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  130.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  126.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  130.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  140.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  130.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  130.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  128.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  128.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56005859375
Memory cached:  130.0
[I 2023-11-29 03:07:39,102] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.878769729030956, 'log_learning_rate_D': -2.9767760276199757, 'log_learning_rate_D_dagger': -2.706673941716582, 'training_batch_size': 10, 'training_p': 7}. Best is trial 8 with value: 1.0.
Time for this trial:  244.99319911003113
Memory status after this trial: 
Memory allocated:  51.35107421875
Memory cached:  108.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.2201264972851686, 'log_learning_rate_D': -3.6728033113969567, 'log_learning_rate_D_dagger': -1.62524652230839, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(8.3478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  180.0
	 epoch  10 training error:  tensor(3.2900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  296.0
	 epoch  20 training error:  tensor(2.0188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  286.0
	 epoch  30 training error:  tensor(1.5927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  298.0
	 epoch  40 training error:  tensor(11.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  306.0
	 epoch  50 training error:  tensor(14.3883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  296.0
	 epoch  60 training error:  tensor(15.6341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  300.0
	 epoch  70 training error:  tensor(14.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  298.0
	 epoch  80 training error:  tensor(14.2170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  294.0
	 epoch  90 training error:  tensor(13.8749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.99365234375
Memory cached:  292.0
[I 2023-11-29 03:12:27,188] Trial 20 finished with value: 14.7479887008667 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.2201264972851686, 'log_learning_rate_D': -3.6728033113969567, 'log_learning_rate_D_dagger': -1.62524652230839, 'training_batch_size': 11, 'training_p': 3}. Best is trial 8 with value: 1.0.
Time for this trial:  287.8390164375305
Memory status after this trial: 
Memory allocated:  182.55126953125
Memory cached:  234.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -3.65297456457057, 'log_learning_rate_D': -4.1763557239199915, 'log_learning_rate_D_dagger': -1.9979507174759283, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.5347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  128.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  208.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  220.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  214.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  210.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  220.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  216.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  222.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  212.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.4287109375
Memory cached:  222.0
[I 2023-11-29 03:15:59,198] Trial 21 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -3.65297456457057, 'log_learning_rate_D': -4.1763557239199915, 'log_learning_rate_D_dagger': -1.9979507174759283, 'training_batch_size': 7, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  211.7800953388214
Memory status after this trial: 
Memory allocated:  122.4267578125
Memory cached:  172.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.187328769202453, 'log_learning_rate_D': -3.197346889991975, 'log_learning_rate_D_dagger': -1.325193203916345, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(4.4203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  174.0
	 epoch  10 training error:  tensor(2.5624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  384.0
	 epoch  20 training error:  tensor(3.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  378.0
	 epoch  30 training error:  tensor(3.3759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  364.0
	 epoch  40 training error:  tensor(3.3784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  364.0
	 epoch  50 training error:  tensor(3.4656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  372.0
	 epoch  60 training error:  tensor(3.4181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  366.0
	 epoch  70 training error:  tensor(3.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  360.0
	 epoch  80 training error:  tensor(3.3740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  378.0
	 epoch  90 training error:  tensor(3.4319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.80419921875
Memory cached:  376.0
[I 2023-11-29 03:21:34,119] Trial 22 finished with value: 3.396843671798706 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.187328769202453, 'log_learning_rate_D': -3.197346889991975, 'log_learning_rate_D_dagger': -1.325193203916345, 'training_batch_size': 9, 'training_p': 8}. Best is trial 8 with value: 1.0.
Time for this trial:  334.6756067276001
Memory status after this trial: 
Memory allocated:  313.57080078125
Memory cached:  340.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.2375792634487222, 'log_learning_rate_D': -4.861187947369759, 'log_learning_rate_D_dagger': -1.0292255181360783, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  188.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  300.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  310.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  306.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  304.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  300.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  314.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  304.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  310.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.5732421875
Memory cached:  308.0
[I 2023-11-29 03:25:46,786] Trial 23 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.2375792634487222, 'log_learning_rate_D': -4.861187947369759, 'log_learning_rate_D_dagger': -1.0292255181360783, 'training_batch_size': 8, 'training_p': 2}. Best is trial 8 with value: 1.0.
Time for this trial:  252.42140769958496
Memory status after this trial: 
Memory allocated:  235.3212890625
Memory cached:  254.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.3844119324898756, 'log_learning_rate_D': -4.975661869665564, 'log_learning_rate_D_dagger': -1.0014613273944208, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  126.0
	 epoch  10 training error:  tensor(1.4429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  218.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  214.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  216.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  214.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  214.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  216.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  216.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  212.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.359375
Memory cached:  214.0
[I 2023-11-29 03:29:18,671] Trial 24 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.3844119324898756, 'log_learning_rate_D': -4.975661869665564, 'log_learning_rate_D_dagger': -1.0014613273944208, 'training_batch_size': 8, 'training_p': 3}. Best is trial 8 with value: 1.0.
Time for this trial:  211.65002465248108
Memory status after this trial: 
Memory allocated:  126.09716796875
Memory cached:  154.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -1.0128136584726675, 'log_learning_rate_D': -4.548843863433613, 'log_learning_rate_D_dagger': -1.3886057113585035, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(2.2067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  172.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  316.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  336.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  316.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  328.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  316.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  326.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  326.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  328.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.177734375
Memory cached:  340.0
[I 2023-11-29 03:34:02,360] Trial 25 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -1.0128136584726675, 'log_learning_rate_D': -4.548843863433613, 'log_learning_rate_D_dagger': -1.3886057113585035, 'training_batch_size': 7, 'training_p': 2}. Best is trial 8 with value: 1.0.
Time for this trial:  283.4519839286804
Memory status after this trial: 
Memory allocated:  248.08544921875
Memory cached:  264.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -1.7742520812439442, 'log_learning_rate_D': -4.481374461593001, 'log_learning_rate_D_dagger': -1.9625231357242905, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  138.0
	 epoch  10 training error:  tensor(1.4281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  210.0
	 epoch  20 training error:  tensor(2.8214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  208.0
	 epoch  30 training error:  tensor(3.2701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  204.0
	 epoch  40 training error:  tensor(3.2791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  212.0
	 epoch  50 training error:  tensor(3.4003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  206.0
	 epoch  60 training error:  tensor(3.4583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  192.0
	 epoch  70 training error:  tensor(3.4901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  210.0
	 epoch  80 training error:  tensor(3.4455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  204.0
	 epoch  90 training error:  tensor(3.5294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9541015625
Memory cached:  210.0
[I 2023-11-29 03:38:30,793] Trial 26 finished with value: 2.294699192047119 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -1.7742520812439442, 'log_learning_rate_D': -4.481374461593001, 'log_learning_rate_D_dagger': -1.9625231357242905, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  268.1905846595764
Memory status after this trial: 
Memory allocated:  111.79833984375
Memory cached:  154.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.9334790980235241, 'log_learning_rate_D': -3.74793138825393, 'log_learning_rate_D_dagger': -1.4040345516265231, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(12.6334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  164.0
	 epoch  10 training error:  tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  290.0
	 epoch  20 training error:  tensor(1.2108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  286.0
	 epoch  30 training error:  tensor(1.4688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  304.0
	 epoch  40 training error:  tensor(1.1795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  284.0
	 epoch  50 training error:  tensor(5.7180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  294.0
	 epoch  60 training error:  tensor(6.3358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  288.0
	 epoch  70 training error:  tensor(4.4505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  284.0
	 epoch  80 training error:  tensor(5.2081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  282.0
	 epoch  90 training error:  tensor(4.8064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.84814453125
Memory cached:  292.0
[I 2023-11-29 03:43:53,361] Trial 27 finished with value: 3.9023079872131348 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.9334790980235241, 'log_learning_rate_D': -3.74793138825393, 'log_learning_rate_D_dagger': -1.4040345516265231, 'training_batch_size': 8, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  322.3083143234253
Memory status after this trial: 
Memory allocated:  209.421875
Memory cached:  214.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.611340682866027, 'log_learning_rate_D': -4.1101880154750825, 'log_learning_rate_D_dagger': -1.846068392358411, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.9668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  78.0
	 epoch  10 training error:  tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  96.0
	 epoch  20 training error:  tensor(1.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  102.0
	 epoch  30 training error:  tensor(1.0245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  100.0
	 epoch  40 training error:  tensor(1.0127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  98.0
	 epoch  50 training error:  tensor(1.0251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  96.0
	 epoch  60 training error:  tensor(1.0077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  100.0
	 epoch  70 training error:  tensor(1.0158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  96.0
	 epoch  80 training error:  tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  96.0
	 epoch  90 training error:  tensor(1.0161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.96337890625
Memory cached:  92.0
[I 2023-11-29 03:47:01,055] Trial 28 finished with value: 1.0035673379898071 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.611340682866027, 'log_learning_rate_D': -4.1101880154750825, 'log_learning_rate_D_dagger': -1.846068392358411, 'training_batch_size': 9, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  187.46309304237366
Memory status after this trial: 
Memory allocated:  42.291015625
Memory cached:  78.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.0348390136955823, 'log_learning_rate_D': -4.732944343079753, 'log_learning_rate_D_dagger': -2.31827819777756, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(6.1655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  126.0
	 epoch  10 training error:  tensor(3.0807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  180.0
	 epoch  20 training error:  tensor(2.3115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  176.0
	 epoch  30 training error:  tensor(3.2318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  176.0
	 epoch  40 training error:  tensor(2.8810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  188.0
	 epoch  50 training error:  tensor(2.7072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  184.0
	 epoch  60 training error:  tensor(2.5610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  188.0
	 epoch  70 training error:  tensor(2.7324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  184.0
	 epoch  80 training error:  tensor(2.8154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  174.0
	 epoch  90 training error:  tensor(2.7872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.603515625
Memory cached:  182.0
[I 2023-11-29 03:51:25,781] Trial 29 finished with value: 1.6953295469284058 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.0348390136955823, 'log_learning_rate_D': -4.732944343079753, 'log_learning_rate_D_dagger': -2.31827819777756, 'training_batch_size': 10, 'training_p': 7}. Best is trial 8 with value: 1.0.
Time for this trial:  264.4868426322937
Memory status after this trial: 
Memory allocated:  95.98046875
Memory cached:  138.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.6661710082475194, 'log_learning_rate_D': -4.2628026161740085, 'log_learning_rate_D_dagger': -1.2699067337703613, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  152.0
	 epoch  10 training error:  tensor(1.6830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  240.0
	 epoch  20 training error:  tensor(1.5934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  236.0
	 epoch  30 training error:  tensor(1.1662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  238.0
	 epoch  40 training error:  tensor(1.2702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  242.0
	 epoch  50 training error:  tensor(1.1786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  228.0
	 epoch  60 training error:  tensor(1.2068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  240.0
	 epoch  70 training error:  tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  238.0
	 epoch  80 training error:  tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  238.0
	 epoch  90 training error:  tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8076171875
Memory cached:  230.0
[I 2023-11-29 03:54:28,520] Trial 30 finished with value: 1.1000837087631226 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.6661710082475194, 'log_learning_rate_D': -4.2628026161740085, 'log_learning_rate_D_dagger': -1.2699067337703613, 'training_batch_size': 7, 'training_p': 3}. Best is trial 8 with value: 1.0.
Time for this trial:  182.52807879447937
Memory status after this trial: 
Memory allocated:  129.65283203125
Memory cached:  184.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.9628980125548257, 'log_learning_rate_D': -4.693585742618298, 'log_learning_rate_D_dagger': -1.251335095685878, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(14.1755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  144.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  270.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  270.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  274.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  260.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  268.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  268.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  274.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  262.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5
Memory cached:  266.0
[I 2023-11-29 03:59:01,237] Trial 31 finished with value: 8.836609840393066 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.9628980125548257, 'log_learning_rate_D': -4.693585742618298, 'log_learning_rate_D_dagger': -1.251335095685878, 'training_batch_size': 12, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  272.4945013523102
Memory status after this trial: 
Memory allocated:  162.17041015625
Memory cached:  206.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.3327714667707053, 'log_learning_rate_D': -3.8734576803159886, 'log_learning_rate_D_dagger': -1.023067391075536, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.8799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  204.0
	 epoch  10 training error:  tensor(32.5556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  302.0
	 epoch  20 training error:  tensor(59.6750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  306.0
	 epoch  30 training error:  tensor(62.0180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  318.0
	 epoch  40 training error:  tensor(63.8789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  318.0
	 epoch  50 training error:  tensor(63.4335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  318.0
	 epoch  60 training error:  tensor(60.7263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  314.0
	 epoch  70 training error:  tensor(72.2032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  312.0
	 epoch  80 training error:  tensor(64.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  324.0
	 epoch  90 training error:  tensor(64.6002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.080078125
Memory cached:  318.0
[I 2023-11-29 04:09:48,420] Trial 32 finished with value: 78.88162231445312 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.3327714667707053, 'log_learning_rate_D': -3.8734576803159886, 'log_learning_rate_D_dagger': -1.023067391075536, 'training_batch_size': 6, 'training_p': 2}. Best is trial 8 with value: 1.0.
Time for this trial:  646.8930442333221
Memory status after this trial: 
Memory allocated:  282.5947265625
Memory cached:  296.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.8141774385826706, 'log_learning_rate_D': -3.599822035390482, 'log_learning_rate_D_dagger': -2.253076210552682, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(3.6745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  130.0
	 epoch  10 training error:  tensor(4.6305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  194.0
	 epoch  20 training error:  tensor(5.7889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  188.0
	 epoch  30 training error:  tensor(5.5830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  192.0
	 epoch  40 training error:  tensor(5.9781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  196.0
	 epoch  50 training error:  tensor(5.7894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  196.0
	 epoch  60 training error:  tensor(5.8079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  194.0
	 epoch  70 training error:  tensor(5.2329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  200.0
	 epoch  80 training error:  tensor(5.3894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  192.0
	 epoch  90 training error:  tensor(6.3474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0751953125
Memory cached:  190.0
[I 2023-11-29 04:13:47,170] Trial 33 finished with value: 6.325852394104004 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.8141774385826706, 'log_learning_rate_D': -3.599822035390482, 'log_learning_rate_D_dagger': -2.253076210552682, 'training_batch_size': 8, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  238.49836945533752
Memory status after this trial: 
Memory allocated:  102.14599609375
Memory cached:  154.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.4471931327992364, 'log_learning_rate_D': -3.4820211864093533, 'log_learning_rate_D_dagger': -2.752887644500441, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(7.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  174.0
	 epoch  10 training error:  tensor(6.1041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  316.0
	 epoch  20 training error:  tensor(4.6871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  322.0
	 epoch  30 training error:  tensor(5.1646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  336.0
	 epoch  40 training error:  tensor(5.8208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  308.0
	 epoch  50 training error:  tensor(5.9840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  322.0
	 epoch  60 training error:  tensor(5.8479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  328.0
	 epoch  70 training error:  tensor(5.7963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  312.0
	 epoch  80 training error:  tensor(6.2214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  322.0
	 epoch  90 training error:  tensor(6.0157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.51416015625
Memory cached:  330.0
[I 2023-11-29 04:18:12,321] Trial 34 finished with value: 4.965824127197266 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.4471931327992364, 'log_learning_rate_D': -3.4820211864093533, 'log_learning_rate_D_dagger': -2.752887644500441, 'training_batch_size': 9, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  264.9187285900116
Memory status after this trial: 
Memory allocated:  230.31396484375
Memory cached:  250.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.812998378356313, 'log_learning_rate_D': -3.433165587602618, 'log_learning_rate_D_dagger': -2.4952747481915796, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(5.4910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  188.0
	 epoch  10 training error:  tensor(1.7008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  318.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  320.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  308.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  304.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  308.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  310.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  306.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  316.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.07666015625
Memory cached:  314.0
[I 2023-11-29 04:22:38,217] Trial 35 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.812998378356313, 'log_learning_rate_D': -3.433165587602618, 'log_learning_rate_D_dagger': -2.4952747481915796, 'training_batch_size': 11, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  265.64852643013
Memory status after this trial: 
Memory allocated:  214.42236328125
Memory cached:  250.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -3.1223206381381523, 'log_learning_rate_D': -4.254102422444621, 'log_learning_rate_D_dagger': -2.1650097589814354, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(6.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  140.0
	 epoch  10 training error:  tensor(5.0243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  280.0
	 epoch  20 training error:  tensor(5.2825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  282.0
	 epoch  30 training error:  tensor(6.4855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  278.0
	 epoch  40 training error:  tensor(6.8885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  276.0
	 epoch  50 training error:  tensor(7.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  280.0
	 epoch  60 training error:  tensor(7.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  276.0
	 epoch  70 training error:  tensor(7.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  260.0
	 epoch  80 training error:  tensor(7.0951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  278.0
	 epoch  90 training error:  tensor(7.1849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1513671875
Memory cached:  278.0
[I 2023-11-29 04:26:42,042] Trial 36 finished with value: 4.776010990142822 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -3.1223206381381523, 'log_learning_rate_D': -4.254102422444621, 'log_learning_rate_D_dagger': -2.1650097589814354, 'training_batch_size': 9, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  243.5937898159027
Memory status after this trial: 
Memory allocated:  169.439453125
Memory cached:  210.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.5368483504082517, 'log_learning_rate_D': -3.9576855485915603, 'log_learning_rate_D_dagger': -1.7458256028278991, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(2.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  156.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  246.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  256.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  250.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  262.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  254.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  246.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  258.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  258.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.5654296875
Memory cached:  270.0
[I 2023-11-29 04:30:45,973] Trial 37 finished with value: 1.0049494504928589 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.5368483504082517, 'log_learning_rate_D': -3.9576855485915603, 'log_learning_rate_D_dagger': -1.7458256028278991, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  243.70708537101746
Memory status after this trial: 
Memory allocated:  153.36669921875
Memory cached:  198.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.3465929506613707, 'log_learning_rate_D': -2.790113246199416, 'log_learning_rate_D_dagger': -1.5006174979865912, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(8.4086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  168.0
	 epoch  10 training error:  tensor(5.8304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  296.0
	 epoch  20 training error:  tensor(5.4365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  304.0
	 epoch  30 training error:  tensor(4.3593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  304.0
	 epoch  40 training error:  tensor(4.2773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  300.0
	 epoch  50 training error:  tensor(4.4331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  286.0
	 epoch  60 training error:  tensor(4.4351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  286.0
	 epoch  70 training error:  tensor(4.4514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  302.0
	 epoch  80 training error:  tensor(4.4546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  298.0
	 epoch  90 training error:  tensor(4.6274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.3662109375
Memory cached:  290.0
[I 2023-11-29 04:36:19,806] Trial 38 finished with value: 5.556926727294922 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.3465929506613707, 'log_learning_rate_D': -2.790113246199416, 'log_learning_rate_D_dagger': -1.5006174979865912, 'training_batch_size': 10, 'training_p': 3}. Best is trial 8 with value: 1.0.
Time for this trial:  333.5513150691986
Memory status after this trial: 
Memory allocated:  201.2060546875
Memory cached:  222.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.8736851030057533, 'log_learning_rate_D': -3.1666589544252206, 'log_learning_rate_D_dagger': -1.8380042547275268, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(5.8928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  110.0
	 epoch  10 training error:  tensor(4.2105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  160.0
	 epoch  20 training error:  tensor(2.3300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  166.0
	 epoch  30 training error:  tensor(2.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  162.0
	 epoch  40 training error:  tensor(2.0597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  166.0
	 epoch  50 training error:  tensor(1.9377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  156.0
	 epoch  60 training error:  tensor(1.8134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  160.0
	 epoch  70 training error:  tensor(1.7973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  158.0
	 epoch  80 training error:  tensor(1.8054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  160.0
	 epoch  90 training error:  tensor(1.7631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3203125
Memory cached:  148.0
[I 2023-11-29 04:40:14,953] Trial 39 finished with value: 1.7929489612579346 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.8736851030057533, 'log_learning_rate_D': -3.1666589544252206, 'log_learning_rate_D_dagger': -1.8380042547275268, 'training_batch_size': 8, 'training_p': 5}. Best is trial 8 with value: 1.0.
Time for this trial:  234.89487409591675
Memory status after this trial: 
Memory allocated:  76.634765625
Memory cached:  130.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.7480392699683454, 'log_learning_rate_D': -3.3417305805304274, 'log_learning_rate_D_dagger': -3.0027624006176503, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(11.6861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  148.0
	 epoch  10 training error:  tensor(1.7664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  228.0
	 epoch  20 training error:  tensor(1.8053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  222.0
	 epoch  30 training error:  tensor(1.0987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  218.0
	 epoch  40 training error:  tensor(1.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  234.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  228.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  224.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  224.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  228.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.408203125
Memory cached:  216.0
[I 2023-11-29 04:44:41,506] Trial 40 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.7480392699683454, 'log_learning_rate_D': -3.3417305805304274, 'log_learning_rate_D_dagger': -3.0027624006176503, 'training_batch_size': 12, 'training_p': 4}. Best is trial 8 with value: 1.0.
Time for this trial:  266.3068096637726
Memory status after this trial: 
Memory allocated:  122.4755859375
Memory cached:  164.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.172982069257571, 'log_learning_rate_D': -2.6108211461083926, 'log_learning_rate_D_dagger': -2.1318831194349026, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(32.4528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  190.0
	 epoch  10 training error:  tensor(1.5854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  364.0
	 epoch  20 training error:  tensor(6.9118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  350.0
	 epoch  30 training error:  tensor(4.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  360.0
	 epoch  40 training error:  tensor(2.9828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  342.0
	 epoch  50 training error:  tensor(2.7634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  350.0
	 epoch  60 training error:  tensor(2.3197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  342.0
	 epoch  70 training error:  tensor(4.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  356.0
	 epoch  80 training error:  tensor(2.8951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  346.0
	 epoch  90 training error:  tensor(7.6345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.0732421875
Memory cached:  344.0
[I 2023-11-29 04:50:56,386] Trial 41 finished with value: 3.2610535621643066 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.172982069257571, 'log_learning_rate_D': -2.6108211461083926, 'log_learning_rate_D_dagger': -2.1318831194349026, 'training_batch_size': 10, 'training_p': 8}. Best is trial 8 with value: 1.0.
Time for this trial:  374.5868389606476
Memory status after this trial: 
Memory allocated:  302.919921875
Memory cached:  320.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.5520368520712293, 'log_learning_rate_D': -3.814638223416594, 'log_learning_rate_D_dagger': -1.2244726644057877, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(5.7428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  166.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  322.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  310.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  328.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  310.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  320.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  322.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  324.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  308.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.15283203125
Memory cached:  324.0
[I 2023-11-29 04:55:24,790] Trial 42 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.5520368520712293, 'log_learning_rate_D': -3.814638223416594, 'log_learning_rate_D_dagger': -1.2244726644057877, 'training_batch_size': 9, 'training_p': 2}. Best is trial 8 with value: 1.0.
Time for this trial:  268.11746883392334
Memory status after this trial: 
Memory allocated:  240.73876953125
Memory cached:  260.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.7667899850163895, 'log_learning_rate_D': -2.2478805124415517, 'log_learning_rate_D_dagger': -1.592283870498639, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.7128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  144.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  266.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  240.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  256.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  244.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  254.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  240.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  244.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  234.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.14599609375
Memory cached:  254.0
[I 2023-11-29 04:59:15,056] Trial 43 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.7667899850163895, 'log_learning_rate_D': -2.2478805124415517, 'log_learning_rate_D_dagger': -1.592283870498639, 'training_batch_size': 7, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  230.02774620056152
Memory status after this trial: 
Memory allocated:  160.24365234375
Memory cached:  192.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.992730724133578, 'log_learning_rate_D': -2.206805251719854, 'log_learning_rate_D_dagger': -1.707057336861197, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(2.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  150.0
	 epoch  10 training error:  tensor(2.2709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  252.0
	 epoch  20 training error:  tensor(2.4789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  256.0
	 epoch  30 training error:  tensor(2.4449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  264.0
	 epoch  40 training error:  tensor(3.0244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  246.0
	 epoch  50 training error:  tensor(3.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  250.0
	 epoch  60 training error:  tensor(7.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  256.0
	 epoch  70 training error:  tensor(9.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  250.0
	 epoch  80 training error:  tensor(9.6384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  258.0
	 epoch  90 training error:  tensor(9.5139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.30419921875
Memory cached:  258.0
[I 2023-11-29 05:03:35,175] Trial 44 finished with value: 8.04073715209961 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.992730724133578, 'log_learning_rate_D': -2.206805251719854, 'log_learning_rate_D_dagger': -1.707057336861197, 'training_batch_size': 7, 'training_p': 6}. Best is trial 8 with value: 1.0.
Time for this trial:  259.86754035949707
Memory status after this trial: 
Memory allocated:  174.1650390625
Memory cached:  190.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.437573245339558, 'log_learning_rate_D': -1.7192336634081835, 'log_learning_rate_D_dagger': -1.5278555361782618, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(2.2404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  148.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  260.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  256.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  258.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  248.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  252.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  252.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  262.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  256.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.77001953125
Memory cached:  254.0
[I 2023-11-29 05:07:55,839] Trial 45 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.437573245339558, 'log_learning_rate_D': -1.7192336634081835, 'log_learning_rate_D_dagger': -1.5278555361782618, 'training_batch_size': 8, 'training_p': 7}. Best is trial 8 with value: 1.0.
Time for this trial:  260.4024660587311
Memory status after this trial: 
Memory allocated:  173.193359375
Memory cached:  184.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.5698374634471137, 'log_learning_rate_D': -2.9735415199257007, 'log_learning_rate_D_dagger': -1.1684696320060004, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(2.2358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.42724609375
Memory cached:  174.0
[W 2023-11-29 05:08:01,975] Trial 46 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.5698374634471137, 'log_learning_rate_D': -2.9735415199257007, 'log_learning_rate_D_dagger': -1.1684696320060004, 'training_batch_size': 8, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-11-29 05:08:01,976] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.892653226852417
Memory status after this trial: 
Memory allocated:  187.666015625
Memory cached:  224.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.265299439063742, 'log_learning_rate_D': -3.0044064606143674, 'log_learning_rate_D_dagger': -2.4972059749499422, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(2.1138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  148.0
[W 2023-11-29 05:08:36,446] Trial 47 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.265299439063742, 'log_learning_rate_D': -3.0044064606143674, 'log_learning_rate_D_dagger': -2.4972059749499422, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-11-29 05:08:36,447] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  34.2256646156311
Memory status after this trial: 
Memory allocated:  246.6640625
Memory cached:  262.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.243881782036217, 'log_learning_rate_D': -3.016326257866686, 'log_learning_rate_D_dagger': -1.185630721642971, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(9.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  160.0
	 epoch  10 training error:  tensor(91.6030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  222.0
	 epoch  20 training error:  tensor(105.2967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  222.0
	 epoch  30 training error:  tensor(104.8483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  214.0
	 epoch  40 training error:  tensor(104.4567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  214.0
	 epoch  50 training error:  tensor(104.2727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  198.0
	 epoch  60 training error:  tensor(138.8786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  216.0
	 epoch  70 training error:  tensor(182.6678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  214.0
	 epoch  80 training error:  tensor(209.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  212.0
	 epoch  90 training error:  tensor(109.0188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.5146484375
Memory cached:  220.0
[I 2023-11-29 05:16:29,104] Trial 48 finished with value: 83.78661346435547 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -4.243881782036217, 'log_learning_rate_D': -3.016326257866686, 'log_learning_rate_D_dagger': -1.185630721642971, 'training_batch_size': 6, 'training_p': 8}. Best is trial 8 with value: 1.0.
Time for this trial:  472.4059281349182
Memory status after this trial: 
Memory allocated:  246.6640625
Memory cached:  262.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.636626291698961, 'log_learning_rate_D': -2.7484377162560483, 'log_learning_rate_D_dagger': -1.4583898491914997, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(2.8800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  136.0
	 epoch  10 training error:  tensor(1.8310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  230.0
	 epoch  20 training error:  tensor(2.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  228.0
	 epoch  30 training error:  tensor(1.9861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  232.0
	 epoch  40 training error:  tensor(2.0181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  228.0
	 epoch  50 training error:  tensor(2.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  218.0
	 epoch  60 training error:  tensor(1.9164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  228.0
	 epoch  70 training error:  tensor(2.0903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  238.0
	 epoch  80 training error:  tensor(1.9832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  238.0
	 epoch  90 training error:  tensor(2.1305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.794921875
Memory cached:  232.0
[I 2023-11-29 05:20:31,923] Trial 49 finished with value: 1.8639135360717773 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.636626291698961, 'log_learning_rate_D': -2.7484377162560483, 'log_learning_rate_D_dagger': -1.4583898491914997, 'training_batch_size': 7, 'training_p': 5}. Best is trial 8 with value: 1.0.
[I 2023-11-29 05:20:31,960] A new study created in memory with name: no-name-93175a17-ef26-41e9-a80c-b363429515a0
Time for this trial:  242.5841519832611
Memory status after this trial: 
Memory allocated:  137.11962890625
Memory cached:  168.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.82332501541763, 'log_learning_rate_D': -4.682060040478076, 'log_learning_rate_D_dagger': -2.046706780699102, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  192.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  340.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  336.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  346.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  366.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  354.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  348.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  342.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  350.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2900390625
Memory cached:  356.0
[I 2023-11-29 05:26:23,818] Trial 0 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.82332501541763, 'log_learning_rate_D': -4.682060040478076, 'log_learning_rate_D_dagger': -2.046706780699102, 'training_batch_size': 9, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  351.74052119255066
Memory status after this trial: 
Memory allocated:  336.68115234375
Memory cached:  354.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -3.179729976166505, 'log_learning_rate_D': -1.6367880787480589, 'log_learning_rate_D_dagger': -2.652875406804354, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(12.6564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  160.0
	 epoch  10 training error:  tensor(1.6048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  328.0
	 epoch  20 training error:  tensor(1.7022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  322.0
	 epoch  30 training error:  tensor(1.6175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  336.0
	 epoch  40 training error:  tensor(1.6435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  310.0
	 epoch  50 training error:  tensor(1.6795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  326.0
	 epoch  60 training error:  tensor(1.6877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  310.0
	 epoch  70 training error:  tensor(1.6624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  322.0
	 epoch  80 training error:  tensor(1.6527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  322.0
	 epoch  90 training error:  tensor(1.7273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.21142578125
Memory cached:  310.0
[I 2023-11-29 05:33:20,819] Trial 1 finished with value: 1.6589444875717163 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -3.179729976166505, 'log_learning_rate_D': -1.6367880787480589, 'log_learning_rate_D_dagger': -2.652875406804354, 'training_batch_size': 9, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  416.8097491264343
Memory status after this trial: 
Memory allocated:  275.7236328125
Memory cached:  280.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.0244129561482542, 'log_learning_rate_D': -3.4179083208510948, 'log_learning_rate_D_dagger': -1.6721969054579051, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(5.2350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  186.0
	 epoch  10 training error:  tensor(20.2901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  390.0
	 epoch  20 training error:  tensor(25.1320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  384.0
	 epoch  30 training error:  tensor(23.2955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  392.0
	 epoch  40 training error:  tensor(23.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  396.0
	 epoch  50 training error:  tensor(22.8832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  386.0
	 epoch  60 training error:  tensor(22.8773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  388.0
	 epoch  70 training error:  tensor(22.7707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  394.0
	 epoch  80 training error:  tensor(22.7109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  392.0
	 epoch  90 training error:  tensor(22.6911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.16015625
Memory cached:  398.0
[I 2023-11-29 05:40:22,222] Trial 2 finished with value: 15.262740135192871 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.0244129561482542, 'log_learning_rate_D': -3.4179083208510948, 'log_learning_rate_D_dagger': -1.6721969054579051, 'training_batch_size': 7, 'training_p': 6}. Best is trial 0 with value: 1.0.
Time for this trial:  421.20175218582153
Memory status after this trial: 
Memory allocated:  412.63720703125
Memory cached:  440.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.719256915492412, 'log_learning_rate_D': -4.241029455520068, 'log_learning_rate_D_dagger': -1.9987615439643625, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(2.2022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  136.0
	 epoch  10 training error:  tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  202.0
	 epoch  20 training error:  tensor(1.0301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  200.0
	 epoch  30 training error:  tensor(1.0208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  208.0
	 epoch  40 training error:  tensor(1.1716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  206.0
	 epoch  50 training error:  tensor(1.1913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  206.0
	 epoch  60 training error:  tensor(1.1723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  212.0
	 epoch  70 training error:  tensor(1.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  206.0
	 epoch  80 training error:  tensor(1.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  214.0
	 epoch  90 training error:  tensor(1.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7626953125
Memory cached:  202.0
[I 2023-11-29 05:44:18,171] Trial 3 finished with value: 1.0592539310455322 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.719256915492412, 'log_learning_rate_D': -4.241029455520068, 'log_learning_rate_D_dagger': -1.9987615439643625, 'training_batch_size': 11, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  235.76349234580994
Memory status after this trial: 
Memory allocated:  108.2490234375
Memory cached:  152.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.3018564788988676, 'log_learning_rate_D': -2.610877116139382, 'log_learning_rate_D_dagger': -2.1937994396109204, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  122.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  156.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  164.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  156.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  164.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  162.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  160.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  162.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  162.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.19775390625
Memory cached:  166.0
[I 2023-11-29 05:51:23,341] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.3018564788988676, 'log_learning_rate_D': -2.610877116139382, 'log_learning_rate_D_dagger': -2.1937994396109204, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  425.00543904304504
Memory status after this trial: 
Memory allocated:  90.79443359375
Memory cached:  138.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.631191414274336, 'log_learning_rate_D': -1.5536845727051416, 'log_learning_rate_D_dagger': -2.1289740047144603, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(33.1181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  150.0
	 epoch  10 training error:  tensor(19.3737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  246.0
	 epoch  20 training error:  tensor(20.0132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  240.0
	 epoch  30 training error:  tensor(21.2066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  258.0
	 epoch  40 training error:  tensor(19.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  252.0
	 epoch  50 training error:  tensor(20.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  240.0
	 epoch  60 training error:  tensor(18.7645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  264.0
	 epoch  70 training error:  tensor(21.3864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  250.0
	 epoch  80 training error:  tensor(20.2598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  248.0
	 epoch  90 training error:  tensor(19.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.55419921875
Memory cached:  248.0
[I 2023-11-29 05:55:45,833] Trial 5 finished with value: 13.300311088562012 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.631191414274336, 'log_learning_rate_D': -1.5536845727051416, 'log_learning_rate_D_dagger': -2.1289740047144603, 'training_batch_size': 12, 'training_p': 8}. Best is trial 0 with value: 1.0.
Time for this trial:  262.3396236896515
Memory status after this trial: 
Memory allocated:  186.33642578125
Memory cached:  206.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.0044699899784826, 'log_learning_rate_D': -2.341849118961362, 'log_learning_rate_D_dagger': -2.9493003798352735, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.8534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  132.0
	 epoch  10 training error:  tensor(1.7475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  232.0
	 epoch  20 training error:  tensor(1.3179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  220.0
	 epoch  30 training error:  tensor(1.2781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  228.0
	 epoch  40 training error:  tensor(1.9276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  228.0
	 epoch  50 training error:  tensor(1.6256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  236.0
	 epoch  60 training error:  tensor(1.7098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  234.0
	 epoch  70 training error:  tensor(1.7914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  232.0
	 epoch  80 training error:  tensor(1.8120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  236.0
	 epoch  90 training error:  tensor(1.7740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28564453125
Memory cached:  220.0
[I 2023-11-29 05:59:58,619] Trial 6 finished with value: 1.5662881135940552 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.0044699899784826, 'log_learning_rate_D': -2.341849118961362, 'log_learning_rate_D_dagger': -2.9493003798352735, 'training_batch_size': 8, 'training_p': 7}. Best is trial 0 with value: 1.0.
Time for this trial:  252.61626887321472
Memory status after this trial: 
Memory allocated:  124.1630859375
Memory cached:  166.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.340399020732585, 'log_learning_rate_D': -3.818339360757916, 'log_learning_rate_D_dagger': -3.296015413181175, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  162.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  286.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  294.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  290.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  280.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  286.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  302.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  286.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  302.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.70166015625
Memory cached:  300.0
[I 2023-11-29 06:04:22,587] Trial 7 finished with value: 1.0406692028045654 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.340399020732585, 'log_learning_rate_D': -3.818339360757916, 'log_learning_rate_D_dagger': -3.296015413181175, 'training_batch_size': 12, 'training_p': 7}. Best is trial 0 with value: 1.0.
Time for this trial:  263.81551218032837
Memory status after this trial: 
Memory allocated:  212.8466796875
Memory cached:  230.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.3085413897800127, 'log_learning_rate_D': -1.1221278571484605, 'log_learning_rate_D_dagger': -1.1745975801525215, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.5974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  166.0
	 epoch  10 training error:  tensor(24.3905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  294.0
	 epoch  20 training error:  tensor(14.6057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  280.0
	 epoch  30 training error:  tensor(26.1842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  280.0
	 epoch  40 training error:  tensor(28.1995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  292.0
	 epoch  50 training error:  tensor(30.9573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  294.0
	 epoch  60 training error:  tensor(28.7796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  294.0
	 epoch  70 training error:  tensor(31.9815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  292.0
	 epoch  80 training error:  tensor(30.8226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  294.0
	 epoch  90 training error:  tensor(35.1110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.974609375
Memory cached:  292.0
[I 2023-11-29 06:08:27,163] Trial 8 finished with value: 27.709936141967773 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.3085413897800127, 'log_learning_rate_D': -1.1221278571484605, 'log_learning_rate_D_dagger': -1.1745975801525215, 'training_batch_size': 10, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  244.4273805618286
Memory status after this trial: 
Memory allocated:  178.302734375
Memory cached:  206.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.562734334287513, 'log_learning_rate_D': -1.4526899579495756, 'log_learning_rate_D_dagger': -1.841209844399049, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(2.6598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.8046875
Memory cached:  166.0
[W 2023-11-29 06:08:56,852] Trial 9 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.562734334287513, 'log_learning_rate_D': -1.4526899579495756, 'log_learning_rate_D_dagger': -1.841209844399049, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-11-29 06:08:56,853] Trial 9 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  29.541751384735107
Memory status after this trial: 
Memory allocated:  303.63720703125
Memory cached:  328.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.3025897845981675, 'log_learning_rate_D': -2.4022591867780996, 'log_learning_rate_D_dagger': -2.7904785176413776, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(19.4720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  154.0
	 epoch  10 training error:  tensor(2.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  300.0
	 epoch  20 training error:  tensor(1.7181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  306.0
	 epoch  30 training error:  tensor(1.9248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  294.0
	 epoch  40 training error:  tensor(2.7215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  292.0
	 epoch  50 training error:  tensor(1.7532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  294.0
	 epoch  60 training error:  tensor(1.3996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  284.0
	 epoch  70 training error:  tensor(1.7127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  280.0
	 epoch  80 training error:  tensor(1.5299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  292.0
	 epoch  90 training error:  tensor(1.4168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.32470703125
Memory cached:  286.0
[I 2023-11-29 06:13:47,295] Trial 10 finished with value: 2.6409318447113037 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.3025897845981675, 'log_learning_rate_D': -2.4022591867780996, 'log_learning_rate_D_dagger': -2.7904785176413776, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  290.25785732269287
Memory status after this trial: 
Memory allocated:  189.3798828125
Memory cached:  204.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.046451319852828, 'log_learning_rate_D': -4.9163365415012725, 'log_learning_rate_D_dagger': -4.19014257045728, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(4.2035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  196.0
	 epoch  10 training error:  tensor(2.8202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  374.0
	 epoch  20 training error:  tensor(2.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  372.0
	 epoch  30 training error:  tensor(2.4483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  376.0
	 epoch  40 training error:  tensor(2.2728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  366.0
	 epoch  50 training error:  tensor(2.8713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  370.0
	 epoch  60 training error:  tensor(2.8390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  368.0
	 epoch  70 training error:  tensor(2.6290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  376.0
	 epoch  80 training error:  tensor(2.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  376.0
	 epoch  90 training error:  tensor(2.3595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1005859375
Memory cached:  372.0
[I 2023-11-29 06:19:59,866] Trial 11 finished with value: 3.2449233531951904 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.046451319852828, 'log_learning_rate_D': -4.9163365415012725, 'log_learning_rate_D_dagger': -4.19014257045728, 'training_batch_size': 9, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  372.3112413883209
Memory status after this trial: 
Memory allocated:  495.75634765625
Memory cached:  526.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.5484536394433617, 'log_learning_rate_D': -2.9495350823220883, 'log_learning_rate_D_dagger': -1.4023698806737899, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.5964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  126.0
	 epoch  10 training error:  tensor(3.7808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  224.0
	 epoch  20 training error:  tensor(1.4348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  220.0
	 epoch  30 training error:  tensor(4.3698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  214.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  230.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  218.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  228.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  222.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  228.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  232.0
[I 2023-11-29 06:27:39,021] Trial 12 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.5484536394433617, 'log_learning_rate_D': -2.9495350823220883, 'log_learning_rate_D_dagger': -1.4023698806737899, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  458.9101541042328
Memory status after this trial: 
Memory allocated:  160.37890625
Memory cached:  184.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.94837214520722, 'log_learning_rate_D': -4.977889091198375, 'log_learning_rate_D_dagger': -2.268034607637815, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(9.6550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  154.0
	 epoch  10 training error:  tensor(15.3466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  276.0
	 epoch  20 training error:  tensor(30.7895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  280.0
	 epoch  30 training error:  tensor(31.9656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  270.0
	 epoch  40 training error:  tensor(27.1440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  272.0
	 epoch  50 training error:  tensor(36.0155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  270.0
	 epoch  60 training error:  tensor(27.9125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  270.0
	 epoch  70 training error:  tensor(26.6413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  276.0
	 epoch  80 training error:  tensor(32.7991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  282.0
	 epoch  90 training error:  tensor(30.4879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58935546875
Memory cached:  276.0
[I 2023-11-29 06:35:53,155] Trial 13 finished with value: 23.811233520507812 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.94837214520722, 'log_learning_rate_D': -4.977889091198375, 'log_learning_rate_D_dagger': -2.268034607637815, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  493.87654161453247
Memory status after this trial: 
Memory allocated:  209.7841796875
Memory cached:  216.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.6783396138066293, 'log_learning_rate_D': -3.0671185890036123, 'log_learning_rate_D_dagger': -1.0726094908687904, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(2.1005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  148.0
	 epoch  10 training error:  tensor(10.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  282.0
	 epoch  20 training error:  tensor(17.3590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  292.0
	 epoch  30 training error:  tensor(21.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  304.0
	 epoch  40 training error:  tensor(22.9344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  306.0
	 epoch  50 training error:  tensor(23.4613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  314.0
	 epoch  60 training error:  tensor(24.1771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  292.0
	 epoch  70 training error:  tensor(24.1048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  308.0
	 epoch  80 training error:  tensor(24.1312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  300.0
	 epoch  90 training error:  tensor(23.8967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.275390625
Memory cached:  300.0
[I 2023-11-29 06:41:41,268] Trial 14 finished with value: 20.404943466186523 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.6783396138066293, 'log_learning_rate_D': -3.0671185890036123, 'log_learning_rate_D_dagger': -1.0726094908687904, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  347.8306655883789
Memory status after this trial: 
Memory allocated:  278.49951171875
Memory cached:  284.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.335882927740735, 'log_learning_rate_D': -3.9803384135202484, 'log_learning_rate_D_dagger': -1.776855505006806, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(2.7022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  132.0
	 epoch  10 training error:  tensor(3.3763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  216.0
	 epoch  20 training error:  tensor(3.4445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  218.0
	 epoch  30 training error:  tensor(3.5780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  214.0
	 epoch  40 training error:  tensor(3.8353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  220.0
	 epoch  50 training error:  tensor(3.8342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  222.0
	 epoch  60 training error:  tensor(3.9248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  220.0
	 epoch  70 training error:  tensor(3.8812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  222.0
	 epoch  80 training error:  tensor(3.7879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  212.0
	 epoch  90 training error:  tensor(3.5456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.328125
Memory cached:  214.0
[I 2023-11-29 06:46:11,430] Trial 15 finished with value: 3.869377851486206 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.335882927740735, 'log_learning_rate_D': -3.9803384135202484, 'log_learning_rate_D_dagger': -1.776855505006806, 'training_batch_size': 10, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  269.8904130458832
Memory status after this trial: 
Memory allocated:  130.11181640625
Memory cached:  174.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -3.4151348307239564, 'log_learning_rate_D': -4.356004747782249, 'log_learning_rate_D_dagger': -3.500632407918049, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(4.1141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  162.0
	 epoch  10 training error:  tensor(2.1735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  344.0
	 epoch  20 training error:  tensor(3.3086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  344.0
	 epoch  30 training error:  tensor(3.9040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  332.0
	 epoch  40 training error:  tensor(4.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  332.0
	 epoch  50 training error:  tensor(3.8775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  336.0
	 epoch  60 training error:  tensor(3.8894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  340.0
	 epoch  70 training error:  tensor(3.9709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  350.0
	 epoch  80 training error:  tensor(3.9617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  346.0
	 epoch  90 training error:  tensor(4.1469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.353515625
Memory cached:  328.0
[I 2023-11-29 06:52:39,813] Trial 16 finished with value: 4.091176509857178 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -3.4151348307239564, 'log_learning_rate_D': -4.356004747782249, 'log_learning_rate_D_dagger': -3.500632407918049, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  388.0720896720886
Memory status after this trial: 
Memory allocated:  355.08251953125
Memory cached:  366.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.718286036324701, 'log_learning_rate_D': -3.573562175751149, 'log_learning_rate_D_dagger': -2.4434806672581484, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.5674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  116.0
	 epoch  10 training error:  tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  172.0
	 epoch  20 training error:  tensor(1.1042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  180.0
	 epoch  30 training error:  tensor(1.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  186.0
	 epoch  40 training error:  tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  178.0
	 epoch  50 training error:  tensor(1.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  178.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  176.0
	 epoch  70 training error:  tensor(1.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  186.0
	 epoch  80 training error:  tensor(1.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  192.0
	 epoch  90 training error:  tensor(1.0309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.69482421875
Memory cached:  178.0
[I 2023-11-29 06:56:23,531] Trial 17 finished with value: 1.1163326501846313 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.718286036324701, 'log_learning_rate_D': -3.573562175751149, 'log_learning_rate_D_dagger': -2.4434806672581484, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  223.43896079063416
Memory status after this trial: 
Memory allocated:  99.67626953125
Memory cached:  136.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.0452618917137673, 'log_learning_rate_D': -4.521338066819508, 'log_learning_rate_D_dagger': -1.6411767262763344, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.9638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  134.0
	 epoch  10 training error:  tensor(1.2979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  226.0
	 epoch  20 training error:  tensor(1.2405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  228.0
	 epoch  30 training error:  tensor(8.1977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  232.0
	 epoch  40 training error:  tensor(7.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  222.0
	 epoch  50 training error:  tensor(2.7066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  226.0
	 epoch  60 training error:  tensor(1.9184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  226.0
	 epoch  70 training error:  tensor(1.7690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  228.0
	 epoch  80 training error:  tensor(1.7771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  234.0
	 epoch  90 training error:  tensor(1.7311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.861328125
Memory cached:  216.0
[I 2023-11-29 07:00:53,153] Trial 18 finished with value: 2.1847732067108154 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.0452618917137673, 'log_learning_rate_D': -4.521338066819508, 'log_learning_rate_D_dagger': -1.6411767262763344, 'training_batch_size': 10, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  269.38000202178955
Memory status after this trial: 
Memory allocated:  136.7568359375
Memory cached:  174.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.917950855474944, 'log_learning_rate_D': -3.2042110900171883, 'log_learning_rate_D_dagger': -2.2765754918918977, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(12.2986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  158.0
	 epoch  10 training error:  tensor(4.2223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  278.0
	 epoch  20 training error:  tensor(3.8790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  254.0
	 epoch  30 training error:  tensor(2.8271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  262.0
	 epoch  40 training error:  tensor(2.6961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  266.0
	 epoch  50 training error:  tensor(2.7750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  274.0
	 epoch  60 training error:  tensor(2.9438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  266.0
	 epoch  70 training error:  tensor(4.2337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  262.0
	 epoch  80 training error:  tensor(10.9647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  262.0
	 epoch  90 training error:  tensor(11.3791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.60498046875
Memory cached:  262.0
[I 2023-11-29 07:11:01,898] Trial 19 finished with value: 6.70260763168335 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.917950855474944, 'log_learning_rate_D': -3.2042110900171883, 'log_learning_rate_D_dagger': -2.2765754918918977, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 1.0.
Time for this trial:  608.4648447036743
Memory status after this trial: 
Memory allocated:  188.41796875
Memory cached:  216.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.2414212045753263, 'log_learning_rate_D': -2.67501822224388, 'log_learning_rate_D_dagger': -2.5715068658115094, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(3.3273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  166.0
	 epoch  10 training error:  tensor(2.5193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  262.0
	 epoch  20 training error:  tensor(2.4654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  274.0
	 epoch  30 training error:  tensor(3.8165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  258.0
	 epoch  40 training error:  tensor(4.1029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  272.0
	 epoch  50 training error:  tensor(4.4729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  266.0
	 epoch  60 training error:  tensor(4.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  276.0
	 epoch  70 training error:  tensor(3.7990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  262.0
	 epoch  80 training error:  tensor(3.8337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  276.0
	 epoch  90 training error:  tensor(3.6870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.591796875
Memory cached:  270.0
[I 2023-11-29 07:15:38,458] Trial 20 finished with value: 3.0328996181488037 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.2414212045753263, 'log_learning_rate_D': -2.67501822224388, 'log_learning_rate_D_dagger': -2.5715068658115094, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  276.2992765903473
Memory status after this trial: 
Memory allocated:  183.32080078125
Memory cached:  208.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -4.338479825570996, 'log_learning_rate_D': -3.6158604990462297, 'log_learning_rate_D_dagger': -2.0059772022100577, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(7.8911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  198.0
	 epoch  10 training error:  tensor(1.9860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  394.0
	 epoch  20 training error:  tensor(1.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  384.0
	 epoch  30 training error:  tensor(1.1954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  398.0
	 epoch  40 training error:  tensor(1.2798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  408.0
	 epoch  50 training error:  tensor(1.2089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  396.0
	 epoch  60 training error:  tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  398.0
	 epoch  70 training error:  tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  392.0
	 epoch  80 training error:  tensor(1.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  392.0
	 epoch  90 training error:  tensor(1.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.63330078125
Memory cached:  394.0
[I 2023-11-29 07:21:45,773] Trial 21 finished with value: 1.0305566787719727 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -4.338479825570996, 'log_learning_rate_D': -3.6158604990462297, 'log_learning_rate_D_dagger': -2.0059772022100577, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  367.04318952560425
Memory status after this trial: 
Memory allocated:  345.5048828125
Memory cached:  378.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.7309159596894537, 'log_learning_rate_D': -2.8917384691469463, 'log_learning_rate_D_dagger': -1.5490184118279304, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.8050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  120.0
	 epoch  10 training error:  tensor(8.5226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  218.0
	 epoch  20 training error:  tensor(9.6842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  228.0
	 epoch  30 training error:  tensor(10.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  220.0
	 epoch  40 training error:  tensor(10.1993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  226.0
	 epoch  50 training error:  tensor(9.8724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  220.0
	 epoch  60 training error:  tensor(12.5698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  224.0
	 epoch  70 training error:  tensor(10.2440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  216.0
	 epoch  80 training error:  tensor(12.4211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  216.0
	 epoch  90 training error:  tensor(9.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5546875
Memory cached:  220.0
[I 2023-11-29 07:29:26,675] Trial 22 finished with value: 8.678642272949219 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.7309159596894537, 'log_learning_rate_D': -2.8917384691469463, 'log_learning_rate_D_dagger': -1.5490184118279304, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  460.61101603507996
Memory status after this trial: 
Memory allocated:  160.37890625
Memory cached:  182.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.6482812593464415, 'log_learning_rate_D': -3.3923272719452218, 'log_learning_rate_D_dagger': -1.3396518747256247, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  104.0
	 epoch  10 training error:  tensor(6.7514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  164.0
	 epoch  20 training error:  tensor(16.6569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  174.0
	 epoch  30 training error:  tensor(16.7606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  170.0
	 epoch  40 training error:  tensor(17.8110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  174.0
	 epoch  50 training error:  tensor(16.6769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  168.0
	 epoch  60 training error:  tensor(16.8604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  164.0
	 epoch  70 training error:  tensor(16.2797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  170.0
	 epoch  80 training error:  tensor(16.5565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  164.0
	 epoch  90 training error:  tensor(16.4476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.564453125
Memory cached:  168.0
[I 2023-11-29 07:33:22,795] Trial 23 finished with value: 15.710196495056152 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.6482812593464415, 'log_learning_rate_D': -3.3923272719452218, 'log_learning_rate_D_dagger': -1.3396518747256247, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  235.8826711177826
Memory status after this trial: 
Memory allocated:  87.3603515625
Memory cached:  126.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.8332991603550286, 'log_learning_rate_D': -2.9044611204089157, 'log_learning_rate_D_dagger': -1.4022452422097829, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.3874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  138.0
	 epoch  10 training error:  tensor(1.0867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  234.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  226.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  228.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  234.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  224.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  226.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  224.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  224.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  226.0
[I 2023-11-29 07:41:08,390] Trial 24 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.8332991603550286, 'log_learning_rate_D': -2.9044611204089157, 'log_learning_rate_D_dagger': -1.4022452422097829, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  465.33787178993225
Memory status after this trial: 
Memory allocated:  175.21533203125
Memory cached:  188.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.9968989024294066, 'log_learning_rate_D': -3.9250371175849104, 'log_learning_rate_D_dagger': -1.9514316278145771, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  124.0
	 epoch  10 training error:  tensor(1.8555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  210.0
	 epoch  20 training error:  tensor(1.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  228.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  208.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  208.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  206.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  206.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  206.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  218.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7607421875
Memory cached:  212.0
[I 2023-11-29 07:44:43,102] Trial 25 finished with value: 1.3176440000534058 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.9968989024294066, 'log_learning_rate_D': -3.9250371175849104, 'log_learning_rate_D_dagger': -1.9514316278145771, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  214.47812271118164
Memory status after this trial: 
Memory allocated:  142.61962890625
Memory cached:  156.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.3909164555968614, 'log_learning_rate_D': -2.5655731737550838, 'log_learning_rate_D_dagger': -1.0146335474608388, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(2.9068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  144.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  262.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  272.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  270.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  244.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  260.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  254.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  248.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  266.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.10595703125
Memory cached:  252.0
[I 2023-11-29 07:49:04,910] Trial 26 finished with value: 1.6057814359664917 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.3909164555968614, 'log_learning_rate_D': -2.5655731737550838, 'log_learning_rate_D_dagger': -1.0146335474608388, 'training_batch_size': 9, 'training_p': 6}. Best is trial 0 with value: 1.0.
Time for this trial:  261.5278789997101
Memory status after this trial: 
Memory allocated:  183.09765625
Memory cached:  200.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.672129184574993, 'log_learning_rate_D': -2.169597052145148, 'log_learning_rate_D_dagger': -1.4300074955758375, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(2.9138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  138.0
	 epoch  10 training error:  tensor(22.4034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
	 epoch  20 training error:  tensor(55.6849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  202.0
	 epoch  30 training error:  tensor(78.9707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  186.0
	 epoch  40 training error:  tensor(42.3290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  192.0
	 epoch  50 training error:  tensor(26.8913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  194.0
	 epoch  60 training error:  tensor(21.5695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  190.0
	 epoch  70 training error:  tensor(16.7673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  202.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  190.0
[I 2023-11-29 07:56:44,073] Trial 27 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.672129184574993, 'log_learning_rate_D': -2.169597052145148, 'log_learning_rate_D_dagger': -1.4300074955758375, 'training_batch_size': 6, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  458.8809654712677
Memory status after this trial: 
Memory allocated:  127.33642578125
Memory cached:  148.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.3546239144158077, 'log_learning_rate_D': -3.199440500287473, 'log_learning_rate_D_dagger': -1.8424800181606797, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(5.6434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  138.0
	 epoch  10 training error:  tensor(10.3687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  272.0
	 epoch  20 training error:  tensor(11.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  284.0
	 epoch  30 training error:  tensor(12.6166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  274.0
	 epoch  40 training error:  tensor(13.3007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  288.0
	 epoch  50 training error:  tensor(13.2814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  274.0
	 epoch  60 training error:  tensor(13.1657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  282.0
	 epoch  70 training error:  tensor(12.7890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  270.0
	 epoch  80 training error:  tensor(12.6204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  286.0
	 epoch  90 training error:  tensor(12.8541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.705078125
Memory cached:  280.0
[I 2023-11-29 08:01:20,990] Trial 28 finished with value: 18.274539947509766 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.3546239144158077, 'log_learning_rate_D': -3.199440500287473, 'log_learning_rate_D_dagger': -1.8424800181606797, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  276.6517074108124
Memory status after this trial: 
Memory allocated:  193.5986328125
Memory cached:  198.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.385216691247738, 'log_learning_rate_D': -2.7260310455014554, 'log_learning_rate_D_dagger': -2.347661938794649, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(2.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  146.0
	 epoch  10 training error:  tensor(1.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  292.0
	 epoch  20 training error:  tensor(1.0204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  306.0
	 epoch  30 training error:  tensor(1.0130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  290.0
	 epoch  40 training error:  tensor(1.0345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  292.0
	 epoch  50 training error:  tensor(1.0159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  260.0
	 epoch  60 training error:  tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  284.0
	 epoch  70 training error:  tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  290.0
	 epoch  80 training error:  tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  274.0
	 epoch  90 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.38330078125
Memory cached:  278.0
[I 2023-11-29 08:06:39,784] Trial 29 finished with value: 1.0036617517471313 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.385216691247738, 'log_learning_rate_D': -2.7260310455014554, 'log_learning_rate_D_dagger': -2.347661938794649, 'training_batch_size': 11, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  318.5239996910095
Memory status after this trial: 
Memory allocated:  189.6044921875
Memory cached:  212.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.0411940893714764, 'log_learning_rate_D': -2.2078218041995297, 'log_learning_rate_D_dagger': -2.7185446039589225, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.626953125
Memory cached:  166.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.626953125
Memory cached:  304.0
[W 2023-11-29 08:07:39,807] Trial 30 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.0411940893714764, 'log_learning_rate_D': -2.2078218041995297, 'log_learning_rate_D_dagger': -2.7185446039589225, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-11-29 08:07:39,808] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  59.76005458831787
Memory status after this trial: 
Memory allocated:  248.1767578125
Memory cached:  270.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.036052126359015, 'log_learning_rate_D': -1.9542219155394616, 'log_learning_rate_D_dagger': -2.574563219523147, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  174.0
	 epoch  10 training error:  tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  308.0
	 epoch  20 training error:  tensor(1.3277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  298.0
	 epoch  30 training error:  tensor(1.2452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  310.0
	 epoch  40 training error:  tensor(1.2131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  298.0
	 epoch  50 training error:  tensor(1.2687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  296.0
	 epoch  60 training error:  tensor(1.1845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  298.0
	 epoch  70 training error:  tensor(1.1799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  304.0
	 epoch  80 training error:  tensor(1.1839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  290.0
	 epoch  90 training error:  tensor(1.1827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3388671875
Memory cached:  304.0
[I 2023-11-29 08:13:19,750] Trial 31 finished with value: 1.2090084552764893 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.036052126359015, 'log_learning_rate_D': -1.9542219155394616, 'log_learning_rate_D_dagger': -2.574563219523147, 'training_batch_size': 9, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  339.65291142463684
Memory status after this trial: 
Memory allocated:  236.607421875
Memory cached:  258.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.0496066569774603, 'log_learning_rate_D': -2.961889033696976, 'log_learning_rate_D_dagger': -1.8168457900508996, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(9.0093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  122.0
	 epoch  10 training error:  tensor(2.5240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  198.0
	 epoch  20 training error:  tensor(2.7760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  196.0
	 epoch  30 training error:  tensor(3.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  188.0
	 epoch  40 training error:  tensor(3.1752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  192.0
	 epoch  50 training error:  tensor(2.7838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  186.0
	 epoch  60 training error:  tensor(2.8071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  194.0
	 epoch  70 training error:  tensor(3.0257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  190.0
	 epoch  80 training error:  tensor(3.1305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  182.0
	 epoch  90 training error:  tensor(3.2157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.21875
Memory cached:  186.0
[I 2023-11-29 08:20:58,698] Trial 32 finished with value: 2.0822651386260986 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.0496066569774603, 'log_learning_rate_D': -2.961889033696976, 'log_learning_rate_D_dagger': -1.8168457900508996, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  458.6905813217163
Memory status after this trial: 
Memory allocated:  130.6259765625
Memory cached:  156.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.9259561881624858, 'log_learning_rate_D': -2.81988485898312, 'log_learning_rate_D_dagger': -1.4050809120975527, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.3896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  132.0
	 epoch  10 training error:  tensor(6.0138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  228.0
	 epoch  20 training error:  tensor(5.2741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  228.0
	 epoch  30 training error:  tensor(6.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  234.0
	 epoch  40 training error:  tensor(5.8807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  234.0
	 epoch  50 training error:  tensor(5.9028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  236.0
	 epoch  60 training error:  tensor(5.8515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  224.0
	 epoch  70 training error:  tensor(6.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  228.0
	 epoch  80 training error:  tensor(6.0081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  228.0
	 epoch  90 training error:  tensor(5.5954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9892578125
Memory cached:  242.0
[I 2023-11-29 08:28:43,467] Trial 33 finished with value: 3.129462718963623 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.9259561881624858, 'log_learning_rate_D': -2.81988485898312, 'log_learning_rate_D_dagger': -1.4050809120975527, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  464.51555585861206
Memory status after this trial: 
Memory allocated:  175.21533203125
Memory cached:  202.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.8506945893424522, 'log_learning_rate_D': -3.2218077002575587, 'log_learning_rate_D_dagger': -1.6033371831442131, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.9331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  168.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  274.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  268.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  262.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  276.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  274.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  270.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  264.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  266.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.990234375
Memory cached:  258.0
[I 2023-11-29 08:36:32,062] Trial 34 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.8506945893424522, 'log_learning_rate_D': -3.2218077002575587, 'log_learning_rate_D_dagger': -1.6033371831442131, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  468.3165602684021
Memory status after this trial: 
Memory allocated:  228.015625
Memory cached:  248.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.2239864784097993, 'log_learning_rate_D': -2.564155505135573, 'log_learning_rate_D_dagger': -1.2517075907400268, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(7.5834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  152.0
	 epoch  10 training error:  tensor(3.1871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  286.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  314.0
	 epoch  30 training error:  tensor(7.8995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  298.0
	 epoch  40 training error:  tensor(14.3045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  290.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  292.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  294.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  268.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  298.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.8017578125
Memory cached:  298.0
[I 2023-11-29 08:41:53,411] Trial 35 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.2239864784097993, 'log_learning_rate_D': -2.564155505135573, 'log_learning_rate_D_dagger': -1.2517075907400268, 'training_batch_size': 7, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  321.0651240348816
Memory status after this trial: 
Memory allocated:  302.3203125
Memory cached:  312.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.63438040904957, 'log_learning_rate_D': -2.9007125438368724, 'log_learning_rate_D_dagger': -1.5769054874258162, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.8086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  118.0
	 epoch  10 training error:  tensor(1.1901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  154.0
	 epoch  20 training error:  tensor(5.6892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  158.0
	 epoch  30 training error:  tensor(8.0292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  158.0
	 epoch  40 training error:  tensor(4.7901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  156.0
	 epoch  50 training error:  tensor(3.1988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  160.0
	 epoch  60 training error:  tensor(2.2778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  160.0
	 epoch  70 training error:  tensor(1.9819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  164.0
	 epoch  80 training error:  tensor(2.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  162.0
	 epoch  90 training error:  tensor(2.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9384765625
Memory cached:  160.0
[I 2023-11-29 08:49:27,711] Trial 36 finished with value: 1.7689541578292847 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.63438040904957, 'log_learning_rate_D': -2.9007125438368724, 'log_learning_rate_D_dagger': -1.5769054874258162, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  454.0638356208801
Memory status after this trial: 
Memory allocated:  99.2021484375
Memory cached:  134.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -1.6942890821683525, 'log_learning_rate_D': -3.3801631146643905, 'log_learning_rate_D_dagger': -2.1041341736116608, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(2.1609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  90.0
	 epoch  10 training error:  tensor(2.3362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  110.0
	 epoch  20 training error:  tensor(3.4488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  108.0
	 epoch  30 training error:  tensor(4.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  112.0
	 epoch  40 training error:  tensor(4.3801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  106.0
	 epoch  50 training error:  tensor(2.6130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  108.0
	 epoch  60 training error:  tensor(2.0273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  108.0
	 epoch  70 training error:  tensor(2.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  108.0
	 epoch  80 training error:  tensor(1.7822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  108.0
	 epoch  90 training error:  tensor(1.7727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0283203125
Memory cached:  110.0
[I 2023-11-29 08:52:50,240] Trial 37 finished with value: 1.991938591003418 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -1.6942890821683525, 'log_learning_rate_D': -3.3801631146643905, 'log_learning_rate_D_dagger': -2.1041341736116608, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  202.3053262233734
Memory status after this trial: 
Memory allocated:  49.49609375
Memory cached:  98.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.0778072359588533, 'log_learning_rate_D': -3.0843364046576873, 'log_learning_rate_D_dagger': -1.309314462013742, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(2.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  206.0
	 epoch  10 training error:  tensor(1.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  332.0
	 epoch  20 training error:  tensor(1.0215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  336.0
	 epoch  30 training error:  tensor(1.0361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  336.0
	 epoch  40 training error:  tensor(1.5491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  328.0
	 epoch  50 training error:  tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  342.0
	 epoch  60 training error:  tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  336.0
	 epoch  70 training error:  tensor(1.2219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  344.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  348.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5927734375
Memory cached:  334.0
[I 2023-11-29 08:57:49,430] Trial 38 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.0778072359588533, 'log_learning_rate_D': -3.0843364046576873, 'log_learning_rate_D_dagger': -1.309314462013742, 'training_batch_size': 7, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  298.95714259147644
Memory status after this trial: 
Memory allocated:  364.1689453125
Memory cached:  378.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.8794352689387894, 'log_learning_rate_D': -2.185603961812751, 'log_learning_rate_D_dagger': -2.146617701101347, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(5.4992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  146.0
	 epoch  10 training error:  tensor(1.6072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  262.0
	 epoch  20 training error:  tensor(3.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  264.0
	 epoch  30 training error:  tensor(2.7599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  256.0
	 epoch  40 training error:  tensor(2.3809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  260.0
	 epoch  50 training error:  tensor(2.1048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  252.0
	 epoch  60 training error:  tensor(1.8260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  252.0
	 epoch  70 training error:  tensor(1.7310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  254.0
	 epoch  80 training error:  tensor(1.5404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  260.0
	 epoch  90 training error:  tensor(1.4841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.41748046875
Memory cached:  254.0
[I 2023-11-29 09:07:02,148] Trial 39 finished with value: 1.1942447423934937 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.8794352689387894, 'log_learning_rate_D': -2.185603961812751, 'log_learning_rate_D_dagger': -2.146617701101347, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 1.0.
Time for this trial:  552.4351637363434
Memory status after this trial: 
Memory allocated:  174.34423828125
Memory cached:  200.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.472200057446482, 'log_learning_rate_D': -3.587840281283754, 'log_learning_rate_D_dagger': -1.7757248774597902, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.7402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  132.0
	 epoch  10 training error:  tensor(1.9373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  204.0
	 epoch  20 training error:  tensor(2.6580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  202.0
	 epoch  30 training error:  tensor(1.9765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  194.0
	 epoch  40 training error:  tensor(2.5691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  208.0
	 epoch  50 training error:  tensor(2.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  206.0
	 epoch  60 training error:  tensor(1.9307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  200.0
	 epoch  70 training error:  tensor(1.8615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  192.0
	 epoch  80 training error:  tensor(1.9350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  206.0
	 epoch  90 training error:  tensor(1.8229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0126953125
Memory cached:  200.0
[I 2023-11-29 09:10:59,910] Trial 40 finished with value: 1.4970752000808716 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.472200057446482, 'log_learning_rate_D': -3.587840281283754, 'log_learning_rate_D_dagger': -1.7757248774597902, 'training_batch_size': 12, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  237.51354217529297
Memory status after this trial: 
Memory allocated:  108.529296875
Memory cached:  142.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 9, 'log_learning_rate': -2.186795659990776, 'log_learning_rate_D': -2.4564428093600363, 'log_learning_rate_D_dagger': -1.0044707657133993, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(8.5256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  220.0
	 epoch  10 training error:  tensor(4.0085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  388.0
	 epoch  20 training error:  tensor(71.5581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  398.0
	 epoch  30 training error:  tensor(55.5974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  384.0
	 epoch  40 training error:  tensor(35.9764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  402.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  382.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  396.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  392.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  382.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.9443359375
Memory cached:  400.0
[I 2023-11-29 09:16:28,918] Trial 41 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 9, 'log_learning_rate': -2.186795659990776, 'log_learning_rate_D': -2.4564428093600363, 'log_learning_rate_D_dagger': -1.0044707657133993, 'training_batch_size': 8, 'training_p': 8}. Best is trial 0 with value: 1.0.
Time for this trial:  328.7551543712616
Memory status after this trial: 
Memory allocated:  367.5625
Memory cached:  376.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.201670995460387, 'log_learning_rate_D': -2.74574701340747, 'log_learning_rate_D_dagger': -1.9869093778870344, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(2.8100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  120.0
	 epoch  10 training error:  tensor(1.6098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  208.0
	 epoch  20 training error:  tensor(1.2160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  202.0
	 epoch  30 training error:  tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  196.0
	 epoch  40 training error:  tensor(1.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  202.0
	 epoch  50 training error:  tensor(1.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  202.0
	 epoch  60 training error:  tensor(1.0444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  196.0
	 epoch  70 training error:  tensor(1.0299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  210.0
	 epoch  80 training error:  tensor(1.0355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  206.0
	 epoch  90 training error:  tensor(1.0301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.96826171875
Memory cached:  206.0
[I 2023-11-29 09:20:13,918] Trial 42 finished with value: 1.018501877784729 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.201670995460387, 'log_learning_rate_D': -2.74574701340747, 'log_learning_rate_D_dagger': -1.9869093778870344, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 1.0.
Time for this trial:  224.74678111076355
Memory status after this trial: 
Memory allocated:  113.9111328125
Memory cached:  146.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.6333763719495644, 'log_learning_rate_D': -2.1650263628682866, 'log_learning_rate_D_dagger': -1.4657012351197605, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.7435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  140.0
	 epoch  10 training error:  tensor(6.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  182.0
	 epoch  20 training error:  tensor(6.6216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  190.0
	 epoch  30 training error:  tensor(6.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  184.0
	 epoch  40 training error:  tensor(8.5965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  182.0
	 epoch  50 training error:  tensor(7.3218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
	 epoch  60 training error:  tensor(6.2331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  192.0
	 epoch  70 training error:  tensor(6.1220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
	 epoch  80 training error:  tensor(6.8528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
	 epoch  90 training error:  tensor(6.6065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5322265625
Memory cached:  188.0
[I 2023-11-29 09:27:54,704] Trial 43 finished with value: 3.8521840572357178 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.6333763719495644, 'log_learning_rate_D': -2.1650263628682866, 'log_learning_rate_D_dagger': -1.4657012351197605, 'training_batch_size': 6, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  460.53471279144287
Memory status after this trial: 
Memory allocated:  127.33642578125
Memory cached:  158.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.7615360056575726, 'log_learning_rate_D': -1.8938609054540891, 'log_learning_rate_D_dagger': -1.236938954611018, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  124.0
	 epoch  10 training error:  tensor(5.9666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  204.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  200.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  192.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  202.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  190.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  192.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  186.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  182.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.21923828125
Memory cached:  194.0
[I 2023-11-29 09:31:39,128] Trial 44 finished with value: 2.4093384742736816 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -1.7615360056575726, 'log_learning_rate_D': -1.8938609054540891, 'log_learning_rate_D_dagger': -1.236938954611018, 'training_batch_size': 7, 'training_p': 7}. Best is trial 0 with value: 1.0.
Time for this trial:  224.19044375419617
Memory status after this trial: 
Memory allocated:  116.30859375
Memory cached:  146.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -1.5753590632072236, 'log_learning_rate_D': -2.565475510898698, 'log_learning_rate_D_dagger': -1.4545895726357525, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.9194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  182.0
[W 2023-11-29 09:31:50,852] Trial 45 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -1.5753590632072236, 'log_learning_rate_D': -2.565475510898698, 'log_learning_rate_D_dagger': -1.4545895726357525, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-11-29 09:31:50,852] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  11.475318908691406
Memory status after this trial: 
Memory allocated:  273.9453125
Memory cached:  294.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -1.5844980005520286, 'log_learning_rate_D': -2.301023733082917, 'log_learning_rate_D_dagger': -1.438907763331337, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.9650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  180.0
	 epoch  10 training error:  tensor(12.9762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(12.8047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  284.0
	 epoch  30 training error:  tensor(13.1694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  300.0
	 epoch  40 training error:  tensor(14.6279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  292.0
	 epoch  50 training error:  tensor(14.8938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  286.0
	 epoch  60 training error:  tensor(12.9095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  292.0
	 epoch  70 training error:  tensor(14.0353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  294.0
	 epoch  80 training error:  tensor(14.7348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  290.0
	 epoch  90 training error:  tensor(13.8759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.30908203125
Memory cached:  286.0
[I 2023-11-29 09:40:10,975] Trial 46 finished with value: 12.9599609375 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -1.5844980005520286, 'log_learning_rate_D': -2.301023733082917, 'log_learning_rate_D_dagger': -1.438907763331337, 'training_batch_size': 6, 'training_p': 5}. Best is trial 0 with value: 1.0.
Time for this trial:  499.85729217529297
Memory status after this trial: 
Memory allocated:  273.9453125
Memory cached:  294.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.980914700065348, 'log_learning_rate_D': -2.5482147891266815, 'log_learning_rate_D_dagger': -1.66662963380556, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(2.4155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.826171875
Memory cached:  136.0
	 epoch  10 training error:  tensor(1.8179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.826171875
Memory cached:  222.0
	 epoch  20 training error:  tensor(1.7157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.826171875
Memory cached:  220.0
[W 2023-11-29 09:41:58,552] Trial 47 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.980914700065348, 'log_learning_rate_D': -2.5482147891266815, 'log_learning_rate_D_dagger': -1.66662963380556, 'training_batch_size': 6, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-11-29 09:41:58,554] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  107.31057858467102
Memory status after this trial: 
Memory allocated:  168.29052734375
Memory cached:  182.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.0044755008373407, 'log_learning_rate_D': -2.465270528517489, 'log_learning_rate_D_dagger': -1.7034935431457334, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(3.9287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  124.0
	 epoch  10 training error:  tensor(2.9072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  164.0
	 epoch  20 training error:  tensor(6.7553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  180.0
	 epoch  30 training error:  tensor(4.9764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  180.0
	 epoch  40 training error:  tensor(11.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  182.0
	 epoch  50 training error:  tensor(4.8697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  178.0
	 epoch  60 training error:  tensor(4.8688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  174.0
	 epoch  70 training error:  tensor(5.0038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  174.0
	 epoch  80 training error:  tensor(4.9664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  180.0
	 epoch  90 training error:  tensor(4.7693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.271484375
Memory cached:  174.0
[I 2023-11-29 09:49:35,201] Trial 48 finished with value: 4.174754619598389 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.0044755008373407, 'log_learning_rate_D': -2.465270528517489, 'log_learning_rate_D_dagger': -1.7034935431457334, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 1.0.
Time for this trial:  456.38340067863464
Memory status after this trial: 
Memory allocated:  110.67919921875
Memory cached:  150.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.5308256484926934, 'log_learning_rate_D': -2.6600812325438774, 'log_learning_rate_D_dagger': -1.2812117485462613, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(5.7648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  178.0
	 epoch  10 training error:  tensor(58.3731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  282.0
	 epoch  20 training error:  tensor(63.6861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  286.0
	 epoch  30 training error:  tensor(59.7345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  278.0
	 epoch  40 training error:  tensor(56.7404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  292.0
	 epoch  50 training error:  tensor(55.4022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  290.0
	 epoch  60 training error:  tensor(49.9163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  298.0
	 epoch  70 training error:  tensor(49.8327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  286.0
	 epoch  80 training error:  tensor(47.4408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  292.0
	 epoch  90 training error:  tensor(46.0053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.10302734375
Memory cached:  290.0
[I 2023-11-29 09:54:23,833] Trial 49 finished with value: 42.48384475708008 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.5308256484926934, 'log_learning_rate_D': -2.6600812325438774, 'log_learning_rate_D_dagger': -1.2812117485462613, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 1.0.
[I 2023-11-29 09:54:23,880] A new study created in memory with name: no-name-921ec8f9-a0dc-4dcb-bf40-aca8915205bc
Time for this trial:  288.3682975769043
Memory status after this trial: 
Memory allocated:  174.61572265625
Memory cached:  210.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -1.9648499058219007, 'log_learning_rate_D': -1.6491360470321457, 'log_learning_rate_D_dagger': -3.510382895079316, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(29.1616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  208.0
	 epoch  10 training error:  tensor(29.8400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  392.0
	 epoch  20 training error:  tensor(27.1450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  392.0
	 epoch  30 training error:  tensor(27.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  404.0
	 epoch  40 training error:  tensor(27.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  398.0
	 epoch  50 training error:  tensor(25.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  400.0
	 epoch  60 training error:  tensor(25.4001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  402.0
	 epoch  70 training error:  tensor(24.8952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  388.0
	 epoch  80 training error:  tensor(22.6480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  394.0
	 epoch  90 training error:  tensor(23.7786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.83447265625
Memory cached:  408.0
[I 2023-11-29 10:01:35,986] Trial 0 finished with value: 20.750410079956055 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -1.9648499058219007, 'log_learning_rate_D': -1.6491360470321457, 'log_learning_rate_D_dagger': -3.510382895079316, 'training_batch_size': 9, 'training_p': 8}. Best is trial 0 with value: 20.750410079956055.
Time for this trial:  431.98292803764343
Memory status after this trial: 
Memory allocated:  431.61279296875
Memory cached:  450.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -3.9238735631539963, 'log_learning_rate_D': -4.5966039480972976, 'log_learning_rate_D_dagger': -2.636007355539283, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(15.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  126.0
	 epoch  10 training error:  tensor(3.8228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  220.0
	 epoch  20 training error:  tensor(2.3297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  228.0
	 epoch  30 training error:  tensor(2.7457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  228.0
	 epoch  40 training error:  tensor(2.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  226.0
	 epoch  50 training error:  tensor(1.6176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  220.0
	 epoch  60 training error:  tensor(1.3304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  226.0
	 epoch  70 training error:  tensor(1.2229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  230.0
	 epoch  80 training error:  tensor(1.8911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  228.0
	 epoch  90 training error:  tensor(1.4657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.1748046875
Memory cached:  230.0
[I 2023-11-29 10:06:32,725] Trial 1 finished with value: 1.0936754941940308 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -3.9238735631539963, 'log_learning_rate_D': -4.5966039480972976, 'log_learning_rate_D_dagger': -2.636007355539283, 'training_batch_size': 11, 'training_p': 8}. Best is trial 1 with value: 1.0936754941940308.
Time for this trial:  296.5503468513489
Memory status after this trial: 
Memory allocated:  126.7470703125
Memory cached:  168.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -3.9380738329925076, 'log_learning_rate_D': -1.6304388718922302, 'log_learning_rate_D_dagger': -4.835771191375188, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(15.3341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  64.0
	 epoch  10 training error:  tensor(10.5687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  68.0
	 epoch  20 training error:  tensor(11.3737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  64.0
	 epoch  30 training error:  tensor(11.7782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  70.0
	 epoch  40 training error:  tensor(12.1665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  68.0
	 epoch  50 training error:  tensor(12.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  68.0
	 epoch  60 training error:  tensor(12.1059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  64.0
	 epoch  70 training error:  tensor(13.2246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  66.0
	 epoch  80 training error:  tensor(12.7716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  66.0
	 epoch  90 training error:  tensor(12.8220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.46630859375
Memory cached:  70.0
[I 2023-11-29 10:10:06,621] Trial 2 finished with value: 12.174018859863281 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -3.9380738329925076, 'log_learning_rate_D': -1.6304388718922302, 'log_learning_rate_D_dagger': -4.835771191375188, 'training_batch_size': 10, 'training_p': 3}. Best is trial 1 with value: 1.0936754941940308.
Time for this trial:  213.7234766483307
Memory status after this trial: 
Memory allocated:  27.876953125
Memory cached:  60.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -1.462170359496013, 'log_learning_rate_D': -2.857014349989915, 'log_learning_rate_D_dagger': -1.237587087613334, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(31.8316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  150.0
	 epoch  10 training error:  tensor(31.5331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  280.0
	 epoch  20 training error:  tensor(87.6191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  268.0
	 epoch  30 training error:  tensor(63.4252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  270.0
	 epoch  40 training error:  tensor(163.9682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  274.0
	 epoch  50 training error:  tensor(96.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  274.0
	 epoch  60 training error:  tensor(56.9701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  286.0
	 epoch  70 training error:  tensor(22.8229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  280.0
	 epoch  80 training error:  tensor(21.4214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  282.0
	 epoch  90 training error:  tensor(14.3731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.390625
Memory cached:  278.0
[I 2023-11-29 10:14:41,829] Trial 3 finished with value: 17.9637508392334 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -1.462170359496013, 'log_learning_rate_D': -2.857014349989915, 'log_learning_rate_D_dagger': -1.237587087613334, 'training_batch_size': 9, 'training_p': 7}. Best is trial 1 with value: 1.0936754941940308.
Time for this trial:  275.0536091327667
Memory status after this trial: 
Memory allocated:  189.6767578125
Memory cached:  192.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.323784068184425, 'log_learning_rate_D': -3.912640620677719, 'log_learning_rate_D_dagger': -1.8304504278129388, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(3.2085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  184.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  330.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  322.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  338.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  326.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  334.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  322.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  326.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  328.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.7197265625
Memory cached:  332.0
[I 2023-11-29 10:19:45,201] Trial 4 finished with value: 1.0084614753723145 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.323784068184425, 'log_learning_rate_D': -3.912640620677719, 'log_learning_rate_D_dagger': -1.8304504278129388, 'training_batch_size': 12, 'training_p': 2}. Best is trial 4 with value: 1.0084614753723145.
Time for this trial:  303.21022963523865
Memory status after this trial: 
Memory allocated:  210.7724609375
Memory cached:  264.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.061837195697641, 'log_learning_rate_D': -1.3850631177540769, 'log_learning_rate_D_dagger': -3.331960001404541, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(17.6691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.98046875
Memory cached:  154.0
[W 2023-11-29 10:20:10,082] Trial 5 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.061837195697641, 'log_learning_rate_D': -1.3850631177540769, 'log_learning_rate_D_dagger': -3.331960001404541, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-11-29 10:20:10,084] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  24.716701984405518
Memory status after this trial: 
Memory allocated:  337.46337890625
Memory cached:  344.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.7684919739430196, 'log_learning_rate_D': -1.5357205422939288, 'log_learning_rate_D_dagger': -3.3046954075257897, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  148.0
	 epoch  10 training error:  tensor(1.5646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  270.0
	 epoch  20 training error:  tensor(1.5040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  286.0
	 epoch  30 training error:  tensor(2.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  280.0
	 epoch  40 training error:  tensor(2.6422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  286.0
	 epoch  50 training error:  tensor(2.8962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  282.0
	 epoch  60 training error:  tensor(2.8912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  286.0
	 epoch  70 training error:  tensor(3.1144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  274.0
	 epoch  80 training error:  tensor(3.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  272.0
	 epoch  90 training error:  tensor(3.1987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.1083984375
Memory cached:  302.0
[I 2023-11-29 10:24:55,004] Trial 6 finished with value: 2.127117156982422 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.7684919739430196, 'log_learning_rate_D': -1.5357205422939288, 'log_learning_rate_D_dagger': -3.3046954075257897, 'training_batch_size': 10, 'training_p': 6}. Best is trial 4 with value: 1.0084614753723145.
Time for this trial:  284.75138115882874
Memory status after this trial: 
Memory allocated:  248.1640625
Memory cached:  262.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -3.5756353401837515, 'log_learning_rate_D': -1.8785381119801126, 'log_learning_rate_D_dagger': -4.722911221993737, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(9.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  180.0
	 epoch  10 training error:  tensor(9.3432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  372.0
	 epoch  20 training error:  tensor(9.5044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  348.0
	 epoch  30 training error:  tensor(10.1056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  362.0
	 epoch  40 training error:  tensor(9.4988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  350.0
	 epoch  50 training error:  tensor(9.4502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  350.0
	 epoch  60 training error:  tensor(9.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  350.0
	 epoch  70 training error:  tensor(9.4103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  336.0
	 epoch  80 training error:  tensor(9.4043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  344.0
	 epoch  90 training error:  tensor(9.3046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.73779296875
Memory cached:  352.0
[I 2023-11-29 10:30:31,001] Trial 7 finished with value: 8.838847160339355 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -3.5756353401837515, 'log_learning_rate_D': -1.8785381119801126, 'log_learning_rate_D_dagger': -4.722911221993737, 'training_batch_size': 12, 'training_p': 5}. Best is trial 4 with value: 1.0084614753723145.
Time for this trial:  335.83307790756226
Memory status after this trial: 
Memory allocated:  328.62841796875
Memory cached:  362.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.6307799805230632, 'log_learning_rate_D': -3.129777706490171, 'log_learning_rate_D_dagger': -1.8544856374041458, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(8.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.83251953125
Memory cached:  186.0
	 epoch  10 training error:  tensor(48.3949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.83251953125
Memory cached:  324.0
	 epoch  20 training error:  tensor(55.4939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.83251953125
Memory cached:  332.0
[W 2023-11-29 10:33:00,992] Trial 8 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.6307799805230632, 'log_learning_rate_D': -3.129777706490171, 'log_learning_rate_D_dagger': -1.8544856374041458, 'training_batch_size': 6, 'training_p': 7} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV_WDsep_deltaTSqed.py", line 209, in objective
    avg_training_loss = train1Epoch(trainDataLoader, Loss, myWD, params['training_p'])
  File "/home/shengduo/RateAndStateWithPotential/FrictionNNModels.py", line 175, in train1Epoch
    loss.backward()
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[W 2023-11-29 10:33:00,995] Trial 8 failed with value None.
Traceback (most recent call last):
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV_WDsep_deltaTSqed.py", line 258, in <module>
    this_study.optimize(myOpt.objective, n_trials=50)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/study.py", line 442, in optimize
    _optimize(
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 251, in _run_trial
    raise func_err
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "/home/shengduo/RateAndStateWithPotential/TuneDimXi_logV_WDsep_deltaTSqed.py", line 209, in objective
    avg_training_loss = train1Epoch(trainDataLoader, Loss, myWD, params['training_p'])
  File "/home/shengduo/RateAndStateWithPotential/FrictionNNModels.py", line 175, in train1Epoch
    loss.backward()
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
