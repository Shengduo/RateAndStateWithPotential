[I 2024-02-28 13:09:40,464] A new study created in RDB with name: my_study1
Cuda is available:  True
Device is:  cuda
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial0216_combined_800.pt
Vs.shape:  torch.Size([800, 100])
thetas.shape:  torch.Size([800, 100])
fs.shape:  torch.Size([800, 100])
ts.shape:  torch.Size([800, 100])
Xs.shape:  torch.Size([800, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.8863658474837575, 'log_learning_rate_D': -2.3859329573764034, 'log_learning_rate_D_dagger': -2.831397361430057, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0401, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.61474609375
Memory cached:  178.0
[I 2024-02-28 13:10:08,988] Trial 0 finished with value: 0.767223596572876 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.8863658474837575, 'log_learning_rate_D': -2.3859329573764034, 'log_learning_rate_D_dagger': -2.831397361430057, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 0.767223596572876.
res:  tensor(0.7672, grad_fn=<ToCopyBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  27.920659065246582
Memory status after this trial: 
Memory allocated:  813.75146484375
Memory cached:  840.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -4.4889461219260784, 'log_learning_rate_D': -3.660524779285906, 'log_learning_rate_D_dagger': -2.4661980588550496, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9678, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  829.7470703125
Memory cached:  1146.0
[I 2024-02-28 13:11:46,324] Trial 1 finished with value: 0.31982770562171936 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -4.4889461219260784, 'log_learning_rate_D': -3.660524779285906, 'log_learning_rate_D_dagger': -2.4661980588550496, 'training_batch_size': 6, 'training_p': 4}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.7672, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  96.25489544868469
Memory status after this trial: 
Memory allocated:  912.232421875
Memory cached:  1610.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -1.1816912491146985, 'log_learning_rate_D': -3.535786306627106, 'log_learning_rate_D_dagger': -3.510320639641831, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(35.0052, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  926.1123046875
Memory cached:  1612.0
[I 2024-02-28 13:12:29,642] Trial 2 finished with value: 0.7369760870933533 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -1.1816912491146985, 'log_learning_rate_D': -3.535786306627106, 'log_learning_rate_D_dagger': -3.510320639641831, 'training_batch_size': 7, 'training_p': 3}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.7370, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  42.6392502784729
Memory status after this trial: 
Memory allocated:  1569.97607421875
Memory cached:  1598.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.3627029188328637, 'log_learning_rate_D': -3.7303490922426548, 'log_learning_rate_D_dagger': -4.310117092253887, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8770, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  914.0498046875
Memory cached:  1572.0
[I 2024-02-28 13:13:45,629] Trial 3 finished with value: 0.6799643635749817 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.3627029188328637, 'log_learning_rate_D': -3.7303490922426548, 'log_learning_rate_D_dagger': -4.310117092253887, 'training_batch_size': 6, 'training_p': 6}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.6800, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  75.08590269088745
Memory status after this trial: 
Memory allocated:  1374.16943359375
Memory cached:  1572.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.636487149829756, 'log_learning_rate_D': -1.5230137193918587, 'log_learning_rate_D_dagger': -4.334598459896233, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0126, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  935.697265625
Memory cached:  1814.0
[I 2024-02-28 13:14:06,475] Trial 4 finished with value: 0.9618774652481079 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.636487149829756, 'log_learning_rate_D': -1.5230137193918587, 'log_learning_rate_D_dagger': -4.334598459896233, 'training_batch_size': 11, 'training_p': 4}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.9619, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  19.980857849121094
Memory status after this trial: 
Memory allocated:  2129.1201171875
Memory cached:  2162.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.459011790787187, 'log_learning_rate_D': -1.8750120252725058, 'log_learning_rate_D_dagger': -2.117194752609452, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0095, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  916.0107421875
Memory cached:  1682.0
[I 2024-02-28 13:14:19,419] Trial 5 finished with value: 0.4755113124847412 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.459011790787187, 'log_learning_rate_D': -1.8750120252725058, 'log_learning_rate_D_dagger': -2.117194752609452, 'training_batch_size': 11, 'training_p': 3}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.4755, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  12.137787342071533
Memory status after this trial: 
Memory allocated:  1537.9560546875
Memory cached:  1606.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.8694836073121817, 'log_learning_rate_D': -2.8417839334597996, 'log_learning_rate_D_dagger': -1.050392782519419, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(31577.4199, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  929.41064453125
Memory cached:  1632.0
[I 2024-02-28 13:15:08,151] Trial 6 finished with value: 426.2013854980469 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.8694836073121817, 'log_learning_rate_D': -2.8417839334597996, 'log_learning_rate_D_dagger': -1.050392782519419, 'training_batch_size': 7, 'training_p': 7}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(426.2014, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  40.691938638687134
Memory status after this trial: 
Memory allocated:  1571.4169921875
Memory cached:  1600.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -4.8555305456354, 'log_learning_rate_D': -2.0400656739133263, 'log_learning_rate_D_dagger': -3.7960781253951272, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9841, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  917.22998046875
Memory cached:  1580.0
[I 2024-02-28 13:15:34,201] Trial 7 finished with value: 0.8987019658088684 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -4.8555305456354, 'log_learning_rate_D': -2.0400656739133263, 'log_learning_rate_D_dagger': -3.7960781253951272, 'training_batch_size': 9, 'training_p': 3}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.8987, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  25.255924463272095
Memory status after this trial: 
Memory allocated:  1607.43359375
Memory cached:  1636.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.2475382671976867, 'log_learning_rate_D': -3.1196786243644836, 'log_learning_rate_D_dagger': -4.915437382546869, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7720, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  928.00244140625
Memory cached:  1576.0
[I 2024-02-28 13:16:19,309] Trial 8 finished with value: 0.5648543238639832 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.2475382671976867, 'log_learning_rate_D': -3.1196786243644836, 'log_learning_rate_D_dagger': -4.915437382546869, 'training_batch_size': 7, 'training_p': 3}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.5649, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  44.244646072387695
Memory status after this trial: 
Memory allocated:  1559.55078125
Memory cached:  1592.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -2.801963604578889, 'log_learning_rate_D': -4.040580414913243, 'log_learning_rate_D_dagger': -3.584337499567104, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8770, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  916.4130859375
Memory cached:  1580.0
[I 2024-02-28 13:16:49,017] Trial 9 finished with value: 0.7061923146247864 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -2.801963604578889, 'log_learning_rate_D': -4.040580414913243, 'log_learning_rate_D_dagger': -3.584337499567104, 'training_batch_size': 8, 'training_p': 8}. Best is trial 1 with value: 0.31982770562171936.
res:  tensor(0.7062, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.3198, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  26.15921902656555
Memory status after this trial: 
Memory allocated:  1485.58984375
Memory cached:  1580.0
