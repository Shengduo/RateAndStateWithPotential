[I 2024-03-01 07:32:12,440] A new study created in RDB with name: my_study1
Cuda is available:  True
Device is:  cuda
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial0216_combined_800.pt
Vs.shape:  torch.Size([800, 100])
thetas.shape:  torch.Size([800, 100])
fs.shape:  torch.Size([800, 100])
ts.shape:  torch.Size([800, 100])
Xs.shape:  torch.Size([800, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -2.876329842673198, 'log_learning_rate_D': -1.7263905183340387, 'log_learning_rate_D_dagger': -1.7751587305724579, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0025, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1728515625
Memory cached:  280.0
	 epoch  10 training error:  tensor(0.6478, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9228515625
Memory cached:  572.0
	 epoch  20 training error:  tensor(0.6616, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1728515625
Memory cached:  580.0
	 epoch  30 training error:  tensor(0.6623, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9228515625
Memory cached:  558.0
	 epoch  40 training error:  tensor(0.5714, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1728515625
Memory cached:  552.0
	 epoch  50 training error:  tensor(0.3941, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9228515625
Memory cached:  582.0
	 epoch  60 training error:  tensor(0.3528, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9228515625
Memory cached:  560.0
	 epoch  70 training error:  tensor(0.3801, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9228515625
Memory cached:  562.0
	 epoch  80 training error:  tensor(0.3817, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1728515625
Memory cached:  566.0
	 epoch  90 training error:  tensor(0.3554, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1728515625
Memory cached:  548.0
[I 2024-03-01 07:38:56,283] Trial 0 finished with value: 0.23779690265655518 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -2.876329842673198, 'log_learning_rate_D': -1.7263905183340387, 'log_learning_rate_D_dagger': -1.7751587305724579, 'training_batch_size': 10, 'training_p': 5}. Best is trial 0 with value: 0.23779690265655518.
res:  tensor(0.2378, grad_fn=<ToCopyBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  403.42404341697693
Memory status after this trial: 
Memory allocated:  835.33154296875
Memory cached:  858.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -3.4039862550030606, 'log_learning_rate_D': -4.766836598218072, 'log_learning_rate_D_dagger': -1.132941513228249, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9840, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1036.0
	 epoch  10 training error:  tensor(2.1214, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1198.0
	 epoch  20 training error:  tensor(0.6922, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1206.0
	 epoch  30 training error:  tensor(0.6095, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1204.0
	 epoch  40 training error:  tensor(0.5600, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1200.0
	 epoch  50 training error:  tensor(0.3909, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1202.0
	 epoch  60 training error:  tensor(0.4477, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1208.0
	 epoch  70 training error:  tensor(0.3830, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1210.0
	 epoch  80 training error:  tensor(0.3577, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1212.0
	 epoch  90 training error:  tensor(0.3606, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  840.65673828125
Memory cached:  1200.0
[I 2024-03-01 07:44:26,312] Trial 1 finished with value: 0.21908441185951233 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -3.4039862550030606, 'log_learning_rate_D': -4.766836598218072, 'log_learning_rate_D_dagger': -1.132941513228249, 'training_batch_size': 12, 'training_p': 6}. Best is trial 1 with value: 0.21908441185951233.
res:  tensor(0.2191, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.2378, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  329.63944149017334
Memory status after this trial: 
Memory allocated:  517.49658203125
Memory cached:  1062.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.5610831554111426, 'log_learning_rate_D': -4.3931210401030665, 'log_learning_rate_D_dagger': -4.135949106781026, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0467, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1104.0
	 epoch  10 training error:  tensor(0.5426, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1178.0
	 epoch  20 training error:  tensor(0.7130, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1176.0
	 epoch  30 training error:  tensor(0.3650, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1166.0
	 epoch  40 training error:  tensor(0.3520, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1176.0
	 epoch  50 training error:  tensor(0.3383, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1164.0
	 epoch  60 training error:  tensor(0.3454, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1178.0
	 epoch  70 training error:  tensor(0.3321, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1154.0
	 epoch  80 training error:  tensor(0.3308, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1176.0
	 epoch  90 training error:  tensor(0.3288, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  522.35693359375
Memory cached:  1180.0
[I 2024-03-01 07:50:16,646] Trial 2 finished with value: 0.218912273645401 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.5610831554111426, 'log_learning_rate_D': -4.3931210401030665, 'log_learning_rate_D_dagger': -4.135949106781026, 'training_batch_size': 10, 'training_p': 5}. Best is trial 2 with value: 0.218912273645401.
res:  tensor(0.2189, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.2191, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  349.9416825771332
Memory status after this trial: 
Memory allocated:  362.86279296875
Memory cached:  768.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -3.207727754327934, 'log_learning_rate_D': -4.987567753692063, 'log_learning_rate_D_dagger': -4.493450086782318, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0644, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  864.0
	 epoch  10 training error:  tensor(0.5833, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  948.0
	 epoch  20 training error:  tensor(0.5118, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  956.0
	 epoch  30 training error:  tensor(0.3989, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  956.0
	 epoch  40 training error:  tensor(0.2670, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  952.0
	 epoch  50 training error:  tensor(0.2417, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  952.0
	 epoch  60 training error:  tensor(0.2268, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  950.0
	 epoch  70 training error:  tensor(0.2254, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  970.0
	 epoch  80 training error:  tensor(0.2212, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  938.0
	 epoch  90 training error:  tensor(0.2196, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  380.30126953125
Memory cached:  960.0
[I 2024-03-01 07:57:11,975] Trial 3 finished with value: 0.22159424424171448 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -3.207727754327934, 'log_learning_rate_D': -4.987567753692063, 'log_learning_rate_D_dagger': -4.493450086782318, 'training_batch_size': 11, 'training_p': 2}. Best is trial 2 with value: 0.218912273645401.
Time for this trial:  414.9662911891937
Memory status after this trial: 
Memory allocated:  1077.4794921875
Memory cached:  1104.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.1051842323742243, 'log_learning_rate_D': -4.219172398728812, 'log_learning_rate_D_dagger': -4.427868230452528, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(162.2878, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  808.0
	 epoch  10 training error:  tensor(1168.1742, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  802.0
	 epoch  20 training error:  tensor(24.5884, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  814.0
	 epoch  30 training error:  tensor(18.1059, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  814.0
	 epoch  40 training error:  tensor(1.2451, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  806.0
	 epoch  50 training error:  tensor(0.6059, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  820.0
	 epoch  60 training error:  tensor(0.6335, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  808.0
	 epoch  70 training error:  tensor(0.5858, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  806.0
	 epoch  80 training error:  tensor(0.5438, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  812.0
	 epoch  90 training error:  tensor(0.5221, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  376.0166015625
Memory cached:  816.0
[I 2024-03-01 08:12:35,357] Trial 4 finished with value: 0.4579746425151825 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.1051842323742243, 'log_learning_rate_D': -4.219172398728812, 'log_learning_rate_D_dagger': -4.427868230452528, 'training_batch_size': 8, 'training_p': 3}. Best is trial 2 with value: 0.218912273645401.
Time for this trial:  922.740453004837
Memory status after this trial: 
Memory allocated:  1038.90771484375
Memory cached:  1070.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.310388938897606, 'log_learning_rate_D': -2.4029480824326277, 'log_learning_rate_D_dagger': -2.829419028299656, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9908, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  954.0
	 epoch  10 training error:  tensor(0.3514, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1020.0
	 epoch  20 training error:  tensor(0.3075, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1040.0
	 epoch  30 training error:  tensor(0.3019, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1044.0
	 epoch  40 training error:  tensor(0.2976, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1050.0
	 epoch  50 training error:  tensor(0.2934, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1034.0
	 epoch  60 training error:  tensor(0.2870, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1036.0
	 epoch  70 training error:  tensor(0.2876, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1032.0
	 epoch  80 training error:  tensor(0.2888, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1062.0
	 epoch  90 training error:  tensor(0.2886, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  389.36572265625
Memory cached:  1040.0
[I 2024-03-01 08:19:50,135] Trial 5 finished with value: 0.19881682097911835 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.310388938897606, 'log_learning_rate_D': -2.4029480824326277, 'log_learning_rate_D_dagger': -2.829419028299656, 'training_batch_size': 12, 'training_p': 4}. Best is trial 5 with value: 0.19881682097911835.
res:  tensor(0.1988, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.2189, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  434.29022336006165
Memory status after this trial: 
Memory allocated:  776.0146484375
Memory cached:  1132.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.473830775374605, 'log_learning_rate_D': -3.594800608798616, 'log_learning_rate_D_dagger': -3.8556130775781727, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9846, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.7529296875
Memory cached:  1324.0
	 epoch  10 training error:  tensor(0.7295, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  797.2529296875
Memory cached:  1564.0
	 epoch  20 training error:  tensor(0.5476, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  797.2529296875
Memory cached:  1568.0
	 epoch  30 training error:  tensor(0.4320, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.59228515625
Memory cached:  1570.0
	 epoch  40 training error:  tensor(0.3468, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.7529296875
Memory cached:  1576.0
	 epoch  50 training error:  tensor(0.3256, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.7529296875
Memory cached:  1566.0
	 epoch  60 training error:  tensor(0.3180, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.7529296875
Memory cached:  1568.0
	 epoch  70 training error:  tensor(0.3124, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  797.2529296875
Memory cached:  1570.0
	 epoch  80 training error:  tensor(0.3091, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  797.2529296875
Memory cached:  1562.0
	 epoch  90 training error:  tensor(0.3059, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  796.7529296875
Memory cached:  1558.0
[I 2024-03-01 08:27:34,262] Trial 6 finished with value: 0.2205505669116974 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.473830775374605, 'log_learning_rate_D': -3.594800608798616, 'log_learning_rate_D_dagger': -3.8556130775781727, 'training_batch_size': 11, 'training_p': 4}. Best is trial 5 with value: 0.19881682097911835.
Time for this trial:  463.73887753486633
Memory status after this trial: 
Memory allocated:  1973.74169921875
Memory cached:  1998.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.7158302410125437, 'log_learning_rate_D': -4.0715690982473935, 'log_learning_rate_D_dagger': -1.9165455707029593, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9963, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1272.0
	 epoch  10 training error:  tensor(0.5090, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1432.0
	 epoch  20 training error:  tensor(0.5239, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1434.0
	 epoch  30 training error:  tensor(0.4029, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1432.0
	 epoch  40 training error:  tensor(0.4134, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1438.0
	 epoch  50 training error:  tensor(0.3891, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1438.0
	 epoch  60 training error:  tensor(0.4020, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1424.0
	 epoch  70 training error:  tensor(0.4016, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1440.0
	 epoch  80 training error:  tensor(0.3898, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1440.0
	 epoch  90 training error:  tensor(0.3958, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  788.77099609375
Memory cached:  1434.0
[I 2024-03-01 08:35:28,239] Trial 7 finished with value: 0.22201107442378998 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.7158302410125437, 'log_learning_rate_D': -4.0715690982473935, 'log_learning_rate_D_dagger': -1.9165455707029593, 'training_batch_size': 10, 'training_p': 8}. Best is trial 5 with value: 0.19881682097911835.
Time for this trial:  473.483341217041
Memory status after this trial: 
Memory allocated:  1661.63330078125
Memory cached:  1690.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -4.287580002656933, 'log_learning_rate_D': -1.2496795935609448, 'log_learning_rate_D_dagger': -4.0711929150854935, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1943, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1224.0
	 epoch  10 training error:  tensor(0.6307, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1222.0
	 epoch  20 training error:  tensor(0.6307, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1222.0
	 epoch  30 training error:  tensor(0.6306, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1222.0
	 epoch  40 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1216.0
	 epoch  50 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1232.0
	 epoch  60 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1228.0
	 epoch  70 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1228.0
	 epoch  80 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1228.0
	 epoch  90 training error:  tensor(0.6305, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  813.98681640625
Memory cached:  1226.0
[I 2024-03-01 08:53:54,738] Trial 8 finished with value: 0.6089797019958496 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -4.287580002656933, 'log_learning_rate_D': -1.2496795935609448, 'log_learning_rate_D_dagger': -4.0711929150854935, 'training_batch_size': 8, 'training_p': 3}. Best is trial 5 with value: 0.19881682097911835.
Time for this trial:  1106.0067496299744
Memory status after this trial: 
Memory allocated:  1962.904296875
Memory cached:  1990.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -2.872943474903245, 'log_learning_rate_D': -2.3958967990803157, 'log_learning_rate_D_dagger': -3.621852005690122, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0635, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1152.0
	 epoch  10 training error:  tensor(0.4465, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1178.0
	 epoch  20 training error:  tensor(0.4041, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1180.0
	 epoch  30 training error:  tensor(0.3914, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1184.0
	 epoch  40 training error:  tensor(0.3863, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1190.0
	 epoch  50 training error:  tensor(0.3776, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1184.0
	 epoch  60 training error:  tensor(0.3716, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1178.0
	 epoch  70 training error:  tensor(0.3555, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1182.0
	 epoch  80 training error:  tensor(0.3492, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1190.0
	 epoch  90 training error:  tensor(0.3467, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  787.5068359375
Memory cached:  1176.0
[I 2024-03-01 09:09:56,813] Trial 9 finished with value: 0.20622122287750244 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -2.872943474903245, 'log_learning_rate_D': -2.3958967990803157, 'log_learning_rate_D_dagger': -3.621852005690122, 'training_batch_size': 8, 'training_p': 8}. Best is trial 5 with value: 0.19881682097911835.
Time for this trial:  961.5814335346222
Memory status after this trial: 
Memory allocated:  1351.48779296875
Memory cached:  1378.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.787981079750564, 'log_learning_rate_D': -2.7490072012995754, 'log_learning_rate_D_dagger': -2.6262685479195746, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.6804, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1242.0
	 epoch  10 training error:  tensor(0.3495, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1242.0
	 epoch  20 training error:  tensor(0.3269, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  30 training error:  tensor(0.3258, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  40 training error:  tensor(0.3098, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  50 training error:  tensor(0.3026, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  60 training error:  tensor(0.2804, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  70 training error:  tensor(0.2524, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  80 training error:  tensor(0.2424, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
	 epoch  90 training error:  tensor(0.2308, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  801.39306640625
Memory cached:  1240.0
[I 2024-03-01 10:07:05,573] Trial 10 finished with value: 0.15435023605823517 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.787981079750564, 'log_learning_rate_D': -2.7490072012995754, 'log_learning_rate_D_dagger': -2.6262685479195746, 'training_batch_size': 6, 'training_p': 6}. Best is trial 10 with value: 0.15435023605823517.
res:  tensor(0.1544, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.1988, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3427.7361567020416
Memory status after this trial: 
Memory allocated:  975.60693359375
Memory cached:  1478.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.975219313014927, 'log_learning_rate_D': -2.7897243212031446, 'log_learning_rate_D_dagger': -2.8617234705627963, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8156, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  10 training error:  tensor(0.3252, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  20 training error:  tensor(0.3157, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  30 training error:  tensor(0.3139, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  40 training error:  tensor(0.3014, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  50 training error:  tensor(0.2489, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  60 training error:  tensor(0.2208, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  70 training error:  tensor(0.1927, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  80 training error:  tensor(0.1879, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
	 epoch  90 training error:  tensor(0.1756, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1000.736328125
Memory cached:  1482.0
[I 2024-03-01 11:05:07,380] Trial 11 finished with value: 0.1404559463262558 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.975219313014927, 'log_learning_rate_D': -2.7897243212031446, 'log_learning_rate_D_dagger': -2.8617234705627963, 'training_batch_size': 6, 'training_p': 6}. Best is trial 11 with value: 0.1404559463262558.
res:  tensor(0.1405, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.1544, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3480.8031237125397
Memory status after this trial: 
Memory allocated:  975.60693359375
Memory cached:  1462.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.9534710094007375, 'log_learning_rate_D': -3.105366065311643, 'log_learning_rate_D_dagger': -2.865895373659833, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6356, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1572.0
	 epoch  10 training error:  tensor(0.3686, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  20 training error:  tensor(0.3640, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  30 training error:  tensor(0.3611, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  40 training error:  tensor(0.3592, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  50 training error:  tensor(0.3574, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  60 training error:  tensor(0.3559, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  70 training error:  tensor(0.3251, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  80 training error:  tensor(0.3082, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
	 epoch  90 training error:  tensor(0.4545, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1010.455078125
Memory cached:  1584.0
[I 2024-03-01 12:00:15,080] Trial 12 finished with value: 0.12159967422485352 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.9534710094007375, 'log_learning_rate_D': -3.105366065311643, 'log_learning_rate_D_dagger': -2.865895373659833, 'training_batch_size': 6, 'training_p': 7}. Best is trial 12 with value: 0.12159967422485352.
res:  tensor(0.1216, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.1405, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3306.7995312213898
Memory status after this trial: 
Memory allocated:  1134.958984375
Memory cached:  1636.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.932021446227949, 'log_learning_rate_D': -3.3257535755644216, 'log_learning_rate_D_dagger': -3.2758434304116637, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6063, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1702.0
	 epoch  10 training error:  tensor(0.3651, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1702.0
	 epoch  20 training error:  tensor(0.2575, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1698.0
	 epoch  30 training error:  tensor(0.2762, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1698.0
	 epoch  40 training error:  tensor(0.2760, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1700.0
	 epoch  50 training error:  tensor(0.2468, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1696.0
	 epoch  60 training error:  tensor(0.2466, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1696.0
	 epoch  70 training error:  tensor(0.2467, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1698.0
	 epoch  80 training error:  tensor(0.2469, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1696.0
	 epoch  90 training error:  tensor(0.2466, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1182.84423828125
Memory cached:  1698.0
[I 2024-03-01 12:56:52,377] Trial 13 finished with value: 0.15494583547115326 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.932021446227949, 'log_learning_rate_D': -3.3257535755644216, 'log_learning_rate_D_dagger': -3.2758434304116637, 'training_batch_size': 6, 'training_p': 7}. Best is trial 12 with value: 0.12159967422485352.
Time for this trial:  3396.3926515579224
Memory status after this trial: 
Memory allocated:  2834.42333984375
Memory cached:  2876.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.129857282987435, 'log_learning_rate_D': -3.008578502323868, 'log_learning_rate_D_dagger': -2.3844750960053074, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6657, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
	 epoch  10 training error:  tensor(0.3719, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
	 epoch  20 training error:  tensor(0.3757, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
	 epoch  30 training error:  tensor(0.3621, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1636.0
	 epoch  40 training error:  tensor(0.3540, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1642.0
	 epoch  50 training error:  tensor(0.3556, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1640.0
	 epoch  60 training error:  tensor(0.3257, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1636.0
	 epoch  70 training error:  tensor(0.2146, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
	 epoch  80 training error:  tensor(0.1692, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
	 epoch  90 training error:  tensor(0.1497, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1151.435546875
Memory cached:  1638.0
[I 2024-03-01 13:27:36,887] Trial 14 finished with value: 0.12752662599086761 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.129857282987435, 'log_learning_rate_D': -3.008578502323868, 'log_learning_rate_D_dagger': -2.3844750960053074, 'training_batch_size': 7, 'training_p': 7}. Best is trial 12 with value: 0.12159967422485352.
Time for this trial:  1843.675437450409
Memory status after this trial: 
Memory allocated:  1974.3115234375
Memory cached:  1996.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.7912767737190762, 'log_learning_rate_D': -3.450572753138181, 'log_learning_rate_D_dagger': -2.2772223218250205, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0231, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1642.0
	 epoch  10 training error:  tensor(0.3760, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1650.0
	 epoch  20 training error:  tensor(0.3678, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1646.0
	 epoch  30 training error:  tensor(0.3607, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1644.0
	 epoch  40 training error:  tensor(0.3565, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1646.0
	 epoch  50 training error:  tensor(0.3175, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1644.0
	 epoch  60 training error:  tensor(0.2031, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1650.0
	 epoch  70 training error:  tensor(0.1964, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1644.0
	 epoch  80 training error:  tensor(0.1552, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1648.0
	 epoch  90 training error:  tensor(0.1490, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1153.78076171875
Memory cached:  1650.0
[I 2024-03-01 13:57:26,002] Trial 15 finished with value: 0.07262938469648361 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.7912767737190762, 'log_learning_rate_D': -3.450572753138181, 'log_learning_rate_D_dagger': -2.2772223218250205, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.07262938469648361.
res:  tensor(0.0726, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.1216, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  1785.489902496338
Memory status after this trial: 
Memory allocated:  950.724609375
Memory cached:  1608.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.7857733571316494, 'log_learning_rate_D': -3.625923163117787, 'log_learning_rate_D_dagger': -2.1080463066915183, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.2034, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1528.0
	 epoch  10 training error:  tensor(0.3741, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1526.0
	 epoch  20 training error:  tensor(0.3675, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
	 epoch  30 training error:  tensor(0.3596, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1526.0
	 epoch  40 training error:  tensor(0.3433, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
	 epoch  50 training error:  tensor(0.3445, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
	 epoch  60 training error:  tensor(0.3453, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
	 epoch  70 training error:  tensor(0.3308, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
	 epoch  80 training error:  tensor(0.3163, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1526.0
	 epoch  90 training error:  tensor(0.2712, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  960.8359375
Memory cached:  1524.0
[I 2024-03-01 14:27:22,458] Trial 16 finished with value: 0.11692693084478378 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.7857733571316494, 'log_learning_rate_D': -3.625923163117787, 'log_learning_rate_D_dagger': -2.1080463066915183, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  1795.6399774551392
Memory status after this trial: 
Memory allocated:  1754.984375
Memory cached:  1784.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.7117061351477894, 'log_learning_rate_D': -3.812663079946188, 'log_learning_rate_D_dagger': -2.0626238288164003, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.7479, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1524.0
	 epoch  10 training error:  tensor(0.3653, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1526.0
	 epoch  20 training error:  tensor(0.3094, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1524.0
	 epoch  30 training error:  tensor(0.1994, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1528.0
	 epoch  40 training error:  tensor(0.1696, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1526.0
	 epoch  50 training error:  tensor(0.1181, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1524.0
	 epoch  60 training error:  tensor(0.1106, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1528.0
	 epoch  70 training error:  tensor(0.0986, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1526.0
	 epoch  80 training error:  tensor(0.0945, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1524.0
	 epoch  90 training error:  tensor(0.1194, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  964.021484375
Memory cached:  1528.0
[I 2024-03-01 14:58:55,965] Trial 17 finished with value: 1.8042891025543213 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.7117061351477894, 'log_learning_rate_D': -3.812663079946188, 'log_learning_rate_D_dagger': -2.0626238288164003, 'training_batch_size': 7, 'training_p': 8}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  1892.7325704097748
Memory status after this trial: 
Memory allocated:  1874.64501953125
Memory cached:  1906.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.260877498776759, 'log_learning_rate_D': -3.684418703455768, 'log_learning_rate_D_dagger': -1.2451771653895825, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(63.8288, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1532.0
	 epoch  10 training error:  tensor(0.4571, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1532.0
	 epoch  20 training error:  tensor(0.4508, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1532.0
	 epoch  30 training error:  tensor(0.3616, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1528.0
	 epoch  40 training error:  tensor(0.4051, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1532.0
	 epoch  50 training error:  tensor(0.4281, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1534.0
	 epoch  60 training error:  tensor(0.3775, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1530.0
	 epoch  70 training error:  tensor(0.3660, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1530.0
	 epoch  80 training error:  tensor(0.3650, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1534.0
	 epoch  90 training error:  tensor(0.7461, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.65869140625
Memory cached:  1530.0
[I 2024-03-01 15:28:40,809] Trial 18 finished with value: 0.21994610130786896 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.260877498776759, 'log_learning_rate_D': -3.684418703455768, 'log_learning_rate_D_dagger': -1.2451771653895825, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  1784.1232013702393
Memory status after this trial: 
Memory allocated:  1979.4482421875
Memory cached:  2016.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.821110579074639, 'log_learning_rate_D': -2.182451918165141, 'log_learning_rate_D_dagger': -1.4883318167901207, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.4223, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  10 training error:  tensor(0.7235, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  20 training error:  tensor(0.6513, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  30 training error:  tensor(0.6512, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  40 training error:  tensor(0.6502, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  50 training error:  tensor(0.6507, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  60 training error:  tensor(0.6510, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  70 training error:  tensor(0.6513, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  80 training error:  tensor(0.6527, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
	 epoch  90 training error:  tensor(0.6525, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  955.7705078125
Memory cached:  1522.0
[I 2024-03-01 15:40:45,826] Trial 19 finished with value: 0.6093716025352478 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.821110579074639, 'log_learning_rate_D': -2.182451918165141, 'log_learning_rate_D_dagger': -1.4883318167901207, 'training_batch_size': 9, 'training_p': 6}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  724.2828440666199
Memory status after this trial: 
Memory allocated:  1580.16259765625
Memory cached:  1606.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.1388374442824607, 'log_learning_rate_D': -3.399690413777546, 'log_learning_rate_D_dagger': -2.3199062595229947, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.5900, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  10 training error:  tensor(0.4431, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  20 training error:  tensor(0.3773, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  30 training error:  tensor(0.3274, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  40 training error:  tensor(0.3153, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  50 training error:  tensor(0.3166, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  60 training error:  tensor(0.3251, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  70 training error:  tensor(0.3187, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  80 training error:  tensor(0.2998, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
	 epoch  90 training error:  tensor(0.3421, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  954.5908203125
Memory cached:  1520.0
[I 2024-03-01 15:50:20,604] Trial 20 finished with value: 0.2502809166908264 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.1388374442824607, 'log_learning_rate_D': -3.399690413777546, 'log_learning_rate_D_dagger': -2.3199062595229947, 'training_batch_size': 9, 'training_p': 5}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  574.257973909378
Memory status after this trial: 
Memory allocated:  1347.84619140625
Memory cached:  1520.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.7503270152755324, 'log_learning_rate_D': -3.147309233702836, 'log_learning_rate_D_dagger': -3.412392186805879, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8158, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
	 epoch  10 training error:  tensor(0.3807, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1584.0
	 epoch  20 training error:  tensor(0.3691, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1584.0
	 epoch  30 training error:  tensor(0.3628, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1584.0
	 epoch  40 training error:  tensor(0.3589, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1584.0
	 epoch  50 training error:  tensor(0.3568, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
	 epoch  60 training error:  tensor(0.3576, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
	 epoch  70 training error:  tensor(0.3846, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
	 epoch  80 training error:  tensor(0.3290, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
	 epoch  90 training error:  tensor(0.2872, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  968.01220703125
Memory cached:  1582.0
[I 2024-03-01 16:17:52,164] Trial 21 finished with value: 0.1673801690340042 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.7503270152755324, 'log_learning_rate_D': -3.147309233702836, 'log_learning_rate_D_dagger': -3.412392186805879, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.07262938469648361.
Time for this trial:  1650.7943630218506
Memory status after this trial: 
Memory allocated:  1791.69775390625
Memory cached:  1818.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.4039401912870453, 'log_learning_rate_D': -3.779396953521222, 'log_learning_rate_D_dagger': -3.144408468685878, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5703, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  10 training error:  tensor(0.3619, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  20 training error:  tensor(0.2800, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  30 training error:  tensor(0.1884, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  40 training error:  tensor(0.1666, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  50 training error:  tensor(0.1066, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  60 training error:  tensor(0.0904, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  70 training error:  tensor(0.0754, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  80 training error:  tensor(0.0740, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
	 epoch  90 training error:  tensor(0.0749, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  972.3037109375
Memory cached:  1580.0
[I 2024-03-01 17:16:19,807] Trial 22 finished with value: 0.047714147716760635 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.4039401912870453, 'log_learning_rate_D': -3.779396953521222, 'log_learning_rate_D_dagger': -3.144408468685878, 'training_batch_size': 6, 'training_p': 7}. Best is trial 22 with value: 0.047714147716760635.
res:  tensor(0.0477, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.0726, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3506.6546652317047
Memory status after this trial: 
Memory allocated:  949.34033203125
Memory cached:  1604.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.4744499380824365, 'log_learning_rate_D': -4.497474780995899, 'log_learning_rate_D_dagger': -4.875804607579463, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9131, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  10 training error:  tensor(0.5423, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  20 training error:  tensor(0.4335, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1500.0
	 epoch  30 training error:  tensor(0.3980, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  40 training error:  tensor(0.3931, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  50 training error:  tensor(0.3827, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  60 training error:  tensor(0.3763, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  70 training error:  tensor(0.3703, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  80 training error:  tensor(0.3645, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
	 epoch  90 training error:  tensor(0.3580, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  969.74365234375
Memory cached:  1498.0
[I 2024-03-01 17:45:39,055] Trial 23 finished with value: 0.19108577072620392 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.4744499380824365, 'log_learning_rate_D': -4.497474780995899, 'log_learning_rate_D_dagger': -4.875804607579463, 'training_batch_size': 7, 'training_p': 8}. Best is trial 22 with value: 0.047714147716760635.
Time for this trial:  1758.6489717960358
Memory status after this trial: 
Memory allocated:  1909.921875
Memory cached:  1940.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.1953611161063247, 'log_learning_rate_D': -4.047485636187622, 'log_learning_rate_D_dagger': -2.3904582423158565, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.4544, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1462.0
	 epoch  10 training error:  tensor(0.4019, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
	 epoch  20 training error:  tensor(0.3767, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
	 epoch  30 training error:  tensor(0.3737, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1464.0
	 epoch  40 training error:  tensor(0.4069, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1458.0
	 epoch  50 training error:  tensor(0.3911, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
	 epoch  60 training error:  tensor(0.3847, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
	 epoch  70 training error:  tensor(0.3818, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
	 epoch  80 training error:  tensor(0.3666, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1464.0
	 epoch  90 training error:  tensor(0.3552, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  963.95849609375
Memory cached:  1460.0
[I 2024-03-01 18:04:40,037] Trial 24 finished with value: 0.19967451691627502 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.1953611161063247, 'log_learning_rate_D': -4.047485636187622, 'log_learning_rate_D_dagger': -2.3904582423158565, 'training_batch_size': 8, 'training_p': 7}. Best is trial 22 with value: 0.047714147716760635.
Time for this trial:  1140.3559167385101
Memory status after this trial: 
Memory allocated:  2036.23583984375
Memory cached:  2072.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.539982167833467, 'log_learning_rate_D': -3.7868008467359835, 'log_learning_rate_D_dagger': -3.2356114995925633, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7018, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  10 training error:  tensor(0.3408, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  20 training error:  tensor(0.2445, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  30 training error:  tensor(0.1644, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  40 training error:  tensor(0.1214, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1630.0
	 epoch  50 training error:  tensor(0.1164, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  60 training error:  tensor(0.0951, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  70 training error:  tensor(0.0897, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  80 training error:  tensor(0.0557, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
	 epoch  90 training error:  tensor(0.0793, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1024.4208984375
Memory cached:  1628.0
[I 2024-03-01 18:56:10,201] Trial 25 finished with value: 0.03546123579144478 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.539982167833467, 'log_learning_rate_D': -3.7868008467359835, 'log_learning_rate_D_dagger': -3.2356114995925633, 'training_batch_size': 6, 'training_p': 6}. Best is trial 25 with value: 0.03546123579144478.
res:  tensor(0.0355, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.0477, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3089.1153717041016
Memory status after this trial: 
Memory allocated:  1547.6181640625
Memory cached:  1886.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.0590957592830272, 'log_learning_rate_D': -3.8967268803643393, 'log_learning_rate_D_dagger': -3.2107627242637515, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9541, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1636.19189453125
Memory cached:  2068.0
	 epoch  10 training error:  tensor(0.3392, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2040.0
	 epoch  20 training error:  tensor(0.1922, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2056.0
	 epoch  30 training error:  tensor(0.1391, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2046.0
	 epoch  40 training error:  tensor(0.0691, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2054.0
	 epoch  50 training error:  tensor(0.0674, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2046.0
	 epoch  60 training error:  tensor(0.0437, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2050.0
	 epoch  70 training error:  tensor(0.0458, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2052.0
	 epoch  80 training error:  tensor(0.0538, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2044.0
	 epoch  90 training error:  tensor(0.0540, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1635.59521484375
Memory cached:  2052.0
[I 2024-03-01 19:56:11,242] Trial 26 finished with value: 0.02490043081343174 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.0590957592830272, 'log_learning_rate_D': -3.8967268803643393, 'log_learning_rate_D_dagger': -3.2107627242637515, 'training_batch_size': 6, 'training_p': 6}. Best is trial 26 with value: 0.02490043081343174.
res:  tensor(0.0249, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.0355, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3599.980217218399
Memory status after this trial: 
Memory allocated:  1713.65576171875
Memory cached:  2334.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.4329896147360675, 'log_learning_rate_D': -3.863540420309323, 'log_learning_rate_D_dagger': -3.251274524224219, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.8426, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2422.0
	 epoch  10 training error:  tensor(0.3262, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2390.0
	 epoch  20 training error:  tensor(0.1673, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2390.0
	 epoch  30 training error:  tensor(0.0980, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2392.0
	 epoch  40 training error:  tensor(0.1105, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2392.0
	 epoch  50 training error:  tensor(0.0492, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2394.0
	 epoch  60 training error:  tensor(0.0597, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2392.0
	 epoch  70 training error:  tensor(0.0573, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2398.0
	 epoch  80 training error:  tensor(0.0440, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2404.0
	 epoch  90 training error:  tensor(0.0574, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.54345703125
Memory cached:  2404.0
[I 2024-03-01 20:52:31,963] Trial 27 finished with value: 0.019390789791941643 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.4329896147360675, 'log_learning_rate_D': -3.863540420309323, 'log_learning_rate_D_dagger': -3.251274524224219, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
res:  tensor(0.0194, grad_fn=<ToCopyBackward0>)
self.bestValue:  tensor(0.0249, grad_fn=<ToCopyBackward0>)
Save this model!
Time for this trial:  3379.3799633979797
Memory status after this trial: 
Memory allocated:  1719.46044921875
Memory cached:  2976.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.2615444388810264, 'log_learning_rate_D': -4.727604810018816, 'log_learning_rate_D_dagger': -3.584174072796479, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(8.1350, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3182, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.3059, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.2943, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.2064, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.1549, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.1317, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.1225, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.1238, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.1080, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1760.169921875
Memory cached:  2716.0
[I 2024-03-01 21:45:01,849] Trial 28 finished with value: 0.05938718467950821 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.2615444388810264, 'log_learning_rate_D': -4.727604810018816, 'log_learning_rate_D_dagger': -3.584174072796479, 'training_batch_size': 6, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3148.973320007324
Memory status after this trial: 
Memory allocated:  3102.8154296875
Memory cached:  3138.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.9459569366934066, 'log_learning_rate_D': -4.024254709790286, 'log_learning_rate_D_dagger': -3.1028139954730634, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(5.6250, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.39013671875
Memory cached:  2736.0
	 epoch  10 training error:  tensor(0.3312, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.2372, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.1004, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.0882, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.0780, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0517, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0645, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0529, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0572, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1790.3974609375
Memory cached:  2716.0
[I 2024-03-01 22:42:00,689] Trial 29 finished with value: 0.05953236296772957 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.9459569366934066, 'log_learning_rate_D': -4.024254709790286, 'log_learning_rate_D_dagger': -3.1028139954730634, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3417.9856338500977
Memory status after this trial: 
Memory allocated:  3401.2294921875
Memory cached:  3432.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -2.576059520046725, 'log_learning_rate_D': -4.325837907259867, 'log_learning_rate_D_dagger': -3.7329740483320624, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4304, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2782.0
	 epoch  10 training error:  tensor(0.3443, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  20 training error:  tensor(0.3107, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  30 training error:  tensor(0.2920, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  40 training error:  tensor(0.2871, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  50 training error:  tensor(0.2873, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  60 training error:  tensor(0.2838, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  70 training error:  tensor(0.2791, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  80 training error:  tensor(0.2781, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
	 epoch  90 training error:  tensor(0.2791, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.24951171875
Memory cached:  2802.0
[I 2024-03-01 22:58:03,488] Trial 30 finished with value: 0.199973002076149 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -2.576059520046725, 'log_learning_rate_D': -4.325837907259867, 'log_learning_rate_D_dagger': -3.7329740483320624, 'training_batch_size': 9, 'training_p': 4}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  962.1722898483276
Memory status after this trial: 
Memory allocated:  3332.98974609375
Memory cached:  3376.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.7234747138004531, 'log_learning_rate_D': -3.849874935566011, 'log_learning_rate_D_dagger': -3.2112611651996095, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.8023, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3271, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.2124, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.0972, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.0842, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.0757, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0821, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0898, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0551, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0614, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.0830078125
Memory cached:  2716.0
[I 2024-03-01 23:58:10,984] Trial 31 finished with value: 0.029591655358672142 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.7234747138004531, 'log_learning_rate_D': -3.849874935566011, 'log_learning_rate_D_dagger': -3.2112611651996095, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3606.5824019908905
Memory status after this trial: 
Memory allocated:  3056.80224609375
Memory cached:  3092.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.733797580896419, 'log_learning_rate_D': -3.9249022166760774, 'log_learning_rate_D_dagger': -3.3841555536756025, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(12.5897, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  10 training error:  tensor(0.3144, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  20 training error:  tensor(0.1472, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  30 training error:  tensor(0.1283, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  40 training error:  tensor(0.0559, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  50 training error:  tensor(0.0697, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  60 training error:  tensor(0.0597, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  70 training error:  tensor(0.0407, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.0469, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
	 epoch  90 training error:  tensor(0.0569, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2696.0
[I 2024-03-02 00:57:32,221] Trial 32 finished with value: 0.0412452295422554 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.733797580896419, 'log_learning_rate_D': -3.9249022166760774, 'log_learning_rate_D_dagger': -3.3841555536756025, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3560.167883872986
Memory status after this trial: 
Memory allocated:  3236.86962890625
Memory cached:  3274.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.536585979243136, 'log_learning_rate_D': -4.533108054745481, 'log_learning_rate_D_dagger': -2.6612090311159173, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3478, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  10 training error:  tensor(0.3055, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  20 training error:  tensor(0.1798, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  30 training error:  tensor(0.1181, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  40 training error:  tensor(0.0749, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  50 training error:  tensor(0.0832, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  60 training error:  tensor(0.0548, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  70 training error:  tensor(0.0424, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  80 training error:  tensor(0.0422, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
	 epoch  90 training error:  tensor(0.0404, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.28369140625
Memory cached:  2770.0
[I 2024-03-02 01:49:48,874] Trial 33 finished with value: 0.046138763427734375 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.536585979243136, 'log_learning_rate_D': -4.533108054745481, 'log_learning_rate_D_dagger': -2.6612090311159173, 'training_batch_size': 6, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3135.8213546276093
Memory status after this trial: 
Memory allocated:  3132.291015625
Memory cached:  3156.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -2.603445569416748, 'log_learning_rate_D': -4.22253528924519, 'log_learning_rate_D_dagger': -3.9316955733355554, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7186, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2720.0
	 epoch  10 training error:  tensor(0.3474, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2726.0
	 epoch  20 training error:  tensor(0.3299, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2728.0
	 epoch  30 training error:  tensor(0.3105, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2724.0
	 epoch  40 training error:  tensor(0.2381, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2722.0
	 epoch  50 training error:  tensor(0.1689, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2726.0
	 epoch  60 training error:  tensor(0.1486, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2726.0
	 epoch  70 training error:  tensor(0.1169, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2722.0
	 epoch  80 training error:  tensor(0.0940, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2726.0
	 epoch  90 training error:  tensor(0.0911, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.16162109375
Memory cached:  2722.0
[I 2024-03-02 02:19:45,019] Trial 34 finished with value: 0.07839250564575195 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -2.603445569416748, 'log_learning_rate_D': -4.22253528924519, 'log_learning_rate_D_dagger': -3.9316955733355554, 'training_batch_size': 7, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1795.4751119613647
Memory status after this trial: 
Memory allocated:  2996.81787109375
Memory cached:  3036.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -1.2829090606710667, 'log_learning_rate_D': -4.958377486210074, 'log_learning_rate_D_dagger': -3.4873233922113145, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(81.3846, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  10 training error:  tensor(1.0772, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  20 training error:  tensor(0.3470, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  30 training error:  tensor(0.3334, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  40 training error:  tensor(0.3111, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  50 training error:  tensor(0.2051, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  60 training error:  tensor(0.2685, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  70 training error:  tensor(0.1640, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.2029, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
	 epoch  90 training error:  tensor(2.0074, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1751.82275390625
Memory cached:  2696.0
[I 2024-03-02 03:12:22,367] Trial 35 finished with value: 0.10161173343658447 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -1.2829090606710667, 'log_learning_rate_D': -4.958377486210074, 'log_learning_rate_D_dagger': -3.4873233922113145, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3156.4874591827393
Memory status after this trial: 
Memory allocated:  2908.30419921875
Memory cached:  2950.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.9314142700996642, 'log_learning_rate_D': -3.406839738866288, 'log_learning_rate_D_dagger': -4.3151033378487345, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(3.5236, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  10 training error:  tensor(0.5028, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  20 training error:  tensor(0.3531, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  30 training error:  tensor(0.3401, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  40 training error:  tensor(0.3303, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  50 training error:  tensor(0.3208, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  60 training error:  tensor(0.3140, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  70 training error:  tensor(0.3094, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  80 training error:  tensor(0.3038, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
	 epoch  90 training error:  tensor(0.2994, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.2119140625
Memory cached:  2700.0
[I 2024-03-02 03:29:37,682] Trial 36 finished with value: 0.18340565264225006 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.9314142700996642, 'log_learning_rate_D': -3.406839738866288, 'log_learning_rate_D_dagger': -4.3151033378487345, 'training_batch_size': 8, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1034.6793801784515
Memory status after this trial: 
Memory allocated:  2808.2353515625
Memory cached:  2850.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.4025920208709417, 'log_learning_rate_D': -4.6476120216803185, 'log_learning_rate_D_dagger': -3.064857072262238, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9997, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  10 training error:  tensor(0.3111, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  20 training error:  tensor(0.2419, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  30 training error:  tensor(0.1738, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  40 training error:  tensor(0.1483, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  50 training error:  tensor(0.1379, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  60 training error:  tensor(0.0996, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  70 training error:  tensor(0.1212, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  80 training error:  tensor(0.1083, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
	 epoch  90 training error:  tensor(0.0798, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.0732421875
Memory cached:  2756.0
[I 2024-03-02 04:26:25,788] Trial 37 finished with value: 0.04492693766951561 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.4025920208709417, 'log_learning_rate_D': -4.6476120216803185, 'log_learning_rate_D_dagger': -3.064857072262238, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3406.9412384033203
Memory status after this trial: 
Memory allocated:  3337.482421875
Memory cached:  3372.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.3722565210741338, 'log_learning_rate_D': -4.18978220901657, 'log_learning_rate_D_dagger': -3.263203862126002, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(69.5767, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  10 training error:  tensor(0.3934, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  20 training error:  tensor(0.2856, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  30 training error:  tensor(37.9756, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  40 training error:  tensor(3.2087, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  50 training error:  tensor(0.3370, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  60 training error:  tensor(0.2805, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  70 training error:  tensor(0.2770, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  80 training error:  tensor(0.2748, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
	 epoch  90 training error:  tensor(0.2709, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1725.52734375
Memory cached:  2636.0
[I 2024-03-02 04:53:22,417] Trial 38 finished with value: 0.18489369750022888 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.3722565210741338, 'log_learning_rate_D': -4.18978220901657, 'log_learning_rate_D_dagger': -3.263203862126002, 'training_batch_size': 7, 'training_p': 4}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1615.8780007362366
Memory status after this trial: 
Memory allocated:  2493.33203125
Memory cached:  2636.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.9248511168167117, 'log_learning_rate_D': -3.893644983166852, 'log_learning_rate_D_dagger': -2.6415453106488433, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0117, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2656.0
	 epoch  10 training error:  tensor(0.4967, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2660.0
	 epoch  20 training error:  tensor(0.3751, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2658.0
	 epoch  30 training error:  tensor(0.3656, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2662.0
	 epoch  40 training error:  tensor(0.3438, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2664.0
	 epoch  50 training error:  tensor(0.3355, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2666.0
	 epoch  60 training error:  tensor(0.3267, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2662.0
	 epoch  70 training error:  tensor(0.3193, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2660.0
	 epoch  80 training error:  tensor(0.3171, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2662.0
	 epoch  90 training error:  tensor(0.3055, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1731.1552734375
Memory cached:  2660.0
[I 2024-03-02 05:01:18,305] Trial 39 finished with value: 0.1925772726535797 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.9248511168167117, 'log_learning_rate_D': -3.893644983166852, 'log_learning_rate_D_dagger': -2.6415453106488433, 'training_batch_size': 12, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  475.2915668487549
Memory status after this trial: 
Memory allocated:  2491.32958984375
Memory cached:  2646.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.9372780232838087, 'log_learning_rate_D': -4.391617598704332, 'log_learning_rate_D_dagger': -3.9773548421370997, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9341, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2646.0
	 epoch  10 training error:  tensor(0.6127, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2652.0
	 epoch  20 training error:  tensor(0.4040, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2656.0
	 epoch  30 training error:  tensor(0.3689, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2658.0
	 epoch  40 training error:  tensor(0.3607, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2654.0
	 epoch  50 training error:  tensor(0.3561, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2650.0
	 epoch  60 training error:  tensor(0.3490, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2654.0
	 epoch  70 training error:  tensor(0.3451, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2652.0
	 epoch  80 training error:  tensor(0.3418, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2656.0
	 epoch  90 training error:  tensor(0.3462, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1732.1279296875
Memory cached:  2650.0
[I 2024-03-02 05:07:32,144] Trial 40 finished with value: 0.20215237140655518 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.9372780232838087, 'log_learning_rate_D': -4.391617598704332, 'log_learning_rate_D_dagger': -3.9773548421370997, 'training_batch_size': 11, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  373.3282742500305
Memory status after this trial: 
Memory allocated:  2551.00048828125
Memory cached:  2644.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.7151267860337793, 'log_learning_rate_D': -3.943899556759779, 'log_learning_rate_D_dagger': -3.3814667248943606, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(3.6423, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3244, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.1773, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.1152, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.0964, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.0641, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0689, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0481, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0409, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0566, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1775.71533203125
Memory cached:  2716.0
[I 2024-03-02 06:04:04,001] Trial 41 finished with value: 0.04970167577266693 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.7151267860337793, 'log_learning_rate_D': -3.943899556759779, 'log_learning_rate_D_dagger': -3.3814667248943606, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3391.011830329895
Memory status after this trial: 
Memory allocated:  3138.9599609375
Memory cached:  3176.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.6940382311789484, 'log_learning_rate_D': -3.6354273907996664, 'log_learning_rate_D_dagger': -3.7248761032423063, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(5.0132, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  10 training error:  tensor(0.3380, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  20 training error:  tensor(0.3188, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  30 training error:  tensor(0.1245, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  40 training error:  tensor(0.0887, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  50 training error:  tensor(0.0591, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  60 training error:  tensor(0.0513, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  70 training error:  tensor(0.0514, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  80 training error:  tensor(0.0536, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
	 epoch  90 training error:  tensor(0.0578, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.68603515625
Memory cached:  2756.0
[I 2024-03-02 07:00:29,748] Trial 42 finished with value: 0.02172061800956726 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.6940382311789484, 'log_learning_rate_D': -3.6354273907996664, 'log_learning_rate_D_dagger': -3.7248761032423063, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3384.908411502838
Memory status after this trial: 
Memory allocated:  3146.26318359375
Memory cached:  3174.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -1.094514901795593, 'log_learning_rate_D': -3.564261947289918, 'log_learning_rate_D_dagger': -3.742981642600348, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(156.0055, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  10 training error:  tensor(0.4108, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  20 training error:  tensor(0.3417, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  30 training error:  tensor(0.3274, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  40 training error:  tensor(0.1973, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  50 training error:  tensor(0.1346, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  60 training error:  tensor(0.1027, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  70 training error:  tensor(0.1532, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.0862, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
	 epoch  90 training error:  tensor(0.0712, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1744.24951171875
Memory cached:  2696.0
[I 2024-03-02 07:55:54,233] Trial 43 finished with value: 0.05217823013663292 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -1.094514901795593, 'log_learning_rate_D': -3.564261947289918, 'log_learning_rate_D_dagger': -3.742981642600348, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3323.652185678482
Memory status after this trial: 
Memory allocated:  2653.5810546875
Memory cached:  2694.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.124778853089042, 'log_learning_rate_D': -3.303922476580392, 'log_learning_rate_D_dagger': -4.288850686905695, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.5866, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2726.0
	 epoch  10 training error:  tensor(0.3628, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2722.0
	 epoch  20 training error:  tensor(0.3300, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2722.0
	 epoch  30 training error:  tensor(0.3218, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2724.0
	 epoch  40 training error:  tensor(0.3168, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2724.0
	 epoch  50 training error:  tensor(0.3119, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2726.0
	 epoch  60 training error:  tensor(0.2971, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2724.0
	 epoch  70 training error:  tensor(0.2803, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2722.0
	 epoch  80 training error:  tensor(0.2734, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2724.0
	 epoch  90 training error:  tensor(0.2641, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1781.154296875
Memory cached:  2726.0
[I 2024-03-02 08:23:37,666] Trial 44 finished with value: 0.15978765487670898 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.124778853089042, 'log_learning_rate_D': -3.303922476580392, 'log_learning_rate_D_dagger': -4.288850686905695, 'training_batch_size': 7, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1662.5761795043945
Memory status after this trial: 
Memory allocated:  2943.25830078125
Memory cached:  2978.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.3976174463495235, 'log_learning_rate_D': -3.6768583874900695, 'log_learning_rate_D_dagger': -3.0013985454186, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9077, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2676.0
	 epoch  10 training error:  tensor(0.1823, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  20 training error:  tensor(0.1845, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  30 training error:  tensor(0.1748, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  40 training error:  tensor(0.1721, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  50 training error:  tensor(0.1562, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  60 training error:  tensor(0.0883, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  70 training error:  tensor(0.0840, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.0500, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
	 epoch  90 training error:  tensor(0.0567, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1741.85302734375
Memory cached:  2696.0
[I 2024-03-02 09:19:00,406] Trial 45 finished with value: 0.04977912828326225 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.3976174463495235, 'log_learning_rate_D': -3.6768583874900695, 'log_learning_rate_D_dagger': -3.0013985454186, 'training_batch_size': 6, 'training_p': 2}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3321.8517487049103
Memory status after this trial: 
Memory allocated:  2613.61279296875
Memory cached:  2654.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.712821234281597, 'log_learning_rate_D': -2.7997013418117054, 'log_learning_rate_D_dagger': -2.8340992991255542, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.4474, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  10 training error:  tensor(0.3397, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  20 training error:  tensor(0.3291, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  30 training error:  tensor(0.3147, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  40 training error:  tensor(0.3920, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  50 training error:  tensor(0.3130, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  60 training error:  tensor(0.3033, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  70 training error:  tensor(0.3155, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  80 training error:  tensor(0.1558, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
	 epoch  90 training error:  tensor(0.1098, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1773.138671875
Memory cached:  2776.0
[I 2024-03-02 10:18:29,233] Trial 46 finished with value: 0.07852157205343246 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -1.712821234281597, 'log_learning_rate_D': -2.7997013418117054, 'log_learning_rate_D_dagger': -2.8340992991255542, 'training_batch_size': 6, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3567.9464399814606
Memory status after this trial: 
Memory allocated:  2881.6669921875
Memory cached:  2914.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -1.4998572879498375, 'log_learning_rate_D': -4.190428469215456, 'log_learning_rate_D_dagger': -3.7418960950424904, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(16.1564, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2644.0
	 epoch  10 training error:  tensor(0.8486, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2646.0
	 epoch  20 training error:  tensor(0.5202, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2648.0
	 epoch  30 training error:  tensor(0.3546, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2646.0
	 epoch  40 training error:  tensor(0.3522, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2646.0
	 epoch  50 training error:  tensor(0.3475, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2650.0
	 epoch  60 training error:  tensor(0.3424, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2646.0
	 epoch  70 training error:  tensor(0.3384, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2646.0
	 epoch  80 training error:  tensor(0.3340, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2648.0
	 epoch  90 training error:  tensor(0.3350, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1738.041015625
Memory cached:  2648.0
[I 2024-03-02 10:35:45,894] Trial 47 finished with value: 0.22129257023334503 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -1.4998572879498375, 'log_learning_rate_D': -4.190428469215456, 'log_learning_rate_D_dagger': -3.7418960950424904, 'training_batch_size': 8, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1036.0052399635315
Memory status after this trial: 
Memory allocated:  2849.73583984375
Memory cached:  2896.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -2.772081181737083, 'log_learning_rate_D': -3.133494865092841, 'log_learning_rate_D_dagger': -3.219030379999294, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9904, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.296875
Memory cached:  2678.0
	 epoch  10 training error:  tensor(0.4735, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.3505859375
Memory cached:  2702.0
	 epoch  20 training error:  tensor(0.3716, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1737.12744140625
Memory cached:  2680.0
	 epoch  30 training error:  tensor(0.3455, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.3505859375
Memory cached:  2704.0
	 epoch  40 training error:  tensor(0.3251, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.8505859375
Memory cached:  2700.0
	 epoch  50 training error:  tensor(0.3187, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.1005859375
Memory cached:  2704.0
	 epoch  60 training error:  tensor(0.3111, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.87744140625
Memory cached:  2682.0
	 epoch  70 training error:  tensor(0.2573, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.3505859375
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.2227, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1737.1005859375
Memory cached:  2696.0
	 epoch  90 training error:  tensor(0.1944, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1736.046875
Memory cached:  2682.0
[I 2024-03-02 10:43:41,752] Trial 48 finished with value: 0.13092191517353058 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -2.772081181737083, 'log_learning_rate_D': -3.133494865092841, 'log_learning_rate_D_dagger': -3.219030379999294, 'training_batch_size': 10, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  475.25836420059204
Memory status after this trial: 
Memory allocated:  2763.37060546875
Memory cached:  2800.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -2.49598086451974, 'log_learning_rate_D': -1.460372658762099, 'log_learning_rate_D_dagger': -4.679345477460323, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7938, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2786.0
	 epoch  10 training error:  tensor(0.6400, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2790.0
	 epoch  20 training error:  tensor(0.6390, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2790.0
	 epoch  30 training error:  tensor(0.6410, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2788.0
	 epoch  40 training error:  tensor(0.6403, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2788.0
	 epoch  50 training error:  tensor(0.6389, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2794.0
	 epoch  60 training error:  tensor(0.6438, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2792.0
	 epoch  70 training error:  tensor(0.6433, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2792.0
	 epoch  80 training error:  tensor(0.6384, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2786.0
	 epoch  90 training error:  tensor(0.6386, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1770.4921875
Memory cached:  2794.0
[I 2024-03-02 11:11:23,128] Trial 49 finished with value: 0.6098594069480896 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -2.49598086451974, 'log_learning_rate_D': -1.460372658762099, 'log_learning_rate_D_dagger': -4.679345477460323, 'training_batch_size': 7, 'training_p': 4}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1660.7256908416748
Memory status after this trial: 
Memory allocated:  2923.25732421875
Memory cached:  2950.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -2.0661545246629194, 'log_learning_rate_D': -3.565134707553611, 'log_learning_rate_D_dagger': -3.6280932807375024, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8806, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  10 training error:  tensor(0.3483, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  20 training error:  tensor(0.2813, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  30 training error:  tensor(0.1382, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  40 training error:  tensor(0.0899, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  50 training error:  tensor(0.0793, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  60 training error:  tensor(0.0911, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  70 training error:  tensor(0.0631, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  80 training error:  tensor(0.0633, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
	 epoch  90 training error:  tensor(0.0641, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1734.27978515625
Memory cached:  2636.0
[I 2024-03-02 12:15:16,048] Trial 50 finished with value: 0.06990495324134827 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -2.0661545246629194, 'log_learning_rate_D': -3.565134707553611, 'log_learning_rate_D_dagger': -3.6280932807375024, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3831.6872680187225
Memory status after this trial: 
Memory allocated:  2691.22412109375
Memory cached:  2734.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.8416405062703205, 'log_learning_rate_D': -3.833998630762282, 'log_learning_rate_D_dagger': -3.381971291119639, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(5.2669, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3464, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.3091, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.1588, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.1246, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.0915, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0649, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0701, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0701, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0399, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.982421875
Memory cached:  2716.0
[I 2024-03-02 13:15:52,322] Trial 51 finished with value: 0.051674630492925644 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.8416405062703205, 'log_learning_rate_D': -3.833998630762282, 'log_learning_rate_D_dagger': -3.381971291119639, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3635.197108030319
Memory status after this trial: 
Memory allocated:  3236.86962890625
Memory cached:  3274.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.695087081091144, 'log_learning_rate_D': -4.075031151097049, 'log_learning_rate_D_dagger': -2.945848993549443, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(19.5241, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3485, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.2087, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.3717, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.0878, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.0618, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0538, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0624, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0740, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0473, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1777.685546875
Memory cached:  2716.0
[I 2024-03-02 14:16:25,925] Trial 52 finished with value: 0.028744135051965714 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -1.695087081091144, 'log_learning_rate_D': -4.075031151097049, 'log_learning_rate_D_dagger': -2.945848993549443, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3632.585959672928
Memory status after this trial: 
Memory allocated:  3237.01025390625
Memory cached:  3274.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -1.3593458811240189, 'log_learning_rate_D': -4.1288576647497575, 'log_learning_rate_D_dagger': -2.750693221877853, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(407.6779, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3871, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  20 training error:  tensor(0.3197, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  30 training error:  tensor(0.2844, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  40 training error:  tensor(0.2005, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  50 training error:  tensor(0.1111, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  60 training error:  tensor(0.0875, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  70 training error:  tensor(0.0611, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0514, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
	 epoch  90 training error:  tensor(0.0461, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1766.49169921875
Memory cached:  2716.0
[I 2024-03-02 15:16:41,993] Trial 53 finished with value: 0.04821261391043663 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -1.3593458811240189, 'log_learning_rate_D': -4.1288576647497575, 'log_learning_rate_D_dagger': -2.750693221877853, 'training_batch_size': 6, 'training_p': 5}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3615.1445939540863
Memory status after this trial: 
Memory allocated:  3061.638671875
Memory cached:  3100.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0064862476733496, 'log_learning_rate_D': -3.7413823607805003, 'log_learning_rate_D_dagger': -2.965755584320195, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1347.7054, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2716.0
	 epoch  10 training error:  tensor(0.3510, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2712.0
	 epoch  20 training error:  tensor(0.2933, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2714.0
	 epoch  30 training error:  tensor(0.1580, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2712.0
	 epoch  40 training error:  tensor(0.1081, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2714.0
	 epoch  50 training error:  tensor(0.1251, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2714.0
	 epoch  60 training error:  tensor(0.0729, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2714.0
	 epoch  70 training error:  tensor(0.0764, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2710.0
	 epoch  80 training error:  tensor(0.0617, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2710.0
	 epoch  90 training error:  tensor(0.0560, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1746.80126953125
Memory cached:  2710.0
[I 2024-03-02 15:47:54,609] Trial 54 finished with value: 0.04165497049689293 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -1.0064862476733496, 'log_learning_rate_D': -3.7413823607805003, 'log_learning_rate_D_dagger': -2.965755584320195, 'training_batch_size': 7, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1871.7996680736542
Memory status after this trial: 
Memory allocated:  2929.99072265625
Memory cached:  2972.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -3.102514721256589, 'log_learning_rate_D': -3.2522493072795733, 'log_learning_rate_D_dagger': -2.506981641775088, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(2.0692, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2818.0
	 epoch  10 training error:  tensor(0.4470, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  20 training error:  tensor(0.3704, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  30 training error:  tensor(0.3639, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  40 training error:  tensor(0.3648, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  50 training error:  tensor(0.3547, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  60 training error:  tensor(0.3562, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  70 training error:  tensor(0.3379, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  80 training error:  tensor(0.3371, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
	 epoch  90 training error:  tensor(0.3351, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1812.2529296875
Memory cached:  2840.0
[I 2024-03-02 16:45:40,648] Trial 55 finished with value: 0.25484904646873474 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -3.102514721256589, 'log_learning_rate_D': -3.2522493072795733, 'log_learning_rate_D_dagger': -2.506981641775088, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3464.937008857727
Memory status after this trial: 
Memory allocated:  3585.548828125
Memory cached:  3618.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.6485644193985682, 'log_learning_rate_D': -3.4724141250122984, 'log_learning_rate_D_dagger': -2.8991309529159652, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(77.6092, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2698.0
	 epoch  10 training error:  tensor(0.5741, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2686.0
	 epoch  20 training error:  tensor(0.4227, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2686.0
	 epoch  30 training error:  tensor(0.3395, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2688.0
	 epoch  40 training error:  tensor(0.3296, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2684.0
	 epoch  50 training error:  tensor(0.3265, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2688.0
	 epoch  60 training error:  tensor(0.2958, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2684.0
	 epoch  70 training error:  tensor(0.1909, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2686.0
	 epoch  80 training error:  tensor(0.1639, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2686.0
	 epoch  90 training error:  tensor(0.1672, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1742.63671875
Memory cached:  2686.0
[I 2024-03-02 17:16:32,481] Trial 56 finished with value: 0.112279511988163 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.6485644193985682, 'log_learning_rate_D': -3.4724141250122984, 'log_learning_rate_D_dagger': -2.8991309529159652, 'training_batch_size': 7, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1851.050169467926
Memory status after this trial: 
Memory allocated:  2933.2041015625
Memory cached:  2974.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.2149060904099165, 'log_learning_rate_D': -4.3193337598594725, 'log_learning_rate_D_dagger': -3.2343620592868314, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(6.4664, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  10 training error:  tensor(0.3579, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  20 training error:  tensor(0.2699, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  30 training error:  tensor(0.1433, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  40 training error:  tensor(0.1029, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  50 training error:  tensor(0.0716, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  60 training error:  tensor(0.0775, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  70 training error:  tensor(0.0548, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  80 training error:  tensor(0.0633, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
	 epoch  90 training error:  tensor(0.0551, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1782.76123046875
Memory cached:  2736.0
[I 2024-03-02 18:11:39,025] Trial 57 finished with value: 0.0270866546779871 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.2149060904099165, 'log_learning_rate_D': -4.3193337598594725, 'log_learning_rate_D_dagger': -3.2343620592868314, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3305.6377816200256
Memory status after this trial: 
Memory allocated:  3301.04541015625
Memory cached:  3342.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.1977710792802005, 'log_learning_rate_D': -4.335055967908529, 'log_learning_rate_D_dagger': -4.080432175702312, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4299, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2710.0
	 epoch  10 training error:  tensor(0.3866, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2710.0
	 epoch  20 training error:  tensor(0.3529, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2712.0
	 epoch  30 training error:  tensor(0.3254, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2712.0
	 epoch  40 training error:  tensor(0.2260, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2706.0
	 epoch  50 training error:  tensor(0.1700, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2712.0
	 epoch  60 training error:  tensor(0.1362, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2710.0
	 epoch  70 training error:  tensor(0.1064, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2716.0
	 epoch  80 training error:  tensor(0.0991, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2712.0
	 epoch  90 training error:  tensor(0.0934, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1763.54248046875
Memory cached:  2712.0
[I 2024-03-02 18:37:15,289] Trial 58 finished with value: 0.06873047351837158 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.1977710792802005, 'log_learning_rate_D': -4.335055967908529, 'log_learning_rate_D_dagger': -4.080432175702312, 'training_batch_size': 7, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1535.5807855129242
Memory status after this trial: 
Memory allocated:  2828.41357421875
Memory cached:  2872.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.0045709482236673, 'log_learning_rate_D': -4.53218284347116, 'log_learning_rate_D_dagger': -3.4658016295905405, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(8.3605, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  10 training error:  tensor(0.3523, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  20 training error:  tensor(0.3389, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  30 training error:  tensor(0.1807, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  40 training error:  tensor(0.1643, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  50 training error:  tensor(0.1231, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  60 training error:  tensor(0.0966, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  70 training error:  tensor(0.1004, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  80 training error:  tensor(0.0582, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
	 epoch  90 training error:  tensor(0.0790, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1786.26611328125
Memory cached:  2836.0
[I 2024-03-02 19:42:40,915] Trial 59 finished with value: 0.031239861622452736 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.0045709482236673, 'log_learning_rate_D': -4.53218284347116, 'log_learning_rate_D_dagger': -3.4658016295905405, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3924.6197600364685
Memory status after this trial: 
Memory allocated:  3497.9638671875
Memory cached:  3532.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.3299071432590903, 'log_learning_rate_D': -4.838592375758774, 'log_learning_rate_D_dagger': -3.078424664396801, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(4.6427, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2708.0
	 epoch  10 training error:  tensor(0.3705, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2706.0
	 epoch  20 training error:  tensor(0.3508, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2704.0
	 epoch  30 training error:  tensor(0.3104, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2708.0
	 epoch  40 training error:  tensor(0.2260, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2706.0
	 epoch  50 training error:  tensor(0.1770, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2704.0
	 epoch  60 training error:  tensor(0.1795, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2702.0
	 epoch  70 training error:  tensor(0.1492, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2706.0
	 epoch  80 training error:  tensor(0.1368, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2708.0
	 epoch  90 training error:  tensor(0.1233, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1747.6220703125
Memory cached:  2708.0
[I 2024-03-02 20:12:01,294] Trial 60 finished with value: 0.08813804388046265 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.3299071432590903, 'log_learning_rate_D': -4.838592375758774, 'log_learning_rate_D_dagger': -3.078424664396801, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1734.5086941719055
Memory status after this trial: 
Memory allocated:  2970.41943359375
Memory cached:  3012.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.008543456862988, 'log_learning_rate_D': -4.5418838302220825, 'log_learning_rate_D_dagger': -3.505292712271574, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(13.8504, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  10 training error:  tensor(0.3497, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  20 training error:  tensor(0.3310, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  30 training error:  tensor(0.1787, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  40 training error:  tensor(0.1531, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  50 training error:  tensor(0.1166, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  60 training error:  tensor(0.0977, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  70 training error:  tensor(0.0765, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  80 training error:  tensor(0.0886, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
	 epoch  90 training error:  tensor(0.0722, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1789.57763671875
Memory cached:  2816.0
[I 2024-03-02 21:19:36,765] Trial 61 finished with value: 0.033606868237257004 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.008543456862988, 'log_learning_rate_D': -4.5418838302220825, 'log_learning_rate_D_dagger': -3.505292712271574, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  4054.3526690006256
Memory status after this trial: 
Memory allocated:  3560.3388671875
Memory cached:  3596.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -1.797005035952242, 'log_learning_rate_D': -4.033872625748041, 'log_learning_rate_D_dagger': -3.8454262098991157, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(56.5719, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1837.443359375
Memory cached:  2894.0
	 epoch  10 training error:  tensor(0.4295, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2892.0
	 epoch  20 training error:  tensor(0.3368, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2896.0
	 epoch  30 training error:  tensor(0.3569, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2896.0
	 epoch  40 training error:  tensor(0.1502, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2896.0
	 epoch  50 training error:  tensor(0.1608, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2898.0
	 epoch  60 training error:  tensor(0.1155, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2898.0
	 epoch  70 training error:  tensor(0.0852, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2894.0
	 epoch  80 training error:  tensor(0.0887, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2898.0
	 epoch  90 training error:  tensor(0.0742, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1838.42138671875
Memory cached:  2894.0
[I 2024-03-02 22:23:35,599] Trial 62 finished with value: 1.9559268951416016 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -1.797005035952242, 'log_learning_rate_D': -4.033872625748041, 'log_learning_rate_D_dagger': -3.8454262098991157, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3837.7644412517548
Memory status after this trial: 
Memory allocated:  3947.2412109375
Memory cached:  3990.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.5673721256332915, 'log_learning_rate_D': -4.446553261194368, 'log_learning_rate_D_dagger': -3.1882415144602385, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(464.5772, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  10 training error:  tensor(0.4142, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  20 training error:  tensor(0.3549, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  30 training error:  tensor(0.1669, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  40 training error:  tensor(0.1458, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  50 training error:  tensor(0.2509, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  60 training error:  tensor(0.0996, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  70 training error:  tensor(0.0752, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  80 training error:  tensor(0.0631, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
	 epoch  90 training error:  tensor(0.0645, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.9912109375
Memory cached:  2796.0
[I 2024-03-02 23:28:52,389] Trial 63 finished with value: 0.02802693285048008 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.5673721256332915, 'log_learning_rate_D': -4.446553261194368, 'log_learning_rate_D_dagger': -3.1882415144602385, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3915.578165769577
Memory status after this trial: 
Memory allocated:  3573.95166015625
Memory cached:  3612.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -1.5376156970549983, 'log_learning_rate_D': -4.239564714180853, 'log_learning_rate_D_dagger': -3.225893811694915, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(3.6690, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  10 training error:  tensor(0.3753, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  20 training error:  tensor(0.2442, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  30 training error:  tensor(0.1680, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  40 training error:  tensor(0.1214, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  50 training error:  tensor(0.1045, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  60 training error:  tensor(0.1039, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  70 training error:  tensor(0.1090, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  80 training error:  tensor(0.0866, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
	 epoch  90 training error:  tensor(0.0747, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1765.50634765625
Memory cached:  2736.0
[I 2024-03-03 00:23:07,861] Trial 64 finished with value: 0.03506132960319519 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -1.5376156970549983, 'log_learning_rate_D': -4.239564714180853, 'log_learning_rate_D_dagger': -3.225893811694915, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3254.3527381420135
Memory status after this trial: 
Memory allocated:  3067.2978515625
Memory cached:  3106.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.2793950602307065, 'log_learning_rate_D': -3.984399272201026, 'log_learning_rate_D_dagger': -2.7600348004901876, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(585.2578, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  10 training error:  tensor(0.4282, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  20 training error:  tensor(0.3032, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  30 training error:  tensor(0.1499, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  40 training error:  tensor(0.1777, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  50 training error:  tensor(0.0854, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  60 training error:  tensor(0.1048, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  70 training error:  tensor(0.0839, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  80 training error:  tensor(0.0744, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
	 epoch  90 training error:  tensor(0.0808, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.4501953125
Memory cached:  2796.0
[I 2024-03-03 01:30:33,297] Trial 65 finished with value: 0.04059654474258423 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.2793950602307065, 'log_learning_rate_D': -3.984399272201026, 'log_learning_rate_D_dagger': -2.7600348004901876, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  4044.100728034973
Memory status after this trial: 
Memory allocated:  3424.87744140625
Memory cached:  3462.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -1.5727725805217767, 'log_learning_rate_D': -4.67697007150559, 'log_learning_rate_D_dagger': -3.1535760041832184, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(208.8012, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2804.0
	 epoch  10 training error:  tensor(5.8350, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2808.0
	 epoch  20 training error:  tensor(0.4873, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2806.0
	 epoch  30 training error:  tensor(0.5041, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2802.0
	 epoch  40 training error:  tensor(0.3640, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2808.0
	 epoch  50 training error:  tensor(0.3384, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2808.0
	 epoch  60 training error:  tensor(0.2360, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2808.0
	 epoch  70 training error:  tensor(0.1596, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2802.0
	 epoch  80 training error:  tensor(0.1211, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2810.0
	 epoch  90 training error:  tensor(0.1162, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1776.60888671875
Memory cached:  2804.0
[I 2024-03-03 02:05:47,356] Trial 66 finished with value: 0.06180727481842041 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -1.5727725805217767, 'log_learning_rate_D': -4.67697007150559, 'log_learning_rate_D_dagger': -3.1535760041832184, 'training_batch_size': 7, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  2113.0378448963165
Memory status after this trial: 
Memory allocated:  3213.32861328125
Memory cached:  3250.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.8713070247164347, 'log_learning_rate_D': -4.274926860520874, 'log_learning_rate_D_dagger': -3.599298291429156, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(2.3718, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  10 training error:  tensor(0.3421, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  20 training error:  tensor(0.1859, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  30 training error:  tensor(0.1869, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  40 training error:  tensor(0.1323, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  50 training error:  tensor(0.1057, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  60 training error:  tensor(0.1117, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  70 training error:  tensor(0.0765, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  80 training error:  tensor(0.0880, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
	 epoch  90 training error:  tensor(0.0796, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.83740234375
Memory cached:  2836.0
[I 2024-03-03 03:03:32,784] Trial 67 finished with value: 0.1047520861029625 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.8713070247164347, 'log_learning_rate_D': -4.274926860520874, 'log_learning_rate_D_dagger': -3.599298291429156, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3464.2995488643646
Memory status after this trial: 
Memory allocated:  3288.697265625
Memory cached:  3354.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -1.4068587348710102, 'log_learning_rate_D': -4.374097911006732, 'log_learning_rate_D_dagger': -2.52336131600843, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(17.1445, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  10 training error:  tensor(0.3818, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  20 training error:  tensor(0.2373, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  30 training error:  tensor(0.1942, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  40 training error:  tensor(0.1780, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  50 training error:  tensor(0.2741, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  60 training error:  tensor(0.1317, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  70 training error:  tensor(0.0914, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  80 training error:  tensor(0.0824, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
	 epoch  90 training error:  tensor(0.1184, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1796.3720703125
Memory cached:  2756.0
[I 2024-03-03 04:04:51,336] Trial 68 finished with value: 0.03937028720974922 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -1.4068587348710102, 'log_learning_rate_D': -4.374097911006732, 'log_learning_rate_D_dagger': -2.52336131600843, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3659.323000431061
Memory status after this trial: 
Memory allocated:  3376.5927734375
Memory cached:  3410.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -1.238141529168906, 'log_learning_rate_D': -4.10146591478698, 'log_learning_rate_D_dagger': -3.329087401691144, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1242.0778, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2724.0
	 epoch  10 training error:  tensor(0.3935, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2724.0
	 epoch  20 training error:  tensor(0.3448, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2726.0
	 epoch  30 training error:  tensor(0.3447, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2722.0
	 epoch  40 training error:  tensor(0.1932, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2732.0
	 epoch  50 training error:  tensor(0.1317, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2726.0
	 epoch  60 training error:  tensor(0.1139, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2726.0
	 epoch  70 training error:  tensor(0.1153, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2726.0
	 epoch  80 training error:  tensor(0.0912, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2726.0
	 epoch  90 training error:  tensor(0.0764, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1785.85302734375
Memory cached:  2724.0
[I 2024-03-03 04:37:45,967] Trial 69 finished with value: 0.09925884008407593 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -1.238141529168906, 'log_learning_rate_D': -4.10146591478698, 'log_learning_rate_D_dagger': -3.329087401691144, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  1960.8161962032318
Memory status after this trial: 
Memory allocated:  3300.09814453125
Memory cached:  3334.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.196332998580764, 'log_learning_rate_D': -4.890311197032488, 'log_learning_rate_D_dagger': -2.958622282630498, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(3.2857, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  10 training error:  tensor(0.3459, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  20 training error:  tensor(0.3230, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  30 training error:  tensor(0.2009, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  40 training error:  tensor(0.1837, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  50 training error:  tensor(0.1639, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  60 training error:  tensor(0.1594, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  70 training error:  tensor(0.1473, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  80 training error:  tensor(0.1053, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
	 epoch  90 training error:  tensor(0.0958, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1752.9716796875
Memory cached:  2696.0
[I 2024-03-03 05:33:11,500] Trial 70 finished with value: 0.0718565285205841 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.196332998580764, 'log_learning_rate_D': -4.890311197032488, 'log_learning_rate_D_dagger': -2.958622282630498, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3314.7464349269867
Memory status after this trial: 
Memory allocated:  2983.33642578125
Memory cached:  3022.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -1.6637869978333546, 'log_learning_rate_D': -4.484688069980077, 'log_learning_rate_D_dagger': -3.4628974486518174, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(52.5685, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  10 training error:  tensor(0.3543, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  20 training error:  tensor(0.3303, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  30 training error:  tensor(0.1508, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  40 training error:  tensor(0.1105, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  50 training error:  tensor(0.0834, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  60 training error:  tensor(0.0682, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  70 training error:  tensor(0.0698, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  80 training error:  tensor(0.0420, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
	 epoch  90 training error:  tensor(0.0496, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1778.67724609375
Memory cached:  2776.0
[I 2024-03-03 06:34:21,901] Trial 71 finished with value: 0.053943514823913574 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -1.6637869978333546, 'log_learning_rate_D': -4.484688069980077, 'log_learning_rate_D_dagger': -3.4628974486518174, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.019390789791941643.
Time for this trial:  3646.664885997772
Memory status after this trial: 
Memory allocated:  3374.2197265625
Memory cached:  3412.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -2.0722646139655807, 'log_learning_rate_D': -4.559792736586435, 'log_learning_rate_D_dagger': -3.5309514925568117, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(6.3245, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  10 training error:  tensor(0.3483, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  20 training error:  tensor(0.2261, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  30 training error:  tensor(0.1185, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  40 training error:  tensor(0.0845, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  50 training error:  tensor(0.1186, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  60 training error:  tensor(0.0619, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  70 training error:  tensor(0.0722, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
	 epoch  80 training error:  tensor(0.0644, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1804.43896484375
Memory cached:  2916.0
