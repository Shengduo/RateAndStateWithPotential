/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-02 22:42:04,058] A new study created in memory with name: no-name-9f3e3ce9-b0f0-4059-8675-e0c1dcc3bbf1
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1108_bigDRS_Burigede.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.270576161349951, 'log_learning_rate_D': -1.0904490606704078, 'log_learning_rate_D_dagger': -4.978164179503836, 'training_batch_size': 9, 'training_p': 4}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.0829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  54.0
	 epoch  10 training error:  tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  54.0
	 epoch  50 training error:  tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  54.0
	 epoch  90 training error:  tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1982421875
Memory cached:  58.0
[I 2023-12-02 22:42:25,494] Trial 0 finished with value: 0.1084551140666008 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.270576161349951, 'log_learning_rate_D': -1.0904490606704078, 'log_learning_rate_D_dagger': -4.978164179503836, 'training_batch_size': 9, 'training_p': 4}. Best is trial 0 with value: 0.1084551140666008.
res:  tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  21.33836078643799
Memory status after this trial: 
Memory allocated:  278.630859375
Memory cached:  318.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -4.304530517362828, 'log_learning_rate_D': -1.013231744913476, 'log_learning_rate_D_dagger': -1.3386786677404028, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  10 training error:  tensor(329.2895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  20 training error:  tensor(41.1436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  30 training error:  tensor(1081.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  40 training error:  tensor(31.1143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  50 training error:  tensor(5.7762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.5117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.9306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.5459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  284.61083984375
Memory cached:  326.0
[I 2023-12-02 22:42:45,026] Trial 1 finished with value: 0.2769660949707031 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -4.304530517362828, 'log_learning_rate_D': -1.013231744913476, 'log_learning_rate_D_dagger': -1.3386786677404028, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.1084551140666008.
Time for this trial:  19.436399936676025
Memory status after this trial: 
Memory allocated:  494.55810546875
Memory cached:  520.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.4529026776729204, 'log_learning_rate_D': -4.87918078719019, 'log_learning_rate_D_dagger': -2.7272222159695185, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  324.0
	 epoch  10 training error:  tensor(1.0354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.4046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  330.0
	 epoch  30 training error:  tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  283.7578125
Memory cached:  330.0
[I 2023-12-02 22:43:01,839] Trial 2 finished with value: 0.07184018194675446 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.4529026776729204, 'log_learning_rate_D': -4.87918078719019, 'log_learning_rate_D_dagger': -2.7272222159695185, 'training_batch_size': 12, 'training_p': 3}. Best is trial 2 with value: 0.07184018194675446.
res:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.688812971115112
Memory status after this trial: 
Memory allocated:  108.544921875
Memory cached:  210.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -1.6121735165248827, 'log_learning_rate_D': -2.4026146587474138, 'log_learning_rate_D_dagger': -3.2500761828514055, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  234.0
	 epoch  10 training error:  tensor(1.2302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  236.0
	 epoch  20 training error:  tensor(1.6295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
	 epoch  30 training error:  tensor(2.3117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
	 epoch  40 training error:  tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  236.0
	 epoch  50 training error:  tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
	 epoch  60 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
	 epoch  70 training error:  tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  236.0
	 epoch  80 training error:  tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
	 epoch  90 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.31689453125
Memory cached:  238.0
[I 2023-12-02 22:43:22,233] Trial 3 finished with value: 0.07739335298538208 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -1.6121735165248827, 'log_learning_rate_D': -2.4026146587474138, 'log_learning_rate_D_dagger': -3.2500761828514055, 'training_batch_size': 10, 'training_p': 7}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  20.285829305648804
Memory status after this trial: 
Memory allocated:  381.02099609375
Memory cached:  422.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.561436153529872, 'log_learning_rate_D': -4.538826698396575, 'log_learning_rate_D_dagger': -2.990540279075866, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  10 training error:  tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  20 training error:  tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  30 training error:  tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  40 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  50 training error:  tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  60 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  70 training error:  tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  80 training error:  tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
	 epoch  90 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.78466796875
Memory cached:  210.0
[I 2023-12-02 22:43:40,678] Trial 4 finished with value: 0.07500194013118744 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.561436153529872, 'log_learning_rate_D': -4.538826698396575, 'log_learning_rate_D_dagger': -2.990540279075866, 'training_batch_size': 10, 'training_p': 4}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  18.331856727600098
Memory status after this trial: 
Memory allocated:  248.85107421875
Memory cached:  264.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -3.9488031760095392, 'log_learning_rate_D': -3.3545874609023536, 'log_learning_rate_D_dagger': -1.609643135488684, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(48.3656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  212.0
	 epoch  10 training error:  tensor(92.0834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  20 training error:  tensor(2.6944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  30 training error:  tensor(3.9822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  40 training error:  tensor(10.7548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  50 training error:  tensor(0.7419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  60 training error:  tensor(0.6764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  70 training error:  tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  80 training error:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
	 epoch  90 training error:  tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.81103515625
Memory cached:  214.0
[I 2023-12-02 22:44:01,657] Trial 5 finished with value: 0.08051398396492004 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -3.9488031760095392, 'log_learning_rate_D': -3.3545874609023536, 'log_learning_rate_D_dagger': -1.609643135488684, 'training_batch_size': 6, 'training_p': 6}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  20.864891052246094
Memory status after this trial: 
Memory allocated:  301.78759765625
Memory cached:  332.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.873142474546556, 'log_learning_rate_D': -2.7975145756341933, 'log_learning_rate_D_dagger': -2.833943567175908, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  10 training error:  tensor(2.1605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  20 training error:  tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  30 training error:  tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  40 training error:  tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  50 training error:  tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  60 training error:  tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  70 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  80 training error:  tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
	 epoch  90 training error:  tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.9189453125
Memory cached:  234.0
[I 2023-12-02 22:44:19,880] Trial 6 finished with value: 0.09592606872320175 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -1.873142474546556, 'log_learning_rate_D': -2.7975145756341933, 'log_learning_rate_D_dagger': -2.833943567175908, 'training_batch_size': 11, 'training_p': 5}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  18.09874200820923
Memory status after this trial: 
Memory allocated:  293.33447265625
Memory cached:  322.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.772548858566626, 'log_learning_rate_D': -2.995831191830544, 'log_learning_rate_D_dagger': -1.6704234936888138, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  10 training error:  tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  20 training error:  tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  30 training error:  tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  40 training error:  tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  50 training error:  tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  60 training error:  tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  70 training error:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  80 training error:  tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
	 epoch  90 training error:  tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.4208984375
Memory cached:  212.0
[I 2023-12-02 22:44:36,577] Trial 7 finished with value: 0.13083067536354065 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.772548858566626, 'log_learning_rate_D': -2.995831191830544, 'log_learning_rate_D_dagger': -1.6704234936888138, 'training_batch_size': 10, 'training_p': 2}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  16.57146406173706
Memory status after this trial: 
Memory allocated:  187.99951171875
Memory cached:  220.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.7472273694003233, 'log_learning_rate_D': -1.2021954840271656, 'log_learning_rate_D_dagger': -3.6023312343360945, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  10 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  20 training error:  tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  30 training error:  tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  40 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  50 training error:  tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  60 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  70 training error:  tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  80 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
	 epoch  90 training error:  tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.802734375
Memory cached:  210.0
[I 2023-12-02 22:44:54,118] Trial 8 finished with value: 0.07963192462921143 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -2.7472273694003233, 'log_learning_rate_D': -1.2021954840271656, 'log_learning_rate_D_dagger': -3.6023312343360945, 'training_batch_size': 8, 'training_p': 4}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  17.418233156204224
Memory status after this trial: 
Memory allocated:  213.82080078125
Memory cached:  234.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.526228982361069, 'log_learning_rate_D': -2.055370590723397, 'log_learning_rate_D_dagger': -2.72517760944957, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  10 training error:  tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  20 training error:  tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  30 training error:  tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  40 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  50 training error:  tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  60 training error:  tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  70 training error:  tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  80 training error:  tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
	 epoch  90 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.67236328125
Memory cached:  210.0
[I 2023-12-02 22:45:11,524] Trial 9 finished with value: 0.072943314909935 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.526228982361069, 'log_learning_rate_D': -2.055370590723397, 'log_learning_rate_D_dagger': -2.72517760944957, 'training_batch_size': 12, 'training_p': 4}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  17.27930784225464
Memory status after this trial: 
Memory allocated:  247.50048828125
Memory cached:  270.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.1859097422776568, 'log_learning_rate_D': -4.456117627335117, 'log_learning_rate_D_dagger': -2.191594004788967, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  10 training error:  tensor(154.7032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  20 training error:  tensor(142.1500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  30 training error:  tensor(11.1142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  40 training error:  tensor(10.4691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  50 training error:  tensor(11.2905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  60 training error:  tensor(3.5555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  70 training error:  tensor(2.7405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  80 training error:  tensor(1.4669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
	 epoch  90 training error:  tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.15283203125
Memory cached:  210.0
[I 2023-12-02 22:45:27,731] Trial 10 finished with value: 1.6813076734542847 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.1859097422776568, 'log_learning_rate_D': -4.456117627335117, 'log_learning_rate_D_dagger': -2.191594004788967, 'training_batch_size': 12, 'training_p': 2}. Best is trial 2 with value: 0.07184018194675446.
Time for this trial:  16.013543367385864
Memory status after this trial: 
Memory allocated:  220.45556640625
Memory cached:  270.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.937938651142253, 'log_learning_rate_D': -4.753922972034518, 'log_learning_rate_D_dagger': -2.381854108501888, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  10 training error:  tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  20 training error:  tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  30 training error:  tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  40 training error:  tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  50 training error:  tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  60 training error:  tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  70 training error:  tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  80 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
	 epoch  90 training error:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.47705078125
Memory cached:  226.0
[I 2023-12-02 22:45:45,279] Trial 11 finished with value: 0.06905489414930344 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.937938651142253, 'log_learning_rate_D': -4.753922972034518, 'log_learning_rate_D_dagger': -2.381854108501888, 'training_batch_size': 12, 'training_p': 3}. Best is trial 11 with value: 0.06905489414930344.
res:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  17.323587656021118
Memory status after this trial: 
Memory allocated:  173.6708984375
Memory cached:  288.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.0536076169434283, 'log_learning_rate_D': -4.91886650108088, 'log_learning_rate_D_dagger': -2.1774128484835997, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(2.3077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  10 training error:  tensor(1.3945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  20 training error:  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  30 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  40 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  50 training error:  tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  60 training error:  tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  70 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  80 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
	 epoch  90 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  179.81689453125
Memory cached:  288.0
[I 2023-12-02 22:46:02,282] Trial 12 finished with value: 0.06371106207370758 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.0536076169434283, 'log_learning_rate_D': -4.91886650108088, 'log_learning_rate_D_dagger': -2.1774128484835997, 'training_batch_size': 12, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
res:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.785095691680908
Memory status after this trial: 
Memory allocated:  138.89453125
Memory cached:  252.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -3.197271290670084, 'log_learning_rate_D': -4.022033526710697, 'log_learning_rate_D_dagger': -1.0787941332330644, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.8745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  10 training error:  tensor(34.9560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  20 training error:  tensor(8.5651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  30 training error:  tensor(4.5426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  40 training error:  tensor(1.1689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.6476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.01025390625
Memory cached:  252.0
[I 2023-12-02 22:46:18,891] Trial 13 finished with value: 0.09416952729225159 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -3.197271290670084, 'log_learning_rate_D': -4.022033526710697, 'log_learning_rate_D_dagger': -1.0787941332330644, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.417592763900757
Memory status after this trial: 
Memory allocated:  276.99853515625
Memory cached:  308.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.1791335111056904, 'log_learning_rate_D': -3.8986491706371096, 'log_learning_rate_D_dagger': -2.1185240311377482, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  10 training error:  tensor(3.0972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  20 training error:  tensor(1.4567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  30 training error:  tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  40 training error:  tensor(0.5547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  50 training error:  tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  60 training error:  tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  70 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  80 training error:  tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
	 epoch  90 training error:  tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.11181640625
Memory cached:  272.0
[I 2023-12-02 22:46:36,356] Trial 14 finished with value: 0.07877584546804428 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.1791335111056904, 'log_learning_rate_D': -3.8986491706371096, 'log_learning_rate_D_dagger': -2.1185240311377482, 'training_batch_size': 11, 'training_p': 8}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.2731831073761
Memory status after this trial: 
Memory allocated:  281.66650390625
Memory cached:  312.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.869231319442364, 'log_learning_rate_D': -4.960957868441435, 'log_learning_rate_D_dagger': -2.0379831740346477, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  10 training error:  tensor(3.6285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  20 training error:  tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  30 training error:  tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  40 training error:  tensor(0.9112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  50 training error:  tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  60 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  70 training error:  tensor(0.5147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  80 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
	 epoch  90 training error:  tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.2705078125
Memory cached:  272.0
[I 2023-12-02 22:46:53,027] Trial 15 finished with value: 0.3087998330593109 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -2.869231319442364, 'log_learning_rate_D': -4.960957868441435, 'log_learning_rate_D_dagger': -2.0379831740346477, 'training_batch_size': 9, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.476648092269897
Memory status after this trial: 
Memory allocated:  277.89404296875
Memory cached:  308.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.6376267691178468, 'log_learning_rate_D': -3.7620266059334075, 'log_learning_rate_D_dagger': -2.3912072758889957, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  10 training error:  tensor(1.2253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
[I 2023-12-02 22:47:11,042] Trial 16 finished with value: 0.07125581800937653 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.6376267691178468, 'log_learning_rate_D': -3.7620266059334075, 'log_learning_rate_D_dagger': -2.3912072758889957, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.791210412979126
Memory status after this trial: 
Memory allocated:  260.02783203125
Memory cached:  268.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.384090884540111, 'log_learning_rate_D': -4.396334845552626, 'log_learning_rate_D_dagger': -1.7943589530136597, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.6545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  10 training error:  tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.04541015625
Memory cached:  252.0
[I 2023-12-02 22:47:27,133] Trial 17 finished with value: 0.08044984191656113 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -2.384090884540111, 'log_learning_rate_D': -4.396334845552626, 'log_learning_rate_D_dagger': -1.7943589530136597, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  15.917476892471313
Memory status after this trial: 
Memory allocated:  237.83251953125
Memory cached:  252.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.287312634607676, 'log_learning_rate_D': -4.742527049136459, 'log_learning_rate_D_dagger': -1.2316907542087305, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  252.0
	 epoch  10 training error:  tensor(1.8048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  20 training error:  tensor(0.6721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  30 training error:  tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  50 training error:  tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
	 epoch  90 training error:  tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.3212890625
Memory cached:  254.0
[I 2023-12-02 22:47:44,855] Trial 18 finished with value: 0.1295495331287384 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.287312634607676, 'log_learning_rate_D': -4.742527049136459, 'log_learning_rate_D_dagger': -1.2316907542087305, 'training_batch_size': 8, 'training_p': 5}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.521843433380127
Memory status after this trial: 
Memory allocated:  293.75146484375
Memory cached:  324.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.99991682987621, 'log_learning_rate_D': -4.144822013773761, 'log_learning_rate_D_dagger': -2.5362473376879233, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  256.0
	 epoch  10 training error:  tensor(1.1484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  20 training error:  tensor(2.0994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.625
Memory cached:  258.0
[I 2023-12-02 22:48:03,566] Trial 19 finished with value: 0.06906194239854813 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.99991682987621, 'log_learning_rate_D': -4.144822013773761, 'log_learning_rate_D_dagger': -2.5362473376879233, 'training_batch_size': 10, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  18.492538452148438
Memory status after this trial: 
Memory allocated:  298.85888671875
Memory cached:  312.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.767566420693697, 'log_learning_rate_D': -3.6985481111564376, 'log_learning_rate_D_dagger': -3.3931102650432456, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  10 training error:  tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.076171875
Memory cached:  252.0
[I 2023-12-02 22:48:19,356] Trial 20 finished with value: 0.07209237664937973 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.767566420693697, 'log_learning_rate_D': -3.6985481111564376, 'log_learning_rate_D_dagger': -3.3931102650432456, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  15.570701122283936
Memory status after this trial: 
Memory allocated:  206.83349609375
Memory cached:  270.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.877811437904969, 'log_learning_rate_D': -4.996210874723551, 'log_learning_rate_D_dagger': -2.2713263935335752, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  254.0
	 epoch  10 training error:  tensor(5.8688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.55078125
Memory cached:  258.0
[I 2023-12-02 22:48:37,418] Trial 21 finished with value: 0.07356695085763931 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.877811437904969, 'log_learning_rate_D': -4.996210874723551, 'log_learning_rate_D_dagger': -2.2713263935335752, 'training_batch_size': 10, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.860587120056152
Memory status after this trial: 
Memory allocated:  284.72021484375
Memory cached:  312.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.241610041104024, 'log_learning_rate_D': -4.236617940229778, 'log_learning_rate_D_dagger': -2.4991707177643763, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.8722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  256.0
	 epoch  40 training error:  tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.58935546875
Memory cached:  258.0
[I 2023-12-02 22:48:57,390] Trial 22 finished with value: 0.1311650574207306 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.241610041104024, 'log_learning_rate_D': -4.236617940229778, 'log_learning_rate_D_dagger': -2.4991707177643763, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  19.75256323814392
Memory status after this trial: 
Memory allocated:  403.10302734375
Memory cached:  444.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.4300542660446323, 'log_learning_rate_D': -4.589647899919968, 'log_learning_rate_D_dagger': -1.8874844606747585, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  10 training error:  tensor(3.6274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  20 training error:  tensor(2.1301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.81640625
Memory cached:  258.0
[I 2023-12-02 22:49:16,908] Trial 23 finished with value: 0.10833144187927246 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.4300542660446323, 'log_learning_rate_D': -4.589647899919968, 'log_learning_rate_D_dagger': -1.8874844606747585, 'training_batch_size': 11, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  19.29875659942627
Memory status after this trial: 
Memory allocated:  338.13427734375
Memory cached:  366.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.040830014764229, 'log_learning_rate_D': -4.195563045487704, 'log_learning_rate_D_dagger': -2.462977400490532, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  30 training error:  tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  50 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
	 epoch  90 training error:  tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.0263671875
Memory cached:  254.0
[I 2023-12-02 22:49:35,261] Trial 24 finished with value: 0.07703116536140442 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.040830014764229, 'log_learning_rate_D': -4.195563045487704, 'log_learning_rate_D_dagger': -2.462977400490532, 'training_batch_size': 12, 'training_p': 6}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  18.14307141304016
Memory status after this trial: 
Memory allocated:  324.25439453125
Memory cached:  352.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.8047501634010037, 'log_learning_rate_D': -4.640327801112033, 'log_learning_rate_D_dagger': -1.4907924379657298, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  252.0
	 epoch  10 training error:  tensor(4.0265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  20 training error:  tensor(4.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  30 training error:  tensor(1.4444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.3842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  50 training error:  tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
	 epoch  90 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.302734375
Memory cached:  254.0
[I 2023-12-02 22:49:52,229] Trial 25 finished with value: 0.07986129820346832 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.8047501634010037, 'log_learning_rate_D': -4.640327801112033, 'log_learning_rate_D_dagger': -1.4907924379657298, 'training_batch_size': 8, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.78492522239685
Memory status after this trial: 
Memory allocated:  254.00341796875
Memory cached:  272.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -4.9284590567431135, 'log_learning_rate_D': -4.237259124547829, 'log_learning_rate_D_dagger': -1.9413013684002747, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  10 training error:  tensor(1.0791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.7743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.3662109375
Memory cached:  252.0
[I 2023-12-02 22:50:06,863] Trial 26 finished with value: 0.08080100268125534 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -4.9284590567431135, 'log_learning_rate_D': -4.237259124547829, 'log_learning_rate_D_dagger': -1.9413013684002747, 'training_batch_size': 10, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  14.44264030456543
Memory status after this trial: 
Memory allocated:  182.10986328125
Memory cached:  258.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -3.5557148535460126, 'log_learning_rate_D': -4.6803073552483765, 'log_learning_rate_D_dagger': -2.4818940516025028, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  10 training error:  tensor(1.1816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.53564453125
Memory cached:  252.0
[I 2023-12-02 22:50:24,551] Trial 27 finished with value: 0.07329293340444565 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -3.5557148535460126, 'log_learning_rate_D': -4.6803073552483765, 'log_learning_rate_D_dagger': -2.4818940516025028, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.479981184005737
Memory status after this trial: 
Memory allocated:  318.05322265625
Memory cached:  336.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -4.11349007203757, 'log_learning_rate_D': -4.9828352412983286, 'log_learning_rate_D_dagger': -1.001587738259603, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  256.0
	 epoch  10 training error:  tensor(31.8268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  262.0
	 epoch  20 training error:  tensor(48.5255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  30 training error:  tensor(304.8020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  40 training error:  tensor(385.2415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  50 training error:  tensor(20.1421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  262.0
	 epoch  60 training error:  tensor(53.3251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  70 training error:  tensor(3.3991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  80 training error:  tensor(3.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  260.0
	 epoch  90 training error:  tensor(1.7612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.62939453125
Memory cached:  262.0
[I 2023-12-02 22:50:43,963] Trial 28 finished with value: 0.23599015176296234 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -4.11349007203757, 'log_learning_rate_D': -4.9828352412983286, 'log_learning_rate_D_dagger': -1.001587738259603, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  19.207542896270752
Memory status after this trial: 
Memory allocated:  370.18701171875
Memory cached:  404.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.9676734483174876, 'log_learning_rate_D': -4.061557968458944, 'log_learning_rate_D_dagger': -3.8969226563669705, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.3921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.01220703125
Memory cached:  252.0
[I 2023-12-02 22:51:02,685] Trial 29 finished with value: 0.07596563547849655 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.9676734483174876, 'log_learning_rate_D': -4.061557968458944, 'log_learning_rate_D_dagger': -3.8969226563669705, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  18.518959045410156
Memory status after this trial: 
Memory allocated:  383.33544921875
Memory cached:  424.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.6095204136534846, 'log_learning_rate_D': -3.5789869368026523, 'log_learning_rate_D_dagger': -1.8409804352663561, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  10 training error:  tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  20 training error:  tensor(1.3436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.37060546875
Memory cached:  252.0
[I 2023-12-02 22:51:19,440] Trial 30 finished with value: 0.0950419008731842 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.6095204136534846, 'log_learning_rate_D': -3.5789869368026523, 'log_learning_rate_D_dagger': -1.8409804352663561, 'training_batch_size': 7, 'training_p': 6}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.561091899871826
Memory status after this trial: 
Memory allocated:  247.93505859375
Memory cached:  258.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.692745024038423, 'log_learning_rate_D': -4.3010723848942405, 'log_learning_rate_D_dagger': -2.315622363575834, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  10 training error:  tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  260.0
	 epoch  60 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  260.0
	 epoch  70 training error:  tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.8515625
Memory cached:  258.0
[I 2023-12-02 22:51:37,415] Trial 31 finished with value: 0.06996847689151764 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.692745024038423, 'log_learning_rate_D': -4.3010723848942405, 'log_learning_rate_D_dagger': -2.315622363575834, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.75243902206421
Memory status after this trial: 
Memory allocated:  260.02783203125
Memory cached:  268.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.4370631511421954, 'log_learning_rate_D': -4.3847604552606025, 'log_learning_rate_D_dagger': -2.1846434547023255, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.6076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.3583984375
Memory cached:  256.0
[I 2023-12-02 22:51:53,530] Trial 32 finished with value: 0.07336486130952835 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.4370631511421954, 'log_learning_rate_D': -4.3847604552606025, 'log_learning_rate_D_dagger': -2.1846434547023255, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  15.89801836013794
Memory status after this trial: 
Memory allocated:  214.39990234375
Memory cached:  262.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.762565957269265, 'log_learning_rate_D': -4.711404801470396, 'log_learning_rate_D_dagger': -2.643119561697288, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.4580078125
Memory cached:  258.0
[I 2023-12-02 22:52:12,551] Trial 33 finished with value: 0.07296352833509445 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.762565957269265, 'log_learning_rate_D': -4.711404801470396, 'log_learning_rate_D_dagger': -2.643119561697288, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  18.78750729560852
Memory status after this trial: 
Memory allocated:  270.86181640625
Memory cached:  282.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.054375335615754, 'log_learning_rate_D': -4.780239307460756, 'log_learning_rate_D_dagger': -2.9386698762498398, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  278.0
	 epoch  10 training error:  tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  20 training error:  tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  30 training error:  tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  40 training error:  tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  50 training error:  tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  60 training error:  tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  70 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  80 training error:  tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.52880859375
Memory cached:  280.0
[I 2023-12-02 22:52:30,235] Trial 34 finished with value: 0.07801677286624908 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.054375335615754, 'log_learning_rate_D': -4.780239307460756, 'log_learning_rate_D_dagger': -2.9386698762498398, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.43266534805298
Memory status after this trial: 
Memory allocated:  279.07666015625
Memory cached:  300.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.427952259784706, 'log_learning_rate_D': -4.412643864378854, 'log_learning_rate_D_dagger': -2.649988006793893, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
	 epoch  10 training error:  tensor(0.9596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  260.0
	 epoch  30 training error:  tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  260.0
	 epoch  50 training error:  tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  260.0
	 epoch  70 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  260.0
	 epoch  90 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.25341796875
Memory cached:  258.0
[I 2023-12-02 22:52:48,568] Trial 35 finished with value: 0.07041674107313156 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.427952259784706, 'log_learning_rate_D': -4.412643864378854, 'log_learning_rate_D_dagger': -2.649988006793893, 'training_batch_size': 10, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  18.117231845855713
Memory status after this trial: 
Memory allocated:  313.59228515625
Memory cached:  332.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.3157119528536674, 'log_learning_rate_D': -3.980422336201319, 'log_learning_rate_D_dagger': -2.2983488432389594, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  10 training error:  tensor(2.9313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  20 training error:  tensor(1.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  70 training error:  tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  80 training error:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.08251953125
Memory cached:  252.0
[I 2023-12-02 22:53:04,964] Trial 36 finished with value: 0.07622014731168747 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.3157119528536674, 'log_learning_rate_D': -3.980422336201319, 'log_learning_rate_D_dagger': -2.2983488432389594, 'training_batch_size': 9, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.191786527633667
Memory status after this trial: 
Memory allocated:  245.85400390625
Memory cached:  270.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.0243252332873216, 'log_learning_rate_D': -4.797768662034274, 'log_learning_rate_D_dagger': -3.0335847958787747, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  40 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  60 training error:  tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.08251953125
Memory cached:  256.0
[I 2023-12-02 22:53:22,952] Trial 37 finished with value: 0.06753917783498764 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.0243252332873216, 'log_learning_rate_D': -4.797768662034274, 'log_learning_rate_D_dagger': -3.0335847958787747, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.764798164367676
Memory status after this trial: 
Memory allocated:  249.97509765625
Memory cached:  270.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.5364257004172543, 'log_learning_rate_D': -4.570378621399451, 'log_learning_rate_D_dagger': -3.1528247563660687, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  254.0
	 epoch  20 training error:  tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  254.0
	 epoch  30 training error:  tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  40 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  60 training error:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6328125
Memory cached:  256.0
[I 2023-12-02 22:53:46,280] Trial 38 finished with value: 0.08265213668346405 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.5364257004172543, 'log_learning_rate_D': -4.570378621399451, 'log_learning_rate_D_dagger': -3.1528247563660687, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  23.110645532608032
Memory status after this trial: 
Memory allocated:  325.99658203125
Memory cached:  356.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.0782241086269795, 'log_learning_rate_D': -4.822897040353166, 'log_learning_rate_D_dagger': -2.8883221846356486, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.9073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  20 training error:  tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  30 training error:  tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  40 training error:  tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  50 training error:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  60 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  70 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  80 training error:  tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
	 epoch  90 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  143.56298828125
Memory cached:  260.0
[I 2023-12-02 22:54:05,797] Trial 39 finished with value: 0.07571151107549667 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -2.0782241086269795, 'log_learning_rate_D': -4.822897040353166, 'log_learning_rate_D_dagger': -2.8883221846356486, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  19.274576902389526
Memory status after this trial: 
Memory allocated:  299.49365234375
Memory cached:  324.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.23720191899143, 'log_learning_rate_D': -4.79264756714774, 'log_learning_rate_D_dagger': -3.076473670063576, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  10 training error:  tensor(1.1494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  20 training error:  tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  30 training error:  tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  40 training error:  tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  50 training error:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  60 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  70 training error:  tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  80 training error:  tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
	 epoch  90 training error:  tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  161.36767578125
Memory cached:  272.0
[I 2023-12-02 22:54:25,008] Trial 40 finished with value: 0.08538499474525452 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.23720191899143, 'log_learning_rate_D': -4.79264756714774, 'log_learning_rate_D_dagger': -3.076473670063576, 'training_batch_size': 10, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  19.001672983169556
Memory status after this trial: 
Memory allocated:  385.74267578125
Memory cached:  418.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.1465479006326613, 'log_learning_rate_D': -4.235257095322666, 'log_learning_rate_D_dagger': -2.6822635703036544, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  260.0
	 epoch  10 training error:  tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  260.0
	 epoch  40 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  260.0
	 epoch  60 training error:  tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  260.0
	 epoch  80 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.53076171875
Memory cached:  256.0
[I 2023-12-02 22:54:42,435] Trial 41 finished with value: 0.06649582833051682 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.1465479006326613, 'log_learning_rate_D': -4.235257095322666, 'log_learning_rate_D_dagger': -2.6822635703036544, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.2123601436615
Memory status after this trial: 
Memory allocated:  236.72216796875
Memory cached:  258.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.0424413061415696, 'log_learning_rate_D': -4.57581466016354, 'log_learning_rate_D_dagger': -2.8581620026935517, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.13623046875
Memory cached:  258.0
[I 2023-12-02 22:55:00,196] Trial 42 finished with value: 0.06737890094518661 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.0424413061415696, 'log_learning_rate_D': -4.57581466016354, 'log_learning_rate_D_dagger': -2.8581620026935517, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  17.538769483566284
Memory status after this trial: 
Memory allocated:  226.54638671875
Memory cached:  258.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.053689859599479, 'log_learning_rate_D': -4.517542645321402, 'log_learning_rate_D_dagger': -2.792375623463813, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  260.0
	 epoch  20 training error:  tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  260.0
	 epoch  40 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  260.0
	 epoch  60 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  260.0
	 epoch  80 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.58740234375
Memory cached:  260.0
[I 2023-12-02 22:55:17,024] Trial 43 finished with value: 0.07212107628583908 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -3.053689859599479, 'log_learning_rate_D': -4.517542645321402, 'log_learning_rate_D_dagger': -2.792375623463813, 'training_batch_size': 12, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.613797426223755
Memory status after this trial: 
Memory allocated:  216.39599609375
Memory cached:  262.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.7945109819161917, 'log_learning_rate_D': -4.872614540258816, 'log_learning_rate_D_dagger': -3.026654018314452, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  256.0
	 epoch  40 training error:  tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.75732421875
Memory cached:  258.0
[I 2023-12-02 22:55:34,037] Trial 44 finished with value: 0.07284324616193771 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.7945109819161917, 'log_learning_rate_D': -4.872614540258816, 'log_learning_rate_D_dagger': -3.026654018314452, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.78845500946045
Memory status after this trial: 
Memory allocated:  212.68505859375
Memory cached:  258.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.096521466795425, 'log_learning_rate_D': -4.999574419909844, 'log_learning_rate_D_dagger': -2.718065054658644, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  60 training error:  tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.95458984375
Memory cached:  258.0
[I 2023-12-02 22:55:50,922] Trial 45 finished with value: 0.0715450868010521 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.096521466795425, 'log_learning_rate_D': -4.999574419909844, 'log_learning_rate_D_dagger': -2.718065054658644, 'training_batch_size': 12, 'training_p': 5}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.678446531295776
Memory status after this trial: 
Memory allocated:  208.62158203125
Memory cached:  270.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.653742153335333, 'log_learning_rate_D': -4.530291655587464, 'log_learning_rate_D_dagger': -3.3192478591266807, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  10 training error:  tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  20 training error:  tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  40 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  60 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.10986328125
Memory cached:  256.0
[I 2023-12-02 22:56:07,440] Trial 46 finished with value: 0.07059653848409653 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.653742153335333, 'log_learning_rate_D': -4.530291655587464, 'log_learning_rate_D_dagger': -3.3192478591266807, 'training_batch_size': 11, 'training_p': 3}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.31113910675049
Memory status after this trial: 
Memory allocated:  202.78662109375
Memory cached:  278.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.897532081489211, 'log_learning_rate_D': -4.342412706010597, 'log_learning_rate_D_dagger': -2.0887709915708323, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.2640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  252.0
	 epoch  10 training error:  tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  20 training error:  tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  30 training error:  tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  50 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
	 epoch  90 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.99755859375
Memory cached:  254.0
[I 2023-12-02 22:56:24,571] Trial 47 finished with value: 0.092429518699646 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.897532081489211, 'log_learning_rate_D': -4.342412706010597, 'log_learning_rate_D_dagger': -2.0887709915708323, 'training_batch_size': 12, 'training_p': 7}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  16.92066240310669
Memory status after this trial: 
Memory allocated:  245.78369140625
Memory cached:  266.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.1852426869747004, 'log_learning_rate_D': -4.631398663772918, 'log_learning_rate_D_dagger': -2.886964188096685, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  20 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  40 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  50 training error:  tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.53369140625
Memory cached:  258.0
[I 2023-12-02 22:56:38,918] Trial 48 finished with value: 0.08132269978523254 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.1852426869747004, 'log_learning_rate_D': -4.631398663772918, 'log_learning_rate_D_dagger': -2.886964188096685, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.06371106207370758.
Time for this trial:  14.164478063583374
Memory status after this trial: 
Memory allocated:  171.36767578125
Memory cached:  260.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -2.9087910321527235, 'log_learning_rate_D': -4.82998565901336, 'log_learning_rate_D_dagger': -2.5903125759653656, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.9783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  10 training error:  tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  20 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  30 training error:  tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  50 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
	 epoch  90 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.24169921875
Memory cached:  254.0
[I 2023-12-02 22:56:53,628] Trial 49 finished with value: 0.07093650102615356 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -2.9087910321527235, 'log_learning_rate_D': -4.82998565901336, 'log_learning_rate_D_dagger': -2.5903125759653656, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.06371106207370758.
[I 2023-12-02 22:56:53,629] A new study created in memory with name: no-name-2b3cffd9-2c9c-467c-b5e6-7166987c3230
Time for this trial:  14.522521257400513
Memory status after this trial: 
Memory allocated:  177.81298828125
Memory cached:  254.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.344797830214564, 'log_learning_rate_D': -1.6025124489289824, 'log_learning_rate_D_dagger': -1.2891076432000963, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  90.0
	 epoch  10 training error:  tensor(348.8840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  172.0
	 epoch  20 training error:  tensor(58.8391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  174.0
	 epoch  30 training error:  tensor(92.8008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  176.0
	 epoch  40 training error:  tensor(13.0018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  174.0
	 epoch  50 training error:  tensor(14.1958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  168.0
	 epoch  60 training error:  tensor(82.7855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  174.0
	 epoch  70 training error:  tensor(10.5023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  172.0
	 epoch  80 training error:  tensor(18.1806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  174.0
	 epoch  90 training error:  tensor(10.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.072265625
Memory cached:  174.0
[I 2023-12-02 23:00:00,968] Trial 0 finished with value: 0.8955637216567993 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.344797830214564, 'log_learning_rate_D': -1.6025124489289824, 'log_learning_rate_D_dagger': -1.2891076432000963, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 0.8955637216567993.
res:  tensor(0.8956, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  187.2041096687317
Memory status after this trial: 
Memory allocated:  182.4423828125
Memory cached:  186.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.542050695274455, 'log_learning_rate_D': -1.3784606704159446, 'log_learning_rate_D_dagger': -1.3269627827762225, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.9003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  224.0
	 epoch  10 training error:  tensor(1642.9921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  310.0
	 epoch  20 training error:  tensor(1947.4528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  300.0
	 epoch  30 training error:  tensor(351.1162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  312.0
	 epoch  40 training error:  tensor(37.8583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  300.0
	 epoch  50 training error:  tensor(38.1996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  304.0
	 epoch  60 training error:  tensor(12.3267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  308.0
	 epoch  70 training error:  tensor(3.3637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  302.0
	 epoch  80 training error:  tensor(7.8263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  306.0
	 epoch  90 training error:  tensor(2.7364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.203125
Memory cached:  304.0
[I 2023-12-02 23:02:54,052] Trial 1 finished with value: 0.9675220847129822 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -4.542050695274455, 'log_learning_rate_D': -1.3784606704159446, 'log_learning_rate_D_dagger': -1.3269627827762225, 'training_batch_size': 12, 'training_p': 3}. Best is trial 0 with value: 0.8955637216567993.
Time for this trial:  172.95718502998352
Memory status after this trial: 
Memory allocated:  430.14013671875
Memory cached:  446.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.751415323089909, 'log_learning_rate_D': -2.453322334154339, 'log_learning_rate_D_dagger': -3.025064138372712, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.9394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  246.0
	 epoch  10 training error:  tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  284.0
	 epoch  20 training error:  tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  282.0
	 epoch  30 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  284.0
	 epoch  40 training error:  tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  284.0
	 epoch  50 training error:  tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  280.0
	 epoch  60 training error:  tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  282.0
	 epoch  70 training error:  tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  280.0
	 epoch  80 training error:  tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.072265625
Memory cached:  282.0
[I 2023-12-02 23:05:37,262] Trial 2 finished with value: 0.16639839112758636 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.751415323089909, 'log_learning_rate_D': -2.453322334154339, 'log_learning_rate_D_dagger': -3.025064138372712, 'training_batch_size': 7, 'training_p': 2}. Best is trial 2 with value: 0.16639839112758636.
res:  tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.8956, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  163.05670881271362
Memory status after this trial: 
Memory allocated:  182.42919921875
Memory cached:  360.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -4.854981461545103, 'log_learning_rate_D': -2.4268148678507386, 'log_learning_rate_D_dagger': -4.264264614900948, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  450.0
	 epoch  10 training error:  tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  520.0
	 epoch  20 training error:  tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  514.0
	 epoch  30 training error:  tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  514.0
	 epoch  40 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  510.0
	 epoch  50 training error:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  520.0
	 epoch  60 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  524.0
	 epoch  70 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  510.0
	 epoch  80 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  514.0
	 epoch  90 training error:  tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  237.53759765625
Memory cached:  516.0
[I 2023-12-02 23:09:16,377] Trial 3 finished with value: 0.048846784979104996 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -4.854981461545103, 'log_learning_rate_D': -2.4268148678507386, 'log_learning_rate_D_dagger': -4.264264614900948, 'training_batch_size': 10, 'training_p': 3}. Best is trial 3 with value: 0.048846784979104996.
res:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  218.98059272766113
Memory status after this trial: 
Memory allocated:  399.00341796875
Memory cached:  578.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.892352443435321, 'log_learning_rate_D': -1.0927232961286504, 'log_learning_rate_D_dagger': -4.8271905088028575, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  588.0
	 epoch  10 training error:  tensor(0.8418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  620.0
	 epoch  20 training error:  tensor(0.6145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  632.0
	 epoch  30 training error:  tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  630.0
	 epoch  40 training error:  tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  624.0
	 epoch  50 training error:  tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  632.0
	 epoch  60 training error:  tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  636.0
	 epoch  70 training error:  tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  628.0
	 epoch  80 training error:  tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  638.0
	 epoch  90 training error:  tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  409.16455078125
Memory cached:  634.0
[I 2023-12-02 23:12:14,759] Trial 4 finished with value: 0.10975195467472076 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.892352443435321, 'log_learning_rate_D': -1.0927232961286504, 'log_learning_rate_D_dagger': -4.8271905088028575, 'training_batch_size': 11, 'training_p': 5}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  178.2531132698059
Memory status after this trial: 
Memory allocated:  562.2548828125
Memory cached:  610.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.569417198352099, 'log_learning_rate_D': -2.4792344679762763, 'log_learning_rate_D_dagger': -1.7609725505288432, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  628.0
	 epoch  10 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  690.0
	 epoch  20 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  690.0
	 epoch  30 training error:  tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  696.0
	 epoch  40 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  700.0
	 epoch  50 training error:  tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  690.0
	 epoch  60 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  692.0
	 epoch  70 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  694.0
	 epoch  80 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  680.0
	 epoch  90 training error:  tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  450.77001953125
Memory cached:  694.0
[I 2023-12-02 23:16:24,780] Trial 5 finished with value: 0.049715857952833176 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.569417198352099, 'log_learning_rate_D': -2.4792344679762763, 'log_learning_rate_D_dagger': -1.7609725505288432, 'training_batch_size': 8, 'training_p': 4}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  249.85767006874084
Memory status after this trial: 
Memory allocated:  827.41650390625
Memory cached:  850.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.190445536989097, 'log_learning_rate_D': -3.868918264855515, 'log_learning_rate_D_dagger': -1.0294277155370914, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(79.3895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  606.0
	 epoch  10 training error:  tensor(2.4100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  664.0
	 epoch  20 training error:  tensor(1.8577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  652.0
	 epoch  30 training error:  tensor(1.8751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  658.0
	 epoch  40 training error:  tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  658.0
	 epoch  50 training error:  tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  652.0
	 epoch  60 training error:  tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  666.0
	 epoch  70 training error:  tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  660.0
	 epoch  80 training error:  tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  648.0
	 epoch  90 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.64111328125
Memory cached:  650.0
[I 2023-12-02 23:22:20,713] Trial 6 finished with value: 0.06272581219673157 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.190445536989097, 'log_learning_rate_D': -3.868918264855515, 'log_learning_rate_D_dagger': -1.0294277155370914, 'training_batch_size': 6, 'training_p': 2}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  355.7164740562439
Memory status after this trial: 
Memory allocated:  613.78564453125
Memory cached:  646.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.910051332434436, 'log_learning_rate_D': -1.8894596153243866, 'log_learning_rate_D_dagger': -4.367701143918165, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  586.0
	 epoch  10 training error:  tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  632.0
	 epoch  20 training error:  tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  620.0
	 epoch  30 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  630.0
	 epoch  40 training error:  tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  626.0
	 epoch  50 training error:  tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  630.0
	 epoch  60 training error:  tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  622.0
	 epoch  70 training error:  tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  628.0
	 epoch  80 training error:  tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  624.0
	 epoch  90 training error:  tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  413.81689453125
Memory cached:  624.0
[I 2023-12-02 23:25:51,583] Trial 7 finished with value: 0.13017943501472473 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.910051332434436, 'log_learning_rate_D': -1.8894596153243866, 'log_learning_rate_D_dagger': -4.367701143918165, 'training_batch_size': 8, 'training_p': 5}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  210.68426060676575
Memory status after this trial: 
Memory allocated:  661.640625
Memory cached:  686.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6454279423331677, 'log_learning_rate_D': -4.954378079305073, 'log_learning_rate_D_dagger': -1.7889664886125796, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.7068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  586.0
	 epoch  10 training error:  tensor(0.8618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  644.0
	 epoch  20 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  648.0
	 epoch  30 training error:  tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  642.0
	 epoch  40 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  644.0
	 epoch  50 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  648.0
	 epoch  60 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  648.0
	 epoch  70 training error:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  638.0
	 epoch  80 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  654.0
	 epoch  90 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  406.18994140625
Memory cached:  646.0
[I 2023-12-02 23:29:10,386] Trial 8 finished with value: 0.0601857490837574 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6454279423331677, 'log_learning_rate_D': -4.954378079305073, 'log_learning_rate_D_dagger': -1.7889664886125796, 'training_batch_size': 10, 'training_p': 2}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  198.63535475730896
Memory status after this trial: 
Memory allocated:  594.201171875
Memory cached:  624.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.2568805507786935, 'log_learning_rate_D': -1.3019089996645894, 'log_learning_rate_D_dagger': -2.4079845145839482, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  586.0
	 epoch  10 training error:  tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  618.0
	 epoch  20 training error:  tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  616.0
	 epoch  30 training error:  tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  610.0
	 epoch  40 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  620.0
	 epoch  50 training error:  tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  616.0
	 epoch  60 training error:  tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  620.0
	 epoch  70 training error:  tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  616.0
	 epoch  80 training error:  tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  616.0
	 epoch  90 training error:  tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  399.95751953125
Memory cached:  614.0
[I 2023-12-02 23:31:41,460] Trial 9 finished with value: 0.12899459898471832 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -2.2568805507786935, 'log_learning_rate_D': -1.3019089996645894, 'log_learning_rate_D_dagger': -2.4079845145839482, 'training_batch_size': 12, 'training_p': 8}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  150.89216375350952
Memory status after this trial: 
Memory allocated:  470.01708984375
Memory cached:  608.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.223826639423507, 'log_learning_rate_D': -3.379823190230316, 'log_learning_rate_D_dagger': -3.8696674019012933, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  650.0
	 epoch  10 training error:  tensor(55.3402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  710.0
	 epoch  20 training error:  tensor(0.6844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  720.0
	 epoch  30 training error:  tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  710.0
	 epoch  40 training error:  tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  716.0
	 epoch  50 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  718.0
	 epoch  60 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  720.0
	 epoch  70 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  720.0
	 epoch  80 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  718.0
	 epoch  90 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  477.77783203125
Memory cached:  720.0
[I 2023-12-02 23:35:30,532] Trial 10 finished with value: 0.05729854106903076 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.223826639423507, 'log_learning_rate_D': -3.379823190230316, 'log_learning_rate_D_dagger': -3.8696674019012933, 'training_batch_size': 9, 'training_p': 6}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  228.8026156425476
Memory status after this trial: 
Memory allocated:  891.80419921875
Memory cached:  916.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.963865625110244, 'log_learning_rate_D': -2.4967306104666647, 'log_learning_rate_D_dagger': -3.4006881896026524, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  598.0
	 epoch  10 training error:  tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  656.0
	 epoch  20 training error:  tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  666.0
	 epoch  30 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  658.0
	 epoch  40 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  664.0
	 epoch  50 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  654.0
	 epoch  60 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  656.0
	 epoch  70 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  664.0
	 epoch  80 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  660.0
	 epoch  90 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.02392578125
Memory cached:  644.0
[I 2023-12-02 23:39:46,383] Trial 11 finished with value: 0.04961373284459114 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.963865625110244, 'log_learning_rate_D': -2.4967306104666647, 'log_learning_rate_D_dagger': -3.4006881896026524, 'training_batch_size': 9, 'training_p': 4}. Best is trial 3 with value: 0.048846784979104996.
Time for this trial:  255.56158113479614
Memory status after this trial: 
Memory allocated:  791.0634765625
Memory cached:  806.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -4.995426058654935, 'log_learning_rate_D': -2.4975390881466124, 'log_learning_rate_D_dagger': -3.595998417996423, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  616.0
	 epoch  10 training error:  tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  672.0
	 epoch  20 training error:  tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  666.0
	 epoch  30 training error:  tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  666.0
	 epoch  40 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  674.0
	 epoch  50 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  678.0
	 epoch  60 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  664.0
	 epoch  70 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  678.0
	 epoch  80 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  680.0
	 epoch  90 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  443.01220703125
Memory cached:  672.0
[I 2023-12-02 23:44:33,724] Trial 12 finished with value: 0.04871133714914322 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -4.995426058654935, 'log_learning_rate_D': -2.4975390881466124, 'log_learning_rate_D_dagger': -3.595998417996423, 'training_batch_size': 9, 'training_p': 4}. Best is trial 12 with value: 0.04871133714914322.
res:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  287.01801085472107
Memory status after this trial: 
Memory allocated:  530.68017578125
Memory cached:  850.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -3.788801405084909, 'log_learning_rate_D': -3.1105953997684215, 'log_learning_rate_D_dagger': -3.8963985499919582, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  860.0
	 epoch  10 training error:  tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  898.0
	 epoch  20 training error:  tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  902.0
	 epoch  30 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  902.0
	 epoch  40 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  902.0
	 epoch  50 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  902.0
	 epoch  60 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  904.0
	 epoch  70 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  902.0
	 epoch  80 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  906.0
	 epoch  90 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  571.92919921875
Memory cached:  904.0
[I 2023-12-02 23:48:50,331] Trial 13 finished with value: 0.042232122272253036 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -3.788801405084909, 'log_learning_rate_D': -3.1105953997684215, 'log_learning_rate_D_dagger': -3.8963985499919582, 'training_batch_size': 10, 'training_p': 4}. Best is trial 13 with value: 0.042232122272253036.
res:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  256.3573019504547
Memory status after this trial: 
Memory allocated:  421.86865234375
Memory cached:  728.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -3.6747406609709605, 'log_learning_rate_D': -3.179735755519376, 'log_learning_rate_D_dagger': -3.5207683186207017, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  742.0
	 epoch  20 training error:  tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  744.0
	 epoch  30 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  742.0
	 epoch  40 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  742.0
	 epoch  50 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  746.0
	 epoch  60 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  740.0
	 epoch  70 training error:  tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  744.0
	 epoch  80 training error:  tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  744.0
	 epoch  90 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  452.91650390625
Memory cached:  742.0
[I 2023-12-02 23:53:10,128] Trial 14 finished with value: 0.0555742084980011 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 9, 'log_learning_rate': -3.6747406609709605, 'log_learning_rate_D': -3.179735755519376, 'log_learning_rate_D_dagger': -3.5207683186207017, 'training_batch_size': 10, 'training_p': 4}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  259.547242641449
Memory status after this trial: 
Memory allocated:  820.7041015625
Memory cached:  862.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.478869361604544, 'log_learning_rate_D': -3.7048517544490873, 'log_learning_rate_D_dagger': -2.8410422170908625, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  740.0
	 epoch  20 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  746.0
	 epoch  30 training error:  tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  736.0
	 epoch  40 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  746.0
	 epoch  50 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  744.0
	 epoch  60 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  744.0
	 epoch  70 training error:  tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  744.0
	 epoch  80 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  740.0
	 epoch  90 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.39697265625
Memory cached:  736.0
[I 2023-12-02 23:57:04,788] Trial 15 finished with value: 0.050004810094833374 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.478869361604544, 'log_learning_rate_D': -3.7048517544490873, 'log_learning_rate_D_dagger': -2.8410422170908625, 'training_batch_size': 8, 'training_p': 6}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  234.36757612228394
Memory status after this trial: 
Memory allocated:  730.57177734375
Memory cached:  774.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.119897769231888, 'log_learning_rate_D': -2.9403822250170877, 'log_learning_rate_D_dagger': -3.8706705252346763, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  740.0
	 epoch  20 training error:  tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  740.0
	 epoch  30 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  744.0
	 epoch  40 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  742.0
	 epoch  50 training error:  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  740.0
	 epoch  60 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  744.0
	 epoch  70 training error:  tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  734.0
	 epoch  80 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  742.0
	 epoch  90 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  432.13720703125
Memory cached:  738.0
[I 2023-12-03 00:01:07,462] Trial 16 finished with value: 0.04812850058078766 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.119897769231888, 'log_learning_rate_D': -2.9403822250170877, 'log_learning_rate_D_dagger': -3.8706705252346763, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  242.35879850387573
Memory status after this trial: 
Memory allocated:  658.12646484375
Memory cached:  732.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.2717647588537657, 'log_learning_rate_D': -2.8665576602622824, 'log_learning_rate_D_dagger': -4.989596096732159, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  706.0
	 epoch  10 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  740.0
	 epoch  20 training error:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  754.0
	 epoch  30 training error:  tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  752.0
	 epoch  40 training error:  tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  746.0
	 epoch  50 training error:  tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  746.0
	 epoch  60 training error:  tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  750.0
	 epoch  70 training error:  tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  748.0
	 epoch  80 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  748.0
	 epoch  90 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  444.68212890625
Memory cached:  748.0
[I 2023-12-03 00:05:25,737] Trial 17 finished with value: 0.05847371369600296 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -3.2717647588537657, 'log_learning_rate_D': -2.8665576602622824, 'log_learning_rate_D_dagger': -4.989596096732159, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  257.9521725177765
Memory status after this trial: 
Memory allocated:  757.37841796875
Memory cached:  794.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.086349081620573, 'log_learning_rate_D': -4.004985457092912, 'log_learning_rate_D_dagger': -4.035541112712686, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  700.0
	 epoch  10 training error:  tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  730.0
	 epoch  20 training error:  tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  728.0
	 epoch  30 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  732.0
	 epoch  40 training error:  tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  726.0
	 epoch  50 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  722.0
	 epoch  60 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  724.0
	 epoch  70 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  726.0
	 epoch  80 training error:  tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  722.0
	 epoch  90 training error:  tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.91259765625
Memory cached:  724.0
[I 2023-12-03 00:08:31,057] Trial 18 finished with value: 0.047891389578580856 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.086349081620573, 'log_learning_rate_D': -4.004985457092912, 'log_learning_rate_D_dagger': -4.035541112712686, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  185.02723908424377
Memory status after this trial: 
Memory allocated:  566.978515625
Memory cached:  716.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.1900066724584457, 'log_learning_rate_D': -4.241141468231162, 'log_learning_rate_D_dagger': -4.349540289612081, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  750.0
	 epoch  20 training error:  tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  732.0
	 epoch  30 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  738.0
	 epoch  40 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  730.0
	 epoch  50 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  732.0
	 epoch  60 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  728.0
	 epoch  70 training error:  tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  740.0
	 epoch  80 training error:  tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  734.0
	 epoch  90 training error:  tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.08837890625
Memory cached:  732.0
[I 2023-12-03 00:11:35,499] Trial 19 finished with value: 0.054985880851745605 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.1900066724584457, 'log_learning_rate_D': -4.241141468231162, 'log_learning_rate_D_dagger': -4.349540289612081, 'training_batch_size': 12, 'training_p': 6}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  184.1682744026184
Memory status after this trial: 
Memory allocated:  554.6845703125
Memory cached:  720.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -3.6055032942441634, 'log_learning_rate_D': -4.37815455311331, 'log_learning_rate_D_dagger': -4.641435885908658, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.6080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  708.0
	 epoch  10 training error:  tensor(1.5439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  722.0
	 epoch  20 training error:  tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  724.0
	 epoch  30 training error:  tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  734.0
	 epoch  40 training error:  tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  722.0
	 epoch  50 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  728.0
	 epoch  60 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  734.0
	 epoch  70 training error:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  734.0
	 epoch  80 training error:  tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  722.0
	 epoch  90 training error:  tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  431.60595703125
Memory cached:  726.0
[I 2023-12-03 00:14:31,306] Trial 20 finished with value: 0.09736348688602448 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -3.6055032942441634, 'log_learning_rate_D': -4.37815455311331, 'log_learning_rate_D_dagger': -4.641435885908658, 'training_batch_size': 10, 'training_p': 5}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  175.5507469177246
Memory status after this trial: 
Memory allocated:  557.35107421875
Memory cached:  712.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.115609569658503, 'log_learning_rate_D': -3.4663030444069425, 'log_learning_rate_D_dagger': -3.9220701124246284, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  716.0
	 epoch  10 training error:  tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  738.0
	 epoch  20 training error:  tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  748.0
	 epoch  30 training error:  tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  744.0
	 epoch  40 training error:  tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  748.0
	 epoch  50 training error:  tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  742.0
	 epoch  60 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  742.0
	 epoch  70 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  740.0
	 epoch  80 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  746.0
	 epoch  90 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.32080078125
Memory cached:  742.0
[I 2023-12-03 00:18:10,319] Trial 21 finished with value: 0.052277352660894394 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.115609569658503, 'log_learning_rate_D': -3.4663030444069425, 'log_learning_rate_D_dagger': -3.9220701124246284, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  218.72449326515198
Memory status after this trial: 
Memory allocated:  592.169921875
Memory cached:  732.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.983621539070144, 'log_learning_rate_D': -2.9269419609728455, 'log_learning_rate_D_dagger': -4.006045213942007, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  702.0
	 epoch  10 training error:  tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  736.0
	 epoch  20 training error:  tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  740.0
	 epoch  30 training error:  tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  734.0
	 epoch  40 training error:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  732.0
	 epoch  50 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  728.0
	 epoch  60 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  734.0
	 epoch  70 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  738.0
	 epoch  80 training error:  tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  732.0
	 epoch  90 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  439.50830078125
Memory cached:  732.0
[I 2023-12-03 00:21:55,601] Trial 22 finished with value: 0.05038820579648018 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.983621539070144, 'log_learning_rate_D': -2.9269419609728455, 'log_learning_rate_D_dagger': -4.006045213942007, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  224.97458362579346
Memory status after this trial: 
Memory allocated:  684.16064453125
Memory cached:  720.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -4.274127434651072, 'log_learning_rate_D': -3.051815963615662, 'log_learning_rate_D_dagger': -4.578984274335711, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.3375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  710.0
	 epoch  10 training error:  tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  746.0
	 epoch  20 training error:  tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  748.0
	 epoch  30 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  746.0
	 epoch  40 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  746.0
	 epoch  50 training error:  tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  742.0
	 epoch  60 training error:  tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  742.0
	 epoch  70 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  746.0
	 epoch  80 training error:  tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  746.0
	 epoch  90 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  427.79541015625
Memory cached:  742.0
[I 2023-12-03 00:25:33,225] Trial 23 finished with value: 0.06500726193189621 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -4.274127434651072, 'log_learning_rate_D': -3.051815963615662, 'log_learning_rate_D_dagger': -4.578984274335711, 'training_batch_size': 10, 'training_p': 4}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  217.2933909893036
Memory status after this trial: 
Memory allocated:  590.46875
Memory cached:  734.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -3.794415070861998, 'log_learning_rate_D': -3.671893822988822, 'log_learning_rate_D_dagger': -4.090723522712253, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  702.0
	 epoch  10 training error:  tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  754.0
	 epoch  20 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  754.0
	 epoch  30 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  754.0
	 epoch  40 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  746.0
	 epoch  50 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  744.0
	 epoch  60 training error:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  742.0
	 epoch  70 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  752.0
	 epoch  80 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  750.0
	 epoch  90 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  434.00244140625
Memory cached:  748.0
[I 2023-12-03 00:29:05,738] Trial 24 finished with value: 0.04788970947265625 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -3.794415070861998, 'log_learning_rate_D': -3.671893822988822, 'log_learning_rate_D_dagger': -4.090723522712253, 'training_batch_size': 12, 'training_p': 2}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  212.21213388442993
Memory status after this trial: 
Memory allocated:  662.365234375
Memory cached:  728.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.759045119491111, 'log_learning_rate_D': -3.8643488342052392, 'log_learning_rate_D_dagger': -4.243605115593905, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  706.0
	 epoch  10 training error:  tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  736.0
	 epoch  20 training error:  tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  734.0
	 epoch  30 training error:  tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  736.0
	 epoch  40 training error:  tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  738.0
	 epoch  50 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  740.0
	 epoch  60 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  742.0
	 epoch  70 training error:  tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  740.0
	 epoch  80 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  740.0
	 epoch  90 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  436.84033203125
Memory cached:  738.0
[I 2023-12-03 00:32:44,669] Trial 25 finished with value: 0.050907742232084274 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.759045119491111, 'log_learning_rate_D': -3.8643488342052392, 'log_learning_rate_D_dagger': -4.243605115593905, 'training_batch_size': 12, 'training_p': 2}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  218.6382598876953
Memory status after this trial: 
Memory allocated:  688.75244140625
Memory cached:  728.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.310400260751955, 'log_learning_rate_D': -3.5920213115357504, 'log_learning_rate_D_dagger': -4.654769062214861, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  714.0
	 epoch  10 training error:  tensor(2.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  756.0
	 epoch  20 training error:  tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  736.0
	 epoch  30 training error:  tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  746.0
	 epoch  40 training error:  tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  756.0
	 epoch  50 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  752.0
	 epoch  60 training error:  tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  754.0
	 epoch  70 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  750.0
	 epoch  80 training error:  tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  738.0
	 epoch  90 training error:  tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.20166015625
Memory cached:  742.0
[I 2023-12-03 00:35:27,369] Trial 26 finished with value: 0.23451447486877441 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.310400260751955, 'log_learning_rate_D': -3.5920213115357504, 'log_learning_rate_D_dagger': -4.654769062214861, 'training_batch_size': 12, 'training_p': 2}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  162.43992400169373
Memory status after this trial: 
Memory allocated:  600.00146484375
Memory cached:  730.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.8066072765999097, 'log_learning_rate_D': -4.075784610094964, 'log_learning_rate_D_dagger': -3.279557137399171, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  712.0
	 epoch  10 training error:  tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  732.0
	 epoch  20 training error:  tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  734.0
	 epoch  30 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  730.0
	 epoch  40 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  732.0
	 epoch  50 training error:  tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  744.0
	 epoch  60 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  740.0
	 epoch  70 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  742.0
	 epoch  80 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  738.0
	 epoch  90 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  429.36572265625
Memory cached:  746.0
[I 2023-12-03 00:38:25,026] Trial 27 finished with value: 0.045183271169662476 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.8066072765999097, 'log_learning_rate_D': -4.075784610094964, 'log_learning_rate_D_dagger': -3.279557137399171, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  177.40474200248718
Memory status after this trial: 
Memory allocated:  604.80126953125
Memory cached:  728.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.741108167354722, 'log_learning_rate_D': -4.333201490037606, 'log_learning_rate_D_dagger': -3.358442503610924, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  698.0
	 epoch  10 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  718.0
	 epoch  20 training error:  tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  708.0
	 epoch  30 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  718.0
	 epoch  40 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  718.0
	 epoch  50 training error:  tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  720.0
	 epoch  60 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  720.0
	 epoch  70 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  720.0
	 epoch  80 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  720.0
	 epoch  90 training error:  tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.36181640625
Memory cached:  728.0
[I 2023-12-03 00:41:26,040] Trial 28 finished with value: 0.04892457649111748 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.741108167354722, 'log_learning_rate_D': -4.333201490037606, 'log_learning_rate_D_dagger': -3.358442503610924, 'training_batch_size': 12, 'training_p': 2}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  180.76672840118408
Memory status after this trial: 
Memory allocated:  617.3330078125
Memory cached:  712.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.513514907277164, 'log_learning_rate_D': -3.273244931869779, 'log_learning_rate_D_dagger': -3.6603510048580623, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.6486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  706.0
	 epoch  10 training error:  tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  748.0
	 epoch  20 training error:  tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  742.0
	 epoch  30 training error:  tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  742.0
	 epoch  40 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  736.0
	 epoch  50 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  738.0
	 epoch  60 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  750.0
	 epoch  70 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  732.0
	 epoch  80 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  740.0
	 epoch  90 training error:  tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  426.13916015625
Memory cached:  748.0
[I 2023-12-03 00:44:34,926] Trial 29 finished with value: 0.053107596933841705 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.513514907277164, 'log_learning_rate_D': -3.273244931869779, 'log_learning_rate_D_dagger': -3.6603510048580623, 'training_batch_size': 10, 'training_p': 5}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  188.61583042144775
Memory status after this trial: 
Memory allocated:  582.5654296875
Memory cached:  728.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.012487231126204, 'log_learning_rate_D': -3.4980288229004515, 'log_learning_rate_D_dagger': -3.1122139697060196, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  738.0
	 epoch  20 training error:  tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  742.0
	 epoch  30 training error:  tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  742.0
	 epoch  40 training error:  tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  736.0
	 epoch  50 training error:  tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  730.0
	 epoch  60 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  738.0
	 epoch  70 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  738.0
	 epoch  80 training error:  tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  734.0
	 epoch  90 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  441.63134765625
Memory cached:  734.0
[I 2023-12-03 00:47:50,878] Trial 30 finished with value: 0.07229708880186081 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.012487231126204, 'log_learning_rate_D': -3.4980288229004515, 'log_learning_rate_D_dagger': -3.1122139697060196, 'training_batch_size': 11, 'training_p': 4}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  195.67746806144714
Memory status after this trial: 
Memory allocated:  676.21728515625
Memory cached:  720.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.8423580006826907, 'log_learning_rate_D': -4.049456221589548, 'log_learning_rate_D_dagger': -4.132002585749594, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  720.0
	 epoch  10 training error:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  754.0
	 epoch  20 training error:  tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  742.0
	 epoch  30 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  752.0
	 epoch  40 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  748.0
	 epoch  50 training error:  tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  748.0
	 epoch  60 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  748.0
	 epoch  70 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  748.0
	 epoch  80 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  750.0
	 epoch  90 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.71728515625
Memory cached:  752.0
[I 2023-12-03 00:51:03,843] Trial 31 finished with value: 0.04901713505387306 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -3.8423580006826907, 'log_learning_rate_D': -4.049456221589548, 'log_learning_rate_D_dagger': -4.132002585749594, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  192.68733644485474
Memory status after this trial: 
Memory allocated:  615.30517578125
Memory cached:  724.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.341621306521076, 'log_learning_rate_D': -3.726549173798156, 'log_learning_rate_D_dagger': -3.7681883946177104, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  698.0
	 epoch  10 training error:  tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  712.0
	 epoch  20 training error:  tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  716.0
	 epoch  30 training error:  tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  718.0
	 epoch  40 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  708.0
	 epoch  50 training error:  tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  720.0
	 epoch  60 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  718.0
	 epoch  70 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  720.0
	 epoch  80 training error:  tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  712.0
	 epoch  90 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  430.15673828125
Memory cached:  712.0
[I 2023-12-03 00:54:03,206] Trial 32 finished with value: 0.043496113270521164 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.341621306521076, 'log_learning_rate_D': -3.726549173798156, 'log_learning_rate_D_dagger': -3.7681883946177104, 'training_batch_size': 11, 'training_p': 3}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  179.09553050994873
Memory status after this trial: 
Memory allocated:  613.4794921875
Memory cached:  706.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.3915953155053895, 'log_learning_rate_D': -3.6651803263379747, 'log_learning_rate_D_dagger': -3.262642097908282, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.5541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  748.0
	 epoch  20 training error:  tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  744.0
	 epoch  30 training error:  tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  746.0
	 epoch  40 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  750.0
	 epoch  50 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  742.0
	 epoch  60 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  750.0
	 epoch  70 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  746.0
	 epoch  80 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  736.0
	 epoch  90 training error:  tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  428.46337890625
Memory cached:  740.0
[I 2023-12-03 00:56:36,096] Trial 33 finished with value: 0.05628710985183716 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.3915953155053895, 'log_learning_rate_D': -3.6651803263379747, 'log_learning_rate_D_dagger': -3.262642097908282, 'training_batch_size': 12, 'training_p': 2}. Best is trial 13 with value: 0.042232122272253036.
Time for this trial:  152.6307303905487
Memory status after this trial: 
Memory allocated:  586.4326171875
Memory cached:  734.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.543947388491094, 'log_learning_rate_D': -3.274608095540596, 'log_learning_rate_D_dagger': -3.6898059040044884, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  708.0
	 epoch  10 training error:  tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  726.0
	 epoch  20 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  730.0
	 epoch  30 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  734.0
	 epoch  40 training error:  tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  728.0
	 epoch  50 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  728.0
	 epoch  60 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  728.0
	 epoch  70 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  732.0
	 epoch  80 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  730.0
	 epoch  90 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  425.31298828125
Memory cached:  730.0
[I 2023-12-03 00:59:15,003] Trial 34 finished with value: 0.04209517315030098 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.543947388491094, 'log_learning_rate_D': -3.274608095540596, 'log_learning_rate_D_dagger': -3.6898059040044884, 'training_batch_size': 10, 'training_p': 3}. Best is trial 34 with value: 0.04209517315030098.
res:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  158.65140914916992
Memory status after this trial: 
Memory allocated:  165.79833984375
Memory cached:  558.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.527379146876994, 'log_learning_rate_D': -3.2009899250655036, 'log_learning_rate_D_dagger': -3.7059807470688537, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(3.2349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  532.0
	 epoch  10 training error:  tensor(1.1928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  20 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  532.0
	 epoch  30 training error:  tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  40 training error:  tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  50 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  60 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  70 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  532.0
	 epoch  80 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
	 epoch  90 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.58642578125
Memory cached:  530.0
[I 2023-12-03 01:01:37,628] Trial 35 finished with value: 0.04115964472293854 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.527379146876994, 'log_learning_rate_D': -3.2009899250655036, 'log_learning_rate_D_dagger': -3.7059807470688537, 'training_batch_size': 10, 'training_p': 3}. Best is trial 35 with value: 0.04115964472293854.
res:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  142.39532041549683
Memory status after this trial: 
Memory allocated:  124.0419921875
Memory cached:  456.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.645156399015908, 'log_learning_rate_D': -3.1933826398119636, 'log_learning_rate_D_dagger': -3.751330119467964, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  444.0
	 epoch  10 training error:  tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  466.0
	 epoch  20 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  462.0
	 epoch  30 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  470.0
	 epoch  40 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  470.0
	 epoch  50 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  474.0
	 epoch  60 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  470.0
	 epoch  70 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  470.0
	 epoch  80 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  468.0
	 epoch  90 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.115234375
Memory cached:  468.0
[I 2023-12-03 01:04:02,352] Trial 36 finished with value: 0.03745831176638603 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -4.645156399015908, 'log_learning_rate_D': -3.1933826398119636, 'log_learning_rate_D_dagger': -3.751330119467964, 'training_batch_size': 10, 'training_p': 4}. Best is trial 36 with value: 0.03745831176638603.
res:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  144.52461647987366
Memory status after this trial: 
Memory allocated:  137.7880859375
Memory cached:  388.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.582323891698455, 'log_learning_rate_D': -2.723193624901005, 'log_learning_rate_D_dagger': -3.6866449184803773, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  374.0
	 epoch  10 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  390.0
	 epoch  20 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  384.0
	 epoch  30 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  384.0
	 epoch  40 training error:  tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  398.0
	 epoch  50 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  390.0
	 epoch  60 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  392.0
	 epoch  70 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  392.0
	 epoch  80 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  388.0
	 epoch  90 training error:  tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  386.0
[I 2023-12-03 01:06:14,051] Trial 37 finished with value: 0.03799160197377205 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.582323891698455, 'log_learning_rate_D': -2.723193624901005, 'log_learning_rate_D_dagger': -3.6866449184803773, 'training_batch_size': 9, 'training_p': 4}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  131.5039975643158
Memory status after this trial: 
Memory allocated:  267.216796875
Memory cached:  378.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.702222534301146, 'log_learning_rate_D': -2.7643372738164467, 'log_learning_rate_D_dagger': -3.629210568080422, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  364.0
	 epoch  10 training error:  tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  380.0
	 epoch  20 training error:  tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  386.0
	 epoch  30 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  388.0
	 epoch  40 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  386.0
	 epoch  50 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  388.0
	 epoch  60 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  394.0
	 epoch  70 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  394.0
	 epoch  80 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  386.0
	 epoch  90 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.11328125
Memory cached:  390.0
[I 2023-12-03 01:08:26,847] Trial 38 finished with value: 0.03935789689421654 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.702222534301146, 'log_learning_rate_D': -2.7643372738164467, 'log_learning_rate_D_dagger': -3.629210568080422, 'training_batch_size': 9, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  132.59457516670227
Memory status after this trial: 
Memory allocated:  267.216796875
Memory cached:  370.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.738736591294657, 'log_learning_rate_D': -2.724151667767632, 'log_learning_rate_D_dagger': -3.5751591768714994, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  368.0
	 epoch  10 training error:  tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  396.0
	 epoch  20 training error:  tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  394.0
	 epoch  30 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  392.0
	 epoch  40 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  390.0
	 epoch  50 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  388.0
	 epoch  60 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  390.0
	 epoch  70 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  398.0
	 epoch  80 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  394.0
	 epoch  90 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.544921875
Memory cached:  390.0
[I 2023-12-03 01:10:35,197] Trial 39 finished with value: 0.03913966566324234 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.738736591294657, 'log_learning_rate_D': -2.724151667767632, 'log_learning_rate_D_dagger': -3.5751591768714994, 'training_batch_size': 8, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  128.15423941612244
Memory status after this trial: 
Memory allocated:  263.76904296875
Memory cached:  378.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.750614482125645, 'log_learning_rate_D': -2.738573943023598, 'log_learning_rate_D_dagger': -2.853962784859685, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  10 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  20 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  30 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  40 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  50 training error:  tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  362.0
	 epoch  60 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
[I 2023-12-03 01:12:36,788] Trial 40 finished with value: 0.040359389036893845 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.750614482125645, 'log_learning_rate_D': -2.738573943023598, 'log_learning_rate_D_dagger': -2.853962784859685, 'training_batch_size': 7, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  121.37945413589478
Memory status after this trial: 
Memory allocated:  209.96240234375
Memory cached:  356.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.695403538931189, 'log_learning_rate_D': -2.7522032802653182, 'log_learning_rate_D_dagger': -2.7988552564010623, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  10 training error:  tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  20 training error:  tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  30 training error:  tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  40 training error:  tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  362.0
	 epoch  50 training error:  tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
	 epoch  60 training error:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  70 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  80 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  358.0
	 epoch  90 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.255859375
Memory cached:  360.0
[I 2023-12-03 01:14:38,806] Trial 41 finished with value: 0.04371652007102966 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.695403538931189, 'log_learning_rate_D': -2.7522032802653182, 'log_learning_rate_D_dagger': -2.7988552564010623, 'training_batch_size': 7, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  121.80882740020752
Memory status after this trial: 
Memory allocated:  209.96240234375
Memory cached:  358.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -4.774622087442209, 'log_learning_rate_D': -2.7119401645365, 'log_learning_rate_D_dagger': -3.081979242103426, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.8249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  10 training error:  tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  20 training error:  tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  30 training error:  tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  40 training error:  tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  50 training error:  tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  60 training error:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  70 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  80 training error:  tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
	 epoch  90 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.94921875
Memory cached:  356.0
[I 2023-12-03 01:16:29,289] Trial 42 finished with value: 0.06690074503421783 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -4.774622087442209, 'log_learning_rate_D': -2.7119401645365, 'log_learning_rate_D_dagger': -3.081979242103426, 'training_batch_size': 7, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  110.28318476676941
Memory status after this trial: 
Memory allocated:  160.05322265625
Memory cached:  356.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.764462544894271, 'log_learning_rate_D': -2.148722664070661, 'log_learning_rate_D_dagger': -3.437793826974749, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  364.0
	 epoch  10 training error:  tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  366.0
	 epoch  20 training error:  tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  372.0
	 epoch  30 training error:  tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  372.0
	 epoch  40 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  362.0
	 epoch  50 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  368.0
	 epoch  60 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  366.0
	 epoch  80 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  372.0
	 epoch  90 training error:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.66796875
Memory cached:  366.0
[I 2023-12-03 01:18:40,953] Trial 43 finished with value: 0.04676369950175285 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.764462544894271, 'log_learning_rate_D': -2.148722664070661, 'log_learning_rate_D_dagger': -3.437793826974749, 'training_batch_size': 8, 'training_p': 6}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  131.45873165130615
Memory status after this trial: 
Memory allocated:  227.90283203125
Memory cached:  364.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.675177150722258, 'log_learning_rate_D': -2.274973361873027, 'log_learning_rate_D_dagger': -3.5703888063358344, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  360.0
	 epoch  10 training error:  tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  20 training error:  tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  360.0
	 epoch  30 training error:  tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  40 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  50 training error:  tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  60 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  70 training error:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
	 epoch  90 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.23046875
Memory cached:  358.0
[I 2023-12-03 01:20:50,235] Trial 44 finished with value: 0.04855296015739441 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.675177150722258, 'log_learning_rate_D': -2.274973361873027, 'log_learning_rate_D_dagger': -3.5703888063358344, 'training_batch_size': 7, 'training_p': 7}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  129.0716369152069
Memory status after this trial: 
Memory allocated:  210.37890625
Memory cached:  358.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -4.984349240802165, 'log_learning_rate_D': -2.621523186742796, 'log_learning_rate_D_dagger': -2.9148145326411985, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  394.0
	 epoch  10 training error:  tensor(0.8698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  424.0
	 epoch  20 training error:  tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  422.0
	 epoch  30 training error:  tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  432.0
	 epoch  40 training error:  tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  422.0
	 epoch  50 training error:  tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  430.0
	 epoch  60 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  428.0
	 epoch  70 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  432.0
	 epoch  80 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  418.0
	 epoch  90 training error:  tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.6953125
Memory cached:  430.0
[I 2023-12-03 01:23:00,384] Trial 45 finished with value: 0.15667180716991425 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -4.984349240802165, 'log_learning_rate_D': -2.621523186742796, 'log_learning_rate_D_dagger': -2.9148145326411985, 'training_batch_size': 9, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  129.94236946105957
Memory status after this trial: 
Memory allocated:  285.66650390625
Memory cached:  410.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.479072209365124, 'log_learning_rate_D': -2.8236495823463748, 'log_learning_rate_D_dagger': -2.588584081761368, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  364.0
	 epoch  20 training error:  tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  30 training error:  tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  40 training error:  tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  50 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  60 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.36328125
Memory cached:  360.0
[I 2023-12-03 01:25:10,773] Trial 46 finished with value: 0.04556629806756973 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.479072209365124, 'log_learning_rate_D': -2.8236495823463748, 'log_learning_rate_D_dagger': -2.588584081761368, 'training_batch_size': 8, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  130.17010164260864
Memory status after this trial: 
Memory allocated:  215.82666015625
Memory cached:  356.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -4.836036909708986, 'log_learning_rate_D': -2.665186053283005, 'log_learning_rate_D_dagger': -3.188499375079261, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  10 training error:  tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  20 training error:  tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  30 training error:  tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  40 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  50 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  60 training error:  tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  70 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  80 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
	 epoch  90 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.3203125
Memory cached:  356.0
[I 2023-12-03 01:28:48,082] Trial 47 finished with value: 0.06363902240991592 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -4.836036909708986, 'log_learning_rate_D': -2.665186053283005, 'log_learning_rate_D_dagger': -3.188499375079261, 'training_batch_size': 6, 'training_p': 4}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  217.07770490646362
Memory status after this trial: 
Memory allocated:  227.21875
Memory cached:  356.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.321261858943847, 'log_learning_rate_D': -2.4249649814320677, 'log_learning_rate_D_dagger': -3.4557672541014863, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  368.0
	 epoch  10 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  388.0
	 epoch  20 training error:  tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  388.0
	 epoch  30 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  386.0
	 epoch  40 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  386.0
	 epoch  50 training error:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  388.0
	 epoch  60 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  386.0
	 epoch  70 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  392.0
	 epoch  80 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  388.0
	 epoch  90 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.42578125
Memory cached:  386.0
[I 2023-12-03 01:31:09,668] Trial 48 finished with value: 0.044867485761642456 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.321261858943847, 'log_learning_rate_D': -2.4249649814320677, 'log_learning_rate_D_dagger': -3.4557672541014863, 'training_batch_size': 9, 'training_p': 6}. Best is trial 36 with value: 0.03745831176638603.
Time for this trial:  141.35749650001526
Memory status after this trial: 
Memory allocated:  250.15185546875
Memory cached:  370.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.611308568993768, 'log_learning_rate_D': -3.0398464668002196, 'log_learning_rate_D_dagger': -3.813306290252398, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  362.0
	 epoch  10 training error:  tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  394.0
	 epoch  20 training error:  tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  384.0
	 epoch  30 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  388.0
	 epoch  40 training error:  tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  398.0
	 epoch  50 training error:  tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  388.0
	 epoch  60 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  386.0
	 epoch  70 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  392.0
	 epoch  80 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  390.0
	 epoch  90 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.55078125
Memory cached:  392.0
[I 2023-12-03 01:33:25,901] Trial 49 finished with value: 0.044498320668935776 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.611308568993768, 'log_learning_rate_D': -3.0398464668002196, 'log_learning_rate_D_dagger': -3.813306290252398, 'training_batch_size': 9, 'training_p': 5}. Best is trial 36 with value: 0.03745831176638603.
[I 2023-12-03 01:33:25,954] A new study created in memory with name: no-name-1d3bd2b7-a547-4539-9bcd-1c04aa198194
Time for this trial:  136.00772261619568
Memory status after this trial: 
Memory allocated:  264.787109375
Memory cached:  376.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.7944921741659599, 'log_learning_rate_D': -3.2496690895290925, 'log_learning_rate_D_dagger': -2.458295723027454, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  178.0
	 epoch  10 training error:  tensor(5.5632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  278.0
	 epoch  20 training error:  tensor(1.3605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  276.0
	 epoch  30 training error:  tensor(0.5257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  278.0
	 epoch  40 training error:  tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  272.0
	 epoch  50 training error:  tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  272.0
	 epoch  60 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  272.0
	 epoch  70 training error:  tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  276.0
	 epoch  80 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  276.0
	 epoch  90 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.5947265625
Memory cached:  276.0
[I 2023-12-03 01:37:04,107] Trial 0 finished with value: 0.08190666139125824 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.7944921741659599, 'log_learning_rate_D': -3.2496690895290925, 'log_learning_rate_D_dagger': -2.458295723027454, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 0.08190666139125824.
res:  tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  218.03648781776428
Memory status after this trial: 
Memory allocated:  274.09814453125
Memory cached:  286.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 9, 'log_learning_rate': -3.9804175331154004, 'log_learning_rate_D': -2.6791509406859744, 'log_learning_rate_D_dagger': -4.620786765049255, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  346.0
	 epoch  10 training error:  tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  452.0
	 epoch  30 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  442.0
	 epoch  40 training error:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  446.0
	 epoch  50 training error:  tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  454.0
	 epoch  60 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  446.0
	 epoch  70 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  436.0
	 epoch  90 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  315.21630859375
Memory cached:  458.0
[I 2023-12-03 01:41:49,521] Trial 1 finished with value: 0.06021098047494888 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 9, 'log_learning_rate': -3.9804175331154004, 'log_learning_rate_D': -2.6791509406859744, 'log_learning_rate_D_dagger': -4.620786765049255, 'training_batch_size': 10, 'training_p': 5}. Best is trial 1 with value: 0.06021098047494888.
res:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  285.2864902019501
Memory status after this trial: 
Memory allocated:  408.0
Memory cached:  668.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.619627423634946, 'log_learning_rate_D': -2.8129957576480185, 'log_learning_rate_D_dagger': -2.980300966548454, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  660.0
	 epoch  10 training error:  tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  668.0
	 epoch  20 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  672.0
	 epoch  30 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  664.0
	 epoch  40 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  672.0
	 epoch  50 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  664.0
	 epoch  60 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  664.0
	 epoch  70 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  668.0
	 epoch  80 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  670.0
	 epoch  90 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  416.302734375
Memory cached:  666.0
[I 2023-12-03 01:47:42,065] Trial 2 finished with value: 0.05423837527632713 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.619627423634946, 'log_learning_rate_D': -2.8129957576480185, 'log_learning_rate_D_dagger': -2.980300966548454, 'training_batch_size': 6, 'training_p': 3}. Best is trial 2 with value: 0.05423837527632713.
res:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  352.3857321739197
Memory status after this trial: 
Memory allocated:  208.96728515625
Memory cached:  454.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.8895063491812865, 'log_learning_rate_D': -4.946126074759707, 'log_learning_rate_D_dagger': -3.166322688033929, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.3925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  436.0
	 epoch  10 training error:  tensor(5.5721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  446.0
	 epoch  20 training error:  tensor(2.5402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  442.0
	 epoch  30 training error:  tensor(3.8118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  444.0
	 epoch  40 training error:  tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  446.0
	 epoch  50 training error:  tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  450.0
	 epoch  60 training error:  tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  446.0
	 epoch  70 training error:  tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  450.0
	 epoch  80 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  442.0
	 epoch  90 training error:  tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.15966796875
Memory cached:  446.0
[I 2023-12-03 01:50:15,229] Trial 3 finished with value: 0.11891211569309235 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.8895063491812865, 'log_learning_rate_D': -4.946126074759707, 'log_learning_rate_D_dagger': -3.166322688033929, 'training_batch_size': 11, 'training_p': 3}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  153.05906677246094
Memory status after this trial: 
Memory allocated:  335.419921875
Memory cached:  436.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 7, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -3.801585399343868, 'log_learning_rate_D': -1.8630738309933128, 'log_learning_rate_D_dagger': -4.520783833308572, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  434.0
	 epoch  10 training error:  tensor(0.5190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  462.0
	 epoch  20 training error:  tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  468.0
	 epoch  30 training error:  tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  470.0
	 epoch  40 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  464.0
	 epoch  50 training error:  tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  476.0
	 epoch  60 training error:  tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  468.0
	 epoch  70 training error:  tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  466.0
	 epoch  80 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  470.0
	 epoch  90 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.10888671875
Memory cached:  472.0
[I 2023-12-03 01:53:50,302] Trial 4 finished with value: 0.05895305797457695 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 7, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -3.801585399343868, 'log_learning_rate_D': -1.8630738309933128, 'log_learning_rate_D_dagger': -4.520783833308572, 'training_batch_size': 10, 'training_p': 7}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  214.9043209552765
Memory status after this trial: 
Memory allocated:  366.5224609375
Memory cached:  456.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.4954472009396924, 'log_learning_rate_D': -2.0444725208781436, 'log_learning_rate_D_dagger': -3.942453033726833, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.7673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  450.0
	 epoch  10 training error:  tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  472.0
	 epoch  30 training error:  tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  476.0
	 epoch  50 training error:  tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  476.0
	 epoch  60 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  472.0
	 epoch  70 training error:  tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  472.0
	 epoch  80 training error:  tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  228.65771484375
Memory cached:  478.0
[I 2023-12-03 01:57:11,116] Trial 5 finished with value: 0.12623745203018188 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.4954472009396924, 'log_learning_rate_D': -2.0444725208781436, 'log_learning_rate_D_dagger': -3.942453033726833, 'training_batch_size': 9, 'training_p': 4}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  200.6456217765808
Memory status after this trial: 
Memory allocated:  423.49072265625
Memory cached:  468.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.3823545868321614, 'log_learning_rate_D': -3.5345325305429482, 'log_learning_rate_D_dagger': -3.5622476706843975, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  438.0
	 epoch  10 training error:  tensor(0.6788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  460.0
	 epoch  20 training error:  tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  462.0
	 epoch  30 training error:  tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  460.0
	 epoch  40 training error:  tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  458.0
	 epoch  50 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  458.0
	 epoch  60 training error:  tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  452.0
	 epoch  70 training error:  tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  464.0
	 epoch  80 training error:  tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  462.0
	 epoch  90 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.37060546875
Memory cached:  456.0
[I 2023-12-03 01:59:58,260] Trial 6 finished with value: 0.16606171429157257 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.3823545868321614, 'log_learning_rate_D': -3.5345325305429482, 'log_learning_rate_D_dagger': -3.5622476706843975, 'training_batch_size': 8, 'training_p': 6}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  166.96730732917786
Memory status after this trial: 
Memory allocated:  371.86279296875
Memory cached:  450.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.9331491438668813, 'log_learning_rate_D': -3.9574604151533355, 'log_learning_rate_D_dagger': -2.462837323650471, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.5397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  432.0
	 epoch  10 training error:  tensor(7.4876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  470.0
	 epoch  20 training error:  tensor(0.7134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  466.0
	 epoch  30 training error:  tensor(0.4417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  456.0
	 epoch  40 training error:  tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  470.0
	 epoch  50 training error:  tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  460.0
	 epoch  60 training error:  tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  456.0
	 epoch  70 training error:  tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  464.0
	 epoch  80 training error:  tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  468.0
	 epoch  90 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  215.73974609375
Memory cached:  460.0
[I 2023-12-03 02:03:33,714] Trial 7 finished with value: 0.08974011987447739 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -1.9331491438668813, 'log_learning_rate_D': -3.9574604151533355, 'log_learning_rate_D_dagger': -2.462837323650471, 'training_batch_size': 9, 'training_p': 8}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  215.29491448402405
Memory status after this trial: 
Memory allocated:  447.04638671875
Memory cached:  452.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.7626566775596078, 'log_learning_rate_D': -2.908918649879088, 'log_learning_rate_D_dagger': -1.1379156663297354, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  456.0
	 epoch  10 training error:  tensor(1652.3134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  486.0
	 epoch  20 training error:  tensor(105411.6484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(313552.9688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  492.0
	 epoch  40 training error:  tensor(287906.9062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  476.0
	 epoch  50 training error:  tensor(159256.6094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  486.0
	 epoch  60 training error:  tensor(105604.2891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  484.0
	 epoch  70 training error:  tensor(16796.6855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  488.0
	 epoch  80 training error:  tensor(964.5779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(1112.1669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  231.07177734375
Memory cached:  490.0
[I 2023-12-03 02:07:37,084] Trial 8 finished with value: 328.415283203125 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -3.7626566775596078, 'log_learning_rate_D': -2.908918649879088, 'log_learning_rate_D_dagger': -1.1379156663297354, 'training_batch_size': 8, 'training_p': 3}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  243.19378685951233
Memory status after this trial: 
Memory allocated:  489.18994140625
Memory cached:  514.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -3.942597664912133, 'log_learning_rate_D': -3.822369122147088, 'log_learning_rate_D_dagger': -4.559688506055154, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  454.0
	 epoch  10 training error:  tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  484.0
	 epoch  40 training error:  tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  492.0
	 epoch  60 training error:  tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  488.0
	 epoch  70 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  484.0
	 epoch  90 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  238.46630859375
Memory cached:  492.0
[I 2023-12-03 02:11:39,617] Trial 9 finished with value: 0.05577670410275459 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 6, 'log_learning_rate': -3.942597664912133, 'log_learning_rate_D': -3.822369122147088, 'log_learning_rate_D_dagger': -4.559688506055154, 'training_batch_size': 9, 'training_p': 4}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  242.33304905891418
Memory status after this trial: 
Memory allocated:  538.4296875
Memory cached:  558.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -4.579474779948948, 'log_learning_rate_D': -1.1927136962249834, 'log_learning_rate_D_dagger': -2.6323792944472575, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  552.0
	 epoch  10 training error:  tensor(1.1613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  578.0
	 epoch  20 training error:  tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  582.0
	 epoch  30 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  582.0
	 epoch  40 training error:  tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  580.0
	 epoch  50 training error:  tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  580.0
	 epoch  60 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  580.0
	 epoch  70 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  584.0
	 epoch  80 training error:  tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  582.0
	 epoch  90 training error:  tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.97705078125
Memory cached:  584.0
[I 2023-12-03 02:18:24,517] Trial 10 finished with value: 0.1288178414106369 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -4.579474779948948, 'log_learning_rate_D': -1.1927136962249834, 'log_learning_rate_D_dagger': -2.6323792944472575, 'training_batch_size': 6, 'training_p': 2}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  404.5987684726715
Memory status after this trial: 
Memory allocated:  755.7490234375
Memory cached:  792.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.950658134495805, 'log_learning_rate_D': -4.065510407644661, 'log_learning_rate_D_dagger': -4.950344099598257, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  454.0
	 epoch  10 training error:  tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  474.0
	 epoch  30 training error:  tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  474.0
	 epoch  40 training error:  tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  478.0
	 epoch  50 training error:  tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  476.0
	 epoch  60 training error:  tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  476.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  476.0
	 epoch  80 training error:  tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  232.14013671875
Memory cached:  474.0
[I 2023-12-03 02:21:44,613] Trial 11 finished with value: 0.06649154424667358 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.950658134495805, 'log_learning_rate_D': -4.065510407644661, 'log_learning_rate_D_dagger': -4.950344099598257, 'training_batch_size': 12, 'training_p': 5}. Best is trial 2 with value: 0.05423837527632713.
Time for this trial:  199.82098007202148
Memory status after this trial: 
Memory allocated:  448.38916015625
Memory cached:  466.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.7502216521162968, 'log_learning_rate_D': -2.647211857573971, 'log_learning_rate_D_dagger': -4.006366357622752, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  434.0
	 epoch  10 training error:  tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  454.0
	 epoch  20 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  454.0
	 epoch  30 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  452.0
	 epoch  40 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  450.0
	 epoch  50 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  454.0
	 epoch  60 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  454.0
	 epoch  70 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  450.0
	 epoch  80 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  446.0
	 epoch  90 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.33837890625
Memory cached:  452.0
[I 2023-12-03 02:27:29,196] Trial 12 finished with value: 0.053665149956941605 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.7502216521162968, 'log_learning_rate_D': -2.647211857573971, 'log_learning_rate_D_dagger': -4.006366357622752, 'training_batch_size': 6, 'training_p': 4}. Best is trial 12 with value: 0.053665149956941605.
res:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  344.3089761734009
Memory status after this trial: 
Memory allocated:  248.37158203125
Memory cached:  462.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.7847196593681707, 'log_learning_rate_D': -2.4952610247134626, 'log_learning_rate_D_dagger': -3.8604148312209494, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.6779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  10 training error:  tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  20 training error:  tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  30 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  40 training error:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  50 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  60 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  70 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  80 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
	 epoch  90 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.66455078125
Memory cached:  456.0
[I 2023-12-03 02:33:10,294] Trial 13 finished with value: 0.06997191905975342 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.7847196593681707, 'log_learning_rate_D': -2.4952610247134626, 'log_learning_rate_D_dagger': -3.8604148312209494, 'training_batch_size': 6, 'training_p': 2}. Best is trial 12 with value: 0.053665149956941605.
Time for this trial:  340.8524343967438
Memory status after this trial: 
Memory allocated:  458.77001953125
Memory cached:  466.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.4413399894035743, 'log_learning_rate_D': -2.360939885277989, 'log_learning_rate_D_dagger': -3.2454006333791336, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  462.0
	 epoch  10 training error:  tensor(1.1510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  498.0
	 epoch  20 training error:  tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  486.0
	 epoch  30 training error:  tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  490.0
	 epoch  40 training error:  tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  488.0
	 epoch  50 training error:  tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  492.0
	 epoch  60 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  492.0
	 epoch  70 training error:  tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  490.0
	 epoch  80 training error:  tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.46826171875
Memory cached:  484.0
[I 2023-12-03 02:36:24,895] Trial 14 finished with value: 0.06656644493341446 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.4413399894035743, 'log_learning_rate_D': -2.360939885277989, 'log_learning_rate_D_dagger': -3.2454006333791336, 'training_batch_size': 7, 'training_p': 4}. Best is trial 12 with value: 0.053665149956941605.
Time for this trial:  194.34250164031982
Memory status after this trial: 
Memory allocated:  466.37646484375
Memory cached:  482.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.1302583622701703, 'log_learning_rate_D': -3.0845038972493026, 'log_learning_rate_D_dagger': -3.8318440928524327, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(36.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  10 training error:  tensor(35.8596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  460.0
	 epoch  20 training error:  tensor(3.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  30 training error:  tensor(0.6679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  460.0
	 epoch  40 training error:  tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  50 training error:  tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  460.0
	 epoch  60 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  70 training error:  tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  80 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
	 epoch  90 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.38330078125
Memory cached:  458.0
[I 2023-12-03 02:41:27,350] Trial 15 finished with value: 0.06369419395923615 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.1302583622701703, 'log_learning_rate_D': -3.0845038972493026, 'log_learning_rate_D_dagger': -3.8318440928524327, 'training_batch_size': 6, 'training_p': 6}. Best is trial 12 with value: 0.053665149956941605.
Time for this trial:  302.1937792301178
Memory status after this trial: 
Memory allocated:  394.12109375
Memory cached:  460.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.252959172234083, 'log_learning_rate_D': -1.6827321170098615, 'log_learning_rate_D_dagger': -2.849236055537598, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  458.0
	 epoch  10 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  468.0
	 epoch  20 training error:  tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  468.0
	 epoch  30 training error:  tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  464.0
	 epoch  40 training error:  tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  466.0
	 epoch  50 training error:  tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  468.0
	 epoch  60 training error:  tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  470.0
	 epoch  70 training error:  tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  472.0
	 epoch  80 training error:  tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  470.0
	 epoch  90 training error:  tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  259.30224609375
Memory cached:  468.0
[I 2023-12-03 02:45:20,588] Trial 16 finished with value: 0.13025423884391785 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.252959172234083, 'log_learning_rate_D': -1.6827321170098615, 'log_learning_rate_D_dagger': -2.849236055537598, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.053665149956941605.
Time for this trial:  232.95187616348267
Memory status after this trial: 
Memory allocated:  452.95751953125
Memory cached:  460.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.549144461985737, 'log_learning_rate_D': -2.343867467155518, 'log_learning_rate_D_dagger': -4.168078399925929, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  484.0
	 epoch  10 training error:  tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  488.0
	 epoch  20 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  490.0
	 epoch  30 training error:  tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  490.0
	 epoch  40 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  490.0
	 epoch  50 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  488.0
	 epoch  60 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  486.0
	 epoch  70 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  488.0
	 epoch  80 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  486.0
	 epoch  90 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  265.17333984375
Memory cached:  490.0
[I 2023-12-03 02:48:00,164] Trial 17 finished with value: 0.04461294040083885 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.549144461985737, 'log_learning_rate_D': -2.343867467155518, 'log_learning_rate_D_dagger': -4.168078399925929, 'training_batch_size': 8, 'training_p': 4}. Best is trial 17 with value: 0.04461294040083885.
res:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  159.33186388015747
Memory status after this trial: 
Memory allocated:  164.65576171875
Memory cached:  460.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.4984633633540603, 'log_learning_rate_D': -2.3649951063377417, 'log_learning_rate_D_dagger': -4.295511279189726, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  440.0
	 epoch  10 training error:  tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  456.0
	 epoch  20 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  450.0
	 epoch  30 training error:  tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  452.0
	 epoch  40 training error:  tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  452.0
	 epoch  50 training error:  tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  450.0
	 epoch  60 training error:  tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  452.0
	 epoch  70 training error:  tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  446.0
	 epoch  80 training error:  tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  450.0
	 epoch  90 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.78173828125
Memory cached:  454.0
[I 2023-12-03 02:50:32,581] Trial 18 finished with value: 0.06268718093633652 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.4984633633540603, 'log_learning_rate_D': -2.3649951063377417, 'log_learning_rate_D_dagger': -4.295511279189726, 'training_batch_size': 8, 'training_p': 6}. Best is trial 17 with value: 0.04461294040083885.
Time for this trial:  152.22534441947937
Memory status after this trial: 
Memory allocated:  292.65625
Memory cached:  446.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.0685564430579726, 'log_learning_rate_D': -1.4008620088699943, 'log_learning_rate_D_dagger': -4.996320141943886, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  440.0
	 epoch  10 training error:  tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  448.0
	 epoch  30 training error:  tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  450.0
	 epoch  40 training error:  tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  446.0
	 epoch  50 training error:  tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  448.0
	 epoch  60 training error:  tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  446.0
	 epoch  70 training error:  tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  446.0
	 epoch  90 training error:  tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.10205078125
Memory cached:  448.0
[I 2023-12-03 02:53:07,327] Trial 19 finished with value: 0.12894557416439056 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -3.0685564430579726, 'log_learning_rate_D': -1.4008620088699943, 'log_learning_rate_D_dagger': -4.996320141943886, 'training_batch_size': 7, 'training_p': 5}. Best is trial 17 with value: 0.04461294040083885.
Time for this trial:  154.53668093681335
Memory status after this trial: 
Memory allocated:  361.0390625
Memory cached:  442.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.51735896932646, 'log_learning_rate_D': -2.0939113456026437, 'log_learning_rate_D_dagger': -4.158030629178363, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.6959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  444.0
	 epoch  10 training error:  tensor(0.8808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  452.0
	 epoch  20 training error:  tensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  450.0
	 epoch  30 training error:  tensor(0.6563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  452.0
	 epoch  40 training error:  tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  448.0
	 epoch  50 training error:  tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  446.0
	 epoch  60 training error:  tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  448.0
	 epoch  70 training error:  tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  448.0
	 epoch  90 training error:  tensor(0.3366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.43212890625
Memory cached:  452.0
[I 2023-12-03 02:55:45,383] Trial 20 finished with value: 0.23820295929908752 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.51735896932646, 'log_learning_rate_D': -2.0939113456026437, 'log_learning_rate_D_dagger': -4.158030629178363, 'training_batch_size': 8, 'training_p': 4}. Best is trial 17 with value: 0.04461294040083885.
Time for this trial:  157.85664248466492
Memory status after this trial: 
Memory allocated:  345.4052734375
Memory cached:  444.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.0777202291856147, 'log_learning_rate_D': -2.6146596336130705, 'log_learning_rate_D_dagger': -3.4802851608421417, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  438.0
	 epoch  10 training error:  tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  20 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  30 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  440.0
	 epoch  40 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  50 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  446.0
	 epoch  60 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  70 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  80 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
	 epoch  90 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.39208984375
Memory cached:  444.0
[I 2023-12-03 03:01:18,063] Trial 21 finished with value: 0.043347932398319244 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.0777202291856147, 'log_learning_rate_D': -2.6146596336130705, 'log_learning_rate_D_dagger': -3.4802851608421417, 'training_batch_size': 6, 'training_p': 2}. Best is trial 21 with value: 0.043347932398319244.
res:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  332.41596126556396
Memory status after this trial: 
Memory allocated:  186.91796875
Memory cached:  376.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.9843802227264553, 'log_learning_rate_D': -2.3337067751459357, 'log_learning_rate_D_dagger': -3.789032185315974, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  392.0
	 epoch  10 training error:  tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  422.0
	 epoch  20 training error:  tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  422.0
	 epoch  30 training error:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  410.0
	 epoch  40 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  418.0
	 epoch  50 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  424.0
	 epoch  60 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  418.0
	 epoch  70 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  420.0
	 epoch  80 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  420.0
	 epoch  90 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.8720703125
Memory cached:  424.0
[I 2023-12-03 03:04:54,346] Trial 22 finished with value: 0.054773177951574326 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 4, 'log_learning_rate': -2.9843802227264553, 'log_learning_rate_D': -2.3337067751459357, 'log_learning_rate_D_dagger': -3.789032185315974, 'training_batch_size': 7, 'training_p': 2}. Best is trial 21 with value: 0.043347932398319244.
Time for this trial:  216.059237241745
Memory status after this trial: 
Memory allocated:  443.04638671875
Memory cached:  458.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -2.0703639375058973, 'log_learning_rate_D': -2.648500434399614, 'log_learning_rate_D_dagger': -3.419162416546099, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(2.3464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  386.0
	 epoch  10 training error:  tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  390.0
	 epoch  20 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  388.0
	 epoch  30 training error:  tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  390.0
	 epoch  40 training error:  tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  388.0
	 epoch  50 training error:  tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  390.0
	 epoch  60 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  388.0
	 epoch  70 training error:  tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  390.0
	 epoch  80 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  388.0
	 epoch  90 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.765625
Memory cached:  392.0
[I 2023-12-03 03:09:41,725] Trial 23 finished with value: 0.04280778393149376 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -2.0703639375058973, 'log_learning_rate_D': -2.648500434399614, 'log_learning_rate_D_dagger': -3.419162416546099, 'training_batch_size': 6, 'training_p': 4}. Best is trial 23 with value: 0.04280778393149376.
res:  tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  287.12332224845886
Memory status after this trial: 
Memory allocated:  155.3916015625
Memory cached:  368.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.1412870058077518, 'log_learning_rate_D': -1.658844960127006, 'log_learning_rate_D_dagger': -3.4412199970822415, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.7000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  372.0
	 epoch  10 training error:  tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  392.0
	 epoch  20 training error:  tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  400.0
	 epoch  30 training error:  tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  396.0
	 epoch  40 training error:  tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  402.0
	 epoch  50 training error:  tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  404.0
	 epoch  60 training error:  tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  400.0
	 epoch  70 training error:  tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  400.0
	 epoch  80 training error:  tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  400.0
	 epoch  90 training error:  tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.048828125
Memory cached:  394.0
[I 2023-12-03 03:12:15,691] Trial 24 finished with value: 0.12151365727186203 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.1412870058077518, 'log_learning_rate_D': -1.658844960127006, 'log_learning_rate_D_dagger': -3.4412199970822415, 'training_batch_size': 7, 'training_p': 2}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  153.7755811214447
Memory status after this trial: 
Memory allocated:  282.44189453125
Memory cached:  382.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.181095205387606, 'log_learning_rate_D': -2.1649548872101594, 'log_learning_rate_D_dagger': -3.5404809082417175, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(2.9609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  366.0
	 epoch  10 training error:  tensor(4.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  20 training error:  tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  30 training error:  tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  40 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  50 training error:  tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  378.0
	 epoch  60 training error:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  70 training error:  tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  378.0
	 epoch  80 training error:  tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
	 epoch  90 training error:  tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.537109375
Memory cached:  380.0
[I 2023-12-03 03:15:00,930] Trial 25 finished with value: 0.08026125282049179 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.181095205387606, 'log_learning_rate_D': -2.1649548872101594, 'log_learning_rate_D_dagger': -3.5404809082417175, 'training_batch_size': 10, 'training_p': 5}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  165.01830196380615
Memory status after this trial: 
Memory allocated:  300.29736328125
Memory cached:  374.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.656085423930746, 'log_learning_rate_D': -3.065400800538446, 'log_learning_rate_D_dagger': -4.209942723179097, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(4.1368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.6870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  20 training error:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  30 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  40 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  60 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  80 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
	 epoch  90 training error:  tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.4990234375
Memory cached:  366.0
[I 2023-12-03 03:19:29,338] Trial 26 finished with value: 0.0559159517288208 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.656085423930746, 'log_learning_rate_D': -3.065400800538446, 'log_learning_rate_D_dagger': -4.209942723179097, 'training_batch_size': 6, 'training_p': 4}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  268.1488206386566
Memory status after this trial: 
Memory allocated:  268.068359375
Memory cached:  366.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.5757539047858458, 'log_learning_rate_D': -2.5723837584962044, 'log_learning_rate_D_dagger': -3.36971733890093, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  20 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  372.0
	 epoch  30 training error:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  40 training error:  tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  368.0
	 epoch  60 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  80 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
	 epoch  90 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.13671875
Memory cached:  366.0
[I 2023-12-03 03:21:55,913] Trial 27 finished with value: 0.04545953497290611 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.5757539047858458, 'log_learning_rate_D': -2.5723837584962044, 'log_learning_rate_D_dagger': -3.36971733890093, 'training_batch_size': 8, 'training_p': 7}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  146.33623814582825
Memory status after this trial: 
Memory allocated:  222.85693359375
Memory cached:  366.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.146614349460827, 'log_learning_rate_D': -1.9817456897917742, 'log_learning_rate_D_dagger': -3.7334819733074203, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  388.0
	 epoch  20 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  380.0
	 epoch  30 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  386.0
	 epoch  40 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  396.0
	 epoch  50 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  382.0
	 epoch  60 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  384.0
	 epoch  70 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  386.0
	 epoch  80 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  392.0
	 epoch  90 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9609375
Memory cached:  386.0
[I 2023-12-03 03:24:36,402] Trial 28 finished with value: 0.04867677763104439 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -3.146614349460827, 'log_learning_rate_D': -1.9817456897917742, 'log_learning_rate_D_dagger': -3.7334819733074203, 'training_batch_size': 7, 'training_p': 3}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  160.26244640350342
Memory status after this trial: 
Memory allocated:  270.68408203125
Memory cached:  368.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.2381663355119805, 'log_learning_rate_D': -3.1870517621832035, 'log_learning_rate_D_dagger': -3.221459918398423, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.8195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  20 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  30 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  40 training error:  tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  60 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  80 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
	 epoch  90 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.1396484375
Memory cached:  366.0
[I 2023-12-03 03:29:47,268] Trial 29 finished with value: 0.04829821363091469 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.2381663355119805, 'log_learning_rate_D': -3.1870517621832035, 'log_learning_rate_D_dagger': -3.221459918398423, 'training_batch_size': 6, 'training_p': 3}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  310.6137344837189
Memory status after this trial: 
Memory allocated:  275.36474609375
Memory cached:  366.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -2.6122556826528105, 'log_learning_rate_D': -2.8205281547277523, 'log_learning_rate_D_dagger': -3.561436770198597, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  388.0
	 epoch  10 training error:  tensor(0.9313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  402.0
	 epoch  20 training error:  tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  410.0
	 epoch  30 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  406.0
	 epoch  40 training error:  tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  410.0
	 epoch  50 training error:  tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  416.0
	 epoch  60 training error:  tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  402.0
	 epoch  70 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  410.0
	 epoch  80 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  410.0
	 epoch  90 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  192.529296875
Memory cached:  412.0
[I 2023-12-03 03:33:12,367] Trial 30 finished with value: 0.055609799921512604 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -2.6122556826528105, 'log_learning_rate_D': -2.8205281547277523, 'log_learning_rate_D_dagger': -3.561436770198597, 'training_batch_size': 12, 'training_p': 2}. Best is trial 23 with value: 0.04280778393149376.
Time for this trial:  204.83227157592773
Memory status after this trial: 
Memory allocated:  442.6552734375
Memory cached:  466.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.5969733934697834, 'log_learning_rate_D': -2.5757182007162247, 'log_learning_rate_D_dagger': -2.8551738049864355, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.5620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  20 training error:  tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  30 training error:  tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  40 training error:  tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  60 training error:  tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  80 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
	 epoch  90 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.869140625
Memory cached:  366.0
[I 2023-12-03 03:35:37,937] Trial 31 finished with value: 0.03769756108522415 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.5969733934697834, 'log_learning_rate_D': -2.5757182007162247, 'log_learning_rate_D_dagger': -2.8551738049864355, 'training_batch_size': 8, 'training_p': 8}. Best is trial 31 with value: 0.03769756108522415.
res:  tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  145.30918979644775
Memory status after this trial: 
Memory allocated:  64.0615234375
Memory cached:  330.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -1.8965281536763883, 'log_learning_rate_D': -2.6981574158291837, 'log_learning_rate_D_dagger': -2.7309615391696083, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.7623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  10 training error:  tensor(0.6926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  20 training error:  tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  40 training error:  tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.3515625
Memory cached:  324.0
[I 2023-12-03 03:37:53,526] Trial 32 finished with value: 0.0458914078772068 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -1.8965281536763883, 'log_learning_rate_D': -2.6981574158291837, 'log_learning_rate_D_dagger': -2.7309615391696083, 'training_batch_size': 8, 'training_p': 8}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  135.39117097854614
Memory status after this trial: 
Memory allocated:  116.705078125
Memory cached:  324.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.4295050989367066, 'log_learning_rate_D': -2.296612891130347, 'log_learning_rate_D_dagger': -3.0485344786480413, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  20 training error:  tensor(1.6333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  30 training error:  tensor(1.8773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.6724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.052734375
Memory cached:  326.0
[I 2023-12-03 03:40:35,300] Trial 33 finished with value: 0.04484918341040611 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.4295050989367066, 'log_learning_rate_D': -2.296612891130347, 'log_learning_rate_D_dagger': -3.0485344786480413, 'training_batch_size': 9, 'training_p': 7}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  161.52805519104004
Memory status after this trial: 
Memory allocated:  160.958984375
Memory cached:  324.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.9541651613498652, 'log_learning_rate_D': -2.768896809719792, 'log_learning_rate_D_dagger': -3.1145428726727618, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  10 training error:  tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.26953125
Memory cached:  326.0
[I 2023-12-03 03:43:12,203] Trial 34 finished with value: 0.04271215200424194 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.9541651613498652, 'log_learning_rate_D': -2.768896809719792, 'log_learning_rate_D_dagger': -3.1145428726727618, 'training_batch_size': 10, 'training_p': 5}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  156.67155122756958
Memory status after this trial: 
Memory allocated:  167.9697265625
Memory cached:  324.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.323909315240854, 'log_learning_rate_D': -2.864395118692277, 'log_learning_rate_D_dagger': -2.921421605101867, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  330.0
	 epoch  10 training error:  tensor(2.0993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  340.0
	 epoch  20 training error:  tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  342.0
	 epoch  30 training error:  tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  336.0
	 epoch  40 training error:  tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  348.0
	 epoch  50 training error:  tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  352.0
	 epoch  60 training error:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  336.0
	 epoch  70 training error:  tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  348.0
	 epoch  80 training error:  tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  338.0
	 epoch  90 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.5078125
Memory cached:  336.0
[I 2023-12-03 03:45:55,346] Trial 35 finished with value: 0.05458035692572594 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.323909315240854, 'log_learning_rate_D': -2.864395118692277, 'log_learning_rate_D_dagger': -2.921421605101867, 'training_batch_size': 11, 'training_p': 5}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  162.89781141281128
Memory status after this trial: 
Memory allocated:  211.23046875
Memory cached:  332.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.7745297690875241, 'log_learning_rate_D': -3.26831830399489, 'log_learning_rate_D_dagger': -3.0308831049952096, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8046875
Memory cached:  326.0
[I 2023-12-03 03:48:24,040] Trial 36 finished with value: 0.04720962047576904 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.7745297690875241, 'log_learning_rate_D': -3.26831830399489, 'log_learning_rate_D_dagger': -3.0308831049952096, 'training_batch_size': 10, 'training_p': 6}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  148.46686339378357
Memory status after this trial: 
Memory allocated:  156.1220703125
Memory cached:  324.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.9836882207578896, 'log_learning_rate_D': -2.5988577489816387, 'log_learning_rate_D_dagger': -3.2116025875046126, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  370.0
	 epoch  10 training error:  tensor(9.5792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  386.0
	 epoch  20 training error:  tensor(2.3905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  394.0
	 epoch  30 training error:  tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  392.0
	 epoch  40 training error:  tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  386.0
	 epoch  50 training error:  tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  380.0
	 epoch  60 training error:  tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  388.0
	 epoch  70 training error:  tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  386.0
	 epoch  80 training error:  tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  388.0
	 epoch  90 training error:  tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.884765625
Memory cached:  386.0
[I 2023-12-03 03:52:17,980] Trial 37 finished with value: 0.04824362322688103 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.9836882207578896, 'log_learning_rate_D': -2.5988577489816387, 'log_learning_rate_D_dagger': -3.2116025875046126, 'training_batch_size': 11, 'training_p': 6}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  233.6754286289215
Memory status after this trial: 
Memory allocated:  358.67578125
Memory cached:  390.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.6670974441872044, 'log_learning_rate_D': -2.8486897236013506, 'log_learning_rate_D_dagger': -2.4613683513610893, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  332.0
	 epoch  10 training error:  tensor(11.1455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  332.0
	 epoch  20 training error:  tensor(2.0077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  330.0
	 epoch  70 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.90625
Memory cached:  328.0
[I 2023-12-03 03:54:53,464] Trial 38 finished with value: 0.08790895342826843 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -1.6670974441872044, 'log_learning_rate_D': -2.8486897236013506, 'log_learning_rate_D_dagger': -2.4613683513610893, 'training_batch_size': 10, 'training_p': 7}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  155.22426629066467
Memory status after this trial: 
Memory allocated:  154.455078125
Memory cached:  326.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.0009160861474447, 'log_learning_rate_D': -3.3349867957479464, 'log_learning_rate_D_dagger': -2.239051571265657, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  10 training error:  tensor(80.7748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  20 training error:  tensor(37.2306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  30 training error:  tensor(4.7530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  40 training error:  tensor(6.1964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  50 training error:  tensor(1.5563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.87890625
Memory cached:  324.0
[I 2023-12-03 03:57:44,198] Trial 39 finished with value: 0.06451761722564697 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.0009160861474447, 'log_learning_rate_D': -3.3349867957479464, 'log_learning_rate_D_dagger': -2.239051571265657, 'training_batch_size': 11, 'training_p': 5}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  170.47935700416565
Memory status after this trial: 
Memory allocated:  113.42626953125
Memory cached:  324.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.2971180587870696, 'log_learning_rate_D': -1.8615724424754942, 'log_learning_rate_D_dagger': -3.3681407627767834, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.9212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  332.0
	 epoch  40 training error:  tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  330.0
	 epoch  50 training error:  tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  330.0
	 epoch  60 training error:  tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  330.0
	 epoch  70 training error:  tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.03515625
Memory cached:  330.0
[I 2023-12-03 04:00:44,601] Trial 40 finished with value: 0.1276257038116455 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.2971180587870696, 'log_learning_rate_D': -1.8615724424754942, 'log_learning_rate_D_dagger': -3.3681407627767834, 'training_batch_size': 10, 'training_p': 8}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  180.13407945632935
Memory status after this trial: 
Memory allocated:  184.56884765625
Memory cached:  326.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.051439974008606, 'log_learning_rate_D': -2.5433036799535613, 'log_learning_rate_D_dagger': -3.735783473554798, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.5777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  326.0
	 epoch  10 training error:  tensor(1.2064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  330.0
	 epoch  60 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  330.0
	 epoch  70 training error:  tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.75390625
Memory cached:  328.0
[I 2023-12-03 04:03:15,665] Trial 41 finished with value: 0.05138157680630684 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.051439974008606, 'log_learning_rate_D': -2.5433036799535613, 'log_learning_rate_D_dagger': -3.735783473554798, 'training_batch_size': 9, 'training_p': 4}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  150.7978549003601
Memory status after this trial: 
Memory allocated:  182.10888671875
Memory cached:  326.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.849948820980941, 'log_learning_rate_D': -2.9951358706099533, 'log_learning_rate_D_dagger': -3.6127064922799548, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.810546875
Memory cached:  328.0
[I 2023-12-03 04:05:46,363] Trial 42 finished with value: 0.0503867082297802 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.849948820980941, 'log_learning_rate_D': -2.9951358706099533, 'log_learning_rate_D_dagger': -3.6127064922799548, 'training_batch_size': 9, 'training_p': 3}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  150.47864627838135
Memory status after this trial: 
Memory allocated:  181.78369140625
Memory cached:  324.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -1.8362941375409447, 'log_learning_rate_D': -2.7163704272956206, 'log_learning_rate_D_dagger': -3.9904201922754052, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  326.0
	 epoch  10 training error:  tensor(1.0870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  334.0
	 epoch  20 training error:  tensor(2.1241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  342.0
	 epoch  30 training error:  tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  336.0
	 epoch  40 training error:  tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  334.0
	 epoch  50 training error:  tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  332.0
	 epoch  60 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  336.0
	 epoch  70 training error:  tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  334.0
	 epoch  80 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  332.0
	 epoch  90 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.287109375
Memory cached:  334.0
[I 2023-12-03 04:08:36,878] Trial 43 finished with value: 0.05501518398523331 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -1.8362941375409447, 'log_learning_rate_D': -2.7163704272956206, 'log_learning_rate_D_dagger': -3.9904201922754052, 'training_batch_size': 8, 'training_p': 5}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  170.2588610649109
Memory status after this trial: 
Memory allocated:  205.74072265625
Memory cached:  330.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -2.313763026997074, 'log_learning_rate_D': -2.2861860742900633, 'log_learning_rate_D_dagger': -3.1136557496416097, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(2.6827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  10 training error:  tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  20 training error:  tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  30 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  40 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  50 training error:  tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  60 training error:  tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  70 training error:  tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  80 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
	 epoch  90 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.1845703125
Memory cached:  344.0
[I 2023-12-03 04:13:09,791] Trial 44 finished with value: 0.08203398436307907 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -2.313763026997074, 'log_learning_rate_D': -2.2861860742900633, 'log_learning_rate_D_dagger': -3.1136557496416097, 'training_batch_size': 6, 'training_p': 5}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  272.65220618247986
Memory status after this trial: 
Memory allocated:  230.89013671875
Memory cached:  344.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.0047692957718657, 'log_learning_rate_D': -2.454506635434242, 'log_learning_rate_D_dagger': -4.34595835607258, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  350.0
	 epoch  10 training error:  tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  362.0
	 epoch  20 training error:  tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  368.0
	 epoch  30 training error:  tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  362.0
	 epoch  40 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  364.0
	 epoch  60 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  364.0
	 epoch  90 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.826171875
Memory cached:  372.0
[I 2023-12-03 04:16:14,051] Trial 45 finished with value: 0.05688238888978958 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.0047692957718657, 'log_learning_rate_D': -2.454506635434242, 'log_learning_rate_D_dagger': -4.34595835607258, 'training_batch_size': 9, 'training_p': 4}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  183.9929850101471
Memory status after this trial: 
Memory allocated:  247.52734375
Memory cached:  346.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.671885501598743, 'log_learning_rate_D': -2.212703742088501, 'log_learning_rate_D_dagger': -2.846141034122783, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.8671875
Memory cached:  328.0
[I 2023-12-03 04:18:45,999] Trial 46 finished with value: 0.042223673313856125 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.671885501598743, 'log_learning_rate_D': -2.212703742088501, 'log_learning_rate_D_dagger': -2.846141034122783, 'training_batch_size': 8, 'training_p': 3}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  151.705815076828
Memory status after this trial: 
Memory allocated:  180.38134765625
Memory cached:  326.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.7040495732821013, 'log_learning_rate_D': -2.156780748337012, 'log_learning_rate_D_dagger': -2.7842355123047504, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  342.0
	 epoch  20 training error:  tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  344.0
	 epoch  30 training error:  tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  342.0
	 epoch  40 training error:  tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  336.0
	 epoch  50 training error:  tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  338.0
	 epoch  60 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  340.0
	 epoch  70 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  342.0
	 epoch  80 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  336.0
	 epoch  90 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.099609375
Memory cached:  348.0
[I 2023-12-03 04:21:35,901] Trial 47 finished with value: 0.04416288062930107 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -2.7040495732821013, 'log_learning_rate_D': -2.156780748337012, 'log_learning_rate_D_dagger': -2.7842355123047504, 'training_batch_size': 7, 'training_p': 3}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  169.6348044872284
Memory status after this trial: 
Memory allocated:  206.3212890625
Memory cached:  338.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.3477225623787343, 'log_learning_rate_D': -2.7324234814968333, 'log_learning_rate_D_dagger': -2.6100094524026045, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  10 training error:  tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  20 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  40 training error:  tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.6396484375
Memory cached:  324.0
[I 2023-12-03 04:26:16,875] Trial 48 finished with value: 0.07166209071874619 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.3477225623787343, 'log_learning_rate_D': -2.7324234814968333, 'log_learning_rate_D_dagger': -2.6100094524026045, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.03769756108522415.
Time for this trial:  280.71260261535645
Memory status after this trial: 
Memory allocated:  171.07568359375
Memory cached:  324.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.456320853419674, 'log_learning_rate_D': -3.025437896504977, 'log_learning_rate_D_dagger': -2.942021680678367, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  10 training error:  tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.013671875
Memory cached:  326.0
[I 2023-12-03 04:29:08,966] Trial 49 finished with value: 0.10210740566253662 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -3.456320853419674, 'log_learning_rate_D': -3.025437896504977, 'log_learning_rate_D_dagger': -2.942021680678367, 'training_batch_size': 9, 'training_p': 3}. Best is trial 31 with value: 0.03769756108522415.
[I 2023-12-03 04:29:09,034] A new study created in memory with name: no-name-240d90f6-7b2e-4197-b6d4-eee406f09a04
Time for this trial:  171.83700370788574
Memory status after this trial: 
Memory allocated:  170.19873046875
Memory cached:  326.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.6357748574789164, 'log_learning_rate_D': -3.212961865993988, 'log_learning_rate_D_dagger': -3.1329812764319316, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  250.0
	 epoch  20 training error:  tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  222.0
	 epoch  30 training error:  tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  222.0
	 epoch  40 training error:  tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  238.0
	 epoch  50 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  218.0
	 epoch  60 training error:  tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  236.0
	 epoch  80 training error:  tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  244.0
	 epoch  90 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5390625
Memory cached:  230.0
[I 2023-12-03 04:32:41,436] Trial 0 finished with value: 0.048587024211883545 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.6357748574789164, 'log_learning_rate_D': -3.212961865993988, 'log_learning_rate_D_dagger': -3.1329812764319316, 'training_batch_size': 10, 'training_p': 6}. Best is trial 0 with value: 0.048587024211883545.
res:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  212.26388692855835
Memory status after this trial: 
Memory allocated:  150.25
Memory cached:  174.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.0897149284649692, 'log_learning_rate_D': -1.6916839955782907, 'log_learning_rate_D_dagger': -2.4488847681085133, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  208.0
	 epoch  10 training error:  tensor(4.5625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  286.0
	 epoch  20 training error:  tensor(1.0238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  280.0
	 epoch  40 training error:  tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  288.0
	 epoch  50 training error:  tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  282.0
	 epoch  70 training error:  tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  286.0
	 epoch  80 training error:  tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  155.3818359375
Memory cached:  296.0
[I 2023-12-03 04:36:20,193] Trial 1 finished with value: 0.12837915122509003 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.0897149284649692, 'log_learning_rate_D': -1.6916839955782907, 'log_learning_rate_D_dagger': -2.4488847681085133, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  218.61714100837708
Memory status after this trial: 
Memory allocated:  373.607421875
Memory cached:  378.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -4.512466716428412, 'log_learning_rate_D': -3.134907759002372, 'log_learning_rate_D_dagger': -1.0539723359319404, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  210.0
	 epoch  10 training error:  tensor(313.4693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  290.0
	 epoch  30 training error:  tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  290.0
	 epoch  50 training error:  tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  292.0
	 epoch  60 training error:  tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  290.0
	 epoch  70 training error:  tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  290.0
	 epoch  90 training error:  tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.1552734375
Memory cached:  298.0
[I 2023-12-03 04:40:18,298] Trial 2 finished with value: 0.13115237653255463 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -4.512466716428412, 'log_learning_rate_D': -3.134907759002372, 'log_learning_rate_D_dagger': -1.0539723359319404, 'training_batch_size': 9, 'training_p': 4}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  237.8960063457489
Memory status after this trial: 
Memory allocated:  474.59619140625
Memory cached:  484.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.02298630181491, 'log_learning_rate_D': -2.836147315049726, 'log_learning_rate_D_dagger': -4.307786690180125, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0810546875
Memory cached:  216.0
[W 2023-12-03 04:40:36,205] Trial 3 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.02298630181491, 'log_learning_rate_D': -2.836147315049726, 'log_learning_rate_D_dagger': -4.307786690180125, 'training_batch_size': 10, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-03 04:40:36,205] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  17.716305255889893
Memory status after this trial: 
Memory allocated:  448.52978515625
Memory cached:  458.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.2645248431743137, 'log_learning_rate_D': -3.718877259089141, 'log_learning_rate_D_dagger': -4.8609242408554145, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  194.0
	 epoch  10 training error:  tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  284.0
	 epoch  20 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  282.0
	 epoch  30 training error:  tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  276.0
	 epoch  40 training error:  tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  284.0
	 epoch  50 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  284.0
	 epoch  60 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  282.0
	 epoch  70 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  284.0
	 epoch  80 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  286.0
	 epoch  90 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.6083984375
Memory cached:  276.0
[I 2023-12-03 04:43:38,961] Trial 4 finished with value: 0.06719201058149338 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 5, 'log_learning_rate': -3.2645248431743137, 'log_learning_rate_D': -3.718877259089141, 'log_learning_rate_D_dagger': -4.8609242408554145, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  182.60106205940247
Memory status after this trial: 
Memory allocated:  341.42333984375
Memory cached:  350.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.2194223814189393, 'log_learning_rate_D': -1.6035205638613692, 'log_learning_rate_D_dagger': -4.036645507855462, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  214.0
	 epoch  10 training error:  tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  306.0
	 epoch  30 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  300.0
	 epoch  40 training error:  tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  290.0
	 epoch  50 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  288.0
	 epoch  70 training error:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  292.0
	 epoch  90 training error:  tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.0791015625
Memory cached:  302.0
[I 2023-12-03 04:47:34,207] Trial 5 finished with value: 0.15464970469474792 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -2.2194223814189393, 'log_learning_rate_D': -1.6035205638613692, 'log_learning_rate_D_dagger': -4.036645507855462, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  235.06754398345947
Memory status after this trial: 
Memory allocated:  483.0654296875
Memory cached:  492.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.266491713581546, 'log_learning_rate_D': -2.2476945151743326, 'log_learning_rate_D_dagger': -1.3820784878656682, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(2.1414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  190.0
	 epoch  10 training error:  tensor(165.5620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  236.0
	 epoch  20 training error:  tensor(4782.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  236.0
	 epoch  30 training error:  tensor(5647.7271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  238.0
	 epoch  40 training error:  tensor(6380.5327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  242.0
	 epoch  50 training error:  tensor(5920.6890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  232.0
	 epoch  60 training error:  tensor(6369.7222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  236.0
	 epoch  70 training error:  tensor(7447.6572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  240.0
	 epoch  80 training error:  tensor(7790.9644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  234.0
	 epoch  90 training error:  tensor(7843.8306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  159.3857421875
Memory cached:  234.0
[I 2023-12-03 04:51:00,067] Trial 6 finished with value: 7386.8447265625 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.266491713581546, 'log_learning_rate_D': -2.2476945151743326, 'log_learning_rate_D_dagger': -1.3820784878656682, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  205.6768298149109
Memory status after this trial: 
Memory allocated:  463.80322265625
Memory cached:  470.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -1.3551464513997944, 'log_learning_rate_D': -3.5777939061404203, 'log_learning_rate_D_dagger': -4.299193567139626, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.7219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  222.0
	 epoch  10 training error:  tensor(39255.1367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  296.0
	 epoch  20 training error:  tensor(6807.2080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  290.0
	 epoch  30 training error:  tensor(312.5908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  296.0
	 epoch  40 training error:  tensor(22.3821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  304.0
	 epoch  50 training error:  tensor(203.6651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  294.0
	 epoch  60 training error:  tensor(16.9258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  298.0
	 epoch  70 training error:  tensor(155.9308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  300.0
	 epoch  80 training error:  tensor(96.2330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  284.0
	 epoch  90 training error:  tensor(48.8162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.2958984375
Memory cached:  290.0
[I 2023-12-03 04:53:55,972] Trial 7 finished with value: 17.908430099487305 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -1.3551464513997944, 'log_learning_rate_D': -3.5777939061404203, 'log_learning_rate_D_dagger': -4.299193567139626, 'training_batch_size': 7, 'training_p': 5}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  175.74389672279358
Memory status after this trial: 
Memory allocated:  385.0126953125
Memory cached:  408.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -1.2744198886615021, 'log_learning_rate_D': -1.0313247532101943, 'log_learning_rate_D_dagger': -1.9340084896271912, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.3440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  230.0
	 epoch  10 training error:  tensor(50.4100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  296.0
	 epoch  20 training error:  tensor(27.3537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  300.0
	 epoch  30 training error:  tensor(15.6815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  290.0
	 epoch  40 training error:  tensor(7.4177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  278.0
	 epoch  50 training error:  tensor(5.0169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  282.0
	 epoch  60 training error:  tensor(18.5827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  280.0
	 epoch  70 training error:  tensor(32.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  288.0
	 epoch  80 training error:  tensor(14.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  272.0
	 epoch  90 training error:  tensor(106.7914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  162.111328125
Memory cached:  294.0
[I 2023-12-03 05:00:59,772] Trial 8 finished with value: 263.6553649902344 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -1.2744198886615021, 'log_learning_rate_D': -1.0313247532101943, 'log_learning_rate_D_dagger': -1.9340084896271912, 'training_batch_size': 6, 'training_p': 8}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  423.60107612609863
Memory status after this trial: 
Memory allocated:  356.572265625
Memory cached:  364.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -4.672373599063068, 'log_learning_rate_D': -3.0927322788582474, 'log_learning_rate_D_dagger': -4.379440890338445, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  226.0
	 epoch  10 training error:  tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  308.0
	 epoch  20 training error:  tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  310.0
	 epoch  30 training error:  tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.5029296875
Memory cached:  312.0
[I 2023-12-03 05:04:54,490] Trial 9 finished with value: 0.05566888675093651 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -4.672373599063068, 'log_learning_rate_D': -3.0927322788582474, 'log_learning_rate_D_dagger': -4.379440890338445, 'training_batch_size': 7, 'training_p': 7}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  234.50530624389648
Memory status after this trial: 
Memory allocated:  445.62353515625
Memory cached:  466.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -1.904937642816642, 'log_learning_rate_D': -3.9691138701690427, 'log_learning_rate_D_dagger': -1.234501363637865, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  214.0
	 epoch  10 training error:  tensor(26747.3691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  300.0
	 epoch  20 training error:  tensor(117306.7500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  296.0
	 epoch  30 training error:  tensor(1.0123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  302.0
	 epoch  40 training error:  tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  304.0
	 epoch  50 training error:  tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  302.0
	 epoch  60 training error:  tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  306.0
	 epoch  70 training error:  tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  300.0
	 epoch  80 training error:  tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  298.0
	 epoch  90 training error:  tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.5263671875
Memory cached:  302.0
[I 2023-12-03 05:09:07,298] Trial 10 finished with value: 0.13169801235198975 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 9, 'D_dagger_layer_units_exponent_7': 5, 'log_learning_rate': -1.904937642816642, 'log_learning_rate_D': -3.9691138701690427, 'log_learning_rate_D_dagger': -1.234501363637865, 'training_batch_size': 11, 'training_p': 4}. Best is trial 0 with value: 0.048587024211883545.
Time for this trial:  252.62041759490967
Memory status after this trial: 
Memory allocated:  489.69677734375
Memory cached:  498.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.469360293881297, 'log_learning_rate_D': -4.346359284355319, 'log_learning_rate_D_dagger': -3.198502239347015, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  206.0
	 epoch  10 training error:  tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  292.0
	 epoch  20 training error:  tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  290.0
	 epoch  30 training error:  tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  282.0
	 epoch  40 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  290.0
	 epoch  50 training error:  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  282.0
	 epoch  60 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  288.0
	 epoch  80 training error:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.9775390625
Memory cached:  276.0
[I 2023-12-03 05:11:51,916] Trial 11 finished with value: 0.047786351293325424 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.469360293881297, 'log_learning_rate_D': -4.346359284355319, 'log_learning_rate_D_dagger': -3.198502239347015, 'training_batch_size': 12, 'training_p': 6}. Best is trial 11 with value: 0.047786351293325424.
res:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  164.3595380783081
Memory status after this trial: 
Memory allocated:  175.99560546875
Memory cached:  342.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.471922751447061, 'log_learning_rate_D': -4.820374615189647, 'log_learning_rate_D_dagger': -3.2600919058876214, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  366.0
	 epoch  10 training error:  tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  430.0
	 epoch  20 training error:  tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  422.0
	 epoch  30 training error:  tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  424.0
	 epoch  40 training error:  tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  438.0
	 epoch  50 training error:  tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  428.0
	 epoch  60 training error:  tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  432.0
	 epoch  70 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  428.0
	 epoch  80 training error:  tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  434.0
	 epoch  90 training error:  tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  184.98095703125
Memory cached:  430.0
[I 2023-12-03 05:14:37,630] Trial 12 finished with value: 0.06550750881433487 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -3.471922751447061, 'log_learning_rate_D': -4.820374615189647, 'log_learning_rate_D_dagger': -3.2600919058876214, 'training_batch_size': 12, 'training_p': 6}. Best is trial 11 with value: 0.047786351293325424.
Time for this trial:  165.5261788368225
Memory status after this trial: 
Memory allocated:  379.380859375
Memory cached:  392.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -3.6206406453352358, 'log_learning_rate_D': -4.493748093942609, 'log_learning_rate_D_dagger': -3.2089001235689145, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  358.0
	 epoch  10 training error:  tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  416.0
	 epoch  20 training error:  tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  420.0
	 epoch  30 training error:  tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  406.0
	 epoch  40 training error:  tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  416.0
	 epoch  50 training error:  tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  406.0
	 epoch  60 training error:  tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  414.0
	 epoch  70 training error:  tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  416.0
	 epoch  80 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  424.0
	 epoch  90 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.66845703125
Memory cached:  400.0
[I 2023-12-03 05:17:39,358] Trial 13 finished with value: 0.05499181151390076 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -3.6206406453352358, 'log_learning_rate_D': -4.493748093942609, 'log_learning_rate_D_dagger': -3.2089001235689145, 'training_batch_size': 10, 'training_p': 6}. Best is trial 11 with value: 0.047786351293325424.
Time for this trial:  181.47948336601257
Memory status after this trial: 
Memory allocated:  318.65380859375
Memory cached:  388.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.784915975312702, 'log_learning_rate_D': -4.2878447550635705, 'log_learning_rate_D_dagger': -2.5500874317636133, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  346.0
	 epoch  10 training error:  tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  342.0
	 epoch  20 training error:  tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  30 training error:  tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  40 training error:  tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  50 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  60 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  70 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  80 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
	 epoch  90 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.83642578125
Memory cached:  340.0
[I 2023-12-03 05:19:57,177] Trial 14 finished with value: 0.04378952831029892 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.784915975312702, 'log_learning_rate_D': -4.2878447550635705, 'log_learning_rate_D_dagger': -2.5500874317636133, 'training_batch_size': 12, 'training_p': 6}. Best is trial 14 with value: 0.04378952831029892.
res:  tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  137.6050066947937
Memory status after this trial: 
Memory allocated:  62.88232421875
Memory cached:  296.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7647012021231134, 'log_learning_rate_D': -4.403381715261373, 'log_learning_rate_D_dagger': -2.493595519986266, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  288.0
	 epoch  10 training error:  tensor(0.6022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  322.0
	 epoch  50 training error:  tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.52978515625
Memory cached:  318.0
[I 2023-12-03 05:22:36,432] Trial 15 finished with value: 0.045454736799001694 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7647012021231134, 'log_learning_rate_D': -4.403381715261373, 'log_learning_rate_D_dagger': -2.493595519986266, 'training_batch_size': 12, 'training_p': 8}. Best is trial 14 with value: 0.04378952831029892.
Time for this trial:  159.05589079856873
Memory status after this trial: 
Memory allocated:  240.6923828125
Memory cached:  310.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6189157088028368, 'log_learning_rate_D': -4.8577437015115335, 'log_learning_rate_D_dagger': -2.4655513358622207, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.6219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  10 training error:  tensor(0.7793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  20 training error:  tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  30 training error:  tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  40 training error:  tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  50 training error:  tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  60 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  70 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  80 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.25439453125
Memory cached:  280.0
[I 2023-12-03 05:25:02,252] Trial 16 finished with value: 0.049248989671468735 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6189157088028368, 'log_learning_rate_D': -4.8577437015115335, 'log_learning_rate_D_dagger': -2.4655513358622207, 'training_batch_size': 12, 'training_p': 8}. Best is trial 14 with value: 0.04378952831029892.
Time for this trial:  145.6048719882965
Memory status after this trial: 
Memory allocated:  154.767578125
Memory cached:  278.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7844042422989768, 'log_learning_rate_D': -3.977223108941701, 'log_learning_rate_D_dagger': -2.405761634421278, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  10 training error:  tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  20 training error:  tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  30 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  40 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  50 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  60 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  70 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  80 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.84814453125
Memory cached:  280.0
[I 2023-12-03 05:27:31,787] Trial 17 finished with value: 0.0411190502345562 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7844042422989768, 'log_learning_rate_D': -3.977223108941701, 'log_learning_rate_D_dagger': -2.405761634421278, 'training_batch_size': 10, 'training_p': 7}. Best is trial 17 with value: 0.0411190502345562.
res:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  149.29895663261414
Memory status after this trial: 
Memory allocated:  78.75732421875
Memory cached:  254.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.9227857468503795, 'log_learning_rate_D': -4.060073618302062, 'log_learning_rate_D_dagger': -1.7877862880975277, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  250.0
	 epoch  10 training error:  tensor(0.6982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  270.0
	 epoch  20 training error:  tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  264.0
	 epoch  30 training error:  tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  268.0
	 epoch  40 training error:  tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  266.0
	 epoch  50 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  266.0
	 epoch  60 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  266.0
	 epoch  70 training error:  tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  266.0
	 epoch  80 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  266.0
	 epoch  90 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.99267578125
Memory cached:  264.0
[I 2023-12-03 05:30:13,228] Trial 18 finished with value: 0.06447680294513702 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.9227857468503795, 'log_learning_rate_D': -4.060073618302062, 'log_learning_rate_D_dagger': -1.7877862880975277, 'training_batch_size': 10, 'training_p': 7}. Best is trial 17 with value: 0.0411190502345562.
Time for this trial:  161.2572524547577
Memory status after this trial: 
Memory allocated:  222.107421875
Memory cached:  258.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.380791387285803, 'log_learning_rate_D': -4.982476128361488, 'log_learning_rate_D_dagger': -3.648303028615889, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  268.0
	 epoch  10 training error:  tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  274.0
	 epoch  20 training error:  tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  276.0
	 epoch  30 training error:  tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  276.0
	 epoch  40 training error:  tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  270.0
	 epoch  50 training error:  tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  274.0
	 epoch  60 training error:  tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  278.0
	 epoch  70 training error:  tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  276.0
	 epoch  80 training error:  tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  280.0
	 epoch  90 training error:  tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.49267578125
Memory cached:  276.0
[I 2023-12-03 05:32:57,639] Trial 19 finished with value: 0.08043613284826279 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.380791387285803, 'log_learning_rate_D': -4.982476128361488, 'log_learning_rate_D_dagger': -3.648303028615889, 'training_batch_size': 9, 'training_p': 7}. Best is trial 17 with value: 0.0411190502345562.
Time for this trial:  164.17189002037048
Memory status after this trial: 
Memory allocated:  198.26953125
Memory cached:  274.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.0249876175757686, 'log_learning_rate_D': -3.5637063316089357, 'log_learning_rate_D_dagger': -2.7393099122480162, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  258.0
	 epoch  10 training error:  tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  292.0
	 epoch  20 training error:  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  288.0
	 epoch  30 training error:  tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  286.0
	 epoch  40 training error:  tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  298.0
	 epoch  50 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  292.0
	 epoch  60 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  286.0
	 epoch  70 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  290.0
	 epoch  80 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  298.0
	 epoch  90 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  290.0
[I 2023-12-03 05:36:05,872] Trial 20 finished with value: 0.0441325306892395 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.0249876175757686, 'log_learning_rate_D': -3.5637063316089357, 'log_learning_rate_D_dagger': -2.7393099122480162, 'training_batch_size': 9, 'training_p': 4}. Best is trial 17 with value: 0.0411190502345562.
Time for this trial:  187.92106461524963
Memory status after this trial: 
Memory allocated:  262.353515625
Memory cached:  272.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.748596666959736, 'log_learning_rate_D': -2.560280121014567, 'log_learning_rate_D_dagger': -2.0516499828703645, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  254.0
	 epoch  10 training error:  tensor(3.5622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  284.0
	 epoch  20 training error:  tensor(0.8871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  290.0
	 epoch  30 training error:  tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  290.0
	 epoch  40 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  286.0
	 epoch  60 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.32861328125
Memory cached:  294.0
[I 2023-12-03 05:39:09,886] Trial 21 finished with value: 0.06400009989738464 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.748596666959736, 'log_learning_rate_D': -2.560280121014567, 'log_learning_rate_D_dagger': -2.0516499828703645, 'training_batch_size': 11, 'training_p': 5}. Best is trial 17 with value: 0.0411190502345562.
Time for this trial:  183.75659728050232
Memory status after this trial: 
Memory allocated:  235.84619140625
Memory cached:  270.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.1367799695103145, 'log_learning_rate_D': -3.5315234481595033, 'log_learning_rate_D_dagger': -2.770757613310469, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  264.0
	 epoch  10 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  292.0
	 epoch  50 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  290.0
	 epoch  70 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  288.0
	 epoch  90 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.99072265625
Memory cached:  298.0
[I 2023-12-03 05:42:19,381] Trial 22 finished with value: 0.05481799319386482 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -3.1367799695103145, 'log_learning_rate_D': -3.5315234481595033, 'log_learning_rate_D_dagger': -2.770757613310469, 'training_batch_size': 8, 'training_p': 4}. Best is trial 17 with value: 0.0411190502345562.
Time for this trial:  189.24008703231812
Memory status after this trial: 
Memory allocated:  262.353515625
Memory cached:  284.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.6250180415751014, 'log_learning_rate_D': -3.943462821376566, 'log_learning_rate_D_dagger': -2.59287146619785, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  250.0
	 epoch  10 training error:  tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  250.0
	 epoch  20 training error:  tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  252.0
	 epoch  40 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  252.0
	 epoch  50 training error:  tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  248.0
	 epoch  60 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  248.0
	 epoch  70 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  256.0
	 epoch  80 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.73876953125
Memory cached:  258.0
[I 2023-12-03 05:45:25,652] Trial 23 finished with value: 0.03875265270471573 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.6250180415751014, 'log_learning_rate_D': -3.943462821376566, 'log_learning_rate_D_dagger': -2.59287146619785, 'training_batch_size': 10, 'training_p': 3}. Best is trial 23 with value: 0.03875265270471573.
res:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  186.0111861228943
Memory status after this trial: 
Memory allocated:  107.87939453125
Memory cached:  218.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.4777464727214737, 'log_learning_rate_D': -4.012829966848145, 'log_learning_rate_D_dagger': -2.189078329257425, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  212.0
	 epoch  10 training error:  tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  234.0
	 epoch  20 training error:  tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  248.0
	 epoch  40 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  246.0
	 epoch  50 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  240.0
	 epoch  60 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  244.0
	 epoch  70 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  238.0
	 epoch  80 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  246.0
	 epoch  90 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.25732421875
Memory cached:  234.0
[I 2023-12-03 05:48:23,955] Trial 24 finished with value: 0.05432751774787903 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.4777464727214737, 'log_learning_rate_D': -4.012829966848145, 'log_learning_rate_D_dagger': -2.189078329257425, 'training_batch_size': 10, 'training_p': 3}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  178.0899622440338
Memory status after this trial: 
Memory allocated:  203.58447265625
Memory cached:  228.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.1806993708097027, 'log_learning_rate_D': -4.252339053384853, 'log_learning_rate_D_dagger': -2.850521837057905, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  212.0
	 epoch  10 training error:  tensor(0.8889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  252.0
	 epoch  20 training error:  tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  250.0
	 epoch  30 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  250.0
	 epoch  40 training error:  tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  248.0
	 epoch  50 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  248.0
	 epoch  70 training error:  tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  258.0
	 epoch  80 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  250.0
	 epoch  90 training error:  tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33154296875
Memory cached:  254.0
[I 2023-12-03 05:51:35,350] Trial 25 finished with value: 0.04261668771505356 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.1806993708097027, 'log_learning_rate_D': -4.252339053384853, 'log_learning_rate_D_dagger': -2.850521837057905, 'training_batch_size': 10, 'training_p': 2}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  191.12964606285095
Memory status after this trial: 
Memory allocated:  244.98388671875
Memory cached:  248.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.1288594411988755, 'log_learning_rate_D': -4.64719013363576, 'log_learning_rate_D_dagger': -1.6163954095434727, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  254.0
	 epoch  10 training error:  tensor(11.3902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  274.0
	 epoch  20 training error:  tensor(2.2368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  272.0
	 epoch  30 training error:  tensor(0.2940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  280.0
	 epoch  40 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  272.0
	 epoch  50 training error:  tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  274.0
	 epoch  60 training error:  tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  278.0
	 epoch  70 training error:  tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  264.0
	 epoch  80 training error:  tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  272.0
	 epoch  90 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.95068359375
Memory cached:  278.0
[I 2023-12-03 05:55:00,922] Trial 26 finished with value: 0.08158906549215317 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.1288594411988755, 'log_learning_rate_D': -4.64719013363576, 'log_learning_rate_D_dagger': -1.6163954095434727, 'training_batch_size': 10, 'training_p': 2}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  205.28394174575806
Memory status after this trial: 
Memory allocated:  284.98876953125
Memory cached:  304.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.5180383573962435, 'log_learning_rate_D': -3.93304077171235, 'log_learning_rate_D_dagger': -2.8647161361816624, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  226.0
	 epoch  10 training error:  tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  260.0
	 epoch  20 training error:  tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  260.0
	 epoch  30 training error:  tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  270.0
	 epoch  40 training error:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  268.0
	 epoch  50 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  266.0
	 epoch  60 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  268.0
	 epoch  70 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  266.0
	 epoch  80 training error:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  260.0
	 epoch  90 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.10693359375
Memory cached:  262.0
[I 2023-12-03 05:58:33,688] Trial 27 finished with value: 0.050333987921476364 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -2.5180383573962435, 'log_learning_rate_D': -3.93304077171235, 'log_learning_rate_D_dagger': -2.8647161361816624, 'training_batch_size': 9, 'training_p': 3}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  212.4755711555481
Memory status after this trial: 
Memory allocated:  332.443359375
Memory cached:  338.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.9697773738539992, 'log_learning_rate_D': -4.1991621747874275, 'log_learning_rate_D_dagger': -2.2862252052789893, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  236.0
	 epoch  10 training error:  tensor(0.6989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  252.0
	 epoch  20 training error:  tensor(1.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  262.0
	 epoch  40 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  250.0
	 epoch  50 training error:  tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  254.0
	 epoch  60 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  250.0
	 epoch  70 training error:  tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  264.0
	 epoch  80 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  252.0
	 epoch  90 training error:  tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.67529296875
Memory cached:  254.0
[I 2023-12-03 06:01:47,787] Trial 28 finished with value: 0.0718589648604393 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.9697773738539992, 'log_learning_rate_D': -4.1991621747874275, 'log_learning_rate_D_dagger': -2.2862252052789893, 'training_batch_size': 10, 'training_p': 2}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  193.81681489944458
Memory status after this trial: 
Memory allocated:  215.31982421875
Memory cached:  238.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -1.7308989807168838, 'log_learning_rate_D': -4.617115574295331, 'log_learning_rate_D_dagger': -3.4783722524003986, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  212.0
	 epoch  10 training error:  tensor(1.8904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  240.0
	 epoch  30 training error:  tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  238.0
	 epoch  40 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  238.0
	 epoch  50 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  238.0
	 epoch  70 training error:  tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  246.0
	 epoch  80 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  240.0
	 epoch  90 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.29638671875
Memory cached:  240.0
[I 2023-12-03 06:04:52,254] Trial 29 finished with value: 0.07065080851316452 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -1.7308989807168838, 'log_learning_rate_D': -4.617115574295331, 'log_learning_rate_D_dagger': -3.4783722524003986, 'training_batch_size': 11, 'training_p': 3}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  184.18494844436646
Memory status after this trial: 
Memory allocated:  197.48583984375
Memory cached:  222.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.8947993441127764, 'log_learning_rate_D': -3.3621042519286535, 'log_learning_rate_D_dagger': -2.849955628377897, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  214.0
	 epoch  10 training error:  tensor(0.8623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  244.0
	 epoch  20 training error:  tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  252.0
	 epoch  30 training error:  tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  246.0
	 epoch  40 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  244.0
	 epoch  50 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  252.0
	 epoch  60 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  248.0
	 epoch  70 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  246.0
	 epoch  80 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  246.0
	 epoch  90 training error:  tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.73193359375
Memory cached:  250.0
[I 2023-12-03 06:08:21,521] Trial 30 finished with value: 0.04735863581299782 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -3.8947993441127764, 'log_learning_rate_D': -3.3621042519286535, 'log_learning_rate_D_dagger': -2.849955628377897, 'training_batch_size': 10, 'training_p': 2}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  208.9830105304718
Memory status after this trial: 
Memory allocated:  261.6591796875
Memory cached:  266.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.285455071042995, 'log_learning_rate_D': -3.6897326341959005, 'log_learning_rate_D_dagger': -3.045224288581945, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  224.0
	 epoch  10 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  264.0
	 epoch  20 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  266.0
	 epoch  40 training error:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  260.0
	 epoch  50 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  254.0
	 epoch  70 training error:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  262.0
	 epoch  80 training error:  tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  262.0
	 epoch  90 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.86669921875
Memory cached:  264.0
[I 2023-12-03 06:11:04,733] Trial 31 finished with value: 0.0456685945391655 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.285455071042995, 'log_learning_rate_D': -3.6897326341959005, 'log_learning_rate_D_dagger': -3.045224288581945, 'training_batch_size': 9, 'training_p': 3}. Best is trial 23 with value: 0.03875265270471573.
Time for this trial:  162.899085521698
Memory status after this trial: 
Memory allocated:  208.5498046875
Memory cached:  230.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.809845754992157, 'log_learning_rate_D': -4.217113416415802, 'log_learning_rate_D_dagger': -2.6405788210250685, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  210.0
	 epoch  10 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  248.0
	 epoch  20 training error:  tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  234.0
	 epoch  40 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  238.0
	 epoch  50 training error:  tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  238.0
	 epoch  80 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  236.0
	 epoch  90 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.86279296875
Memory cached:  244.0
[I 2023-12-03 06:13:44,126] Trial 32 finished with value: 0.03862375020980835 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.809845754992157, 'log_learning_rate_D': -4.217113416415802, 'log_learning_rate_D_dagger': -2.6405788210250685, 'training_batch_size': 11, 'training_p': 6}. Best is trial 32 with value: 0.03862375020980835.
res:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  159.16292190551758
Memory status after this trial: 
Memory allocated:  115.21630859375
Memory cached:  228.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.747678007003363, 'log_learning_rate_D': -4.172828560933846, 'log_learning_rate_D_dagger': -2.218354863353877, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  242.0
	 epoch  10 training error:  tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  264.0
	 epoch  20 training error:  tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  262.0
	 epoch  30 training error:  tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  262.0
	 epoch  40 training error:  tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  262.0
	 epoch  50 training error:  tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  264.0
	 epoch  60 training error:  tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  264.0
	 epoch  70 training error:  tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  262.0
	 epoch  80 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  262.0
	 epoch  90 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.85986328125
Memory cached:  264.0
[I 2023-12-03 06:16:30,821] Trial 33 finished with value: 0.05353320762515068 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.747678007003363, 'log_learning_rate_D': -4.172828560933846, 'log_learning_rate_D_dagger': -2.218354863353877, 'training_batch_size': 11, 'training_p': 7}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  166.51009154319763
Memory status after this trial: 
Memory allocated:  293.1796875
Memory cached:  296.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -3.0581000601685955, 'log_learning_rate_D': -3.8699113242106122, 'log_learning_rate_D_dagger': -2.537593304754717, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  238.0
	 epoch  10 training error:  tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  266.0
	 epoch  20 training error:  tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  262.0
	 epoch  30 training error:  tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  272.0
	 epoch  40 training error:  tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  264.0
	 epoch  50 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  256.0
	 epoch  60 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  260.0
	 epoch  70 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  262.0
	 epoch  80 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  272.0
	 epoch  90 training error:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.04541015625
Memory cached:  262.0
[I 2023-12-03 06:19:24,460] Trial 34 finished with value: 0.04061161354184151 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -3.0581000601685955, 'log_learning_rate_D': -3.8699113242106122, 'log_learning_rate_D_dagger': -2.537593304754717, 'training_batch_size': 10, 'training_p': 2}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  173.4137213230133
Memory status after this trial: 
Memory allocated:  252.79736328125
Memory cached:  256.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -3.1514816753014268, 'log_learning_rate_D': -3.8108214312923527, 'log_learning_rate_D_dagger': -2.611478962672571, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  228.0
	 epoch  10 training error:  tensor(0.7356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  232.0
	 epoch  20 training error:  tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  232.0
	 epoch  30 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  230.0
	 epoch  40 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  230.0
	 epoch  50 training error:  tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  228.0
	 epoch  60 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  228.0
	 epoch  70 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  228.0
	 epoch  80 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  232.0
	 epoch  90 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.82275390625
Memory cached:  228.0
[I 2023-12-03 06:22:04,731] Trial 35 finished with value: 0.04515958949923515 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -3.1514816753014268, 'log_learning_rate_D': -3.8108214312923527, 'log_learning_rate_D_dagger': -2.611478962672571, 'training_batch_size': 11, 'training_p': 7}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  159.99615693092346
Memory status after this trial: 
Memory allocated:  227.47802734375
Memory cached:  230.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.9447879256532903, 'log_learning_rate_D': -3.82298815031561, 'log_learning_rate_D_dagger': -2.3818465319279767, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  264.0
	 epoch  10 training error:  tensor(0.6090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  290.0
	 epoch  40 training error:  tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  292.0
	 epoch  50 training error:  tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  290.0
	 epoch  60 training error:  tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  290.0
	 epoch  70 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  292.0
	 epoch  80 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  292.0
	 epoch  90 training error:  tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.00244140625
Memory cached:  292.0
[I 2023-12-03 06:25:04,495] Trial 36 finished with value: 0.04906800389289856 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.9447879256532903, 'log_learning_rate_D': -3.82298815031561, 'log_learning_rate_D_dagger': -2.3818465319279767, 'training_batch_size': 9, 'training_p': 6}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  179.50779700279236
Memory status after this trial: 
Memory allocated:  274.0009765625
Memory cached:  292.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.6049784033314447, 'log_learning_rate_D': -3.31717739153968, 'log_learning_rate_D_dagger': -2.075237192703973, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.6603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  258.0
	 epoch  10 training error:  tensor(0.8268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  274.0
	 epoch  20 training error:  tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  276.0
	 epoch  30 training error:  tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  274.0
	 epoch  40 training error:  tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  276.0
	 epoch  50 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  282.0
	 epoch  60 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  268.0
	 epoch  70 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  272.0
	 epoch  80 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  270.0
	 epoch  90 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.03369140625
Memory cached:  270.0
[I 2023-12-03 06:28:17,094] Trial 37 finished with value: 0.05436430126428604 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.6049784033314447, 'log_learning_rate_D': -3.31717739153968, 'log_learning_rate_D_dagger': -2.075237192703973, 'training_batch_size': 11, 'training_p': 5}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  192.3533194065094
Memory status after this trial: 
Memory allocated:  349.68408203125
Memory cached:  370.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.2630377169044804, 'log_learning_rate_D': -3.001645685295117, 'log_learning_rate_D_dagger': -2.6210662678587746, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.4972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  234.0
	 epoch  10 training error:  tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  250.0
	 epoch  20 training error:  tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  256.0
	 epoch  30 training error:  tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  250.0
	 epoch  40 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  258.0
	 epoch  60 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  256.0
	 epoch  70 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  254.0
	 epoch  80 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.91455078125
Memory cached:  246.0
[I 2023-12-03 06:31:13,714] Trial 38 finished with value: 0.04001208022236824 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.2630377169044804, 'log_learning_rate_D': -3.001645685295117, 'log_learning_rate_D_dagger': -2.6210662678587746, 'training_batch_size': 10, 'training_p': 5}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  176.36502146720886
Memory status after this trial: 
Memory allocated:  246.62646484375
Memory cached:  250.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.249551201674632, 'log_learning_rate_D': -2.864338875715684, 'log_learning_rate_D_dagger': -2.6439460247009148, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  234.0
	 epoch  10 training error:  tensor(0.4721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  262.0
	 epoch  20 training error:  tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  270.0
	 epoch  30 training error:  tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  254.0
	 epoch  40 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  262.0
	 epoch  50 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  260.0
	 epoch  60 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  258.0
	 epoch  70 training error:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  260.0
	 epoch  80 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  260.0
	 epoch  90 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.37158203125
Memory cached:  258.0
[I 2023-12-03 06:33:59,536] Trial 39 finished with value: 0.04708140343427658 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -3.249551201674632, 'log_learning_rate_D': -2.864338875715684, 'log_learning_rate_D_dagger': -2.6439460247009148, 'training_batch_size': 11, 'training_p': 4}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  165.56313562393188
Memory status after this trial: 
Memory allocated:  233.7333984375
Memory cached:  246.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.3628030554779955, 'log_learning_rate_D': -2.986808181135585, 'log_learning_rate_D_dagger': -2.967975799121246, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  232.0
	 epoch  10 training error:  tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  264.0
	 epoch  20 training error:  tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  272.0
	 epoch  30 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  270.0
	 epoch  40 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  270.0
	 epoch  50 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  262.0
	 epoch  60 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  268.0
	 epoch  70 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  272.0
	 epoch  80 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  268.0
	 epoch  90 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.24267578125
Memory cached:  266.0
[I 2023-12-03 06:37:16,698] Trial 40 finished with value: 0.05233025178313255 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -3.3628030554779955, 'log_learning_rate_D': -2.986808181135585, 'log_learning_rate_D_dagger': -2.967975799121246, 'training_batch_size': 9, 'training_p': 2}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  196.81191182136536
Memory status after this trial: 
Memory allocated:  241.75439453125
Memory cached:  252.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.761756628732813, 'log_learning_rate_D': -3.295568274472912, 'log_learning_rate_D_dagger': -1.8441327723037575, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  234.0
	 epoch  10 training error:  tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  20 training error:  tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  30 training error:  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  240.0
	 epoch  40 training error:  tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  50 training error:  tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  240.0
	 epoch  60 training error:  tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  70 training error:  tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  80 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  238.0
	 epoch  90 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.33251953125
Memory cached:  236.0
[I 2023-12-03 06:39:54,886] Trial 41 finished with value: 0.05646868422627449 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.761756628732813, 'log_learning_rate_D': -3.295568274472912, 'log_learning_rate_D_dagger': -1.8441327723037575, 'training_batch_size': 8, 'training_p': 5}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  157.93184566497803
Memory status after this trial: 
Memory allocated:  224.21826171875
Memory cached:  232.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.0108859645850123, 'log_learning_rate_D': -3.7874985903391662, 'log_learning_rate_D_dagger': -2.344998471801317, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.6649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  228.0
	 epoch  10 training error:  tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  238.0
	 epoch  20 training error:  tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  236.0
	 epoch  30 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  242.0
	 epoch  40 training error:  tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  242.0
	 epoch  50 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  240.0
	 epoch  70 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  248.0
	 epoch  80 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  246.0
	 epoch  90 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.10205078125
Memory cached:  240.0
[I 2023-12-03 06:42:47,724] Trial 42 finished with value: 0.04198552295565605 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.0108859645850123, 'log_learning_rate_D': -3.7874985903391662, 'log_learning_rate_D_dagger': -2.344998471801317, 'training_batch_size': 10, 'training_p': 5}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  172.56905937194824
Memory status after this trial: 
Memory allocated:  262.32958984375
Memory cached:  264.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.8290185167534823, 'log_learning_rate_D': -4.078701318313554, 'log_learning_rate_D_dagger': -2.6211245510133363, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  232.0
	 epoch  10 training error:  tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  240.0
	 epoch  30 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  238.0
	 epoch  40 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  240.0
	 epoch  50 training error:  tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  246.0
	 epoch  70 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  240.0
	 epoch  80 training error:  tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  244.0
	 epoch  90 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.32080078125
Memory cached:  242.0
[I 2023-12-03 06:45:35,118] Trial 43 finished with value: 0.05063781142234802 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -2.8290185167534823, 'log_learning_rate_D': -4.078701318313554, 'log_learning_rate_D_dagger': -2.6211245510133363, 'training_batch_size': 10, 'training_p': 3}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  167.1455204486847
Memory status after this trial: 
Memory allocated:  273.91015625
Memory cached:  280.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.150684526595195, 'log_learning_rate_D': -3.5528182999763938, 'log_learning_rate_D_dagger': -2.3803055089424427, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  234.0
	 epoch  10 training error:  tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  246.0
	 epoch  20 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  240.0
	 epoch  30 training error:  tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  236.0
	 epoch  40 training error:  tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  230.0
	 epoch  50 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  232.0
	 epoch  60 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  236.0
	 epoch  70 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  228.0
	 epoch  80 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  230.0
	 epoch  90 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.34423828125
Memory cached:  236.0
[I 2023-12-03 06:48:18,230] Trial 44 finished with value: 0.04134128615260124 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.150684526595195, 'log_learning_rate_D': -3.5528182999763938, 'log_learning_rate_D_dagger': -2.3803055089424427, 'training_batch_size': 10, 'training_p': 6}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  162.85751056671143
Memory status after this trial: 
Memory allocated:  206.39306640625
Memory cached:  230.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.7222230926610407, 'log_learning_rate_D': -3.9056207613267, 'log_learning_rate_D_dagger': -3.048917231568931, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.3936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  270.0
	 epoch  10 training error:  tensor(1.0053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  316.0
	 epoch  40 training error:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  314.0
	 epoch  90 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.82275390625
Memory cached:  320.0
[I 2023-12-03 06:51:27,236] Trial 45 finished with value: 0.045575741678476334 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -2.7222230926610407, 'log_learning_rate_D': -3.9056207613267, 'log_learning_rate_D_dagger': -3.048917231568931, 'training_batch_size': 11, 'training_p': 7}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  188.76516342163086
Memory status after this trial: 
Memory allocated:  339.6474609375
Memory cached:  362.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.395050314566162, 'log_learning_rate_D': -4.510413221567656, 'log_learning_rate_D_dagger': -2.0913837735156213, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  228.0
	 epoch  10 training error:  tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  232.0
	 epoch  20 training error:  tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  230.0
	 epoch  30 training error:  tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  232.0
	 epoch  40 training error:  tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  234.0
	 epoch  50 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  230.0
	 epoch  60 training error:  tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  230.0
	 epoch  70 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  234.0
	 epoch  80 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  232.0
	 epoch  90 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.72509765625
Memory cached:  230.0
[I 2023-12-03 06:54:30,287] Trial 46 finished with value: 0.0518343523144722 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.395050314566162, 'log_learning_rate_D': -4.510413221567656, 'log_learning_rate_D_dagger': -2.0913837735156213, 'training_batch_size': 10, 'training_p': 6}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  182.7969253063202
Memory status after this trial: 
Memory allocated:  236.9765625
Memory cached:  240.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.4391069109952936, 'log_learning_rate_D': -3.695337019024168, 'log_learning_rate_D_dagger': -2.519815582819696, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  236.0
	 epoch  10 training error:  tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  268.0
	 epoch  20 training error:  tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  262.0
	 epoch  30 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  262.0
	 epoch  40 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  256.0
	 epoch  50 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  264.0
	 epoch  60 training error:  tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  248.0
	 epoch  70 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  262.0
	 epoch  80 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  256.0
	 epoch  90 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.76416015625
Memory cached:  260.0
[I 2023-12-03 06:57:21,533] Trial 47 finished with value: 0.06550987809896469 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -3.4391069109952936, 'log_learning_rate_D': -3.695337019024168, 'log_learning_rate_D_dagger': -2.519815582819696, 'training_batch_size': 11, 'training_p': 8}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  170.9870946407318
Memory status after this trial: 
Memory allocated:  265.5283203125
Memory cached:  268.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.629167560868643, 'log_learning_rate_D': -4.330319973079979, 'log_learning_rate_D_dagger': -2.245610734422364, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  240.0
	 epoch  10 training error:  tensor(1.9833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  274.0
	 epoch  20 training error:  tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  278.0
	 epoch  30 training error:  tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  274.0
	 epoch  40 training error:  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  274.0
	 epoch  50 training error:  tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  272.0
	 epoch  60 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  270.0
	 epoch  70 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  276.0
	 epoch  80 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  276.0
	 epoch  90 training error:  tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.89306640625
Memory cached:  270.0
[I 2023-12-03 07:00:43,564] Trial 48 finished with value: 0.056330569088459015 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -2.629167560868643, 'log_learning_rate_D': -4.330319973079979, 'log_learning_rate_D_dagger': -2.245610734422364, 'training_batch_size': 10, 'training_p': 7}. Best is trial 32 with value: 0.03862375020980835.
Time for this trial:  201.76465678215027
Memory status after this trial: 
Memory allocated:  384.986328125
Memory cached:  396.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.898694969023535, 'log_learning_rate_D': -4.121696482225453, 'log_learning_rate_D_dagger': -2.613846054326725, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  250.0
	 epoch  10 training error:  tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  292.0
	 epoch  30 training error:  tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  292.0
	 epoch  40 training error:  tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  298.0
	 epoch  50 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.14306640625
Memory cached:  294.0
[I 2023-12-03 07:03:48,201] Trial 49 finished with value: 0.03705648332834244 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'log_learning_rate': -2.898694969023535, 'log_learning_rate_D': -4.121696482225453, 'log_learning_rate_D_dagger': -2.613846054326725, 'training_batch_size': 9, 'training_p': 5}. Best is trial 49 with value: 0.03705648332834244.
[I 2023-12-03 07:03:48,242] A new study created in memory with name: no-name-d60af42c-e629-4813-877a-20975e94207b
res:  tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  184.379079580307
Memory status after this trial: 
Memory allocated:  201.337890625
Memory cached:  320.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.038523568962213, 'log_learning_rate_D': -4.303734729715296, 'log_learning_rate_D_dagger': -4.893001972801058, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  100.0
	 epoch  10 training error:  tensor(1.1699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  138.0
	 epoch  20 training error:  tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  160.0
	 epoch  30 training error:  tensor(0.3766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  156.0
	 epoch  60 training error:  tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.169921875
Memory cached:  148.0
[I 2023-12-03 07:06:50,486] Trial 0 finished with value: 0.10980270057916641 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -2.038523568962213, 'log_learning_rate_D': -4.303734729715296, 'log_learning_rate_D_dagger': -4.893001972801058, 'training_batch_size': 9, 'training_p': 8}. Best is trial 0 with value: 0.10980270057916641.
res:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  182.10193967819214
Memory status after this trial: 
Memory allocated:  179.6455078125
Memory cached:  200.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.0403869873798297, 'log_learning_rate_D': -4.401156108245462, 'log_learning_rate_D_dagger': -1.3804539294885583, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  208.0
	 epoch  10 training error:  tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  258.0
	 epoch  20 training error:  tensor(88.1248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  248.0
	 epoch  30 training error:  tensor(320.4499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  248.0
	 epoch  40 training error:  tensor(619.6006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  252.0
	 epoch  50 training error:  tensor(103.4946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  250.0
	 epoch  60 training error:  tensor(1.4673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  250.0
	 epoch  70 training error:  tensor(4.5399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  248.0
	 epoch  80 training error:  tensor(14.3318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  260.0
	 epoch  90 training error:  tensor(7.4443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.435546875
Memory cached:  250.0
[I 2023-12-03 07:09:23,165] Trial 1 finished with value: 5.808990001678467 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -1.0403869873798297, 'log_learning_rate_D': -4.401156108245462, 'log_learning_rate_D_dagger': -1.3804539294885583, 'training_batch_size': 11, 'training_p': 5}. Best is trial 0 with value: 0.10980270057916641.
Time for this trial:  152.56603026390076
Memory status after this trial: 
Memory allocated:  310.8515625
Memory cached:  328.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -1.7153209644977472, 'log_learning_rate_D': -3.6880101351999817, 'log_learning_rate_D_dagger': -3.4277423580028645, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  214.0
	 epoch  10 training error:  tensor(1.4661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  260.0
	 epoch  20 training error:  tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  258.0
	 epoch  30 training error:  tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  262.0
	 epoch  40 training error:  tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  250.0
	 epoch  50 training error:  tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  248.0
	 epoch  60 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  244.0
	 epoch  70 training error:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  246.0
	 epoch  80 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  258.0
	 epoch  90 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  190.12109375
Memory cached:  250.0
[I 2023-12-03 07:12:33,754] Trial 2 finished with value: 0.04534578695893288 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -1.7153209644977472, 'log_learning_rate_D': -3.6880101351999817, 'log_learning_rate_D_dagger': -3.4277423580028645, 'training_batch_size': 10, 'training_p': 3}. Best is trial 2 with value: 0.04534578695893288.
res:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  190.4221203327179
Memory status after this trial: 
Memory allocated:  241.56005859375
Memory cached:  410.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.1893375799865678, 'log_learning_rate_D': -1.5317747590079938, 'log_learning_rate_D_dagger': -1.442804849014181, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  414.0
	 epoch  10 training error:  tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  420.0
	 epoch  20 training error:  tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  418.0
	 epoch  30 training error:  tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  422.0
	 epoch  40 training error:  tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  422.0
	 epoch  50 training error:  tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  422.0
	 epoch  60 training error:  tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  420.0
	 epoch  70 training error:  tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  414.0
	 epoch  80 training error:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  414.0
	 epoch  90 training error:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.35205078125
Memory cached:  416.0
[I 2023-12-03 07:15:45,196] Trial 3 finished with value: 0.8242238163948059 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -3.1893375799865678, 'log_learning_rate_D': -1.5317747590079938, 'log_learning_rate_D_dagger': -1.442804849014181, 'training_batch_size': 12, 'training_p': 3}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  191.31558966636658
Memory status after this trial: 
Memory allocated:  352.34033203125
Memory cached:  410.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.7761249619203685, 'log_learning_rate_D': -2.0331616567753947, 'log_learning_rate_D_dagger': -2.3203417972223335, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  514.0
	 epoch  20 training error:  tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  524.0
	 epoch  30 training error:  tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  514.0
	 epoch  40 training error:  tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  512.0
	 epoch  50 training error:  tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  510.0
	 epoch  60 training error:  tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  508.0
	 epoch  70 training error:  tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  508.0
	 epoch  80 training error:  tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  502.0
	 epoch  90 training error:  tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  286.82958984375
Memory cached:  502.0
[I 2023-12-03 07:22:35,857] Trial 4 finished with value: 0.15066085755825043 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 8, 'log_learning_rate': -3.7761249619203685, 'log_learning_rate_D': -2.0331616567753947, 'log_learning_rate_D_dagger': -2.3203417972223335, 'training_batch_size': 6, 'training_p': 5}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  410.4635248184204
Memory status after this trial: 
Memory allocated:  609.43505859375
Memory cached:  614.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.879705386987384, 'log_learning_rate_D': -3.986955644399974, 'log_learning_rate_D_dagger': -1.3073257181148028, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  440.0
	 epoch  10 training error:  tensor(278.1320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  464.0
	 epoch  20 training error:  tensor(6599.7202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  462.0
	 epoch  30 training error:  tensor(876.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  456.0
	 epoch  40 training error:  tensor(487.4250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  452.0
	 epoch  50 training error:  tensor(1.0283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  458.0
	 epoch  60 training error:  tensor(0.9565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  460.0
	 epoch  70 training error:  tensor(0.8324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.6946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  466.0
	 epoch  90 training error:  tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  255.00634765625
Memory cached:  456.0
[I 2023-12-03 07:25:30,686] Trial 5 finished with value: 0.3933829963207245 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.879705386987384, 'log_learning_rate_D': -3.986955644399974, 'log_learning_rate_D_dagger': -1.3073257181148028, 'training_batch_size': 10, 'training_p': 4}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  174.63473773002625
Memory status after this trial: 
Memory allocated:  446.27001953125
Memory cached:  466.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.5428260206828623, 'log_learning_rate_D': -2.3936582376455697, 'log_learning_rate_D_dagger': -2.9154796302780928, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  432.0
	 epoch  10 training error:  tensor(18005.7461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  458.0
	 epoch  20 training error:  tensor(1.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  460.0
	 epoch  30 training error:  tensor(0.9619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  454.0
	 epoch  40 training error:  tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  452.0
	 epoch  50 training error:  tensor(0.4906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  458.0
	 epoch  60 training error:  tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  462.0
	 epoch  70 training error:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  456.0
	 epoch  80 training error:  tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  454.0
	 epoch  90 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.88525390625
Memory cached:  458.0
[I 2023-12-03 07:28:49,505] Trial 6 finished with value: 0.1300732046365738 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -1.5428260206828623, 'log_learning_rate_D': -2.3936582376455697, 'log_learning_rate_D_dagger': -2.9154796302780928, 'training_batch_size': 9, 'training_p': 2}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  198.6178059577942
Memory status after this trial: 
Memory allocated:  479.72119140625
Memory cached:  504.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.062961391208164, 'log_learning_rate_D': -4.89432929494642, 'log_learning_rate_D_dagger': -2.101061730220867, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  418.0
	 epoch  10 training error:  tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  434.0
	 epoch  20 training error:  tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  426.0
	 epoch  30 training error:  tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  434.0
	 epoch  40 training error:  tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  430.0
	 epoch  50 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  428.0
	 epoch  60 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  432.0
	 epoch  70 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  424.0
	 epoch  80 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  432.0
	 epoch  90 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  245.05322265625
Memory cached:  430.0
[I 2023-12-03 07:31:59,139] Trial 7 finished with value: 0.053691502660512924 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -4.062961391208164, 'log_learning_rate_D': -4.89432929494642, 'log_learning_rate_D_dagger': -2.101061730220867, 'training_batch_size': 10, 'training_p': 6}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  189.46262288093567
Memory status after this trial: 
Memory allocated:  430.7490234375
Memory cached:  434.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -4.38447789826802, 'log_learning_rate_D': -2.8880349286878473, 'log_learning_rate_D_dagger': -1.3281468999781638, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  424.0
	 epoch  10 training error:  tensor(1066.3629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  434.0
	 epoch  20 training error:  tensor(53.9775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  438.0
	 epoch  30 training error:  tensor(92.3556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  434.0
	 epoch  40 training error:  tensor(14.3488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  436.0
	 epoch  50 training error:  tensor(22.8587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  438.0
	 epoch  60 training error:  tensor(18.8853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  438.0
	 epoch  70 training error:  tensor(6.2086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  442.0
	 epoch  80 training error:  tensor(7.3811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  430.0
	 epoch  90 training error:  tensor(1.4259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  253.73291015625
Memory cached:  432.0
[I 2023-12-03 07:36:18,343] Trial 8 finished with value: 0.32349544763565063 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -4.38447789826802, 'log_learning_rate_D': -2.8880349286878473, 'log_learning_rate_D_dagger': -1.3281468999781638, 'training_batch_size': 10, 'training_p': 8}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  259.01659750938416
Memory status after this trial: 
Memory allocated:  546.7509765625
Memory cached:  554.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.9346310468940597, 'log_learning_rate_D': -3.9737676472796792, 'log_learning_rate_D_dagger': -1.9853902358312432, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  414.0
	 epoch  10 training error:  tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  420.0
	 epoch  20 training error:  tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  420.0
	 epoch  30 training error:  tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  426.0
	 epoch  40 training error:  tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  422.0
	 epoch  50 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  418.0
	 epoch  60 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  422.0
	 epoch  70 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  422.0
	 epoch  80 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  418.0
	 epoch  90 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.13525390625
Memory cached:  414.0
[I 2023-12-03 07:39:15,757] Trial 9 finished with value: 0.045635998249053955 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.9346310468940597, 'log_learning_rate_D': -3.9737676472796792, 'log_learning_rate_D_dagger': -1.9853902358312432, 'training_batch_size': 9, 'training_p': 6}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  177.22807025909424
Memory status after this trial: 
Memory allocated:  351.4423828125
Memory cached:  404.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.2173274293497274, 'log_learning_rate_D': -3.173226378120285, 'log_learning_rate_D_dagger': -4.006957827395441, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  458.0
	 epoch  10 training error:  tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  492.0
	 epoch  20 training error:  tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  496.0
	 epoch  30 training error:  tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  496.0
	 epoch  50 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  484.0
	 epoch  60 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  498.0
	 epoch  70 training error:  tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  496.0
	 epoch  80 training error:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  502.0
	 epoch  90 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  278.72900390625
Memory cached:  484.0
[I 2023-12-03 07:42:33,541] Trial 10 finished with value: 0.04633171483874321 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.2173274293497274, 'log_learning_rate_D': -3.173226378120285, 'log_learning_rate_D_dagger': -4.006957827395441, 'training_batch_size': 7, 'training_p': 2}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  197.51651310920715
Memory status after this trial: 
Memory allocated:  531.93896484375
Memory cached:  560.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6396007388665983, 'log_learning_rate_D': -3.469521957426263, 'log_learning_rate_D_dagger': -3.36428302816551, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  430.0
	 epoch  10 training error:  tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  442.0
	 epoch  20 training error:  tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  442.0
	 epoch  30 training error:  tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  434.0
	 epoch  40 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  436.0
	 epoch  50 training error:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  436.0
	 epoch  60 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  442.0
	 epoch  70 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  438.0
	 epoch  80 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  436.0
	 epoch  90 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  261.83837890625
Memory cached:  442.0
[I 2023-12-03 07:46:02,776] Trial 11 finished with value: 0.04597044736146927 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.6396007388665983, 'log_learning_rate_D': -3.469521957426263, 'log_learning_rate_D_dagger': -3.36428302816551, 'training_batch_size': 8, 'training_p': 6}. Best is trial 2 with value: 0.04534578695893288.
Time for this trial:  208.94157028198242
Memory status after this trial: 
Memory allocated:  481.599609375
Memory cached:  496.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.9363825583574523, 'log_learning_rate_D': -3.6980656023879894, 'log_learning_rate_D_dagger': -2.879965757109099, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  420.0
	 epoch  10 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  412.0
	 epoch  20 training error:  tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  414.0
	 epoch  30 training error:  tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  418.0
	 epoch  40 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  412.0
	 epoch  50 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  410.0
	 epoch  60 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  412.0
	 epoch  70 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  414.0
	 epoch  80 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  414.0
	 epoch  90 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  244.38134765625
Memory cached:  414.0
[I 2023-12-03 07:49:11,993] Trial 12 finished with value: 0.04295838996767998 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.9363825583574523, 'log_learning_rate_D': -3.6980656023879894, 'log_learning_rate_D_dagger': -2.879965757109099, 'training_batch_size': 8, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
res:  tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  188.96006608009338
Memory status after this trial: 
Memory allocated:  145.61328125
Memory cached:  340.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.456651984471575, 'log_learning_rate_D': -3.4939358189208356, 'log_learning_rate_D_dagger': -3.4000154662703945, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  304.0
	 epoch  10 training error:  tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  356.0
	 epoch  20 training error:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  358.0
	 epoch  30 training error:  tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  346.0
	 epoch  40 training error:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  366.0
	 epoch  50 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  364.0
	 epoch  60 training error:  tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  354.0
	 epoch  70 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.4619140625
Memory cached:  356.0
[I 2023-12-03 07:52:24,550] Trial 13 finished with value: 0.051828522235155106 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.456651984471575, 'log_learning_rate_D': -3.4939358189208356, 'log_learning_rate_D_dagger': -3.4000154662703945, 'training_batch_size': 7, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  192.33778500556946
Memory status after this trial: 
Memory allocated:  312.35791015625
Memory cached:  324.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.4241591902509363, 'log_learning_rate_D': -2.8652522246152206, 'log_learning_rate_D_dagger': -2.804859512135973, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  338.0
	 epoch  20 training error:  tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  318.0
	 epoch  60 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  338.0
	 epoch  80 training error:  tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9130859375
Memory cached:  326.0
[I 2023-12-03 07:55:07,195] Trial 14 finished with value: 0.05046650394797325 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.4241591902509363, 'log_learning_rate_D': -2.8652522246152206, 'log_learning_rate_D_dagger': -2.804859512135973, 'training_batch_size': 8, 'training_p': 4}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  162.39528274536133
Memory status after this trial: 
Memory allocated:  291.12451171875
Memory cached:  320.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.737863409044758, 'log_learning_rate_D': -3.7042478151390483, 'log_learning_rate_D_dagger': -3.7757536826373377, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  322.0
	 epoch  10 training error:  tensor(0.5659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  352.0
	 epoch  20 training error:  tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  340.0
	 epoch  30 training error:  tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  336.0
	 epoch  40 training error:  tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  348.0
	 epoch  50 training error:  tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  348.0
	 epoch  60 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  340.0
	 epoch  80 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  350.0
	 epoch  90 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  344.0
[I 2023-12-03 07:58:39,408] Trial 15 finished with value: 0.045617442578077316 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.737863409044758, 'log_learning_rate_D': -3.7042478151390483, 'log_learning_rate_D_dagger': -3.7757536826373377, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  211.9143660068512
Memory status after this trial: 
Memory allocated:  349.27490234375
Memory cached:  364.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.8198101885516484, 'log_learning_rate_D': -1.012939400409305, 'log_learning_rate_D_dagger': -2.5910783661526215, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  298.0
	 epoch  10 training error:  tensor(1.8149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  332.0
	 epoch  30 training error:  tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.8876953125
Memory cached:  324.0
[I 2023-12-03 08:01:29,306] Trial 16 finished with value: 0.239369735121727 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -2.8198101885516484, 'log_learning_rate_D': -1.012939400409305, 'log_learning_rate_D_dagger': -2.5910783661526215, 'training_batch_size': 8, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  169.63756656646729
Memory status after this trial: 
Memory allocated:  337.279296875
Memory cached:  342.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -3.25480254804922, 'log_learning_rate_D': -4.958096728329933, 'log_learning_rate_D_dagger': -3.114527355653678, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  342.0
	 epoch  20 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  350.0
	 epoch  30 training error:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  340.0
	 epoch  40 training error:  tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  346.0
	 epoch  50 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  354.0
	 epoch  60 training error:  tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  340.0
	 epoch  70 training error:  tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  346.0
	 epoch  80 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  342.0
	 epoch  90 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.9501953125
Memory cached:  348.0
[I 2023-12-03 08:05:54,785] Trial 17 finished with value: 0.05076724290847778 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -3.25480254804922, 'log_learning_rate_D': -4.958096728329933, 'log_learning_rate_D_dagger': -3.114527355653678, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  265.14495515823364
Memory status after this trial: 
Memory allocated:  495.009765625
Memory cached:  520.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -2.4870443512612925, 'log_learning_rate_D': -3.4208819084198083, 'log_learning_rate_D_dagger': -3.9302270205543355, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(6.5299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  376.0
	 epoch  10 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  404.0
	 epoch  20 training error:  tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  402.0
	 epoch  30 training error:  tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  398.0
	 epoch  40 training error:  tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  396.0
	 epoch  50 training error:  tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  396.0
	 epoch  60 training error:  tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  398.0
	 epoch  70 training error:  tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  402.0
	 epoch  80 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  400.0
	 epoch  90 training error:  tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.833984375
Memory cached:  406.0
[I 2023-12-03 08:11:49,887] Trial 18 finished with value: 0.07637715339660645 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -2.4870443512612925, 'log_learning_rate_D': -3.4208819084198083, 'log_learning_rate_D_dagger': -3.9302270205543355, 'training_batch_size': 6, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  354.79068994522095
Memory status after this trial: 
Memory allocated:  498.53369140625
Memory cached:  512.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.9789032808095328, 'log_learning_rate_D': -2.6147551701353766, 'log_learning_rate_D_dagger': -2.601039861050532, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  302.0
	 epoch  10 training error:  tensor(11.4150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  346.0
	 epoch  20 training error:  tensor(1.7573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  352.0
	 epoch  30 training error:  tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  356.0
	 epoch  40 training error:  tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  354.0
	 epoch  50 training error:  tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  352.0
	 epoch  60 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  342.0
	 epoch  70 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  350.0
	 epoch  80 training error:  tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  344.0
	 epoch  90 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.3154296875
Memory cached:  346.0
[I 2023-12-03 08:15:09,482] Trial 19 finished with value: 0.05996232107281685 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.9789032808095328, 'log_learning_rate_D': -2.6147551701353766, 'log_learning_rate_D_dagger': -2.601039861050532, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  199.3236949443817
Memory status after this trial: 
Memory allocated:  307.2763671875
Memory cached:  324.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.3043439280660154, 'log_learning_rate_D': -3.0776093081723235, 'log_learning_rate_D_dagger': -4.353639667085654, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  298.0
	 epoch  10 training error:  tensor(4710.7871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  324.0
	 epoch  20 training error:  tensor(1694.1754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  320.0
	 epoch  40 training error:  tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  330.0
	 epoch  70 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  320.0
	 epoch  80 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  316.0
	 epoch  90 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.5361328125
Memory cached:  318.0
[I 2023-12-03 08:19:05,577] Trial 20 finished with value: 0.05039730668067932 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -1.3043439280660154, 'log_learning_rate_D': -3.0776093081723235, 'log_learning_rate_D_dagger': -4.353639667085654, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  235.80389952659607
Memory status after this trial: 
Memory allocated:  496.234375
Memory cached:  504.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.6812842648283204, 'log_learning_rate_D': -3.7192263160842014, 'log_learning_rate_D_dagger': -3.47703573683946, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  344.0
	 epoch  20 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  350.0
	 epoch  30 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  344.0
	 epoch  40 training error:  tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  348.0
	 epoch  50 training error:  tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  336.0
	 epoch  60 training error:  tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  350.0
	 epoch  70 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  344.0
	 epoch  80 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  346.0
	 epoch  90 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.9365234375
Memory cached:  344.0
[I 2023-12-03 08:22:38,296] Trial 21 finished with value: 0.05306596681475639 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -1.6812842648283204, 'log_learning_rate_D': -3.7192263160842014, 'log_learning_rate_D_dagger': -3.47703573683946, 'training_batch_size': 12, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  212.4215955734253
Memory status after this trial: 
Memory allocated:  349.27490234375
Memory cached:  364.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -1.803678185888191, 'log_learning_rate_D': -3.8286728132694696, 'log_learning_rate_D_dagger': -3.7421493769725123, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  322.0
	 epoch  50 training error:  tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  330.0
	 epoch  60 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  318.0
	 epoch  70 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.8935546875
Memory cached:  316.0
[I 2023-12-03 08:26:16,583] Trial 22 finished with value: 0.05412472411990166 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -1.803678185888191, 'log_learning_rate_D': -3.8286728132694696, 'log_learning_rate_D_dagger': -3.7421493769725123, 'training_batch_size': 12, 'training_p': 2}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  217.98652529716492
Memory status after this trial: 
Memory allocated:  336.0322265625
Memory cached:  340.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.4315452288151103, 'log_learning_rate_D': -3.3674901015627494, 'log_learning_rate_D_dagger': -3.1533497441485783, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  298.0
	 epoch  10 training error:  tensor(1.1578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  332.0
	 epoch  20 training error:  tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  332.0
	 epoch  40 training error:  tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  332.0
	 epoch  70 training error:  tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.1806640625
Memory cached:  330.0
[I 2023-12-03 08:28:56,516] Trial 23 finished with value: 0.050887592136859894 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.4315452288151103, 'log_learning_rate_D': -3.3674901015627494, 'log_learning_rate_D_dagger': -3.1533497441485783, 'training_batch_size': 10, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  159.66523122787476
Memory status after this trial: 
Memory allocated:  225.24560546875
Memory cached:  322.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.1255579592081775, 'log_learning_rate_D': -4.250630564670727, 'log_learning_rate_D_dagger': -3.677348372832103, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  308.0
	 epoch  10 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  318.0
	 epoch  70 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  322.0
	 epoch  80 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.0552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.4814453125
Memory cached:  320.0
[I 2023-12-03 08:32:49,123] Trial 24 finished with value: 0.04742450639605522 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 8, 'log_learning_rate': -2.1255579592081775, 'log_learning_rate_D': -4.250630564670727, 'log_learning_rate_D_dagger': -3.677348372832103, 'training_batch_size': 11, 'training_p': 4}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  232.32817101478577
Memory status after this trial: 
Memory allocated:  354.3212890625
Memory cached:  362.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.7419189112579212, 'log_learning_rate_D': -3.7685198538996123, 'log_learning_rate_D_dagger': -3.134254361096236, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  298.0
	 epoch  10 training error:  tensor(4.4519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  334.0
	 epoch  20 training error:  tensor(1.9444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  340.0
	 epoch  30 training error:  tensor(4.6234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  336.0
	 epoch  40 training error:  tensor(1.3758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  332.0
	 epoch  50 training error:  tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  330.0
	 epoch  90 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.0458984375
Memory cached:  328.0
[I 2023-12-03 08:36:11,711] Trial 25 finished with value: 0.08149339258670807 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -1.7419189112579212, 'log_learning_rate_D': -3.7685198538996123, 'log_learning_rate_D_dagger': -3.134254361096236, 'training_batch_size': 8, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  202.2824354171753
Memory status after this trial: 
Memory allocated:  285.38818359375
Memory cached:  312.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.3000882656968384, 'log_learning_rate_D': -3.2498035191261807, 'log_learning_rate_D_dagger': -4.1640190391335015, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  306.0
	 epoch  20 training error:  tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  308.0
	 epoch  30 training error:  tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  310.0
	 epoch  40 training error:  tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  308.0
	 epoch  50 training error:  tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  310.0
	 epoch  60 training error:  tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  306.0
	 epoch  80 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  308.0
	 epoch  90 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.3720703125
Memory cached:  312.0
[I 2023-12-03 08:39:10,650] Trial 26 finished with value: 0.06615638732910156 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -2.3000882656968384, 'log_learning_rate_D': -3.2498035191261807, 'log_learning_rate_D_dagger': -4.1640190391335015, 'training_batch_size': 12, 'training_p': 2}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  178.64301133155823
Memory status after this trial: 
Memory allocated:  213.78173828125
Memory cached:  302.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.0119000400645655, 'log_learning_rate_D': -3.642932873298478, 'log_learning_rate_D_dagger': -3.6438585740280853, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  302.0
	 epoch  10 training error:  tensor(9068.3896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  320.0
	 epoch  20 training error:  tensor(558.4271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  322.0
	 epoch  30 training error:  tensor(1555.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  322.0
	 epoch  40 training error:  tensor(982.7124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  322.0
	 epoch  50 training error:  tensor(445.8202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  336.0
	 epoch  60 training error:  tensor(43.9099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  326.0
	 epoch  70 training error:  tensor(56.5971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  326.0
	 epoch  80 training error:  tensor(52.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  324.0
	 epoch  90 training error:  tensor(7.9734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.9892578125
Memory cached:  326.0
[I 2023-12-03 08:42:31,811] Trial 27 finished with value: 0.4484499394893646 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -1.0119000400645655, 'log_learning_rate_D': -3.642932873298478, 'log_learning_rate_D_dagger': -3.6438585740280853, 'training_batch_size': 9, 'training_p': 5}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  200.88479280471802
Memory status after this trial: 
Memory allocated:  353.40234375
Memory cached:  356.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.566021839836053, 'log_learning_rate_D': -4.057173705462235, 'log_learning_rate_D_dagger': -3.2941150163215016, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  300.0
	 epoch  10 training error:  tensor(1.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  336.0
	 epoch  20 training error:  tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  334.0
	 epoch  30 training error:  tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  340.0
	 epoch  60 training error:  tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  330.0
	 epoch  90 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4208984375
Memory cached:  336.0
[I 2023-12-03 08:45:08,057] Trial 28 finished with value: 0.05118253454566002 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -2.566021839836053, 'log_learning_rate_D': -4.057173705462235, 'log_learning_rate_D_dagger': -3.2941150163215016, 'training_batch_size': 10, 'training_p': 4}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  155.98017811775208
Memory status after this trial: 
Memory allocated:  250.037109375
Memory cached:  314.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -2.009392762359396, 'log_learning_rate_D': -4.493509759137808, 'log_learning_rate_D_dagger': -4.6070134486994725, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  152.9833984375
Memory cached:  320.0
[I 2023-12-03 08:49:06,579] Trial 29 finished with value: 0.08861201256513596 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 5, 'D_dagger_layer_units_exponent_6': 10, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -2.009392762359396, 'log_learning_rate_D': -4.493509759137808, 'log_learning_rate_D_dagger': -4.6070134486994725, 'training_batch_size': 9, 'training_p': 8}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  238.1998381614685
Memory status after this trial: 
Memory allocated:  408.59130859375
Memory cached:  414.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -1.3532681451510993, 'log_learning_rate_D': -4.07280632222515, 'log_learning_rate_D_dagger': -4.772131768672933, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  300.0
	 epoch  10 training error:  tensor(1.4734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  326.0
	 epoch  20 training error:  tensor(2.5233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  322.0
	 epoch  30 training error:  tensor(2.6556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  330.0
	 epoch  40 training error:  tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  322.0
	 epoch  50 training error:  tensor(0.8561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  330.0
	 epoch  60 training error:  tensor(0.7480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.5959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  316.0
	 epoch  80 training error:  tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  330.0
	 epoch  90 training error:  tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.0986328125
Memory cached:  320.0
[I 2023-12-03 08:51:53,256] Trial 30 finished with value: 0.24506211280822754 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -1.3532681451510993, 'log_learning_rate_D': -4.07280632222515, 'log_learning_rate_D_dagger': -4.772131768672933, 'training_batch_size': 11, 'training_p': 8}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  166.41150903701782
Memory status after this trial: 
Memory allocated:  274.99560546875
Memory cached:  312.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.9078068979347917, 'log_learning_rate_D': -3.6766087663723646, 'log_learning_rate_D_dagger': -1.840684947403698, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  304.0
	 epoch  10 training error:  tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  354.0
	 epoch  20 training error:  tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  354.0
	 epoch  30 training error:  tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  350.0
	 epoch  40 training error:  tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  340.0
	 epoch  50 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  356.0
	 epoch  60 training error:  tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  348.0
	 epoch  70 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  352.0
	 epoch  80 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  340.0
	 epoch  90 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.8857421875
Memory cached:  342.0
[I 2023-12-03 08:54:53,662] Trial 31 finished with value: 0.049539610743522644 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.9078068979347917, 'log_learning_rate_D': -3.6766087663723646, 'log_learning_rate_D_dagger': -1.840684947403698, 'training_batch_size': 9, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  180.12873220443726
Memory status after this trial: 
Memory allocated:  264.93310546875
Memory cached:  322.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.8227857689990543, 'log_learning_rate_D': -4.417249300270488, 'log_learning_rate_D_dagger': -2.9461646519098754, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.5063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  302.0
	 epoch  10 training error:  tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  344.0
	 epoch  20 training error:  tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  338.0
	 epoch  30 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  352.0
	 epoch  40 training error:  tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  336.0
	 epoch  50 training error:  tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  344.0
	 epoch  60 training error:  tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  338.0
	 epoch  70 training error:  tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  340.0
	 epoch  80 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  342.0
	 epoch  90 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.6103515625
Memory cached:  342.0
[I 2023-12-03 08:57:58,119] Trial 32 finished with value: 0.0551527738571167 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.8227857689990543, 'log_learning_rate_D': -4.417249300270488, 'log_learning_rate_D_dagger': -2.9461646519098754, 'training_batch_size': 8, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  184.18546271324158
Memory status after this trial: 
Memory allocated:  280.63232421875
Memory cached:  314.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -3.061732992037204, 'log_learning_rate_D': -3.9227271641897277, 'log_learning_rate_D_dagger': -2.5697009496515197, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  330.0
	 epoch  50 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  322.0
	 epoch  80 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  332.0
	 epoch  90 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.7431640625
Memory cached:  324.0
[I 2023-12-03 09:00:41,737] Trial 33 finished with value: 0.0466877706348896 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -3.061732992037204, 'log_learning_rate_D': -3.9227271641897277, 'log_learning_rate_D_dagger': -2.5697009496515197, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  163.3603630065918
Memory status after this trial: 
Memory allocated:  248.4521484375
Memory cached:  306.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.969264599176964, 'log_learning_rate_D': -4.22422352874196, 'log_learning_rate_D_dagger': -1.7045511516117064, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  346.0
	 epoch  20 training error:  tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  344.0
	 epoch  30 training error:  tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  342.0
	 epoch  40 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  344.0
	 epoch  50 training error:  tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  350.0
	 epoch  60 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  344.0
	 epoch  70 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  344.0
	 epoch  80 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  348.0
	 epoch  90 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.7177734375
Memory cached:  350.0
[I 2023-12-03 09:03:48,089] Trial 34 finished with value: 0.056968897581100464 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -1.969264599176964, 'log_learning_rate_D': -4.22422352874196, 'log_learning_rate_D_dagger': -1.7045511516117064, 'training_batch_size': 7, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  186.0071074962616
Memory status after this trial: 
Memory allocated:  274.888671875
Memory cached:  324.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.298008868270943, 'log_learning_rate_D': -3.6200693482835864, 'log_learning_rate_D_dagger': -2.29155991822547, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.2776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  344.0
	 epoch  20 training error:  tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  348.0
	 epoch  30 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  352.0
	 epoch  40 training error:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  338.0
	 epoch  50 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  338.0
	 epoch  60 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  340.0
	 epoch  70 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  340.0
	 epoch  80 training error:  tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  344.0
	 epoch  90 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.5400390625
Memory cached:  346.0
[I 2023-12-03 09:06:54,807] Trial 35 finished with value: 0.043904487043619156 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.298008868270943, 'log_learning_rate_D': -3.6200693482835864, 'log_learning_rate_D_dagger': -2.29155991822547, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  186.4302728176117
Memory status after this trial: 
Memory allocated:  262.291015625
Memory cached:  318.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.2871529886108624, 'log_learning_rate_D': -3.549859055164967, 'log_learning_rate_D_dagger': -2.28134992444762, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  358.0
	 epoch  20 training error:  tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  350.0
	 epoch  30 training error:  tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  352.0
	 epoch  40 training error:  tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  350.0
	 epoch  50 training error:  tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  364.0
	 epoch  60 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  362.0
	 epoch  80 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  356.0
	 epoch  90 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  157.7529296875
Memory cached:  360.0
[I 2023-12-03 09:10:11,206] Trial 36 finished with value: 0.046372897922992706 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -2.2871529886108624, 'log_learning_rate_D': -3.549859055164967, 'log_learning_rate_D_dagger': -2.28134992444762, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  196.10224103927612
Memory status after this trial: 
Memory allocated:  341.35888671875
Memory cached:  360.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.820670361612183, 'log_learning_rate_D': -3.1819502611438564, 'log_learning_rate_D_dagger': -1.0884953879040586, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  304.0
	 epoch  10 training error:  tensor(1.3926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  334.0
	 epoch  20 training error:  tensor(2.3341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  342.0
	 epoch  30 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  336.0
	 epoch  40 training error:  tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  336.0
	 epoch  50 training error:  tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  346.0
	 epoch  70 training error:  tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  338.0
	 epoch  80 training error:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  356.0
	 epoch  90 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.7626953125
Memory cached:  346.0
[I 2023-12-03 09:12:50,897] Trial 37 finished with value: 0.12964704632759094 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -1.820670361612183, 'log_learning_rate_D': -3.1819502611438564, 'log_learning_rate_D_dagger': -1.0884953879040586, 'training_batch_size': 11, 'training_p': 3}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  159.4193036556244
Memory status after this trial: 
Memory allocated:  279.97900390625
Memory cached:  324.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -1.5274686672667241, 'log_learning_rate_D': -3.372824375591712, 'log_learning_rate_D_dagger': -2.3509696030683362, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  318.0
	 epoch  10 training error:  tensor(2.1983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  352.0
	 epoch  20 training error:  tensor(1.7207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  348.0
	 epoch  30 training error:  tensor(0.8261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  348.0
	 epoch  40 training error:  tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  344.0
	 epoch  50 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  344.0
	 epoch  60 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  352.0
	 epoch  70 training error:  tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  340.0
	 epoch  80 training error:  tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  346.0
	 epoch  90 training error:  tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.4443359375
Memory cached:  346.0
[I 2023-12-03 09:16:34,955] Trial 38 finished with value: 0.21651826798915863 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 10, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -1.5274686672667241, 'log_learning_rate_D': -3.372824375591712, 'log_learning_rate_D_dagger': -2.3509696030683362, 'training_batch_size': 12, 'training_p': 4}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  223.7493736743927
Memory status after this trial: 
Memory allocated:  440.58935546875
Memory cached:  458.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.1142475797592652, 'log_learning_rate_D': -3.847179713758794, 'log_learning_rate_D_dagger': -2.8549498344301742, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  318.0
	 epoch  30 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  322.0
	 epoch  70 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.9462890625
Memory cached:  320.0
[I 2023-12-03 09:19:46,229] Trial 39 finished with value: 0.0839630588889122 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -2.1142475797592652, 'log_learning_rate_D': -3.847179713758794, 'log_learning_rate_D_dagger': -2.8549498344301742, 'training_batch_size': 10, 'training_p': 5}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  190.98384404182434
Memory status after this trial: 
Memory allocated:  340.58837890625
Memory cached:  346.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -1.2187564664959054, 'log_learning_rate_D': -4.55320702647679, 'log_learning_rate_D_dagger': -3.561445533911951, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  304.0
	 epoch  10 training error:  tensor(256.6616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  326.0
	 epoch  20 training error:  tensor(95.8932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  326.0
	 epoch  30 training error:  tensor(154.1892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  330.0
	 epoch  50 training error:  tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  336.0
	 epoch  70 training error:  tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  334.0
	 epoch  90 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.2509765625
Memory cached:  326.0
[I 2023-12-03 09:23:41,620] Trial 40 finished with value: 0.07507314532995224 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -1.2187564664959054, 'log_learning_rate_D': -4.55320702647679, 'log_learning_rate_D_dagger': -3.561445533911951, 'training_batch_size': 11, 'training_p': 2}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  235.0764126777649
Memory status after this trial: 
Memory allocated:  339.83203125
Memory cached:  346.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.687593881686846, 'log_learning_rate_D': -4.024442669428689, 'log_learning_rate_D_dagger': -2.057067333652862, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  334.0
	 epoch  20 training error:  tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  326.0
	 epoch  30 training error:  tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  332.0
	 epoch  50 training error:  tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  330.0
	 epoch  90 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.9228515625
Memory cached:  328.0
[I 2023-12-03 09:26:40,438] Trial 41 finished with value: 0.04462409019470215 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.687593881686846, 'log_learning_rate_D': -4.024442669428689, 'log_learning_rate_D_dagger': -2.057067333652862, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  178.52006840705872
Memory status after this trial: 
Memory allocated:  253.66064453125
Memory cached:  320.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.6512534289353775, 'log_learning_rate_D': -3.609440817959601, 'log_learning_rate_D_dagger': -2.1684319496650577, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.2810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  348.0
	 epoch  20 training error:  tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  338.0
	 epoch  30 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  358.0
	 epoch  40 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  356.0
	 epoch  50 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  348.0
	 epoch  60 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  342.0
	 epoch  70 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  342.0
	 epoch  80 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  344.0
	 epoch  90 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.7001953125
Memory cached:  340.0
[I 2023-12-03 09:29:47,484] Trial 42 finished with value: 0.060096800327301025 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.6512534289353775, 'log_learning_rate_D': -3.609440817959601, 'log_learning_rate_D_dagger': -2.1684319496650577, 'training_batch_size': 10, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  186.72533583641052
Memory status after this trial: 
Memory allocated:  273.7119140625
Memory cached:  320.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -1.6154359061923198, 'log_learning_rate_D': -4.135909668318784, 'log_learning_rate_D_dagger': -2.058159230306997, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  300.0
	 epoch  10 training error:  tensor(28.8338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  338.0
	 epoch  20 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  350.0
	 epoch  30 training error:  tensor(2.1776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  344.0
	 epoch  40 training error:  tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  338.0
	 epoch  50 training error:  tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  336.0
	 epoch  70 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  340.0
	 epoch  90 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.1650390625
Memory cached:  338.0
[I 2023-12-03 09:32:41,688] Trial 43 finished with value: 0.050977081060409546 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -1.6154359061923198, 'log_learning_rate_D': -4.135909668318784, 'log_learning_rate_D_dagger': -2.058159230306997, 'training_batch_size': 8, 'training_p': 8}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  173.87006306648254
Memory status after this trial: 
Memory allocated:  280.36328125
Memory cached:  310.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.351899862739367, 'log_learning_rate_D': -3.8737214240859332, 'log_learning_rate_D_dagger': -1.6274221517545615, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.7964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  318.0
	 epoch  30 training error:  tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  322.0
	 epoch  40 training error:  tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  318.0
	 epoch  70 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  320.0
	 epoch  80 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.4404296875
Memory cached:  324.0
[I 2023-12-03 09:35:49,726] Trial 44 finished with value: 0.05965934321284294 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -2.351899862739367, 'log_learning_rate_D': -3.8737214240859332, 'log_learning_rate_D_dagger': -1.6274221517545615, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  187.7667043209076
Memory status after this trial: 
Memory allocated:  318.9052734375
Memory cached:  322.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7067307882457547, 'log_learning_rate_D': -4.015577261197279, 'log_learning_rate_D_dagger': -2.4047976286758033, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  306.0
	 epoch  10 training error:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  338.0
	 epoch  20 training error:  tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  338.0
	 epoch  30 training error:  tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  336.0
	 epoch  40 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  332.0
	 epoch  50 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  342.0
	 epoch  60 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  330.0
	 epoch  70 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  334.0
	 epoch  90 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.3544921875
Memory cached:  336.0
[I 2023-12-03 09:39:05,167] Trial 45 finished with value: 0.04309803247451782 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.7067307882457547, 'log_learning_rate_D': -4.015577261197279, 'log_learning_rate_D_dagger': -2.4047976286758033, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  195.1431748867035
Memory status after this trial: 
Memory allocated:  322.20068359375
Memory cached:  328.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.604706195740313, 'log_learning_rate_D': -4.335642903858137, 'log_learning_rate_D_dagger': -2.408303295775533, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.8191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  318.0
	 epoch  30 training error:  tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  320.0
	 epoch  40 training error:  tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  318.0
	 epoch  60 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  320.0
	 epoch  80 training error:  tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  160.6533203125
Memory cached:  318.0
[I 2023-12-03 09:42:25,466] Trial 46 finished with value: 0.04680801182985306 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -2.604706195740313, 'log_learning_rate_D': -4.335642903858137, 'log_learning_rate_D_dagger': -2.408303295775533, 'training_batch_size': 10, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  199.92089414596558
Memory status after this trial: 
Memory allocated:  373.2509765625
Memory cached:  382.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.7420774971640722, 'log_learning_rate_D': -3.965125491394833, 'log_learning_rate_D_dagger': -2.7362452856307073, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  348.0
	 epoch  20 training error:  tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  362.0
	 epoch  30 training error:  tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  356.0
	 epoch  40 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  354.0
	 epoch  50 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  364.0
	 epoch  60 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  356.0
	 epoch  70 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  346.0
	 epoch  80 training error:  tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  366.0
	 epoch  90 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.1650390625
Memory cached:  366.0
[I 2023-12-03 09:45:24,301] Trial 47 finished with value: 0.043197404593229294 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.7420774971640722, 'log_learning_rate_D': -3.965125491394833, 'log_learning_rate_D_dagger': -2.7362452856307073, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  178.48730516433716
Memory status after this trial: 
Memory allocated:  260.60986328125
Memory cached:  346.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -3.2367972420729547, 'log_learning_rate_D': -4.674811641673367, 'log_learning_rate_D_dagger': -2.6952901884186247, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.7972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  338.0
	 epoch  20 training error:  tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  344.0
	 epoch  30 training error:  tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  352.0
	 epoch  40 training error:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  354.0
	 epoch  50 training error:  tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  344.0
	 epoch  60 training error:  tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  354.0
	 epoch  70 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  354.0
	 epoch  80 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  342.0
	 epoch  90 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.4345703125
Memory cached:  348.0
[I 2023-12-03 09:48:24,886] Trial 48 finished with value: 0.049672409892082214 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -3.2367972420729547, 'log_learning_rate_D': -4.674811641673367, 'log_learning_rate_D_dagger': -2.6952901884186247, 'training_batch_size': 9, 'training_p': 7}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  180.29634356498718
Memory status after this trial: 
Memory allocated:  276.97412109375
Memory cached:  324.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.7183662453067687, 'log_learning_rate_D': -3.9355773473435773, 'log_learning_rate_D_dagger': -1.993471434792262, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  302.0
	 epoch  10 training error:  tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  358.0
	 epoch  20 training error:  tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  356.0
	 epoch  30 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  360.0
	 epoch  40 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  362.0
	 epoch  50 training error:  tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  354.0
	 epoch  60 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  364.0
	 epoch  80 training error:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  153.1845703125
Memory cached:  360.0
[I 2023-12-03 09:51:29,949] Trial 49 finished with value: 0.045418694615364075 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 4, 'log_learning_rate': -2.7183662453067687, 'log_learning_rate_D': -3.9355773473435773, 'log_learning_rate_D_dagger': -1.993471434792262, 'training_batch_size': 9, 'training_p': 6}. Best is trial 12 with value: 0.04295838996767998.
Time for this trial:  184.78439116477966
Memory status after this trial: 
Memory allocated:  311.43603515625
Memory cached:  334.0
