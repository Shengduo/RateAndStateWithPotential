/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-04 00:03:39,586] A new study created in memory with name: no-name-f547b0ad-d621-4459-b3c6-51c2fcb1cb02
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1116_smallDRS_largeA.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.9075044490778423, 'log_learning_rate_D': -3.6064624982737064, 'training_batch_size': 12, 'training_p': 4}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(0.9446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.7761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.6158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.4675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.12548828125
Memory cached:  2.0
[I 2023-12-04 00:03:54,910] Trial 0 finished with value: 0.10206685215234756 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.9075044490778423, 'log_learning_rate_D': -3.6064624982737064, 'training_batch_size': 12, 'training_p': 4}. Best is trial 0 with value: 0.10206685215234756.
res:  tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  15.219303369522095
Memory status after this trial: 
Memory allocated:  7.4990234375
Memory cached:  24.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -1.3098125020147648, 'log_learning_rate_D': -3.4240763647345385, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  10 training error:  tensor(1.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  20 training error:  tensor(1.5923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.7427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  40 training error:  tensor(2.1448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  50 training error:  tensor(4.0035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  60 training error:  tensor(4.4030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  70 training error:  tensor(6.1315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
	 epoch  90 training error:  tensor(1.2841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.14892578125
Memory cached:  24.0
[I 2023-12-04 00:04:09,522] Trial 1 finished with value: 0.4413776099681854 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -1.3098125020147648, 'log_learning_rate_D': -3.4240763647345385, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 0.10206685215234756.
Time for this trial:  14.51552152633667
Memory status after this trial: 
Memory allocated:  49.89208984375
Memory cached:  66.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.7327639669858055, 'log_learning_rate_D': -4.850453126155918, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  10 training error:  tensor(1.0017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.9751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.9478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.9190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.8548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.8179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.7768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.7307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.20654296875
Memory cached:  26.0
[I 2023-12-04 00:04:23,744] Trial 2 finished with value: 0.6738959550857544 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -4.7327639669858055, 'log_learning_rate_D': -4.850453126155918, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 0.10206685215234756.
Time for this trial:  14.119624376296997
Memory status after this trial: 
Memory allocated:  44.81396484375
Memory cached:  52.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.7953943729425137, 'log_learning_rate_D': -2.555174313432639, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.39599609375
Memory cached:  36.0
[I 2023-12-04 00:04:38,728] Trial 3 finished with value: 0.09675099700689316 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.7953943729425137, 'log_learning_rate_D': -2.555174313432639, 'training_batch_size': 7, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
res:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.88166856765747
Memory status after this trial: 
Memory allocated:  78.900390625
Memory cached:  92.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2066115512635034, 'log_learning_rate_D': -3.4208677557693545, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.611328125
Memory cached:  92.0
[I 2023-12-04 00:04:51,716] Trial 4 finished with value: 0.1172911673784256 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2066115512635034, 'log_learning_rate_D': -3.4208677557693545, 'training_batch_size': 8, 'training_p': 6}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  12.900392293930054
Memory status after this trial: 
Memory allocated:  88.45751953125
Memory cached:  94.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.0591434822125425, 'log_learning_rate_D': -3.216357749049215, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  10 training error:  tensor(1.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.810546875
Memory cached:  92.0
[I 2023-12-04 00:05:07,455] Trial 5 finished with value: 0.11408243328332901 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.0591434822125425, 'log_learning_rate_D': -3.216357749049215, 'training_batch_size': 6, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  15.652467489242554
Memory status after this trial: 
Memory allocated:  123.91552734375
Memory cached:  134.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.314115277831933, 'log_learning_rate_D': -4.080865798444872, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  20 training error:  tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  30 training error:  tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  40 training error:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  50 training error:  tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  60 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  70 training error:  tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  80 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
	 epoch  90 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.6787109375
Memory cached:  110.0
[I 2023-12-04 00:05:21,472] Trial 6 finished with value: 0.1064554825425148 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.314115277831933, 'log_learning_rate_D': -4.080865798444872, 'training_batch_size': 9, 'training_p': 4}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.92855978012085
Memory status after this trial: 
Memory allocated:  126.20751953125
Memory cached:  148.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.6829885245361846, 'log_learning_rate_D': -2.177488510660156, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.54833984375
Memory cached:  94.0
[I 2023-12-04 00:05:35,481] Trial 7 finished with value: 0.09977451711893082 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.6829885245361846, 'log_learning_rate_D': -2.177488510660156, 'training_batch_size': 12, 'training_p': 3}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.908690690994263
Memory status after this trial: 
Memory allocated:  112.50927734375
Memory cached:  134.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.036513322864679, 'log_learning_rate_D': -1.3257417687595363, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.2373046875
Memory cached:  94.0
[I 2023-12-04 00:05:49,406] Trial 8 finished with value: 0.11248737573623657 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.036513322864679, 'log_learning_rate_D': -1.3257417687595363, 'training_batch_size': 7, 'training_p': 5}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.83155345916748
Memory status after this trial: 
Memory allocated:  107.43115234375
Memory cached:  116.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.4554379480624382, 'log_learning_rate_D': -4.43882087872071, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  10 training error:  tensor(1.6844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.79150390625
Memory cached:  94.0
[I 2023-12-04 00:06:03,272] Trial 9 finished with value: 0.12068722397089005 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.4554379480624382, 'log_learning_rate_D': -4.43882087872071, 'training_batch_size': 7, 'training_p': 3}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.767669439315796
Memory status after this trial: 
Memory allocated:  99.75927734375
Memory cached:  120.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.2717050731111152, 'log_learning_rate_D': -2.516108273627682, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  10 training error:  tensor(1.8361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.8798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.5496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5546875
Memory cached:  144.0
[I 2023-12-04 00:06:18,058] Trial 10 finished with value: 0.12415673583745956 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.2717050731111152, 'log_learning_rate_D': -2.516108273627682, 'training_batch_size': 11, 'training_p': 8}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.63748812675476
Memory status after this trial: 
Memory allocated:  196.93408203125
Memory cached:  264.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5995876517726906, 'log_learning_rate_D': -2.236397915287114, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.82177734375
Memory cached:  92.0
[I 2023-12-04 00:06:32,377] Trial 11 finished with value: 0.09675443172454834 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5995876517726906, 'log_learning_rate_D': -2.236397915287114, 'training_batch_size': 10, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.15181565284729
Memory status after this trial: 
Memory allocated:  113.74462890625
Memory cached:  134.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.508056811749533, 'log_learning_rate_D': -2.452029013148326, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.8542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.5624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.3720703125
Memory cached:  92.0
[I 2023-12-04 00:06:46,194] Trial 12 finished with value: 0.09685258567333221 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.508056811749533, 'log_learning_rate_D': -2.452029013148326, 'training_batch_size': 10, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.655061960220337
Memory status after this trial: 
Memory allocated:  97.83642578125
Memory cached:  116.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.584761351394823, 'log_learning_rate_D': -1.7639776779174936, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.1474609375
Memory cached:  94.0
[I 2023-12-04 00:07:00,932] Trial 13 finished with value: 0.12225528061389923 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.584761351394823, 'log_learning_rate_D': -1.7639776779174936, 'training_batch_size': 10, 'training_p': 7}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.582144975662231
Memory status after this trial: 
Memory allocated:  127.18212890625
Memory cached:  144.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.9318754128048885, 'log_learning_rate_D': -2.78579132348397, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  10 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  20 training error:  tensor(2.1791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.7171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  60 training error:  tensor(1.3025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.35888671875
Memory cached:  132.0
[I 2023-12-04 00:07:15,298] Trial 14 finished with value: 0.2994596064090729 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.9318754128048885, 'log_learning_rate_D': -2.78579132348397, 'training_batch_size': 10, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.212034702301025
Memory status after this trial: 
Memory allocated:  162.55908203125
Memory cached:  192.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.4272569895574314, 'log_learning_rate_D': -1.8967222066421645, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.01123046875
Memory cached:  92.0
[I 2023-12-04 00:07:30,194] Trial 15 finished with value: 0.11098743975162506 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.4272569895574314, 'log_learning_rate_D': -1.8967222066421645, 'training_batch_size': 6, 'training_p': 5}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.727131128311157
Memory status after this trial: 
Memory allocated:  108.88037109375
Memory cached:  118.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.6694227586595782, 'log_learning_rate_D': -1.0035053681786468, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.24755859375
Memory cached:  94.0
[I 2023-12-04 00:07:44,136] Trial 16 finished with value: 0.10628767311573029 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.6694227586595782, 'log_learning_rate_D': -1.0035053681786468, 'training_batch_size': 9, 'training_p': 4}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.784279823303223
Memory status after this trial: 
Memory allocated:  110.35986328125
Memory cached:  138.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.7313278723470438, 'log_learning_rate_D': -2.9453901749154143, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  10 training error:  tensor(35.5358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  20 training error:  tensor(4.4170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  30 training error:  tensor(2.1241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  40 training error:  tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.3720703125
Memory cached:  114.0
[I 2023-12-04 00:07:59,305] Trial 17 finished with value: 0.18207846581935883 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.7313278723470438, 'log_learning_rate_D': -2.9453901749154143, 'training_batch_size': 11, 'training_p': 2}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  14.997403144836426
Memory status after this trial: 
Memory allocated:  160.94384765625
Memory cached:  194.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.0982448903725506, 'log_learning_rate_D': -2.6867836828403386, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  10 training error:  tensor(4.8132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  20 training error:  tensor(1.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  30 training error:  tensor(1.1609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  50 training error:  tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  60 training error:  tensor(1.0242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.984375
Memory cached:  92.0
[I 2023-12-04 00:08:12,861] Trial 18 finished with value: 0.11526785045862198 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.0982448903725506, 'log_learning_rate_D': -2.6867836828403386, 'training_batch_size': 9, 'training_p': 6}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.383211135864258
Memory status after this trial: 
Memory allocated:  92.47021484375
Memory cached:  96.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.373536538603373, 'log_learning_rate_D': -2.111722268164314, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.1181640625
Memory cached:  92.0
[I 2023-12-04 00:08:26,655] Trial 19 finished with value: 0.10578546673059464 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.373536538603373, 'log_learning_rate_D': -2.111722268164314, 'training_batch_size': 7, 'training_p': 4}. Best is trial 3 with value: 0.09675099700689316.
Time for this trial:  13.607324838638306
Memory status after this trial: 
Memory allocated:  97.81005859375
Memory cached:  116.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.9134536786839504, 'log_learning_rate_D': -1.632309950594732, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.330078125
Memory cached:  94.0
[I 2023-12-04 00:08:40,870] Trial 20 finished with value: 0.09674614667892456 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.9134536786839504, 'log_learning_rate_D': -1.632309950594732, 'training_batch_size': 11, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
res:  tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.0557382106781
Memory status after this trial: 
Memory allocated:  36.7373046875
Memory cached:  92.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.825401884197604, 'log_learning_rate_D': -1.6220952227345156, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  10 training error:  tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  20 training error:  tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  30 training error:  tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  40 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  50 training error:  tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  60 training error:  tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  70 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.1728515625
Memory cached:  100.0
[I 2023-12-04 00:08:55,161] Trial 21 finished with value: 0.09677445143461227 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.825401884197604, 'log_learning_rate_D': -1.6220952227345156, 'training_batch_size': 11, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.127784729003906
Memory status after this trial: 
Memory allocated:  84.79736328125
Memory cached:  96.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9798997716183715, 'log_learning_rate_D': -2.2635119845775495, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.46923828125
Memory cached:  94.0
[I 2023-12-04 00:09:09,837] Trial 22 finished with value: 0.09966683387756348 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9798997716183715, 'log_learning_rate_D': -2.2635119845775495, 'training_batch_size': 10, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.508059740066528
Memory status after this trial: 
Memory allocated:  90.43310546875
Memory cached:  96.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.362834688195857, 'log_learning_rate_D': -1.5488443285263698, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.57373046875
Memory cached:  92.0
[I 2023-12-04 00:09:23,968] Trial 23 finished with value: 0.09686429053544998 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.362834688195857, 'log_learning_rate_D': -1.5488443285263698, 'training_batch_size': 11, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.95225477218628
Memory status after this trial: 
Memory allocated:  77.94775390625
Memory cached:  96.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.368406588137593, 'log_learning_rate_D': -1.9862459516210944, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.62744140625
Memory cached:  96.0
[I 2023-12-04 00:09:38,242] Trial 24 finished with value: 0.09964490681886673 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.368406588137593, 'log_learning_rate_D': -1.9862459516210944, 'training_batch_size': 12, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.110307931900024
Memory status after this trial: 
Memory allocated:  90.83642578125
Memory cached:  96.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.9107634249733856, 'log_learning_rate_D': -2.417935661029799, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.25341796875
Memory cached:  94.0
[I 2023-12-04 00:09:51,412] Trial 25 finished with value: 0.09675108641386032 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.9107634249733856, 'log_learning_rate_D': -2.417935661029799, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  12.99844741821289
Memory status after this trial: 
Memory allocated:  44.20361328125
Memory cached:  96.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.053250513304785, 'log_learning_rate_D': -2.5466538885092245, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.0712890625
Memory cached:  96.0
[I 2023-12-04 00:10:05,236] Trial 26 finished with value: 0.1000850722193718 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.053250513304785, 'log_learning_rate_D': -2.5466538885092245, 'training_batch_size': 11, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.650187969207764
Memory status after this trial: 
Memory allocated:  72.02099609375
Memory cached:  96.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4840374068769697, 'log_learning_rate_D': -2.8613174015319243, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.59814453125
Memory cached:  92.0
[I 2023-12-04 00:10:18,784] Trial 27 finished with value: 0.09681019932031631 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4840374068769697, 'log_learning_rate_D': -2.8613174015319243, 'training_batch_size': 8, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.361933469772339
Memory status after this trial: 
Memory allocated:  55.36572265625
Memory cached:  98.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.6719775715864604, 'log_learning_rate_D': -1.9256872248348045, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.7958984375
Memory cached:  92.0
[I 2023-12-04 00:10:32,040] Trial 28 finished with value: 0.10585957020521164 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.6719775715864604, 'log_learning_rate_D': -1.9256872248348045, 'training_batch_size': 9, 'training_p': 4}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.089624643325806
Memory status after this trial: 
Memory allocated:  53.07666015625
Memory cached:  94.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.9037435497056308, 'log_learning_rate_D': -2.362618365600373, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.5100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.94921875
Memory cached:  92.0
[I 2023-12-04 00:10:45,021] Trial 29 finished with value: 0.10061142593622208 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.9037435497056308, 'log_learning_rate_D': -2.362618365600373, 'training_batch_size': 12, 'training_p': 4}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  12.816593885421753
Memory status after this trial: 
Memory allocated:  44.23583984375
Memory cached:  92.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.1005123540295934, 'log_learning_rate_D': -3.1297025328455357, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.53857421875
Memory cached:  96.0
[I 2023-12-04 00:10:58,498] Trial 30 finished with value: 0.11776405572891235 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.1005123540295934, 'log_learning_rate_D': -3.1297025328455357, 'training_batch_size': 10, 'training_p': 6}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.293153285980225
Memory status after this trial: 
Memory allocated:  59.86767578125
Memory cached:  94.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.8381911456466877, 'log_learning_rate_D': -2.212725966111222, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.00146484375
Memory cached:  94.0
[I 2023-12-04 00:11:12,280] Trial 31 finished with value: 0.09674765169620514 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.8381911456466877, 'log_learning_rate_D': -2.212725966111222, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.608403205871582
Memory status after this trial: 
Memory allocated:  54.66357421875
Memory cached:  96.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.804001249659133, 'log_learning_rate_D': -2.642331803839706, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.37841796875
Memory cached:  94.0
[I 2023-12-04 00:11:25,523] Trial 32 finished with value: 0.099685899913311 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.804001249659133, 'log_learning_rate_D': -2.642331803839706, 'training_batch_size': 9, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.080358743667603
Memory status after this trial: 
Memory allocated:  46.78369140625
Memory cached:  94.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.2342433555999874, 'log_learning_rate_D': -2.0302898851597564, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.8491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.615234375
Memory cached:  94.0
[I 2023-12-04 00:11:39,281] Trial 33 finished with value: 0.09692611545324326 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.2342433555999874, 'log_learning_rate_D': -2.0302898851597564, 'training_batch_size': 11, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.570276021957397
Memory status after this trial: 
Memory allocated:  52.75146484375
Memory cached:  94.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.931451821647639, 'log_learning_rate_D': -2.357304247808223, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.86669921875
Memory cached:  92.0
[I 2023-12-04 00:11:53,452] Trial 34 finished with value: 0.09675294160842896 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.931451821647639, 'log_learning_rate_D': -2.357304247808223, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.993747234344482
Memory status after this trial: 
Memory allocated:  63.61376953125
Memory cached:  106.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2158258627863945, 'log_learning_rate_D': -3.0645204170499714, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.35302734375
Memory cached:  92.0
[I 2023-12-04 00:12:07,640] Trial 35 finished with value: 0.09954278916120529 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2158258627863945, 'log_learning_rate_D': -3.0645204170499714, 'training_batch_size': 8, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.99953579902649
Memory status after this trial: 
Memory allocated:  80.66162109375
Memory cached:  92.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.577229876417915, 'log_learning_rate_D': -3.391641334024639, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.11767578125
Memory cached:  92.0
[I 2023-12-04 00:12:21,933] Trial 36 finished with value: 0.10033237934112549 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.577229876417915, 'log_learning_rate_D': -3.391641334024639, 'training_batch_size': 6, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.12039852142334
Memory status after this trial: 
Memory allocated:  48.26416015625
Memory cached:  94.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.870936857868059, 'log_learning_rate_D': -2.8451545482963394, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  37.28173828125
Memory cached:  94.0
[I 2023-12-04 00:12:34,933] Trial 37 finished with value: 0.09679774940013885 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.870936857868059, 'log_learning_rate_D': -2.8451545482963394, 'training_batch_size': 8, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  12.832394361495972
Memory status after this trial: 
Memory allocated:  43.78076171875
Memory cached:  92.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.3020055609383387, 'log_learning_rate_D': -1.7707709406412153, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.0712890625
Memory cached:  92.0
[I 2023-12-04 00:12:48,813] Trial 38 finished with value: 0.09964247792959213 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.3020055609383387, 'log_learning_rate_D': -1.7707709406412153, 'training_batch_size': 9, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.69884467124939
Memory status after this trial: 
Memory allocated:  55.10205078125
Memory cached:  96.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.68043311659991, 'log_learning_rate_D': -2.117862147675525, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.13134765625
Memory cached:  92.0
[I 2023-12-04 00:13:02,392] Trial 39 finished with value: 0.0968681201338768 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.68043311659991, 'log_learning_rate_D': -2.117862147675525, 'training_batch_size': 12, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.410725355148315
Memory status after this trial: 
Memory allocated:  59.31689453125
Memory cached:  94.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.2577743808200066, 'log_learning_rate_D': -2.5902727944637607, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.15673828125
Memory cached:  92.0
[I 2023-12-04 00:13:16,640] Trial 40 finished with value: 0.12566450238227844 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.2577743808200066, 'log_learning_rate_D': -2.5902727944637607, 'training_batch_size': 11, 'training_p': 8}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.07297134399414
Memory status after this trial: 
Memory allocated:  81.67138671875
Memory cached:  94.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.922562903201256, 'log_learning_rate_D': -2.3495287959037388, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.87060546875
Memory cached:  94.0
[I 2023-12-04 00:13:30,526] Trial 41 finished with value: 0.09674717485904694 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.922562903201256, 'log_learning_rate_D': -2.3495287959037388, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.697653532028198
Memory status after this trial: 
Memory allocated:  67.51416015625
Memory cached:  104.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.763291348987199, 'log_learning_rate_D': -2.3472378824518754, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.99951171875
Memory cached:  94.0
[I 2023-12-04 00:13:44,604] Trial 42 finished with value: 0.09674957394599915 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.763291348987199, 'log_learning_rate_D': -2.3472378824518754, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.88584017753601
Memory status after this trial: 
Memory allocated:  65.95556640625
Memory cached:  102.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.765270501325738, 'log_learning_rate_D': -2.1711714183094832, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.60009765625
Memory cached:  92.0
[I 2023-12-04 00:13:58,569] Trial 43 finished with value: 0.09676157683134079 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.765270501325738, 'log_learning_rate_D': -2.1711714183094832, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.778712272644043
Memory status after this trial: 
Memory allocated:  69.77685546875
Memory cached:  100.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.4958844437630483, 'log_learning_rate_D': -2.3906811665273295, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.75048828125
Memory cached:  96.0
[I 2023-12-04 00:14:12,593] Trial 44 finished with value: 0.09985039383172989 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.4958844437630483, 'log_learning_rate_D': -2.3906811665273295, 'training_batch_size': 9, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.832789182662964
Memory status after this trial: 
Memory allocated:  63.76123046875
Memory cached:  100.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.12972413269145, 'log_learning_rate_D': -2.7043526896434384, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.95654296875
Memory cached:  112.0
[I 2023-12-04 00:14:26,969] Trial 45 finished with value: 0.09675966948270798 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.12972413269145, 'log_learning_rate_D': -2.7043526896434384, 'training_batch_size': 11, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.186423301696777
Memory status after this trial: 
Memory allocated:  90.40771484375
Memory cached:  118.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.106673573827224, 'log_learning_rate_D': -2.2947959174385435, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  94.0
	 epoch  10 training error:  tensor(1.0384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.6992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.79931640625
Memory cached:  96.0
[I 2023-12-04 00:14:41,851] Trial 46 finished with value: 0.12269244343042374 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.106673573827224, 'log_learning_rate_D': -2.2947959174385435, 'training_batch_size': 10, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.69414234161377
Memory status after this trial: 
Memory allocated:  99.66845703125
Memory cached:  120.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.718095247029378, 'log_learning_rate_D': -1.4810743998592917, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.18310546875
Memory cached:  96.0
[I 2023-12-04 00:14:55,969] Trial 47 finished with value: 0.11216079443693161 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.718095247029378, 'log_learning_rate_D': -1.4810743998592917, 'training_batch_size': 7, 'training_p': 5}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  13.930115938186646
Memory status after this trial: 
Memory allocated:  82.71728515625
Memory cached:  102.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.4978199852005605, 'log_learning_rate_D': -1.9530674968194215, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.0927734375
Memory cached:  92.0
[I 2023-12-04 00:15:10,271] Trial 48 finished with value: 0.09675537049770355 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.4978199852005605, 'log_learning_rate_D': -1.9530674968194215, 'training_batch_size': 10, 'training_p': 2}. Best is trial 20 with value: 0.09674614667892456.
Time for this trial:  14.109613418579102
Memory status after this trial: 
Memory allocated:  82.60791015625
Memory cached:  100.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.0296512388177494, 'log_learning_rate_D': -1.7696932035199255, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.04248046875
Memory cached:  96.0
[I 2023-12-04 00:15:24,687] Trial 49 finished with value: 0.09973510354757309 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.0296512388177494, 'log_learning_rate_D': -1.7696932035199255, 'training_batch_size': 11, 'training_p': 3}. Best is trial 20 with value: 0.09674614667892456.
[I 2023-12-04 00:15:24,688] A new study created in memory with name: no-name-442082b0-94b2-4752-a7cb-d87fbebd4ffd
Time for this trial:  14.226101636886597
Memory status after this trial: 
Memory allocated:  89.76220703125
Memory cached:  104.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.955070837873888, 'log_learning_rate_D': -1.8175152431731614, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.015625
Memory cached:  38.0
[W 2023-12-04 00:15:28,079] Trial 0 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.955070837873888, 'log_learning_rate_D': -1.8175152431731614, 'training_batch_size': 9, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:15:28,079] Trial 0 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.303814649581909
Memory status after this trial: 
Memory allocated:  138.70263671875
Memory cached:  162.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.8318304083191874, 'log_learning_rate_D': -4.506589618017729, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.8387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.111328125
Memory cached:  12.0
[I 2023-12-04 00:16:12,602] Trial 1 finished with value: 0.1263095885515213 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.8318304083191874, 'log_learning_rate_D': -4.506589618017729, 'training_batch_size': 10, 'training_p': 2}. Best is trial 1 with value: 0.1263095885515213.
res:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  44.40999174118042
Memory status after this trial: 
Memory allocated:  32.10400390625
Memory cached:  34.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.379004860853768, 'log_learning_rate_D': -4.596877346753008, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  30 training error:  tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  40 training error:  tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  50 training error:  tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.7734375
Memory cached:  88.0
[I 2023-12-04 00:17:10,718] Trial 2 finished with value: 0.12675225734710693 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.379004860853768, 'log_learning_rate_D': -4.596877346753008, 'training_batch_size': 7, 'training_p': 7}. Best is trial 1 with value: 0.1263095885515213.
Time for this trial:  58.01320815086365
Memory status after this trial: 
Memory allocated:  171.1591796875
Memory cached:  186.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.972554833861425, 'log_learning_rate_D': -1.5595091640568524, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.103515625
Memory cached:  46.0
[W 2023-12-04 00:17:12,299] Trial 3 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.972554833861425, 'log_learning_rate_D': -1.5595091640568524, 'training_batch_size': 9, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:17:12,300] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.4652626514434814
Memory status after this trial: 
Memory allocated:  94.75146484375
Memory cached:  100.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.4788184006488296, 'log_learning_rate_D': -3.7031581983392305, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  50 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  70 training error:  tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  80 training error:  tensor(0.0248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
	 epoch  90 training error:  tensor(0.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.259765625
Memory cached:  64.0
[I 2023-12-04 00:17:56,108] Trial 4 finished with value: 0.04626297205686569 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.4788184006488296, 'log_learning_rate_D': -3.7031581983392305, 'training_batch_size': 9, 'training_p': 5}. Best is trial 4 with value: 0.04626297205686569.
res:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  43.7044575214386
Memory status after this trial: 
Memory allocated:  82.97021484375
Memory cached:  134.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.7202558264282937, 'log_learning_rate_D': -1.4753091336946729, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.306640625
Memory cached:  136.0
[W 2023-12-04 00:17:57,802] Trial 5 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.7202558264282937, 'log_learning_rate_D': -1.4753091336946729, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:17:57,803] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.5884449481964111
Memory status after this trial: 
Memory allocated:  148.24365234375
Memory cached:  168.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.0926021538269968, 'log_learning_rate_D': -1.6491608313345272, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  85.4833984375
Memory cached:  136.0
[W 2023-12-04 00:18:01,936] Trial 6 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.0926021538269968, 'log_learning_rate_D': -1.6491608313345272, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:18:01,937] Trial 6 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.038549423217773
Memory status after this trial: 
Memory allocated:  118.45703125
Memory cached:  136.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.4164247927471245, 'log_learning_rate_D': -2.2269853756963, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  10 training error:  tensor(0.7530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  20 training error:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  30 training error:  tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  40 training error:  tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  50 training error:  tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  60 training error:  tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  70 training error:  tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  80 training error:  tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
	 epoch  90 training error:  tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2705078125
Memory cached:  138.0
[I 2023-12-04 00:18:47,491] Trial 7 finished with value: 0.09948625415563583 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.4164247927471245, 'log_learning_rate_D': -2.2269853756963, 'training_batch_size': 11, 'training_p': 3}. Best is trial 4 with value: 0.04626297205686569.
Time for this trial:  45.43923854827881
Memory status after this trial: 
Memory allocated:  145.06689453125
Memory cached:  164.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.5313793795487287, 'log_learning_rate_D': -3.4026138629897216, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  134.0
	 epoch  10 training error:  tensor(0.2296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  20 training error:  tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  30 training error:  tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  40 training error:  tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  50 training error:  tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  60 training error:  tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  70 training error:  tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  80 training error:  tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
	 epoch  90 training error:  tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.9482421875
Memory cached:  136.0
[I 2023-12-04 00:19:23,187] Trial 8 finished with value: 0.07451773434877396 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.5313793795487287, 'log_learning_rate_D': -3.4026138629897216, 'training_batch_size': 7, 'training_p': 8}. Best is trial 4 with value: 0.04626297205686569.
Time for this trial:  35.58914065361023
Memory status after this trial: 
Memory allocated:  110.2333984375
Memory cached:  136.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.109244655601596, 'log_learning_rate_D': -1.3887155566857388, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  138.0
	 epoch  10 training error:  tensor(253.0113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  20 training error:  tensor(3.8370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  30 training error:  tensor(3.2240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  40 training error:  tensor(1.1071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  50 training error:  tensor(6.5739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  60 training error:  tensor(2.2784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  70 training error:  tensor(1.8159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  80 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
	 epoch  90 training error:  tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.2197265625
Memory cached:  140.0
[I 2023-12-04 00:20:03,479] Trial 9 finished with value: 0.1658644676208496 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.109244655601596, 'log_learning_rate_D': -1.3887155566857388, 'training_batch_size': 12, 'training_p': 3}. Best is trial 4 with value: 0.04626297205686569.
Time for this trial:  40.174723863601685
Memory status after this trial: 
Memory allocated:  121.740234375
Memory cached:  140.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.458820503123427, 'log_learning_rate_D': -3.549389016606795, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  138.0
	 epoch  10 training error:  tensor(0.9497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.6707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.4052734375
Memory cached:  142.0
[I 2023-12-04 00:20:55,141] Trial 10 finished with value: 0.13373920321464539 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.458820503123427, 'log_learning_rate_D': -3.549389016606795, 'training_batch_size': 7, 'training_p': 4}. Best is trial 4 with value: 0.04626297205686569.
Time for this trial:  51.547784090042114
Memory status after this trial: 
Memory allocated:  166.09326171875
Memory cached:  188.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3921785030901677, 'log_learning_rate_D': -3.263436586960127, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  136.0
	 epoch  10 training error:  tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  20 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  30 training error:  tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  40 training error:  tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  50 training error:  tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  60 training error:  tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  70 training error:  tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  80 training error:  tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
	 epoch  90 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.5576171875
Memory cached:  140.0
[I 2023-12-04 00:21:30,510] Trial 11 finished with value: 0.03588640317320824 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3921785030901677, 'log_learning_rate_D': -3.263436586960127, 'training_batch_size': 7, 'training_p': 8}. Best is trial 11 with value: 0.03588640317320824.
res:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  35.25705432891846
Memory status after this trial: 
Memory allocated:  38.73779296875
Memory cached:  98.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.073713872626035, 'log_learning_rate_D': -2.2360519305789515, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  100.0
	 epoch  10 training error:  tensor(0.9288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.5069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.8642578125
Memory cached:  102.0
[I 2023-12-04 00:22:22,098] Trial 12 finished with value: 0.1155298724770546 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.073713872626035, 'log_learning_rate_D': -2.2360519305789515, 'training_batch_size': 9, 'training_p': 5}. Best is trial 11 with value: 0.03588640317320824.
Time for this trial:  51.48395562171936
Memory status after this trial: 
Memory allocated:  111.03955078125
Memory cached:  116.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.169542039441748, 'log_learning_rate_D': -4.868969527716736, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4775390625
Memory cached:  102.0
[I 2023-12-04 00:23:10,336] Trial 13 finished with value: 0.09391114860773087 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.169542039441748, 'log_learning_rate_D': -4.868969527716736, 'training_batch_size': 9, 'training_p': 4}. Best is trial 11 with value: 0.03588640317320824.
Time for this trial:  48.11465835571289
Memory status after this trial: 
Memory allocated:  98.57373046875
Memory cached:  104.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.646882576727663, 'log_learning_rate_D': -2.6123931769309157, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  10 training error:  tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  20 training error:  tensor(0.5445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  30 training error:  tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  40 training error:  tensor(0.3996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  50 training error:  tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  60 training error:  tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  70 training error:  tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  80 training error:  tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
	 epoch  90 training error:  tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.177734375
Memory cached:  100.0
[I 2023-12-04 00:24:10,298] Trial 14 finished with value: 0.17913037538528442 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -4.646882576727663, 'log_learning_rate_D': -2.6123931769309157, 'training_batch_size': 6, 'training_p': 7}. Best is trial 11 with value: 0.03588640317320824.
Time for this trial:  59.791253089904785
Memory status after this trial: 
Memory allocated:  83.255859375
Memory cached:  100.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3346853451691874, 'log_learning_rate_D': -3.7611742205856147, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.6689453125
Memory cached:  118.0
[I 2023-12-04 00:24:50,341] Trial 15 finished with value: 0.017919111996889114 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3346853451691874, 'log_learning_rate_D': -3.7611742205856147, 'training_batch_size': 8, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
res:  tensor(0.0179, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  39.87898063659668
Memory status after this trial: 
Memory allocated:  87.13134765625
Memory cached:  144.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.9347405808080875, 'log_learning_rate_D': -4.0262954214905005, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.1484375
Memory cached:  148.0
[I 2023-12-04 00:25:30,213] Trial 16 finished with value: 0.0787866935133934 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.9347405808080875, 'log_learning_rate_D': -4.0262954214905005, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  39.73481845855713
Memory status after this trial: 
Memory allocated:  148.3271484375
Memory cached:  166.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.7841505185415523, 'log_learning_rate_D': -3.032589529796403, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  10 training error:  tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4873046875
Memory cached:  166.0
[I 2023-12-04 00:26:23,672] Trial 17 finished with value: 0.1173441931605339 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.7841505185415523, 'log_learning_rate_D': -3.032589529796403, 'training_batch_size': 6, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  53.31105041503906
Memory status after this trial: 
Memory allocated:  151.10888671875
Memory cached:  162.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.951754814522423, 'log_learning_rate_D': -4.080331091244458, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.9388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.9113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.8778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.8332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.7718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.849609375
Memory cached:  146.0
[I 2023-12-04 00:27:02,076] Trial 18 finished with value: 0.340362548828125 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.951754814522423, 'log_learning_rate_D': -4.080331091244458, 'training_batch_size': 8, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  38.24769067764282
Memory status after this trial: 
Memory allocated:  154.13623046875
Memory cached:  174.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.0475067398038775, 'log_learning_rate_D': -3.1728033110228298, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.490234375
Memory cached:  148.0
[I 2023-12-04 00:27:39,813] Trial 19 finished with value: 0.09271369874477386 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.0475067398038775, 'log_learning_rate_D': -3.1728033110228298, 'training_batch_size': 8, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  37.577056884765625
Memory status after this trial: 
Memory allocated:  112.3759765625
Memory cached:  146.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.495424919224134, 'log_learning_rate_D': -3.943504674219182, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.7507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.365234375
Memory cached:  148.0
[I 2023-12-04 00:28:20,672] Trial 20 finished with value: 0.1058756485581398 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.495424919224134, 'log_learning_rate_D': -3.943504674219182, 'training_batch_size': 7, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  40.69349408149719
Memory status after this trial: 
Memory allocated:  132.43798828125
Memory cached:  152.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.1360195985009875, 'log_learning_rate_D': -2.740025097474872, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.4049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.505859375
Memory cached:  146.0
[I 2023-12-04 00:28:57,448] Trial 21 finished with value: 0.1210174486041069 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.1360195985009875, 'log_learning_rate_D': -2.740025097474872, 'training_batch_size': 10, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  36.62549185752869
Memory status after this trial: 
Memory allocated:  152.39990234375
Memory cached:  168.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.909464906030265, 'log_learning_rate_D': -3.5734720238583315, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2646484375
Memory cached:  146.0
[I 2023-12-04 00:30:01,820] Trial 22 finished with value: 0.025635382160544395 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.909464906030265, 'log_learning_rate_D': -3.5734720238583315, 'training_batch_size': 6, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  64.17791628837585
Memory status after this trial: 
Memory allocated:  135.47802734375
Memory cached:  156.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7927131329098707, 'log_learning_rate_D': -3.6716461862044167, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  10 training error:  tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.6201171875
Memory cached:  150.0
[I 2023-12-04 00:31:07,811] Trial 23 finished with value: 0.07266470044851303 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7927131329098707, 'log_learning_rate_D': -3.6716461862044167, 'training_batch_size': 6, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  65.82522225379944
Memory status after this trial: 
Memory allocated:  157.32861328125
Memory cached:  178.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.5803814007250794, 'log_learning_rate_D': -4.275122066073298, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3427734375
Memory cached:  146.0
[I 2023-12-04 00:32:28,803] Trial 24 finished with value: 0.07807036489248276 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.5803814007250794, 'log_learning_rate_D': -4.275122066073298, 'training_batch_size': 6, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  80.794358253479
Memory status after this trial: 
Memory allocated:  167.98681640625
Memory cached:  186.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.2777916774313347, 'log_learning_rate_D': -3.404038538366709, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.46484375
Memory cached:  146.0
[I 2023-12-04 00:33:06,408] Trial 25 finished with value: 0.022832900285720825 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.2777916774313347, 'log_learning_rate_D': -3.404038538366709, 'training_batch_size': 8, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  37.43906331062317
Memory status after this trial: 
Memory allocated:  146.51708984375
Memory cached:  166.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.1905519813042416, 'log_learning_rate_D': -3.8028635384270335, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.822265625
Memory cached:  146.0
[I 2023-12-04 00:33:45,620] Trial 26 finished with value: 0.019948577508330345 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.1905519813042416, 'log_learning_rate_D': -3.8028635384270335, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  39.048322677612305
Memory status after this trial: 
Memory allocated:  139.4375
Memory cached:  158.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3178592406613765, 'log_learning_rate_D': -3.8850831978724507, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.962890625
Memory cached:  146.0
[I 2023-12-04 00:34:23,768] Trial 27 finished with value: 0.06900107860565186 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.3178592406613765, 'log_learning_rate_D': -3.8850831978724507, 'training_batch_size': 8, 'training_p': 5}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  37.98735046386719
Memory status after this trial: 
Memory allocated:  145.541015625
Memory cached:  164.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.7512223730193, 'log_learning_rate_D': -4.314563419375055, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.93359375
Memory cached:  146.0
[I 2023-12-04 00:35:04,606] Trial 28 finished with value: 0.12140842527151108 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.7512223730193, 'log_learning_rate_D': -4.314563419375055, 'training_batch_size': 10, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  40.68616247177124
Memory status after this trial: 
Memory allocated:  135.07568359375
Memory cached:  154.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.1443913478271934, 'log_learning_rate_D': -3.373102358634053, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
[I 2023-12-04 00:35:42,981] Trial 29 finished with value: 0.023809967562556267 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.1443913478271934, 'log_learning_rate_D': -3.373102358634053, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  38.20802283287048
Memory status after this trial: 
Memory allocated:  128.00146484375
Memory cached:  148.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.2629081863014076, 'log_learning_rate_D': -3.8010296976313374, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.26953125
Memory cached:  148.0
[I 2023-12-04 00:36:16,568] Trial 30 finished with value: 0.05178073048591614 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.2629081863014076, 'log_learning_rate_D': -3.8010296976313374, 'training_batch_size': 9, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  33.437052965164185
Memory status after this trial: 
Memory allocated:  137.86279296875
Memory cached:  158.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7537816565575994, 'log_learning_rate_D': -4.967932904430974, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.009765625
Memory cached:  146.0
[I 2023-12-04 00:36:57,556] Trial 31 finished with value: 0.0928698480129242 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7537816565575994, 'log_learning_rate_D': -4.967932904430974, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  40.83702540397644
Memory status after this trial: 
Memory allocated:  132.6904296875
Memory cached:  152.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.120891044767102, 'log_learning_rate_D': -2.9451832481719613, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.07421875
Memory cached:  144.0
[I 2023-12-04 00:37:43,090] Trial 32 finished with value: 0.0655914768576622 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.120891044767102, 'log_learning_rate_D': -2.9451832481719613, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  45.351775884628296
Memory status after this trial: 
Memory allocated:  163.15673828125
Memory cached:  182.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.817175160489738, 'log_learning_rate_D': -4.619765722433534, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  148.0
	 epoch  10 training error:  tensor(0.8702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.7660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.990234375
Memory cached:  146.0
[I 2023-12-04 00:38:24,509] Trial 33 finished with value: 0.10497784614562988 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.817175160489738, 'log_learning_rate_D': -4.619765722433534, 'training_batch_size': 10, 'training_p': 2}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  41.2405731678009
Memory status after this trial: 
Memory allocated:  117.99267578125
Memory cached:  146.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.6362591920608964, 'log_learning_rate_D': -4.2287648954245896, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.5234375
Memory cached:  148.0
[I 2023-12-04 00:38:59,920] Trial 34 finished with value: 0.07267812639474869 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.6362591920608964, 'log_learning_rate_D': -4.2287648954245896, 'training_batch_size': 11, 'training_p': 6}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  35.268651485443115
Memory status after this trial: 
Memory allocated:  145.34912109375
Memory cached:  166.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2820092029434123, 'log_learning_rate_D': -3.4466460566369372, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.0291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.552734375
Memory cached:  150.0
[I 2023-12-04 00:39:38,307] Trial 35 finished with value: 0.022165760397911072 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.2820092029434123, 'log_learning_rate_D': -3.4466460566369372, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  38.22899341583252
Memory status after this trial: 
Memory allocated:  128.00146484375
Memory cached:  148.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.30217854520681, 'log_learning_rate_D': -3.5716589348442715, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.818359375
Memory cached:  148.0
[I 2023-12-04 00:40:17,559] Trial 36 finished with value: 0.029983554035425186 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.30217854520681, 'log_learning_rate_D': -3.5716589348442715, 'training_batch_size': 8, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  39.054222106933594
Memory status after this trial: 
Memory allocated:  141.96826171875
Memory cached:  162.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.003720258552972, 'log_learning_rate_D': -3.8871503431496457, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  148.0
	 epoch  10 training error:  tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.890625
Memory cached:  150.0
[I 2023-12-04 00:40:58,788] Trial 37 finished with value: 0.05896032601594925 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.003720258552972, 'log_learning_rate_D': -3.8871503431496457, 'training_batch_size': 7, 'training_p': 8}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  41.065438747406006
Memory status after this trial: 
Memory allocated:  165.09033203125
Memory cached:  186.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5847756616164714, 'log_learning_rate_D': -3.3336358561317647, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.638671875
Memory cached:  144.0
[I 2023-12-04 00:41:38,704] Trial 38 finished with value: 0.02223016694188118 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5847756616164714, 'log_learning_rate_D': -3.3336358561317647, 'training_batch_size': 9, 'training_p': 7}. Best is trial 15 with value: 0.017919111996889114.
Time for this trial:  39.764885663986206
Memory status after this trial: 
Memory allocated:  151.0478515625
Memory cached:  164.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.66404120083685, 'log_learning_rate_D': -3.7445875159595396, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.34765625
Memory cached:  148.0
[I 2023-12-04 00:42:26,957] Trial 39 finished with value: 0.015849515795707703 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.66404120083685, 'log_learning_rate_D': -3.7445875159595396, 'training_batch_size': 9, 'training_p': 5}. Best is trial 39 with value: 0.015849515795707703.
res:  tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0179, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  48.068347454071045
Memory status after this trial: 
Memory allocated:  96.2421875
Memory cached:  174.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.9205569290174407, 'log_learning_rate_D': -4.395412373033371, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  20 training error:  tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  30 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  40 training error:  tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  50 training error:  tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  60 training error:  tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  70 training error:  tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  80 training error:  tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
	 epoch  90 training error:  tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.26904296875
Memory cached:  178.0
[I 2023-12-04 00:43:13,832] Trial 40 finished with value: 0.15767168998718262 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.9205569290174407, 'log_learning_rate_D': -4.395412373033371, 'training_batch_size': 9, 'training_p': 5}. Best is trial 39 with value: 0.015849515795707703.
Time for this trial:  46.69897103309631
Memory status after this trial: 
Memory allocated:  175.41845703125
Memory cached:  198.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.6128500206065786, 'log_learning_rate_D': -3.6718889302856224, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  10 training error:  tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  20 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  30 training error:  tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  40 training error:  tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  50 training error:  tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  60 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  70 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  80 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
	 epoch  90 training error:  tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09912109375
Memory cached:  198.0
[I 2023-12-04 00:44:09,224] Trial 41 finished with value: 0.025351842865347862 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.6128500206065786, 'log_learning_rate_D': -3.6718889302856224, 'training_batch_size': 11, 'training_p': 5}. Best is trial 39 with value: 0.015849515795707703.
Time for this trial:  55.21190309524536
Memory status after this trial: 
Memory allocated:  252.662109375
Memory cached:  280.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.9948656057999212, 'log_learning_rate_D': -4.115674147694736, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  10 training error:  tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  20 training error:  tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  30 training error:  tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  40 training error:  tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  50 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  60 training error:  tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  70 training error:  tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  80 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
	 epoch  90 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.19677734375
Memory cached:  178.0
[I 2023-12-04 00:44:55,825] Trial 42 finished with value: 0.05451011285185814 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.9948656057999212, 'log_learning_rate_D': -4.115674147694736, 'training_batch_size': 7, 'training_p': 4}. Best is trial 39 with value: 0.015849515795707703.
Time for this trial:  46.40877366065979
Memory status after this trial: 
Memory allocated:  177.57470703125
Memory cached:  194.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.3553187281226173, 'log_learning_rate_D': -3.771714560791094, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  10 training error:  tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  20 training error:  tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  30 training error:  tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  40 training error:  tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  50 training error:  tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  60 training error:  tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  70 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  80 training error:  tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
	 epoch  90 training error:  tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.61474609375
Memory cached:  198.0
[I 2023-12-04 00:46:00,811] Trial 43 finished with value: 0.040051817893981934 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.3553187281226173, 'log_learning_rate_D': -3.771714560791094, 'training_batch_size': 9, 'training_p': 5}. Best is trial 39 with value: 0.015849515795707703.
Time for this trial:  64.77201676368713
Memory status after this trial: 
Memory allocated:  281.15869140625
Memory cached:  310.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5507338872546415, 'log_learning_rate_D': -4.5921796797651595, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  178.0
	 epoch  10 training error:  tensor(0.7521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.51513671875
Memory cached:  180.0
[I 2023-12-04 00:46:51,438] Trial 44 finished with value: 0.11588316410779953 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5507338872546415, 'log_learning_rate_D': -4.5921796797651595, 'training_batch_size': 8, 'training_p': 6}. Best is trial 39 with value: 0.015849515795707703.
Time for this trial:  50.42228651046753
Memory status after this trial: 
Memory allocated:  170.0966796875
Memory cached:  190.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.510649173045727, 'log_learning_rate_D': -3.4252829226266144, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  20 training error:  tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  30 training error:  tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  40 training error:  tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  50 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  60 training error:  tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  70 training error:  tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  80 training error:  tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
	 epoch  90 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.61083984375
Memory cached:  176.0
[I 2023-12-04 00:47:28,408] Trial 45 finished with value: 0.012832405976951122 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.510649173045727, 'log_learning_rate_D': -3.4252829226266144, 'training_batch_size': 9, 'training_p': 7}. Best is trial 45 with value: 0.012832405976951122.
res:  tensor(0.0128, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  36.80108833312988
Memory status after this trial: 
Memory allocated:  52.12890625
Memory cached:  152.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.779688527570594, 'log_learning_rate_D': -3.4135174794254945, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.49755859375
Memory cached:  152.0
[I 2023-12-04 00:48:05,153] Trial 46 finished with value: 0.067780040204525 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.779688527570594, 'log_learning_rate_D': -3.4135174794254945, 'training_batch_size': 9, 'training_p': 6}. Best is trial 45 with value: 0.012832405976951122.
Time for this trial:  36.60436487197876
Memory status after this trial: 
Memory allocated:  104.25732421875
Memory cached:  152.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.4507435665157824, 'log_learning_rate_D': -3.168284494483798, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  10 training error:  tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  20 training error:  tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  30 training error:  tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  40 training error:  tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  50 training error:  tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  60 training error:  tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  70 training error:  tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  80 training error:  tensor(0.0242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
	 epoch  90 training error:  tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.34521484375
Memory cached:  156.0
[I 2023-12-04 00:48:38,732] Trial 47 finished with value: 0.017965108156204224 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.4507435665157824, 'log_learning_rate_D': -3.168284494483798, 'training_batch_size': 10, 'training_p': 4}. Best is trial 45 with value: 0.012832405976951122.
Time for this trial:  33.422364950180054
Memory status after this trial: 
Memory allocated:  86.47119140625
Memory cached:  154.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5318892093603784, 'log_learning_rate_D': -3.1414166684549905, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  158.0
	 epoch  10 training error:  tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  20 training error:  tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  30 training error:  tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  40 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  50 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  60 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  70 training error:  tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  80 training error:  tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
	 epoch  90 training error:  tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.34521484375
Memory cached:  156.0
[I 2023-12-04 00:49:15,163] Trial 48 finished with value: 0.019788412377238274 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5318892093603784, 'log_learning_rate_D': -3.1414166684549905, 'training_batch_size': 10, 'training_p': 4}. Best is trial 45 with value: 0.012832405976951122.
Time for this trial:  36.260732650756836
Memory status after this trial: 
Memory allocated:  102.07275390625
Memory cached:  156.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.5693192209153866, 'log_learning_rate_D': -2.9808898269070863, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  158.0
	 epoch  10 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  20 training error:  tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  30 training error:  tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  40 training error:  tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  50 training error:  tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  60 training error:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  70 training error:  tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  80 training error:  tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
	 epoch  90 training error:  tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.31005859375
Memory cached:  160.0
[I 2023-12-04 00:49:52,974] Trial 49 finished with value: 0.03595713526010513 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.5693192209153866, 'log_learning_rate_D': -2.9808898269070863, 'training_batch_size': 10, 'training_p': 4}. Best is trial 45 with value: 0.012832405976951122.
[I 2023-12-04 00:49:52,990] A new study created in memory with name: no-name-41539bd9-c044-4995-9058-69d0b6eac15d
Time for this trial:  37.63810729980469
Memory status after this trial: 
Memory allocated:  105.16552734375
Memory cached:  156.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0821426207845173, 'log_learning_rate_D': -3.6521086191245082, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  10.0
	 epoch  10 training error:  tensor(136.5353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  20 training error:  tensor(56.3629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  30 training error:  tensor(19.8657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  40 training error:  tensor(29.8292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  50 training error:  tensor(16.7761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  60 training error:  tensor(19.9231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  70 training error:  tensor(5.1941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  80 training error:  tensor(1.8886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
	 epoch  90 training error:  tensor(7.6956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.208984375
Memory cached:  12.0
[I 2023-12-04 00:50:40,507] Trial 0 finished with value: 7.776602268218994 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.0821426207845173, 'log_learning_rate_D': -3.6521086191245082, 'training_batch_size': 7, 'training_p': 7}. Best is trial 0 with value: 7.776602268218994.
res:  tensor(7.7766, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  47.431889057159424
Memory status after this trial: 
Memory allocated:  62.8759765625
Memory cached:  66.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -1.1129317587143057, 'log_learning_rate_D': -3.022369663060435, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  70.0
	 epoch  10 training error:  tensor(2.1204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  20 training error:  tensor(1.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  50 training error:  tensor(1.2195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.5277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.7209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  80 training error:  tensor(1.1103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.97509765625
Memory cached:  72.0
[I 2023-12-04 00:51:27,341] Trial 1 finished with value: 0.6204009056091309 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -1.1129317587143057, 'log_learning_rate_D': -3.022369663060435, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.6204009056091309.
res:  tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(7.7766, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  46.74527311325073
Memory status after this trial: 
Memory allocated:  31.67529296875
Memory cached:  92.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -1.5261668575266203, 'log_learning_rate_D': -3.5175301842192943, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.6736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.337890625
Memory cached:  94.0
[I 2023-12-04 00:52:49,294] Trial 2 finished with value: 0.08791553974151611 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -1.5261668575266203, 'log_learning_rate_D': -3.5175301842192943, 'training_batch_size': 6, 'training_p': 2}. Best is trial 2 with value: 0.08791553974151611.
res:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  81.85024285316467
Memory status after this trial: 
Memory allocated:  46.14794921875
Memory cached:  86.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.2889659639488666, 'log_learning_rate_D': -2.9353146477811554, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  10 training error:  tensor(2.8948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  20 training error:  tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  30 training error:  tensor(1.1431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  40 training error:  tensor(1.3284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  50 training error:  tensor(1.1727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  60 training error:  tensor(0.8841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  70 training error:  tensor(0.8475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  80 training error:  tensor(0.6239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
	 epoch  90 training error:  tensor(0.8162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.4814453125
Memory cached:  88.0
[I 2023-12-04 00:53:25,375] Trial 3 finished with value: 0.42675232887268066 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.2889659639488666, 'log_learning_rate_D': -2.9353146477811554, 'training_batch_size': 10, 'training_p': 7}. Best is trial 2 with value: 0.08791553974151611.
Time for this trial:  35.98415207862854
Memory status after this trial: 
Memory allocated:  68.58935546875
Memory cached:  88.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.3963276604756505, 'log_learning_rate_D': -4.508498015464882, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  88.0
	 epoch  10 training error:  tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.1533203125
Memory cached:  92.0
[I 2023-12-04 00:54:09,058] Trial 4 finished with value: 0.11909878253936768 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.3963276604756505, 'log_learning_rate_D': -4.508498015464882, 'training_batch_size': 11, 'training_p': 6}. Best is trial 2 with value: 0.08791553974151611.
Time for this trial:  43.58896279335022
Memory status after this trial: 
Memory allocated:  90.4091796875
Memory cached:  94.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.3070299780516361, 'log_learning_rate_D': -1.4701954222248257, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.5
Memory cached:  90.0
[W 2023-12-04 00:54:13,853] Trial 5 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.3070299780516361, 'log_learning_rate_D': -1.4701954222248257, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:54:13,854] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.676304340362549
Memory status after this trial: 
Memory allocated:  109.455078125
Memory cached:  114.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.8526651555195772, 'log_learning_rate_D': -2.051545509947061, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.5893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.337890625
Memory cached:  90.0
[I 2023-12-04 00:55:28,797] Trial 6 finished with value: 0.11423250287771225 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.8526651555195772, 'log_learning_rate_D': -2.051545509947061, 'training_batch_size': 6, 'training_p': 4}. Best is trial 2 with value: 0.08791553974151611.
Time for this trial:  74.81810474395752
Memory status after this trial: 
Memory allocated:  132.1162109375
Memory cached:  136.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.1173658571968406, 'log_learning_rate_D': -2.9960368505729806, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  10 training error:  tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  20 training error:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  30 training error:  tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  40 training error:  tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  50 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  60 training error:  tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  70 training error:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  80 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
	 epoch  90 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3486328125
Memory cached:  108.0
[I 2023-12-04 00:56:18,420] Trial 7 finished with value: 0.10296209156513214 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.1173658571968406, 'log_learning_rate_D': -2.9960368505729806, 'training_batch_size': 9, 'training_p': 2}. Best is trial 2 with value: 0.08791553974151611.
Time for this trial:  49.52318477630615
Memory status after this trial: 
Memory allocated:  129.73876953125
Memory cached:  148.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.1474877927374245, 'log_learning_rate_D': -3.68773667467294, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  10 training error:  tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  20 training error:  tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  30 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  40 training error:  tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  50 training error:  tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  60 training error:  tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  70 training error:  tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  80 training error:  tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
	 epoch  90 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4931640625
Memory cached:  108.0
[I 2023-12-04 00:57:15,994] Trial 8 finished with value: 0.08745536208152771 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.1474877927374245, 'log_learning_rate_D': -3.68773667467294, 'training_batch_size': 7, 'training_p': 6}. Best is trial 8 with value: 0.08745536208152771.
res:  tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  57.45846509933472
Memory status after this trial: 
Memory allocated:  112.0634765625
Memory cached:  178.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.984047746228413, 'log_learning_rate_D': -1.1493007824164394, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.35400390625
Memory cached:  182.0
[W 2023-12-04 00:57:17,898] Trial 9 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.984047746228413, 'log_learning_rate_D': -1.1493007824164394, 'training_batch_size': 7, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:57:17,899] Trial 9 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7980611324310303
Memory status after this trial: 
Memory allocated:  218.87353515625
Memory cached:  238.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.8674736984942792, 'log_learning_rate_D': -2.1315450335760215, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.83544921875
Memory cached:  180.0
[I 2023-12-04 00:58:31,562] Trial 10 finished with value: 0.11182411760091782 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.8674736984942792, 'log_learning_rate_D': -2.1315450335760215, 'training_batch_size': 6, 'training_p': 6}. Best is trial 8 with value: 0.08745536208152771.
Time for this trial:  73.53935480117798
Memory status after this trial: 
Memory allocated:  173.57177734375
Memory cached:  194.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.5916753982377094, 'log_learning_rate_D': -2.9806250710179745, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  202.0
	 epoch  10 training error:  tensor(0.4811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.10205078125
Memory cached:  204.0
[I 2023-12-04 00:59:21,312] Trial 11 finished with value: 0.040604304522275925 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.5916753982377094, 'log_learning_rate_D': -2.9806250710179745, 'training_batch_size': 9, 'training_p': 4}. Best is trial 11 with value: 0.040604304522275925.
res:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  49.6340765953064
Memory status after this trial: 
Memory allocated:  116.1640625
Memory cached:  200.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.932612845686405, 'log_learning_rate_D': -1.030400484356767, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:23,112] Trial 12 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.932612845686405, 'log_learning_rate_D': -1.030400484356767, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:23,113] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6523232460021973
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.836105326594332, 'log_learning_rate_D': -1.3846917826250573, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:24,985] Trial 13 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.836105326594332, 'log_learning_rate_D': -1.3846917826250573, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:24,986] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.687800645828247
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.852971536498279, 'log_learning_rate_D': -1.5247883881942337, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:26,916] Trial 14 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.852971536498279, 'log_learning_rate_D': -1.5247883881942337, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:26,917] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.74589204788208
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.8158598189423625, 'log_learning_rate_D': -1.0942983509524846, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:28,854] Trial 15 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.8158598189423625, 'log_learning_rate_D': -1.0942983509524846, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:28,855] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7508022785186768
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.519398556298341, 'log_learning_rate_D': -1.003250291584929, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.78271484375
Memory cached:  224.0
[W 2023-12-04 00:59:30,812] Trial 16 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.519398556298341, 'log_learning_rate_D': -1.003250291584929, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:30,813] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.778865098953247
Memory status after this trial: 
Memory allocated:  232.9423828125
Memory cached:  254.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.535172267680114, 'log_learning_rate_D': -1.580077627401257, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.55224609375
Memory cached:  224.0
[W 2023-12-04 00:59:32,674] Trial 17 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.535172267680114, 'log_learning_rate_D': -1.580077627401257, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:32,674] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6909983158111572
Memory status after this trial: 
Memory allocated:  214.4248046875
Memory cached:  234.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.903629495269962, 'log_learning_rate_D': -1.0497382004165865, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:34,613] Trial 18 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.903629495269962, 'log_learning_rate_D': -1.0497382004165865, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:34,614] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7513854503631592
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.797134639349336, 'log_learning_rate_D': -1.0856379176835227, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.65380859375
Memory cached:  204.0
[W 2023-12-04 00:59:36,081] Trial 19 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.797134639349336, 'log_learning_rate_D': -1.0856379176835227, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:36,082] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.3216323852539062
Memory status after this trial: 
Memory allocated:  172.03662109375
Memory cached:  202.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.935021522014528, 'log_learning_rate_D': -1.111057918064993, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:38,031] Trial 20 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.935021522014528, 'log_learning_rate_D': -1.111057918064993, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:38,032] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7705111503601074
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.282748044093523, 'log_learning_rate_D': -1.1957136954307162, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.65380859375
Memory cached:  204.0
[W 2023-12-04 00:59:39,583] Trial 21 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.282748044093523, 'log_learning_rate_D': -1.1957136954307162, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:39,584] Trial 21 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.3913753032684326
Memory status after this trial: 
Memory allocated:  172.03662109375
Memory cached:  204.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.477758152242492, 'log_learning_rate_D': -1.556413049613059, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:41,447] Trial 22 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.477758152242492, 'log_learning_rate_D': -1.556413049613059, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:41,448] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.705425500869751
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.526189287933567, 'log_learning_rate_D': -1.4771526730198024, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:43,308] Trial 23 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.526189287933567, 'log_learning_rate_D': -1.4771526730198024, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:43,309] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6973588466644287
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.767851420552386, 'log_learning_rate_D': -1.054116484808771, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.05810546875
Memory cached:  222.0
[W 2023-12-04 00:59:45,314] Trial 24 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.767851420552386, 'log_learning_rate_D': -1.054116484808771, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:45,315] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.824340581893921
Memory status after this trial: 
Memory allocated:  250.0068359375
Memory cached:  270.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.948800380952142, 'log_learning_rate_D': -1.015724343835544, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  222.0
[W 2023-12-04 00:59:47,236] Trial 25 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.948800380952142, 'log_learning_rate_D': -1.015724343835544, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:47,237] Trial 25 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7612895965576172
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.992636861860367, 'log_learning_rate_D': -1.4168694560092616, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:49,097] Trial 26 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.992636861860367, 'log_learning_rate_D': -1.4168694560092616, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:49,098] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6831943988800049
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.982167066099027, 'log_learning_rate_D': -1.266729521679582, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:50,941] Trial 27 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.982167066099027, 'log_learning_rate_D': -1.266729521679582, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:50,942] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6658191680908203
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.69112389297919, 'log_learning_rate_D': -1.1296391913369654, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:52,852] Trial 28 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.69112389297919, 'log_learning_rate_D': -1.1296391913369654, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:52,852] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7318706512451172
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.952762374825648, 'log_learning_rate_D': -1.0838147836395642, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:54,700] Trial 29 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.952762374825648, 'log_learning_rate_D': -1.0838147836395642, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:54,701] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.688511610031128
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.949573320752037, 'log_learning_rate_D': -1.0081721552898943, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:56,553] Trial 30 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.949573320752037, 'log_learning_rate_D': -1.0081721552898943, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:56,554] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6905491352081299
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.48705588555219, 'log_learning_rate_D': -1.2768691512158659, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 00:59:58,528] Trial 31 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.48705588555219, 'log_learning_rate_D': -1.2768691512158659, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 00:59:58,529] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7942991256713867
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.598795229040299, 'log_learning_rate_D': -1.0984247860120506, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:00,350] Trial 32 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.598795229040299, 'log_learning_rate_D': -1.0984247860120506, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:00,351] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.64143967628479
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.49338639582018, 'log_learning_rate_D': -1.5547655147963217, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:02,233] Trial 33 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.49338639582018, 'log_learning_rate_D': -1.5547655147963217, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:02,234] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7041089534759521
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.518307228733524, 'log_learning_rate_D': -1.102004961778851, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:04,116] Trial 34 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.518307228733524, 'log_learning_rate_D': -1.102004961778851, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:04,116] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7045061588287354
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.500002871921277, 'log_learning_rate_D': -1.2184059184225058, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:06,025] Trial 35 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.500002871921277, 'log_learning_rate_D': -1.2184059184225058, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:06,025] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7207317352294922
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.338398211071125, 'log_learning_rate_D': -1.3582447460553764, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:07,869] Trial 36 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.338398211071125, 'log_learning_rate_D': -1.3582447460553764, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:07,870] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.664379596710205
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.6392878277233764, 'log_learning_rate_D': -1.070392897408774, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:09,761] Trial 37 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.6392878277233764, 'log_learning_rate_D': -1.070392897408774, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:09,761] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7138729095458984
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.9319872200806785, 'log_learning_rate_D': -1.1601191279115382, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:11,609] Trial 38 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.9319872200806785, 'log_learning_rate_D': -1.1601191279115382, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:11,609] Trial 38 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6845073699951172
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.117297500632178, 'log_learning_rate_D': -1.2160757253814465, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:13,479] Trial 39 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.117297500632178, 'log_learning_rate_D': -1.2160757253814465, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:13,480] Trial 39 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6914422512054443
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.942744037920562, 'log_learning_rate_D': -1.4054096002381637, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:15,395] Trial 40 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.942744037920562, 'log_learning_rate_D': -1.4054096002381637, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:15,396] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7396249771118164
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.569673075058416, 'log_learning_rate_D': -1.1521859079349832, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:17,284] Trial 41 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.569673075058416, 'log_learning_rate_D': -1.1521859079349832, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:17,285] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7126798629760742
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.428826928705842, 'log_learning_rate_D': -1.3039793632201961, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:19,219] Trial 42 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.428826928705842, 'log_learning_rate_D': -1.3039793632201961, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:19,220] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7675180435180664
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.816878164031117, 'log_learning_rate_D': -1.0134232081221004, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.55224609375
Memory cached:  224.0
[W 2023-12-04 01:00:21,144] Trial 43 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.816878164031117, 'log_learning_rate_D': -1.0134232081221004, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:21,145] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7146837711334229
Memory status after this trial: 
Memory allocated:  214.4248046875
Memory cached:  234.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.963230282940412, 'log_learning_rate_D': -1.5766417456014992, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:23,028] Trial 44 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.963230282940412, 'log_learning_rate_D': -1.5766417456014992, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:23,029] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7125604152679443
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.9327424896212175, 'log_learning_rate_D': -1.3116415421342769, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:24,846] Trial 45 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.9327424896212175, 'log_learning_rate_D': -1.3116415421342769, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:24,847] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6530728340148926
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.807565973503664, 'log_learning_rate_D': -1.0596103215892678, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:26,686] Trial 46 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.807565973503664, 'log_learning_rate_D': -1.0596103215892678, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:26,686] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.660383701324463
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.905811915041843, 'log_learning_rate_D': -1.1638285695518709, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  224.0
[W 2023-12-04 01:00:28,553] Trial 47 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.905811915041843, 'log_learning_rate_D': -1.1638285695518709, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:28,554] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7033162117004395
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.962499077769089, 'log_learning_rate_D': -1.1681564243630427, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  156.72412109375
Memory cached:  242.0
[W 2023-12-04 01:00:30,433] Trial 48 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.962499077769089, 'log_learning_rate_D': -1.1681564243630427, 'training_batch_size': 11, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:30,433] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7026352882385254
Memory status after this trial: 
Memory allocated:  242.7138671875
Memory cached:  280.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.582808120609734, 'log_learning_rate_D': -1.0570323869668004, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.71630859375
Memory cached:  222.0
[W 2023-12-04 01:00:32,302] Trial 49 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.582808120609734, 'log_learning_rate_D': -1.0570323869668004, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:00:32,303] Trial 49 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
[I 2023-12-04 01:00:32,325] A new study created in memory with name: no-name-2baf64be-2ac1-4472-8d25-4dd0901c2aff
Time for this trial:  1.692265272140503
Memory status after this trial: 
Memory allocated:  226.1083984375
Memory cached:  246.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.8713213204944696, 'log_learning_rate_D': -3.4441310107265757, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.400390625
Memory cached:  14.0
[I 2023-12-04 01:01:15,780] Trial 0 finished with value: 0.07213948667049408 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.8713213204944696, 'log_learning_rate_D': -3.4441310107265757, 'training_batch_size': 7, 'training_p': 7}. Best is trial 0 with value: 0.07213948667049408.
res:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  43.35212993621826
Memory status after this trial: 
Memory allocated:  63.6865234375
Memory cached:  70.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.928643390327456, 'log_learning_rate_D': -4.136171341149403, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.6009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.46240234375
Memory cached:  76.0
[I 2023-12-04 01:02:29,518] Trial 1 finished with value: 0.12233655899763107 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.928643390327456, 'log_learning_rate_D': -4.136171341149403, 'training_batch_size': 6, 'training_p': 8}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  73.63399815559387
Memory status after this trial: 
Memory allocated:  99.45556640625
Memory cached:  102.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.714190313538484, 'log_learning_rate_D': -2.6934441713860635, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.9113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.33251953125
Memory cached:  76.0
[I 2023-12-04 01:03:14,148] Trial 2 finished with value: 0.08164599537849426 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.714190313538484, 'log_learning_rate_D': -2.6934441713860635, 'training_batch_size': 9, 'training_p': 8}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  44.532015800476074
Memory status after this trial: 
Memory allocated:  107.31591796875
Memory cached:  110.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.0730321347200737, 'log_learning_rate_D': -4.470414166465824, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(63.6621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.82373046875
Memory cached:  100.0
[W 2023-12-04 01:03:16,235] Trial 3 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.0730321347200737, 'log_learning_rate_D': -4.470414166465824, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:03:16,235] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.983593463897705
Memory status after this trial: 
Memory allocated:  131.91796875
Memory cached:  150.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.5352967838884677, 'log_learning_rate_D': -4.4703737115915025, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.39306640625
Memory cached:  80.0
[I 2023-12-04 01:04:09,498] Trial 4 finished with value: 0.11621882766485214 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.5352967838884677, 'log_learning_rate_D': -4.4703737115915025, 'training_batch_size': 7, 'training_p': 7}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  53.15133738517761
Memory status after this trial: 
Memory allocated:  152.1904296875
Memory cached:  158.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.9815007066274815, 'log_learning_rate_D': -2.1206535287002515, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.6228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.07275390625
Memory cached:  80.0
[I 2023-12-04 01:04:49,216] Trial 5 finished with value: 0.12089115381240845 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.9815007066274815, 'log_learning_rate_D': -2.1206535287002515, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  39.60463285446167
Memory status after this trial: 
Memory allocated:  127.048828125
Memory cached:  132.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.2459191822704385, 'log_learning_rate_D': -1.7054424155945522, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.9585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  20 training error:  tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  30 training error:  tensor(0.9107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  40 training error:  tensor(0.8877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  50 training error:  tensor(0.7334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  60 training error:  tensor(0.6029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  70 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  80 training error:  tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
	 epoch  90 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.38525390625
Memory cached:  78.0
[I 2023-12-04 01:05:35,627] Trial 6 finished with value: 0.20348255336284637 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.2459191822704385, 'log_learning_rate_D': -1.7054424155945522, 'training_batch_size': 10, 'training_p': 2}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  46.2993643283844
Memory status after this trial: 
Memory allocated:  126.81396484375
Memory cached:  130.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.4707066888032694, 'log_learning_rate_D': -3.2865836826482298, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  74.0
	 epoch  10 training error:  tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.33447265625
Memory cached:  76.0
[I 2023-12-04 01:06:10,649] Trial 7 finished with value: 0.07220136374235153 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.4707066888032694, 'log_learning_rate_D': -3.2865836826482298, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 0.07213948667049408.
Time for this trial:  34.92829775810242
Memory status after this trial: 
Memory allocated:  102.6884765625
Memory cached:  104.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.5911930339193, 'log_learning_rate_D': -2.9343288073308655, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.97412109375
Memory cached:  76.0
[I 2023-12-04 01:07:29,537] Trial 8 finished with value: 0.011548519134521484 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.5911930339193, 'log_learning_rate_D': -2.9343288073308655, 'training_batch_size': 6, 'training_p': 4}. Best is trial 8 with value: 0.011548519134521484.
res:  tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  78.77534699440002
Memory status after this trial: 
Memory allocated:  40.9404296875
Memory cached:  104.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -1.3659409780423175, 'log_learning_rate_D': -1.6828965122374933, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.40673828125
Memory cached:  106.0
	 epoch  10 training error:  tensor(10.4323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.40673828125
Memory cached:  106.0
[W 2023-12-04 01:07:36,314] Trial 9 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -1.3659409780423175, 'log_learning_rate_D': -1.6828965122374933, 'training_batch_size': 11, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:07:36,315] Trial 9 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.6716203689575195
Memory status after this trial: 
Memory allocated:  127.71240234375
Memory cached:  132.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.765643268767457, 'log_learning_rate_D': -1.9089910131727073, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.51806640625
Memory cached:  126.0
[W 2023-12-04 01:07:39,837] Trial 10 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.765643268767457, 'log_learning_rate_D': -1.9089910131727073, 'training_batch_size': 12, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:07:39,838] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.397595167160034
Memory status after this trial: 
Memory allocated:  132.2548828125
Memory cached:  148.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.590713202281071, 'log_learning_rate_D': -3.1530720619895027, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  10 training error:  tensor(0.6501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.13720703125
Memory cached:  106.0
[I 2023-12-04 01:08:23,684] Trial 11 finished with value: 0.09349450469017029 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.590713202281071, 'log_learning_rate_D': -3.1530720619895027, 'training_batch_size': 12, 'training_p': 7}. Best is trial 8 with value: 0.011548519134521484.
Time for this trial:  43.730111598968506
Memory status after this trial: 
Memory allocated:  93.900390625
Memory cached:  106.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.254952492454951, 'log_learning_rate_D': -1.5200387733293304, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.79541015625
Memory cached:  106.0
[W 2023-12-04 01:08:27,792] Trial 12 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.254952492454951, 'log_learning_rate_D': -1.5200387733293304, 'training_batch_size': 7, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:08:27,792] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.009156227111816
Memory status after this trial: 
Memory allocated:  111.1865234375
Memory cached:  116.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.442249713509847, 'log_learning_rate_D': -4.520035594878997, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  10 training error:  tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.8993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.8626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.8280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.8049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.7763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.63525390625
Memory cached:  106.0
[I 2023-12-04 01:09:14,215] Trial 13 finished with value: 0.7416028380393982 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.442249713509847, 'log_learning_rate_D': -4.520035594878997, 'training_batch_size': 12, 'training_p': 2}. Best is trial 8 with value: 0.011548519134521484.
Time for this trial:  46.305018186569214
Memory status after this trial: 
Memory allocated:  82.31689453125
Memory cached:  106.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.894548719558935, 'log_learning_rate_D': -1.0500844450364402, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.67822265625
Memory cached:  106.0
[W 2023-12-04 01:09:16,248] Trial 14 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.894548719558935, 'log_learning_rate_D': -1.0500844450364402, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:09:16,249] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8483397960662842
Memory status after this trial: 
Memory allocated:  159.64208984375
Memory cached:  166.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.951462501449184, 'log_learning_rate_D': -1.048471952535062, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.99658203125
Memory cached:  124.0
[W 2023-12-04 01:09:18,312] Trial 15 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.951462501449184, 'log_learning_rate_D': -1.048471952535062, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:09:18,313] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8785254955291748
Memory status after this trial: 
Memory allocated:  167.0712890625
Memory cached:  184.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.91373344933208, 'log_learning_rate_D': -1.1281588578055546, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.00244140625
Memory cached:  124.0
[W 2023-12-04 01:09:20,358] Trial 16 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.91373344933208, 'log_learning_rate_D': -1.1281588578055546, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:09:20,359] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8657622337341309
Memory status after this trial: 
Memory allocated:  167.3671875
Memory cached:  186.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.97747473295086, 'log_learning_rate_D': -1.2351782367873012, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.99658203125
Memory cached:  124.0
[W 2023-12-04 01:09:22,498] Trial 17 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.97747473295086, 'log_learning_rate_D': -1.2351782367873012, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:09:22,499] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9518218040466309
Memory status after this trial: 
Memory allocated:  167.0712890625
Memory cached:  184.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.5546763413974265, 'log_learning_rate_D': -1.1460417419241509, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.99658203125
Memory cached:  124.0
[W 2023-12-04 01:09:24,610] Trial 18 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.5546763413974265, 'log_learning_rate_D': -1.1460417419241509, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:09:24,611] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9103896617889404
Memory status after this trial: 
Memory allocated:  167.0712890625
Memory cached:  184.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.851514764855109, 'log_learning_rate_D': -2.301790109833086, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  10 training error:  tensor(1.0148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  20 training error:  tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.9950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.9726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.9406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.9023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  80 training error:  tensor(17.2990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
	 epoch  90 training error:  tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.23876953125
Memory cached:  106.0
[I 2023-12-04 01:10:16,772] Trial 19 finished with value: 0.9036795496940613 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.851514764855109, 'log_learning_rate_D': -2.301790109833086, 'training_batch_size': 9, 'training_p': 5}. Best is trial 8 with value: 0.011548519134521484.
Time for this trial:  51.96863341331482
Memory status after this trial: 
Memory allocated:  136.232421875
Memory cached:  140.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.7444702958459306, 'log_learning_rate_D': -1.0550472717573398, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
[W 2023-12-04 01:10:18,631] Trial 20 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.7444702958459306, 'log_learning_rate_D': -1.0550472717573398, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:10:18,632] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6957287788391113
Memory status after this trial: 
Memory allocated:  157.7509765625
Memory cached:  190.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.7910143554576035, 'log_learning_rate_D': -3.5833872642619635, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.12060546875
Memory cached:  144.0
[I 2023-12-04 01:11:29,889] Trial 21 finished with value: 0.010489757172763348 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.7910143554576035, 'log_learning_rate_D': -3.5833872642619635, 'training_batch_size': 6, 'training_p': 6}. Best is trial 21 with value: 0.010489757172763348.
res:  tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  71.08236002922058
Memory status after this trial: 
Memory allocated:  116.81103515625
Memory cached:  184.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6666833266859626, 'log_learning_rate_D': -1.0010641866232626, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.2509765625
Memory cached:  186.0
[W 2023-12-04 01:11:32,233] Trial 22 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6666833266859626, 'log_learning_rate_D': -1.0010641866232626, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:11:32,234] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1499273777008057
Memory status after this trial: 
Memory allocated:  224.5498046875
Memory cached:  254.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.506857138102358, 'log_learning_rate_D': -1.193447963181613, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0244140625
Memory cached:  186.0
[W 2023-12-04 01:11:34,574] Trial 23 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.506857138102358, 'log_learning_rate_D': -1.193447963181613, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:11:34,575] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1212410926818848
Memory status after this trial: 
Memory allocated:  254.7685546875
Memory cached:  286.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6650730822145032, 'log_learning_rate_D': -1.107136531468658, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0244140625
Memory cached:  186.0
[W 2023-12-04 01:11:36,870] Trial 24 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.6650730822145032, 'log_learning_rate_D': -1.107136531468658, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:11:36,872] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0645885467529297
Memory status after this trial: 
Memory allocated:  254.7685546875
Memory cached:  286.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.729931904300838, 'log_learning_rate_D': -3.7838328382894963, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  10 training error:  tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  20 training error:  tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  30 training error:  tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  40 training error:  tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  50 training error:  tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  60 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  70 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  80 training error:  tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
	 epoch  90 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.1376953125
Memory cached:  188.0
[I 2023-12-04 01:13:09,214] Trial 25 finished with value: 0.017070060595870018 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.729931904300838, 'log_learning_rate_D': -3.7838328382894963, 'training_batch_size': 6, 'training_p': 5}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  92.12333822250366
Memory status after this trial: 
Memory allocated:  242.8388671875
Memory cached:  274.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.9421540155540358, 'log_learning_rate_D': -1.2370772837879591, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.97265625
Memory cached:  186.0
[W 2023-12-04 01:13:10,798] Trial 26 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.9421540155540358, 'log_learning_rate_D': -1.2370772837879591, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:13:10,799] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.4251914024353027
Memory status after this trial: 
Memory allocated:  191.40966796875
Memory cached:  216.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.750526792571157, 'log_learning_rate_D': -1.0900770472044599, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  186.0
[W 2023-12-04 01:13:12,402] Trial 27 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.750526792571157, 'log_learning_rate_D': -1.0900770472044599, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:13:12,403] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.434528112411499
Memory status after this trial: 
Memory allocated:  196.18115234375
Memory cached:  220.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.803972289226032, 'log_learning_rate_D': -1.018074507130816, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.98046875
Memory cached:  186.0
[W 2023-12-04 01:13:14,042] Trial 28 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.803972289226032, 'log_learning_rate_D': -1.018074507130816, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:13:14,043] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.4885334968566895
Memory status after this trial: 
Memory allocated:  204.10888671875
Memory cached:  222.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7587884820170974, 'log_learning_rate_D': -2.7742129541530547, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  20 training error:  tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  30 training error:  tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  40 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  50 training error:  tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  60 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  70 training error:  tensor(0.0245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  80 training error:  tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
	 epoch  90 training error:  tensor(0.0284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7265625
Memory cached:  188.0
[I 2023-12-04 01:13:55,618] Trial 29 finished with value: 0.02702660672366619 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7587884820170974, 'log_learning_rate_D': -2.7742129541530547, 'training_batch_size': 8, 'training_p': 6}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  41.40900683403015
Memory status after this trial: 
Memory allocated:  196.18115234375
Memory cached:  220.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.375491087077653, 'log_learning_rate_D': -1.0724852308773132, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.1923828125
Memory cached:  184.0
[W 2023-12-04 01:13:57,225] Trial 30 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.375491087077653, 'log_learning_rate_D': -1.0724852308773132, 'training_batch_size': 6, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:13:57,226] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.4463729858398438
Memory status after this trial: 
Memory allocated:  147.9228515625
Memory cached:  184.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.2776329812924216, 'log_learning_rate_D': -4.894832092760268, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  20 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  30 training error:  tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.9443359375
Memory cached:  186.0
[I 2023-12-04 01:15:00,740] Trial 31 finished with value: 0.09078036993741989 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.2776329812924216, 'log_learning_rate_D': -4.894832092760268, 'training_batch_size': 6, 'training_p': 4}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  63.34241008758545
Memory status after this trial: 
Memory allocated:  147.07373046875
Memory cached:  186.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.0154033537918883, 'log_learning_rate_D': -1.156766175330033, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.19140625
Memory cached:  186.0
[W 2023-12-04 01:15:02,219] Trial 32 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.0154033537918883, 'log_learning_rate_D': -1.156766175330033, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:15:02,220] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.3256065845489502
Memory status after this trial: 
Memory allocated:  149.26318359375
Memory cached:  186.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1690084826328677, 'log_learning_rate_D': -1.023330646042885, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.267578125
Memory cached:  186.0
[W 2023-12-04 01:15:03,774] Trial 33 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1690084826328677, 'log_learning_rate_D': -1.023330646042885, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:15:03,775] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.4005262851715088
Memory status after this trial: 
Memory allocated:  154.42822265625
Memory cached:  186.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.1167367898586136, 'log_learning_rate_D': -3.6835179203721973, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  20 training error:  tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  30 training error:  tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  40 training error:  tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  50 training error:  tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  60 training error:  tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  70 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  80 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
	 epoch  90 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.458984375
Memory cached:  188.0
[I 2023-12-04 01:15:43,309] Trial 34 finished with value: 0.022052593529224396 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.1167367898586136, 'log_learning_rate_D': -3.6835179203721973, 'training_batch_size': 8, 'training_p': 4}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  39.376545429229736
Memory status after this trial: 
Memory allocated:  158.91845703125
Memory cached:  188.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.1383904504141378, 'log_learning_rate_D': -1.4330470684057897, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.580078125
Memory cached:  188.0
[W 2023-12-04 01:15:45,887] Trial 35 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.1383904504141378, 'log_learning_rate_D': -1.4330470684057897, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:15:45,887] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.3825950622558594
Memory status after this trial: 
Memory allocated:  207.8447265625
Memory cached:  240.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0354647093624987, 'log_learning_rate_D': -1.013934224688522, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.580078125
Memory cached:  188.0
[W 2023-12-04 01:15:47,990] Trial 36 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0354647093624987, 'log_learning_rate_D': -1.013934224688522, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:15:47,991] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9081218242645264
Memory status after this trial: 
Memory allocated:  207.8447265625
Memory cached:  240.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.247675891138526, 'log_learning_rate_D': -2.9916029629150733, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  188.0
	 epoch  10 training error:  tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  20 training error:  tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  30 training error:  tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  40 training error:  tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  50 training error:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  60 training error:  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  70 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  80 training error:  tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
	 epoch  90 training error:  tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.515625
Memory cached:  190.0
[I 2023-12-04 01:16:42,003] Trial 37 finished with value: 0.15828803181648254 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.247675891138526, 'log_learning_rate_D': -2.9916029629150733, 'training_batch_size': 8, 'training_p': 6}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  53.807984828948975
Memory status after this trial: 
Memory allocated:  207.51953125
Memory cached:  240.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.489761189780209, 'log_learning_rate_D': -1.43712954526307, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.9203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.4267578125
Memory cached:  186.0
[W 2023-12-04 01:16:44,079] Trial 38 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.489761189780209, 'log_learning_rate_D': -1.43712954526307, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:44,079] Trial 38 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8847134113311768
Memory status after this trial: 
Memory allocated:  247.779296875
Memory cached:  272.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.984589389377726, 'log_learning_rate_D': -1.107269501346285, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.0791015625
Memory cached:  186.0
[W 2023-12-04 01:16:46,282] Trial 39 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.984589389377726, 'log_learning_rate_D': -1.107269501346285, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:46,283] Trial 39 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.042539119720459
Memory status after this trial: 
Memory allocated:  179.09765625
Memory cached:  208.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.3456061352180173, 'log_learning_rate_D': -1.1833213221421706, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.4850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.4873046875
Memory cached:  188.0
[W 2023-12-04 01:16:48,354] Trial 40 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.3456061352180173, 'log_learning_rate_D': -1.1833213221421706, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:48,354] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.879159688949585
Memory status after this trial: 
Memory allocated:  242.958984375
Memory cached:  266.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.2495294028813975, 'log_learning_rate_D': -1.1327004155747864, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(2.9653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.4267578125
Memory cached:  186.0
[W 2023-12-04 01:16:50,427] Trial 41 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.2495294028813975, 'log_learning_rate_D': -1.1327004155747864, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:50,428] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8764715194702148
Memory status after this trial: 
Memory allocated:  247.779296875
Memory cached:  272.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.08704340336839, 'log_learning_rate_D': -1.0757185951849308, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.4873046875
Memory cached:  188.0
[W 2023-12-04 01:16:52,561] Trial 42 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.08704340336839, 'log_learning_rate_D': -1.0757185951849308, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:52,562] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.936258316040039
Memory status after this trial: 
Memory allocated:  242.958984375
Memory cached:  266.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0997190462101365, 'log_learning_rate_D': -1.3651485178323912, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(2.6893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9091796875
Memory cached:  188.0
[W 2023-12-04 01:16:54,672] Trial 43 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0997190462101365, 'log_learning_rate_D': -1.3651485178323912, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:54,673] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9237723350524902
Memory status after this trial: 
Memory allocated:  244.18505859375
Memory cached:  268.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0724400435546109, 'log_learning_rate_D': -1.2748556332419771, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(6.8462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.4267578125
Memory cached:  186.0
[W 2023-12-04 01:16:56,740] Trial 44 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0724400435546109, 'log_learning_rate_D': -1.2748556332419771, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:56,741] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8815772533416748
Memory status after this trial: 
Memory allocated:  247.779296875
Memory cached:  272.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.479436615039615, 'log_learning_rate_D': -1.0108692520932574, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.4267578125
Memory cached:  186.0
[W 2023-12-04 01:16:58,817] Trial 45 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.479436615039615, 'log_learning_rate_D': -1.0108692520932574, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:16:58,818] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.887939214706421
Memory status after this trial: 
Memory allocated:  247.779296875
Memory cached:  272.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0421559675089633, 'log_learning_rate_D': -1.1932396250188533, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(6.6274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.2607421875
Memory cached:  190.0
[W 2023-12-04 01:17:00,907] Trial 46 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.0421559675089633, 'log_learning_rate_D': -1.1932396250188533, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:17:00,907] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8985466957092285
Memory status after this trial: 
Memory allocated:  236.81982421875
Memory cached:  262.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.147056300062923, 'log_learning_rate_D': -3.8909344065260383, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(5.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  10 training error:  tensor(11.1068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  20 training error:  tensor(3.4409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  30 training error:  tensor(5.3110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  40 training error:  tensor(1.6802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  50 training error:  tensor(3.6318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  60 training error:  tensor(1.2627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  70 training error:  tensor(2.6513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
	 epoch  90 training error:  tensor(1.8867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8486328125
Memory cached:  186.0
[I 2023-12-04 01:18:21,634] Trial 47 finished with value: 0.5150060057640076 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.147056300062923, 'log_learning_rate_D': -3.8909344065260383, 'training_batch_size': 6, 'training_p': 6}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  80.53290820121765
Memory status after this trial: 
Memory allocated:  249.00537109375
Memory cached:  274.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2336528219201908, 'log_learning_rate_D': -3.4342899575202788, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  20 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  30 training error:  tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.826171875
Memory cached:  186.0
[I 2023-12-04 01:19:10,457] Trial 48 finished with value: 0.07422485202550888 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2336528219201908, 'log_learning_rate_D': -3.4342899575202788, 'training_batch_size': 7, 'training_p': 3}. Best is trial 21 with value: 0.010489757172763348.
Time for this trial:  48.64277744293213
Memory status after this trial: 
Memory allocated:  160.71435546875
Memory cached:  190.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.849727554313486, 'log_learning_rate_D': -2.6408128324420943, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  188.0
	 epoch  10 training error:  tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  20 training error:  tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  30 training error:  tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  40 training error:  tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  50 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  60 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  70 training error:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  80 training error:  tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
	 epoch  90 training error:  tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.0390625
Memory cached:  190.0
[I 2023-12-04 01:20:00,073] Trial 49 finished with value: 0.01700778491795063 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.849727554313486, 'log_learning_rate_D': -2.6408128324420943, 'training_batch_size': 10, 'training_p': 5}. Best is trial 21 with value: 0.010489757172763348.
[I 2023-12-04 01:20:00,096] A new study created in memory with name: no-name-b37e5946-5d5f-476f-b4f4-e8215abf1bf0
Time for this trial:  49.4384241104126
Memory status after this trial: 
Memory allocated:  198.36474609375
Memory cached:  230.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.095924546862624, 'log_learning_rate_D': -3.430309268052161, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6513671875
Memory cached:  32.0
[I 2023-12-04 01:21:13,660] Trial 0 finished with value: 0.027389800176024437 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.095924546862624, 'log_learning_rate_D': -3.430309268052161, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 0.027389800176024437.
res:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  73.46207046508789
Memory status after this trial: 
Memory allocated:  88.85205078125
Memory cached:  108.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -1.4353401854029602, 'log_learning_rate_D': -4.589498170716842, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.8735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.9296875
Memory cached:  118.0
[I 2023-12-04 01:22:00,177] Trial 1 finished with value: 0.6612984538078308 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -1.4353401854029602, 'log_learning_rate_D': -4.589498170716842, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  46.42004990577698
Memory status after this trial: 
Memory allocated:  193.9873046875
Memory cached:  212.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.3211702038251278, 'log_learning_rate_D': -3.2159213419541794, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  114.0
	 epoch  10 training error:  tensor(30.5954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  20 training error:  tensor(3.5018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  30 training error:  tensor(12.3519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  40 training error:  tensor(21.9626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  50 training error:  tensor(27.6770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  60 training error:  tensor(21.2715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  70 training error:  tensor(12.9871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  80 training error:  tensor(3.5997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
	 epoch  90 training error:  tensor(2.9031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.986328125
Memory cached:  116.0
[I 2023-12-04 01:22:50,323] Trial 2 finished with value: 0.9720637202262878 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.3211702038251278, 'log_learning_rate_D': -3.2159213419541794, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  50.03109908103943
Memory status after this trial: 
Memory allocated:  159.43798828125
Memory cached:  170.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.7103408828179267, 'log_learning_rate_D': -3.2025367949447805, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.146484375
Memory cached:  120.0
[I 2023-12-04 01:23:51,801] Trial 3 finished with value: 0.07413359731435776 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.7103408828179267, 'log_learning_rate_D': -3.2025367949447805, 'training_batch_size': 12, 'training_p': 8}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  61.356847524642944
Memory status after this trial: 
Memory allocated:  212.830078125
Memory cached:  226.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.153100660654964, 'log_learning_rate_D': -2.1755857986350167, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  110.0
	 epoch  10 training error:  tensor(0.8321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.7038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.576171875
Memory cached:  114.0
[W 2023-12-04 01:24:32,454] Trial 4 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.153100660654964, 'log_learning_rate_D': -2.1755857986350167, 'training_batch_size': 7, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 01:24:32,455] Trial 4 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  40.53358554840088
Memory status after this trial: 
Memory allocated:  146.15673828125
Memory cached:  164.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8032617098848243, 'log_learning_rate_D': -4.617265110587931, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.4296875
Memory cached:  120.0
[I 2023-12-04 01:25:15,615] Trial 5 finished with value: 0.09339424222707748 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8032617098848243, 'log_learning_rate_D': -4.617265110587931, 'training_batch_size': 10, 'training_p': 7}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  43.04471516609192
Memory status after this trial: 
Memory allocated:  166.1484375
Memory cached:  182.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2813682275069618, 'log_learning_rate_D': -4.87188112512266, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.5286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.283203125
Memory cached:  114.0
[I 2023-12-04 01:26:00,800] Trial 6 finished with value: 0.0947946235537529 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2813682275069618, 'log_learning_rate_D': -4.87188112512266, 'training_batch_size': 9, 'training_p': 2}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  45.074811697006226
Memory status after this trial: 
Memory allocated:  130.541015625
Memory cached:  148.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.830668702315605, 'log_learning_rate_D': -2.322341437047149, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.6484375
Memory cached:  118.0
[I 2023-12-04 01:26:45,947] Trial 7 finished with value: 0.06463190168142319 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.830668702315605, 'log_learning_rate_D': -2.322341437047149, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  45.0490448474884
Memory status after this trial: 
Memory allocated:  132.61279296875
Memory cached:  152.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.498234478015943, 'log_learning_rate_D': -1.2568162878281344, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  10 training error:  tensor(1.1752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.6674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.1689453125
Memory cached:  116.0
[I 2023-12-04 01:27:39,132] Trial 8 finished with value: 0.17079024016857147 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.498234478015943, 'log_learning_rate_D': -1.2568162878281344, 'training_batch_size': 6, 'training_p': 8}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  53.08622694015503
Memory status after this trial: 
Memory allocated:  132.51171875
Memory cached:  152.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.34751214722619, 'log_learning_rate_D': -4.235941414370801, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.7172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.212890625
Memory cached:  114.0
[I 2023-12-04 01:28:20,852] Trial 9 finished with value: 0.11845576763153076 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.34751214722619, 'log_learning_rate_D': -4.235941414370801, 'training_batch_size': 9, 'training_p': 8}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  41.6270534992218
Memory status after this trial: 
Memory allocated:  136.0859375
Memory cached:  154.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.89506608387948, 'log_learning_rate_D': -3.1109194352161498, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.005859375
Memory cached:  118.0
[I 2023-12-04 01:29:04,385] Trial 10 finished with value: 0.033093925565481186 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.89506608387948, 'log_learning_rate_D': -3.1109194352161498, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  43.43871831893921
Memory status after this trial: 
Memory allocated:  162.732421875
Memory cached:  184.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.807167938889431, 'log_learning_rate_D': -3.898331207491409, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.7234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.1279296875
Memory cached:  118.0
[I 2023-12-04 01:30:29,607] Trial 11 finished with value: 0.07137628644704819 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.807167938889431, 'log_learning_rate_D': -3.898331207491409, 'training_batch_size': 6, 'training_p': 5}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  85.03310799598694
Memory status after this trial: 
Memory allocated:  222.9365234375
Memory cached:  234.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.715337338531186, 'log_learning_rate_D': -3.4940823375950454, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  20 training error:  tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  30 training error:  tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  40 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  50 training error:  tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  60 training error:  tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  70 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  80 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
	 epoch  90 training error:  tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.455078125
Memory cached:  126.0
[I 2023-12-04 01:31:19,193] Trial 12 finished with value: 0.03372955694794655 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.715337338531186, 'log_learning_rate_D': -3.4940823375950454, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  49.42175364494324
Memory status after this trial: 
Memory allocated:  199.87841796875
Memory cached:  218.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.793175872560383, 'log_learning_rate_D': -2.6221679883526674, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.5769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.595703125
Memory cached:  114.0
[I 2023-12-04 01:31:52,280] Trial 13 finished with value: 0.1546429544687271 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.793175872560383, 'log_learning_rate_D': -2.6221679883526674, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  32.932647705078125
Memory status after this trial: 
Memory allocated:  125.27197265625
Memory cached:  144.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.243231822920767, 'log_learning_rate_D': -3.7937242146139845, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.7661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.607421875
Memory cached:  120.0
[I 2023-12-04 01:32:43,121] Trial 14 finished with value: 0.07803433388471603 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.243231822920767, 'log_learning_rate_D': -3.7937242146139845, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  50.6632616519928
Memory status after this trial: 
Memory allocated:  184.3740234375
Memory cached:  206.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.8513106559919406, 'log_learning_rate_D': -2.720254496799703, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.6983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.4377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.748046875
Memory cached:  122.0
[I 2023-12-04 01:33:24,484] Trial 15 finished with value: 0.12236650288105011 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.8513106559919406, 'log_learning_rate_D': -2.720254496799703, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  41.19844603538513
Memory status after this trial: 
Memory allocated:  157.49462890625
Memory cached:  178.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.3505978992267798, 'log_learning_rate_D': -2.078930800550485, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.7828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.6754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.697265625
Memory cached:  114.0
[I 2023-12-04 01:34:07,975] Trial 16 finished with value: 0.13531368970870972 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.3505978992267798, 'log_learning_rate_D': -2.078930800550485, 'training_batch_size': 8, 'training_p': 6}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  43.32391595840454
Memory status after this trial: 
Memory allocated:  132.8193359375
Memory cached:  152.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.241204612623746, 'log_learning_rate_D': -3.6600816967050482, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  10 training error:  tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.3583984375
Memory cached:  122.0
[I 2023-12-04 01:35:26,831] Trial 17 finished with value: 0.07869511097669601 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.241204612623746, 'log_learning_rate_D': -3.6600816967050482, 'training_batch_size': 6, 'training_p': 4}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  78.65388894081116
Memory status after this trial: 
Memory allocated:  166.88916015625
Memory cached:  190.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.163435948132439, 'log_learning_rate_D': -2.965715385572291, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.7975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.7151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.3823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.541015625
Memory cached:  118.0
[I 2023-12-04 01:36:16,758] Trial 18 finished with value: 0.12331070005893707 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.163435948132439, 'log_learning_rate_D': -2.965715385572291, 'training_batch_size': 7, 'training_p': 6}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  49.742363691329956
Memory status after this trial: 
Memory allocated:  175.56005859375
Memory cached:  194.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.683416379554625, 'log_learning_rate_D': -4.024150798592354, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.9685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.9256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.8794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.8266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.7628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.6832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.921875
Memory cached:  116.0
[I 2023-12-04 01:37:04,003] Trial 19 finished with value: 0.2697691321372986 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -4.683416379554625, 'log_learning_rate_D': -4.024150798592354, 'training_batch_size': 10, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  47.07539653778076
Memory status after this trial: 
Memory allocated:  137.8564453125
Memory cached:  158.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.885129299281389, 'log_learning_rate_D': -3.3133987145912105, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.9682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.9317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.8458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.7239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.6547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.5976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.560546875
Memory cached:  120.0
[I 2023-12-04 01:37:50,603] Trial 20 finished with value: 0.2770797908306122 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.885129299281389, 'log_learning_rate_D': -3.3133987145912105, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  46.434130907058716
Memory status after this trial: 
Memory allocated:  153.69873046875
Memory cached:  176.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.157379310095664, 'log_learning_rate_D': -3.4837742367063766, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.8068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  90.3779296875
Memory cached:  116.0
[I 2023-12-04 01:38:55,773] Trial 21 finished with value: 0.12002182006835938 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.157379310095664, 'log_learning_rate_D': -3.4837742367063766, 'training_batch_size': 6, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  65.01146817207336
Memory status after this trial: 
Memory allocated:  146.001953125
Memory cached:  164.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.58044449188362, 'log_learning_rate_D': -3.5240349241412505, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  122.0
	 epoch  10 training error:  tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  20 training error:  tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  30 training error:  tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  40 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  50 training error:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  60 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  70 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  80 training error:  tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
	 epoch  90 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.44921875
Memory cached:  126.0
[I 2023-12-04 01:39:42,945] Trial 22 finished with value: 0.05385564640164375 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.58044449188362, 'log_learning_rate_D': -3.5240349241412505, 'training_batch_size': 7, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  46.99409365653992
Memory status after this trial: 
Memory allocated:  199.4404296875
Memory cached:  218.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.8965994209597126, 'log_learning_rate_D': -2.9776690997797006, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  124.0
	 epoch  10 training error:  tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  20 training error:  tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  30 training error:  tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  40 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  50 training error:  tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  60 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  70 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  80 training error:  tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
	 epoch  90 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.50390625
Memory cached:  128.0
[I 2023-12-04 01:40:33,113] Trial 23 finished with value: 0.09472399204969406 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.8965994209597126, 'log_learning_rate_D': -2.9776690997797006, 'training_batch_size': 7, 'training_p': 2}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  49.98740482330322
Memory status after this trial: 
Memory allocated:  195.8251953125
Memory cached:  212.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2447155507165526, 'log_learning_rate_D': -4.240046069047027, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.6796875
Memory cached:  120.0
[I 2023-12-04 01:41:14,520] Trial 24 finished with value: 0.06185202673077583 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2447155507165526, 'log_learning_rate_D': -4.240046069047027, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 0.027389800176024437.
Time for this trial:  41.23696160316467
Memory status after this trial: 
Memory allocated:  164.29443359375
Memory cached:  186.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5937363656895593, 'log_learning_rate_D': -3.588813678405227, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  128.0
	 epoch  10 training error:  tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  105.4169921875
Memory cached:  130.0
[I 2023-12-04 01:42:29,547] Trial 25 finished with value: 0.027072925120592117 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.5937363656895593, 'log_learning_rate_D': -3.588813678405227, 'training_batch_size': 6, 'training_p': 6}. Best is trial 25 with value: 0.027072925120592117.
res:  tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  74.84158182144165
Memory status after this trial: 
Memory allocated:  92.3056640625
Memory cached:  178.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.186926871449069, 'log_learning_rate_D': -3.7393274867146866, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  10 training error:  tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  20 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  30 training error:  tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  40 training error:  tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  50 training error:  tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  60 training error:  tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  70 training error:  tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  80 training error:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
	 epoch  90 training error:  tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.34521484375
Memory cached:  222.0
[I 2023-12-04 01:43:59,123] Trial 26 finished with value: 0.08707144111394882 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.186926871449069, 'log_learning_rate_D': -3.7393274867146866, 'training_batch_size': 6, 'training_p': 6}. Best is trial 25 with value: 0.027072925120592117.
Time for this trial:  89.40080690383911
Memory status after this trial: 
Memory allocated:  247.8681640625
Memory cached:  264.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.489269793092413, 'log_learning_rate_D': -3.1306213384032966, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.0232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.0255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.0220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.0235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.11669921875
Memory cached:  180.0
[I 2023-12-04 01:45:04,770] Trial 27 finished with value: 0.013895528391003609 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.489269793092413, 'log_learning_rate_D': -3.1306213384032966, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.013895528391003609.
res:  tensor(0.0139, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  65.46549105644226
Memory status after this trial: 
Memory allocated:  67.9501953125
Memory cached:  142.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.5633096849899415, 'log_learning_rate_D': -4.064369316678192, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.16162109375
Memory cached:  146.0
[I 2023-12-04 01:46:22,529] Trial 28 finished with value: 0.05197066068649292 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.5633096849899415, 'log_learning_rate_D': -4.064369316678192, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  77.58531212806702
Memory status after this trial: 
Memory allocated:  149.44384765625
Memory cached:  154.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.037021347824453, 'log_learning_rate_D': -3.4125160287639846, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.31591796875
Memory cached:  144.0
[I 2023-12-04 01:47:38,487] Trial 29 finished with value: 0.12312012165784836 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.037021347824453, 'log_learning_rate_D': -3.4125160287639846, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  75.76046514511108
Memory status after this trial: 
Memory allocated:  123.646484375
Memory cached:  144.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.477106588337685, 'log_learning_rate_D': -4.374610581060875, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.7379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.3740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  82.74658203125
Memory cached:  162.0
[I 2023-12-04 01:48:22,048] Trial 30 finished with value: 0.15154282748699188 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.477106588337685, 'log_learning_rate_D': -4.374610581060875, 'training_batch_size': 7, 'training_p': 5}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  43.40300631523132
Memory status after this trial: 
Memory allocated:  154.078125
Memory cached:  174.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.4392458157971553, 'log_learning_rate_D': -3.785597924787882, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.6635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.47802734375
Memory cached:  142.0
[I 2023-12-04 01:49:21,936] Trial 31 finished with value: 0.029382336884737015 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.4392458157971553, 'log_learning_rate_D': -3.785597924787882, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  59.715614318847656
Memory status after this trial: 
Memory allocated:  95.03662109375
Memory cached:  142.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5325791245674094, 'log_learning_rate_D': -3.6895841306156267, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.7593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.4059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.44677734375
Memory cached:  142.0
[I 2023-12-04 01:50:21,566] Trial 32 finished with value: 0.11396250873804092 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5325791245674094, 'log_learning_rate_D': -3.6895841306156267, 'training_batch_size': 6, 'training_p': 6}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  59.458685874938965
Memory status after this trial: 
Memory allocated:  94.72802734375
Memory cached:  142.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2062559778234303, 'log_learning_rate_D': -3.8553806820562864, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.7288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.20849609375
Memory cached:  142.0
[I 2023-12-04 01:51:19,982] Trial 33 finished with value: 0.10814981907606125 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2062559778234303, 'log_learning_rate_D': -3.8553806820562864, 'training_batch_size': 6, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  58.24807596206665
Memory status after this trial: 
Memory allocated:  92.39990234375
Memory cached:  142.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.9114903114578103, 'log_learning_rate_D': -3.3054604632517957, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.8745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.7153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.94775390625
Memory cached:  144.0
[I 2023-12-04 01:52:02,357] Trial 34 finished with value: 0.11673145741224289 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.9114903114578103, 'log_learning_rate_D': -3.3054604632517957, 'training_batch_size': 12, 'training_p': 6}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  42.19991111755371
Memory status after this trial: 
Memory allocated:  105.55712890625
Memory cached:  144.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.0882280542505476, 'log_learning_rate_D': -3.253991312785933, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.30712890625
Memory cached:  146.0
[I 2023-12-04 01:52:41,753] Trial 35 finished with value: 0.022302934899926186 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.0882280542505476, 'log_learning_rate_D': -3.253991312785933, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  39.23304057121277
Memory status after this trial: 
Memory allocated:  93.51806640625
Memory cached:  146.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.0091372603086057, 'log_learning_rate_D': -3.0520306042973417, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  72.08837890625
Memory cached:  144.0
[I 2023-12-04 01:53:24,913] Trial 36 finished with value: 0.02815898135304451 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.0091372603086057, 'log_learning_rate_D': -3.0520306042973417, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  42.985300064086914
Memory status after this trial: 
Memory allocated:  122.77001953125
Memory cached:  144.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.7221316496487167, 'log_learning_rate_D': -3.2423500600896222, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.8345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.96533203125
Memory cached:  144.0
[I 2023-12-04 01:54:04,691] Trial 37 finished with value: 0.10496330261230469 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.7221316496487167, 'log_learning_rate_D': -3.2423500600896222, 'training_batch_size': 10, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  39.59122848510742
Memory status after this trial: 
Memory allocated:  95.029296875
Memory cached:  144.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.5544836547306025, 'log_learning_rate_D': -2.856849037733861, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.6579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.68212890625
Memory cached:  166.0
[I 2023-12-04 01:55:00,728] Trial 38 finished with value: 0.06676354259252548 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.5544836547306025, 'log_learning_rate_D': -2.856849037733861, 'training_batch_size': 7, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  55.81327533721924
Memory status after this trial: 
Memory allocated:  194.89990234375
Memory cached:  212.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.1558972140444927, 'log_learning_rate_D': -3.132925915054385, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.78564453125
Memory cached:  146.0
[I 2023-12-04 01:55:49,408] Trial 39 finished with value: 0.0666266605257988 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.1558972140444927, 'log_learning_rate_D': -3.132925915054385, 'training_batch_size': 9, 'training_p': 5}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  48.47796034812927
Memory status after this trial: 
Memory allocated:  108.73486328125
Memory cached:  146.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.0416914188150956, 'log_learning_rate_D': -4.967274024164242, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.70947265625
Memory cached:  144.0
[I 2023-12-04 01:56:33,154] Trial 40 finished with value: 0.11683261394500732 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.0416914188150956, 'log_learning_rate_D': -4.967274024164242, 'training_batch_size': 11, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  43.563148498535156
Memory status after this trial: 
Memory allocated:  103.81396484375
Memory cached:  144.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.3774345527346177, 'log_learning_rate_D': -3.5848542713179077, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.0186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.0238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
[I 2023-12-04 01:57:47,043] Trial 41 finished with value: 0.01643270067870617 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.3774345527346177, 'log_learning_rate_D': -3.5848542713179077, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  73.69492626190186
Memory status after this trial: 
Memory allocated:  158.74951171875
Memory cached:  174.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.3263543013861674, 'log_learning_rate_D': -3.5392402729959445, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.0242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.0254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
[I 2023-12-04 01:59:00,459] Trial 42 finished with value: 0.024049028754234314 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.3263543013861674, 'log_learning_rate_D': -3.5392402729959445, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  73.2369556427002
Memory status after this trial: 
Memory allocated:  158.74951171875
Memory cached:  174.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.303693373120036, 'log_learning_rate_D': -3.487286631122461, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.0201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.52880859375
Memory cached:  164.0
[I 2023-12-04 02:00:14,768] Trial 43 finished with value: 0.017684180289506912 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.303693373120036, 'log_learning_rate_D': -3.487286631122461, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  74.13059115409851
Memory status after this trial: 
Memory allocated:  158.74951171875
Memory cached:  174.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.404921740978992, 'log_learning_rate_D': -3.337211656339163, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.26513671875
Memory cached:  162.0
[I 2023-12-04 02:01:24,274] Trial 44 finished with value: 0.11620710045099258 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.404921740978992, 'log_learning_rate_D': -3.337211656339163, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  69.33369517326355
Memory status after this trial: 
Memory allocated:  150.79345703125
Memory cached:  166.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1045439320960693, 'log_learning_rate_D': -3.203039181817645, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.0233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.52099609375
Memory cached:  162.0
[I 2023-12-04 02:02:37,088] Trial 45 finished with value: 0.033553220331668854 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1045439320960693, 'log_learning_rate_D': -3.203039181817645, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  72.62693858146667
Memory status after this trial: 
Memory allocated:  142.64404296875
Memory cached:  162.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.3069867007143023, 'log_learning_rate_D': -3.5522526348880437, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  184.0
	 epoch  10 training error:  tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  20 training error:  tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  30 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.53369140625
Memory cached:  186.0
[I 2023-12-04 02:03:26,694] Trial 46 finished with value: 0.02983119525015354 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.3069867007143023, 'log_learning_rate_D': -3.5522526348880437, 'training_batch_size': 7, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  49.41559171676636
Memory status after this trial: 
Memory allocated:  198.58544921875
Memory cached:  226.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.8965421166190954, 'log_learning_rate_D': -3.4049471994426077, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.0220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.0248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.81982421875
Memory cached:  162.0
[I 2023-12-04 02:04:38,835] Trial 47 finished with value: 0.023969614878296852 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.8965421166190954, 'log_learning_rate_D': -3.4049471994426077, 'training_batch_size': 6, 'training_p': 8}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  71.94308686256409
Memory status after this trial: 
Memory allocated:  135.0927734375
Memory cached:  162.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.8028129363903296, 'log_learning_rate_D': -2.8537660530538815, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.60595703125
Memory cached:  144.0
[I 2023-12-04 02:05:27,034] Trial 48 finished with value: 0.015593096613883972 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.8028129363903296, 'log_learning_rate_D': -2.8537660530538815, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  48.004125356674194
Memory status after this trial: 
Memory allocated:  139.3037109375
Memory cached:  144.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.70228625357998, 'log_learning_rate_D': -2.7969869364122437, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  10 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.0419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.53955078125
Memory cached:  144.0
[I 2023-12-04 02:06:15,730] Trial 49 finished with value: 0.016192642971873283 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.70228625357998, 'log_learning_rate_D': -2.7969869364122437, 'training_batch_size': 7, 'training_p': 7}. Best is trial 27 with value: 0.013895528391003609.
Time for this trial:  48.514179944992065
Memory status after this trial: 
Memory allocated:  138.5380859375
Memory cached:  144.0
