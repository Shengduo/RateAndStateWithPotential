/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-04 20:50:09,663] A new study created in memory with name: no-name-a9d14c81-207e-467d-bb58-655a1c710e90
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1204_smallDRS_smallA.pt
Vs.shape:  torch.Size([200, 100])
thetas.shape:  torch.Size([200, 100])
fs.shape:  torch.Size([200, 100])
ts.shape:  torch.Size([200, 100])
Xs.shape:  torch.Size([200, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.999583226373811, 'log_learning_rate_D': -2.671261660162052, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(344.1924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  20.0
	 epoch  10 training error:  tensor(294.1461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  20 training error:  tensor(274.3657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  30 training error:  tensor(212.6814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  28.0
	 epoch  40 training error:  tensor(204.6786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  50 training error:  tensor(174.4462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  60 training error:  tensor(150.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  28.0
	 epoch  70 training error:  tensor(135.1079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  80 training error:  tensor(127.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  26.0
	 epoch  90 training error:  tensor(121.6385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7939453125
Memory cached:  28.0
[I 2023-12-04 20:51:09,531] Trial 0 finished with value: 43.888641357421875 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.999583226373811, 'log_learning_rate_D': -2.671261660162052, 'training_batch_size': 11, 'training_p': 7}. Best is trial 0 with value: 43.888641357421875.
res:  tensor(43.8886, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  59.78691053390503
Memory status after this trial: 
Memory allocated:  204.5546875
Memory cached:  214.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.8076736344183217, 'log_learning_rate_D': -3.6220200148835495, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(436.4549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  10 training error:  tensor(1552.7379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  220.0
	 epoch  20 training error:  tensor(1661.9797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  30 training error:  tensor(604.7412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  40 training error:  tensor(399.2253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  220.0
	 epoch  50 training error:  tensor(151.3172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  60 training error:  tensor(375.2003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  70 training error:  tensor(102.0444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  220.0
	 epoch  80 training error:  tensor(158.3286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
	 epoch  90 training error:  tensor(82.6949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.70166015625
Memory cached:  218.0
[I 2023-12-04 20:51:59,002] Trial 1 finished with value: 129.4978790283203 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.8076736344183217, 'log_learning_rate_D': -3.6220200148835495, 'training_batch_size': 11, 'training_p': 3}. Best is trial 0 with value: 43.888641357421875.
Time for this trial:  49.39038634300232
Memory status after this trial: 
Memory allocated:  321.78955078125
Memory cached:  328.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.0732800778110714, 'log_learning_rate_D': -1.1503047176589205, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(477.9296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.93408203125
Memory cached:  218.0
[W 2023-12-04 20:52:01,299] Trial 2 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.0732800778110714, 'log_learning_rate_D': -1.1503047176589205, 'training_batch_size': 10, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-04 20:52:01,300] Trial 2 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1850898265838623
Memory status after this trial: 
Memory allocated:  355.23828125
Memory cached:  360.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.2129497802067166, 'log_learning_rate_D': -2.3343291127859063, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(468.7427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  10 training error:  tensor(19.0027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  20 training error:  tensor(44.2301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  30 training error:  tensor(17.1677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  40 training error:  tensor(21.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  50 training error:  tensor(13.9204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  60 training error:  tensor(10.6490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  70 training error:  tensor(15.2117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  80 training error:  tensor(17.3904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
	 epoch  90 training error:  tensor(7.1765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.52587890625
Memory cached:  218.0
[I 2023-12-04 20:52:51,784] Trial 3 finished with value: 12.999582290649414 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.2129497802067166, 'log_learning_rate_D': -2.3343291127859063, 'training_batch_size': 11, 'training_p': 5}. Best is trial 3 with value: 12.999582290649414.
res:  tensor(12.9996, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(43.8886, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  50.37731122970581
Memory status after this trial: 
Memory allocated:  131.513671875
Memory cached:  288.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.283202360855391, 'log_learning_rate_D': -2.4777882671366296, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(533.0285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  334.0
	 epoch  10 training error:  tensor(161.2189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  20 training error:  tensor(52.9703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  30 training error:  tensor(28.3617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  40 training error:  tensor(5.3437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  50 training error:  tensor(2.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  60 training error:  tensor(1.9139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  70 training error:  tensor(12.1145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  80 training error:  tensor(3.8945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
	 epoch  90 training error:  tensor(4.7573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.14111328125
Memory cached:  336.0
[I 2023-12-04 20:54:07,895] Trial 4 finished with value: 7.264143466949463 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.283202360855391, 'log_learning_rate_D': -2.4777882671366296, 'training_batch_size': 9, 'training_p': 4}. Best is trial 4 with value: 7.264143466949463.
res:  tensor(7.2641, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(12.9996, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  76.00420570373535
Memory status after this trial: 
Memory allocated:  360.509765625
Memory cached:  504.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.809276862583816, 'log_learning_rate_D': -1.9965443745779754, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(522.8057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  10 training error:  tensor(25841.4043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  20 training error:  tensor(1621.1348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  30 training error:  tensor(336.8594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  40 training error:  tensor(101.6491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  50 training error:  tensor(329.2967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  60 training error:  tensor(559.1796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  70 training error:  tensor(111.1811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  80 training error:  tensor(173.3500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
	 epoch  90 training error:  tensor(26.2976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  379.53955078125
Memory cached:  506.0
[I 2023-12-04 20:55:32,492] Trial 5 finished with value: 18.752798080444336 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.809276862583816, 'log_learning_rate_D': -1.9965443745779754, 'training_batch_size': 7, 'training_p': 4}. Best is trial 4 with value: 7.264143466949463.
Time for this trial:  84.48189043998718
Memory status after this trial: 
Memory allocated:  514.74853515625
Memory cached:  534.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.1192935451091546, 'log_learning_rate_D': -1.5775505655703204, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(149.8023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  363.74072265625
Memory cached:  506.0
[W 2023-12-04 20:55:35,224] Trial 6 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.1192935451091546, 'log_learning_rate_D': -1.5775505655703204, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 20:55:35,225] Trial 6 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.606995105743408
Memory status after this trial: 
Memory allocated:  467.7451171875
Memory cached:  506.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.326605255145957, 'log_learning_rate_D': -3.7775804814111145, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(388.8232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  506.0
	 epoch  10 training error:  tensor(107.4281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  20 training error:  tensor(58.9098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  30 training error:  tensor(26.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  40 training error:  tensor(13.9479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  50 training error:  tensor(7.1928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  60 training error:  tensor(4.2290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  70 training error:  tensor(3.8648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  80 training error:  tensor(3.2091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
	 epoch  90 training error:  tensor(2.6929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  370.83251953125
Memory cached:  508.0
[I 2023-12-04 20:56:23,600] Trial 7 finished with value: 2.541916608810425 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.326605255145957, 'log_learning_rate_D': -3.7775804814111145, 'training_batch_size': 8, 'training_p': 2}. Best is trial 7 with value: 2.541916608810425.
res:  tensor(2.5419, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(7.2641, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  48.26260757446289
Memory status after this trial: 
Memory allocated:  140.4423828125
Memory cached:  354.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.0793637227831514, 'log_learning_rate_D': -1.608867586218513, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(546.9876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.15380859375
Memory cached:  352.0
[W 2023-12-04 20:56:27,228] Trial 8 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.0793637227831514, 'log_learning_rate_D': -1.608867586218513, 'training_batch_size': 10, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-04 20:56:27,229] Trial 8 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.5306003093719482
Memory status after this trial: 
Memory allocated:  286.43212890625
Memory cached:  352.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.793659666328339, 'log_learning_rate_D': -3.698238807651771, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(417.9051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  358.0
	 epoch  10 training error:  tensor(25.9201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  20 training error:  tensor(26.4855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  30 training error:  tensor(31.4973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  40 training error:  tensor(3.9883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  50 training error:  tensor(2.8896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  60 training error:  tensor(3.6914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  70 training error:  tensor(4.5953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  80 training error:  tensor(2.4328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
	 epoch  90 training error:  tensor(10.5120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  149.96826171875
Memory cached:  360.0
[I 2023-12-04 20:57:22,781] Trial 9 finished with value: 11.902506828308105 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.793659666328339, 'log_learning_rate_D': -3.698238807651771, 'training_batch_size': 12, 'training_p': 8}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  55.459473609924316
Memory status after this trial: 
Memory allocated:  309.27734375
Memory cached:  358.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.1916892803396717, 'log_learning_rate_D': -1.9267379372349982, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(3858.3750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  10 training error:  tensor(341.7867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  20 training error:  tensor(337.1251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  30 training error:  tensor(106.8569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  40 training error:  tensor(70.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  50 training error:  tensor(168.2467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  60 training error:  tensor(62.0892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  70 training error:  tensor(177.8231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  80 training error:  tensor(134.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
	 epoch  90 training error:  tensor(12.2405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.63623046875
Memory cached:  392.0
[I 2023-12-04 20:59:11,136] Trial 10 finished with value: 32.04421615600586 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.1916892803396717, 'log_learning_rate_D': -1.9267379372349982, 'training_batch_size': 6, 'training_p': 5}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  108.23225617408752
Memory status after this trial: 
Memory allocated:  385.10400390625
Memory cached:  412.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1704544114941164, 'log_learning_rate_D': -1.3267040337629865, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(543.5817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.57763671875
Memory cached:  356.0
[W 2023-12-04 20:59:13,370] Trial 11 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1704544114941164, 'log_learning_rate_D': -1.3267040337629865, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 20:59:13,371] Trial 11 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.123070478439331
Memory status after this trial: 
Memory allocated:  246.91552734375
Memory cached:  356.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.2453329836578235, 'log_learning_rate_D': -4.005562275813821, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  10 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  20 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  30 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  40 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  50 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  60 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  70 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  80 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
	 epoch  90 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.52685546875
Memory cached:  352.0
[I 2023-12-04 21:00:22,616] Trial 12 finished with value: 6449.79296875 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.2453329836578235, 'log_learning_rate_D': -4.005562275813821, 'training_batch_size': 6, 'training_p': 8}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  69.13375878334045
Memory status after this trial: 
Memory allocated:  180.4541015625
Memory cached:  352.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.9562936323092917, 'log_learning_rate_D': -2.2093531216905506, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(537.9468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  10 training error:  tensor(24.4308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  20 training error:  tensor(17.3354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  30 training error:  tensor(19.6402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  40 training error:  tensor(12.8096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  50 training error:  tensor(14.7218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  60 training error:  tensor(13.0097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  70 training error:  tensor(10.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  80 training error:  tensor(13.0772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
	 epoch  90 training error:  tensor(11.4836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.14794921875
Memory cached:  352.0
[I 2023-12-04 21:01:08,730] Trial 13 finished with value: 13.520614624023438 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.9562936323092917, 'log_learning_rate_D': -2.2093531216905506, 'training_batch_size': 9, 'training_p': 5}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  46.00765061378479
Memory status after this trial: 
Memory allocated:  180.3408203125
Memory cached:  352.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.871206264278005, 'log_learning_rate_D': -1.0177813942826912, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(462.1833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.81005859375
Memory cached:  356.0
[W 2023-12-04 21:01:10,473] Trial 14 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.871206264278005, 'log_learning_rate_D': -1.0177813942826912, 'training_batch_size': 8, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:01:10,474] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.576322317123413
Memory status after this trial: 
Memory allocated:  240.8154296875
Memory cached:  356.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.931908511713459, 'log_learning_rate_D': -4.935182654895175, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(514.4080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  356.0
	 epoch  10 training error:  tensor(504.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  20 training error:  tensor(494.1194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  30 training error:  tensor(483.8040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  40 training error:  tensor(473.1704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  50 training error:  tensor(462.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  60 training error:  tensor(450.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  70 training error:  tensor(437.6238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  80 training error:  tensor(423.9810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
	 epoch  90 training error:  tensor(409.1653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.71630859375
Memory cached:  358.0
[I 2023-12-04 21:01:54,740] Trial 15 finished with value: 514.6669921875 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.931908511713459, 'log_learning_rate_D': -4.935182654895175, 'training_batch_size': 8, 'training_p': 2}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  44.10413980484009
Memory status after this trial: 
Memory allocated:  238.5712890625
Memory cached:  356.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.167324081631541, 'log_learning_rate_D': -1.2993956858838458, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(450.9687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:01:57,423] Trial 16 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.167324081631541, 'log_learning_rate_D': -1.2993956858838458, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:01:57,424] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.509889841079712
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.2768526427339895, 'log_learning_rate_D': -1.3508042587614266, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(430.2539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  396.0
	 epoch  10 training error:  tensor(128.1888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  20 training error:  tensor(1.8297e+11, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  30 training error:  tensor(1.0674e+13, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
[W 2023-12-04 21:02:25,521] Trial 17 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.2768526427339895, 'log_learning_rate_D': -1.3508042587614266, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:25,522] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  27.902588844299316
Memory status after this trial: 
Memory allocated:  473.486328125
Memory cached:  480.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.198098435445308, 'log_learning_rate_D': -1.0885627602236885, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(474.3757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:02:28,166] Trial 18 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.198098435445308, 'log_learning_rate_D': -1.0885627602236885, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:28,167] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4619321823120117
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.096517577025578, 'log_learning_rate_D': -1.3062274845341424, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(487.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  208.92333984375
Memory cached:  436.0
[W 2023-12-04 21:02:32,316] Trial 19 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.096517577025578, 'log_learning_rate_D': -1.3062274845341424, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:32,317] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.9523510932922363
Memory status after this trial: 
Memory allocated:  538.7939453125
Memory cached:  550.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.1359454847903185, 'log_learning_rate_D': -1.2152466398130337, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(447.6356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.21826171875
Memory cached:  416.0
[W 2023-12-04 21:02:34,969] Trial 20 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.1359454847903185, 'log_learning_rate_D': -1.2152466398130337, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:34,970] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.464491844177246
Memory status after this trial: 
Memory allocated:  532.58154296875
Memory cached:  550.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.191706838121702, 'log_learning_rate_D': -1.0857844608319098, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(493.4346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:02:37,606] Trial 21 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.191706838121702, 'log_learning_rate_D': -1.0857844608319098, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:37,606] Trial 21 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4517288208007812
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.159227070616939, 'log_learning_rate_D': -1.0350070518133618, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(486.2265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  180.75927734375
Memory cached:  396.0
[W 2023-12-04 21:02:40,163] Trial 22 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.159227070616939, 'log_learning_rate_D': -1.0350070518133618, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:40,164] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.374694347381592
Memory status after this trial: 
Memory allocated:  498.14697265625
Memory cached:  508.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.142633141063441, 'log_learning_rate_D': -1.064518885256823, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(357.5234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
[W 2023-12-04 21:02:42,729] Trial 23 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.142633141063441, 'log_learning_rate_D': -1.064518885256823, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:42,730] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.3611106872558594
Memory status after this trial: 
Memory allocated:  473.486328125
Memory cached:  480.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.999158295018539, 'log_learning_rate_D': -1.2009613051689332, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(476.9075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:02:46,068] Trial 24 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.999158295018539, 'log_learning_rate_D': -1.2009613051689332, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:46,068] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.1422083377838135
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.135303533405464, 'log_learning_rate_D': -1.020787828155913, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(494.9023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:02:49,606] Trial 25 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.135303533405464, 'log_learning_rate_D': -1.020787828155913, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:49,607] Trial 25 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.3419108390808105
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.245782439989633, 'log_learning_rate_D': -1.2655966567171193, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(474.3485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.27294921875
Memory cached:  436.0
[W 2023-12-04 21:02:53,811] Trial 26 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.245782439989633, 'log_learning_rate_D': -1.2655966567171193, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:02:53,812] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.009861707687378
Memory status after this trial: 
Memory allocated:  560.04638671875
Memory cached:  574.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.215276547169468, 'log_learning_rate_D': -1.3969615057921438, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(483.2747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:03:01,445] Trial 27 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.215276547169468, 'log_learning_rate_D': -1.3969615057921438, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:03:01,446] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.450533151626587
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.152654987951886, 'log_learning_rate_D': -1.0167458178407154, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(488.2369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:03:05,600] Trial 28 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.152654987951886, 'log_learning_rate_D': -1.0167458178407154, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:03:05,601] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.958937644958496
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.174011392775702, 'log_learning_rate_D': -1.0736550037820431, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(480.0237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.90771484375
Memory cached:  436.0
[W 2023-12-04 21:03:08,361] Trial 29 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.174011392775702, 'log_learning_rate_D': -1.0736550037820431, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:03:08,362] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.561668634414673
Memory status after this trial: 
Memory allocated:  535.3857421875
Memory cached:  546.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.045552596828933, 'log_learning_rate_D': -2.9928893254908218, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(404.1830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  396.0
	 epoch  10 training error:  tensor(127.5457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  20 training error:  tensor(31.8956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  30 training error:  tensor(13.7003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  40 training error:  tensor(13.6907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  50 training error:  tensor(14.6145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  60 training error:  tensor(16.4412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  70 training error:  tensor(15.9717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  80 training error:  tensor(15.2986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
	 epoch  90 training error:  tensor(17.9376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  176.39404296875
Memory cached:  398.0
[I 2023-12-04 21:04:17,670] Trial 30 finished with value: 20.649999618530273 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.045552596828933, 'log_learning_rate_D': -2.9928893254908218, 'training_batch_size': 9, 'training_p': 2}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  69.12374496459961
Memory status after this trial: 
Memory allocated:  473.486328125
Memory cached:  480.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.275362847414819, 'log_learning_rate_D': -1.0582095274107473, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(442.3749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  186.20654296875
Memory cached:  396.0
[W 2023-12-04 21:04:20,369] Trial 31 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.275362847414819, 'log_learning_rate_D': -1.0582095274107473, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:20,370] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.47247314453125
Memory status after this trial: 
Memory allocated:  478.06298828125
Memory cached:  510.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.240231291583495, 'log_learning_rate_D': -1.2747271341787223, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(498.5468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.17138671875
Memory cached:  376.0
[W 2023-12-04 21:04:22,915] Trial 32 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.240231291583495, 'log_learning_rate_D': -1.2747271341787223, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:22,915] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.336791753768921
Memory status after this trial: 
Memory allocated:  404.09228515625
Memory cached:  430.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.288178264498718, 'log_learning_rate_D': -1.1039165348334299, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(436.1033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  182.19091796875
Memory cached:  396.0
[W 2023-12-04 21:04:25,548] Trial 33 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.288178264498718, 'log_learning_rate_D': -1.1039165348334299, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:25,549] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.432790994644165
Memory status after this trial: 
Memory allocated:  452.61767578125
Memory cached:  490.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.281628177504281, 'log_learning_rate_D': -1.3021952563754167, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(403.7905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  181.43310546875
Memory cached:  394.0
[W 2023-12-04 21:04:28,205] Trial 34 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.281628177504281, 'log_learning_rate_D': -1.3021952563754167, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:28,206] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.450406074523926
Memory status after this trial: 
Memory allocated:  443.42041015625
Memory cached:  482.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.236571361299832, 'log_learning_rate_D': -1.6304190164547148, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(419.9890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  180.18310546875
Memory cached:  396.0
[W 2023-12-04 21:04:32,315] Trial 35 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.236571361299832, 'log_learning_rate_D': -1.6304190164547148, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:32,316] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.9070513248443604
Memory status after this trial: 
Memory allocated:  439.89501953125
Memory cached:  478.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.247946889677431, 'log_learning_rate_D': -1.0932480481956022, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(410.2149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  180.80810546875
Memory cached:  396.0
[W 2023-12-04 21:04:34,928] Trial 36 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.247946889677431, 'log_learning_rate_D': -1.0932480481956022, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:34,929] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4195709228515625
Memory status after this trial: 
Memory allocated:  443.02001953125
Memory cached:  480.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.26806272245153, 'log_learning_rate_D': -1.580397104151139, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(360.1403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.67919921875
Memory cached:  396.0
[W 2023-12-04 21:04:38,321] Trial 37 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.26806272245153, 'log_learning_rate_D': -1.580397104151139, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:04:38,322] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.1893529891967773
Memory status after this trial: 
Memory allocated:  430.35400390625
Memory cached:  466.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.2321997805437706, 'log_learning_rate_D': -3.1600230670690506, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(468.6312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  376.0
	 epoch  10 training error:  tensor(122.7105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  20 training error:  tensor(6.0095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  30 training error:  tensor(7.7504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  40 training error:  tensor(7.4039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  50 training error:  tensor(7.9258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  60 training error:  tensor(7.0141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  70 training error:  tensor(6.5872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  80 training error:  tensor(7.6956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
	 epoch  90 training error:  tensor(6.9251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.19873046875
Memory cached:  378.0
[I 2023-12-04 21:05:50,087] Trial 38 finished with value: 8.165350914001465 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.2321997805437706, 'log_learning_rate_D': -3.1600230670690506, 'training_batch_size': 8, 'training_p': 3}. Best is trial 7 with value: 2.541916608810425.
Time for this trial:  71.57950472831726
Memory status after this trial: 
Memory allocated:  448.62158203125
Memory cached:  470.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.317412058449637, 'log_learning_rate_D': -1.2733549522094405, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(526.5970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:05:52,537] Trial 39 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.317412058449637, 'log_learning_rate_D': -1.2733549522094405, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:05:52,538] Trial 39 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.275049924850464
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.454601196980979, 'log_learning_rate_D': -1.3305093786925122, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(499.4975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:05:54,980] Trial 40 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.454601196980979, 'log_learning_rate_D': -1.3305093786925122, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:05:54,981] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2727725505828857
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.401154384899149, 'log_learning_rate_D': -1.3006706554862935, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(486.3315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:05:56,900] Trial 41 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.401154384899149, 'log_learning_rate_D': -1.3006706554862935, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:05:56,901] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.746851921081543
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.379775452235095, 'log_learning_rate_D': -1.3418481436600986, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(413.4793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:05:59,345] Trial 42 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.379775452235095, 'log_learning_rate_D': -1.3418481436600986, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:05:59,346] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2744455337524414
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3167600971319, 'log_learning_rate_D': -1.3774837510013547, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(388.5984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:01,291] Trial 43 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3167600971319, 'log_learning_rate_D': -1.3774837510013547, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:01,292] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7816720008850098
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.424665578590764, 'log_learning_rate_D': -1.188475756355344, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(489.8062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:03,288] Trial 44 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.424665578590764, 'log_learning_rate_D': -1.188475756355344, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:03,289] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.82407546043396
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.42867461432961, 'log_learning_rate_D': -1.0368776885320092, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(560.3222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:05,186] Trial 45 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.42867461432961, 'log_learning_rate_D': -1.0368776885320092, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:05,187] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7207214832305908
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.252157437550778, 'log_learning_rate_D': -1.2827276818318594, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(323.3925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:07,500] Trial 46 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.252157437550778, 'log_learning_rate_D': -1.2827276818318594, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:07,501] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1413090229034424
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.444746581239894, 'log_learning_rate_D': -1.0709579211584237, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(401.8011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:09,452] Trial 47 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.444746581239894, 'log_learning_rate_D': -1.0709579211584237, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:09,453] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7790369987487793
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3088127803408245, 'log_learning_rate_D': -1.5843041346477365, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(417.1380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:13,897] Trial 48 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3088127803408245, 'log_learning_rate_D': -1.5843041346477365, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:13,898] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.267984390258789
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.421135649659506, 'log_learning_rate_D': -1.1572143823306345, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(545.7924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.06591796875
Memory cached:  356.0
[W 2023-12-04 21:06:15,848] Trial 49 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.421135649659506, 'log_learning_rate_D': -1.1572143823306345, 'training_batch_size': 8, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:06:15,849] Trial 49 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
[I 2023-12-04 21:06:15,868] A new study created in memory with name: no-name-71e8a12e-cf17-452e-8a96-9de4a266313a
Time for this trial:  1.778000831604004
Memory status after this trial: 
Memory allocated:  282.98828125
Memory cached:  356.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.0896136590964112, 'log_learning_rate_D': -2.739851034203188, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(500.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  10 training error:  tensor(1176.8801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  20 training error:  tensor(397.2920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  30 training error:  tensor(58.7473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  40 training error:  tensor(27.3216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  50 training error:  tensor(15.4417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  60 training error:  tensor(2.8480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  70 training error:  tensor(183.8949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  80 training error:  tensor(141.7190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
	 epoch  90 training error:  tensor(44.2273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6845703125
Memory cached:  8.0
[I 2023-12-04 21:06:55,911] Trial 0 finished with value: 24.53675651550293 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.0896136590964112, 'log_learning_rate_D': -2.739851034203188, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 24.53675651550293.
res:  tensor(24.5368, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  39.9238703250885
Memory status after this trial: 
Memory allocated:  27.439453125
Memory cached:  28.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.0599181067512085, 'log_learning_rate_D': -2.5209859504772023, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(361.1889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  10 training error:  tensor(158.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  20 training error:  tensor(96.5142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  30 training error:  tensor(46.1978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  40 training error:  tensor(13.6273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  50 training error:  tensor(11.4402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  60 training error:  tensor(16.4118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  70 training error:  tensor(11.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  80 training error:  tensor(13.0135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
	 epoch  90 training error:  tensor(6.7497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.70751953125
Memory cached:  42.0
[I 2023-12-04 21:08:41,996] Trial 1 finished with value: 7.735691070556641 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.0599181067512085, 'log_learning_rate_D': -2.5209859504772023, 'training_batch_size': 6, 'training_p': 7}. Best is trial 1 with value: 7.735691070556641.
res:  tensor(7.7357, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(24.5368, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  105.97225689888
Memory status after this trial: 
Memory allocated:  87.45068359375
Memory cached:  120.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.0376726610977514, 'log_learning_rate_D': -3.715042464018655, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(481.1028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  124.0
	 epoch  10 training error:  tensor(69.6952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  20 training error:  tensor(26.7146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  30 training error:  tensor(6.6792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  40 training error:  tensor(20.4646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  50 training error:  tensor(30.5408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  60 training error:  tensor(11.7742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  70 training error:  tensor(18.1304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  80 training error:  tensor(18.2937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
	 epoch  90 training error:  tensor(9.8667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.861328125
Memory cached:  126.0
[I 2023-12-04 21:09:30,556] Trial 2 finished with value: 17.850664138793945 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.0376726610977514, 'log_learning_rate_D': -3.715042464018655, 'training_batch_size': 10, 'training_p': 8}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  48.477404832839966
Memory status after this trial: 
Memory allocated:  203.5322265625
Memory cached:  208.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.108485375535566, 'log_learning_rate_D': -1.6418566791553038, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(611.8224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  10 training error:  tensor(486.3066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  20 training error:  tensor(309.4784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  30 training error:  tensor(250.8652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  40 training error:  tensor(229.4891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  50 training error:  tensor(221.8643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  60 training error:  tensor(214.6214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  70 training error:  tensor(207.3773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  80 training error:  tensor(200.0284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
	 epoch  90 training error:  tensor(192.5494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  87.826171875
Memory cached:  120.0
[I 2023-12-04 21:10:07,994] Trial 3 finished with value: 109.47291564941406 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.108485375535566, 'log_learning_rate_D': -1.6418566791553038, 'training_batch_size': 12, 'training_p': 6}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  37.33553695678711
Memory status after this trial: 
Memory allocated:  138.54638671875
Memory cached:  148.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.8821162018342195, 'log_learning_rate_D': -4.852633713743712, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(528.1992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  142.0
	 epoch  10 training error:  tensor(97.2931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  20 training error:  tensor(14.3032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  30 training error:  tensor(5.1936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  40 training error:  tensor(3.3815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  50 training error:  tensor(3.1573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  60 training error:  tensor(4.7631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  70 training error:  tensor(2.9622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  80 training error:  tensor(12.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
	 epoch  90 training error:  tensor(6.1741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.431640625
Memory cached:  144.0
[I 2023-12-04 21:11:05,098] Trial 4 finished with value: 12.106287956237793 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.8821162018342195, 'log_learning_rate_D': -4.852633713743712, 'training_batch_size': 8, 'training_p': 6}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  56.99542188644409
Memory status after this trial: 
Memory allocated:  253.89599609375
Memory cached:  274.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.9349448658491966, 'log_learning_rate_D': -1.129014556742424, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(536.6454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.515625
Memory cached:  120.0
[W 2023-12-04 21:11:08,434] Trial 5 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.9349448658491966, 'log_learning_rate_D': -1.129014556742424, 'training_batch_size': 7, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:11:08,436] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.215458393096924
Memory status after this trial: 
Memory allocated:  120.0556640625
Memory cached:  122.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.9536488658078084, 'log_learning_rate_D': -4.679377337276051, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1461.4589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  10 training error:  tensor(635.8268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  20 training error:  tensor(412.9831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  30 training error:  tensor(18.0128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  40 training error:  tensor(28.2421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  50 training error:  tensor(23.6617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  60 training error:  tensor(15.8209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  70 training error:  tensor(54.2123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  80 training error:  tensor(42.6020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
	 epoch  90 training error:  tensor(22.0309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.85546875
Memory cached:  128.0
[I 2023-12-04 21:12:50,157] Trial 6 finished with value: 29.751327514648438 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.9536488658078084, 'log_learning_rate_D': -4.679377337276051, 'training_batch_size': 6, 'training_p': 5}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  101.60466861724854
Memory status after this trial: 
Memory allocated:  211.8271484375
Memory cached:  218.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.3695220607643592, 'log_learning_rate_D': -1.832361365494367, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(490.9509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  122.0
	 epoch  10 training error:  tensor(111.4990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  20 training error:  tensor(98.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  30 training error:  tensor(105.4214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  40 training error:  tensor(25.9600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  50 training error:  tensor(18.5250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  60 training error:  tensor(12.0224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  70 training error:  tensor(33.0821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  80 training error:  tensor(10.2959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
	 epoch  90 training error:  tensor(16.0939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.76171875
Memory cached:  124.0
[I 2023-12-04 21:13:37,223] Trial 7 finished with value: 36.81417465209961 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.3695220607643592, 'log_learning_rate_D': -1.832361365494367, 'training_batch_size': 8, 'training_p': 5}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  46.94768476486206
Memory status after this trial: 
Memory allocated:  189.80810546875
Memory cached:  194.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.626479200531503, 'log_learning_rate_D': -1.6450461409692374, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1831.4032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.794921875
Memory cached:  122.0
[W 2023-12-04 21:13:41,062] Trial 8 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.626479200531503, 'log_learning_rate_D': -1.6450461409692374, 'training_batch_size': 6, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:13:41,063] Trial 8 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.7140772342681885
Memory status after this trial: 
Memory allocated:  210.439453125
Memory cached:  216.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.413403344276732, 'log_learning_rate_D': -2.3128118486445066, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(366.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  10 training error:  tensor(15.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  20 training error:  tensor(28.5901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  30 training error:  tensor(5.8124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  40 training error:  tensor(9.7451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  50 training error:  tensor(8.5995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  60 training error:  tensor(7.7598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  70 training error:  tensor(1.4609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  80 training error:  tensor(11.1121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
	 epoch  90 training error:  tensor(4.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.42578125
Memory cached:  122.0
[I 2023-12-04 21:14:24,743] Trial 9 finished with value: 12.815948486328125 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.413403344276732, 'log_learning_rate_D': -2.3128118486445066, 'training_batch_size': 9, 'training_p': 7}. Best is trial 1 with value: 7.735691070556641.
Time for this trial:  43.562633991241455
Memory status after this trial: 
Memory allocated:  143.953125
Memory cached:  146.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.784422153598128, 'log_learning_rate_D': -3.785754748365692, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(426.3432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  10 training error:  tensor(74.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  20 training error:  tensor(57.1407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  30 training error:  tensor(22.4199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  40 training error:  tensor(13.9856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  50 training error:  tensor(5.4816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  60 training error:  tensor(5.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  70 training error:  tensor(3.7528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  80 training error:  tensor(2.4789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
	 epoch  90 training error:  tensor(5.4841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.791015625
Memory cached:  142.0
[I 2023-12-04 21:15:08,222] Trial 10 finished with value: 7.686084270477295 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.784422153598128, 'log_learning_rate_D': -3.785754748365692, 'training_batch_size': 9, 'training_p': 4}. Best is trial 10 with value: 7.686084270477295.
res:  tensor(7.6861, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(7.7357, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  43.37592601776123
Memory status after this trial: 
Memory allocated:  92.55859375
Memory cached:  168.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.6104471611333158, 'log_learning_rate_D': -1.1355629767736248, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(518.1564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.68798828125
Memory cached:  170.0
[W 2023-12-04 21:15:10,709] Trial 11 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.6104471611333158, 'log_learning_rate_D': -1.1355629767736248, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:15:10,709] Trial 11 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.3995189666748047
Memory status after this trial: 
Memory allocated:  200.49755859375
Memory cached:  220.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.601307136998079, 'log_learning_rate_D': -2.81415855014838, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(659.4507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  10 training error:  tensor(43.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  20 training error:  tensor(33.2134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  30 training error:  tensor(16.3581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  40 training error:  tensor(7.9066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  50 training error:  tensor(13.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  60 training error:  tensor(19.3662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  70 training error:  tensor(4.9236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  80 training error:  tensor(9.9631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
	 epoch  90 training error:  tensor(2.9329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.46533203125
Memory cached:  168.0
[I 2023-12-04 21:15:55,208] Trial 12 finished with value: 13.35773754119873 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.601307136998079, 'log_learning_rate_D': -2.81415855014838, 'training_batch_size': 9, 'training_p': 8}. Best is trial 10 with value: 7.686084270477295.
Time for this trial:  44.40478515625
Memory status after this trial: 
Memory allocated:  209.54052734375
Memory cached:  224.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.873558567682219, 'log_learning_rate_D': -3.544418363657214, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(505.3318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  190.0
	 epoch  10 training error:  tensor(437.1243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  20 training error:  tensor(360.7944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  30 training error:  tensor(261.4361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  40 training error:  tensor(120.5272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  50 training error:  tensor(68.1721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  60 training error:  tensor(31.9154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  70 training error:  tensor(17.6500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  80 training error:  tensor(8.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
	 epoch  90 training error:  tensor(7.9449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.15478515625
Memory cached:  192.0
[I 2023-12-04 21:17:04,066] Trial 13 finished with value: 9.011075019836426 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.873558567682219, 'log_learning_rate_D': -3.544418363657214, 'training_batch_size': 11, 'training_p': 3}. Best is trial 10 with value: 7.686084270477295.
Time for this trial:  68.69287061691284
Memory status after this trial: 
Memory allocated:  396.625
Memory cached:  404.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.941287404354638, 'log_learning_rate_D': -1.073667932696679, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(380.2735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
[W 2023-12-04 21:17:06,833] Trial 14 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.941287404354638, 'log_learning_rate_D': -1.073667932696679, 'training_batch_size': 6, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:17:06,833] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.5796384811401367
Memory status after this trial: 
Memory allocated:  213.69287109375
Memory cached:  224.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.810744890391591, 'log_learning_rate_D': -1.1945254147527922, 'training_batch_size': 6, 'training_p': 2}
[W 2023-12-04 21:17:08,523] Trial 15 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.810744890391591, 'log_learning_rate_D': -1.1945254147527922, 'training_batch_size': 6, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:17:08,525] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.5036234855651855
Memory status after this trial: 
Memory allocated:  213.69287109375
Memory cached:  224.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.919537383532174, 'log_learning_rate_D': -3.5833998870899837, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(296.0070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  10 training error:  tensor(217.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  20 training error:  tensor(117.1507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  30 training error:  tensor(96.5250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  40 training error:  tensor(74.3091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  50 training error:  tensor(46.6870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  60 training error:  tensor(32.1976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  70 training error:  tensor(25.7468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  80 training error:  tensor(22.3482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
	 epoch  90 training error:  tensor(20.3123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.49072265625
Memory cached:  170.0
[I 2023-12-04 21:19:00,329] Trial 16 finished with value: 24.75730323791504 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.919537383532174, 'log_learning_rate_D': -3.5833998870899837, 'training_batch_size': 6, 'training_p': 2}. Best is trial 10 with value: 7.686084270477295.
Time for this trial:  111.61663341522217
Memory status after this trial: 
Memory allocated:  213.69287109375
Memory cached:  224.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.307873052255033, 'log_learning_rate_D': -1.128926128878549, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(476.0934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.83837890625
Memory cached:  174.0
[W 2023-12-04 21:19:02,550] Trial 17 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.307873052255033, 'log_learning_rate_D': -1.128926128878549, 'training_batch_size': 7, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:19:02,551] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9918129444122314
Memory status after this trial: 
Memory allocated:  177.37939453125
Memory cached:  196.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.3394869217222904, 'log_learning_rate_D': -1.2035699374839348, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(416.5293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
[W 2023-12-04 21:19:04,673] Trial 18 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.3394869217222904, 'log_learning_rate_D': -1.2035699374839348, 'training_batch_size': 7, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:19:04,674] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9318974018096924
Memory status after this trial: 
Memory allocated:  178.89208984375
Memory cached:  198.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -4.311190276981798, 'log_learning_rate_D': -1.2569901125868932, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(488.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.72509765625
Memory cached:  170.0
[W 2023-12-04 21:19:06,796] Trial 19 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -4.311190276981798, 'log_learning_rate_D': -1.2569901125868932, 'training_batch_size': 7, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:19:06,798] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9496054649353027
Memory status after this trial: 
Memory allocated:  200.07568359375
Memory cached:  220.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -4.381261181844398, 'log_learning_rate_D': -1.1013865863110799, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(470.1770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.72509765625
Memory cached:  170.0
[W 2023-12-04 21:19:09,012] Trial 20 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -4.381261181844398, 'log_learning_rate_D': -1.1013865863110799, 'training_batch_size': 7, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:19:09,014] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0442862510681152
Memory status after this trial: 
Memory allocated:  200.07568359375
Memory cached:  220.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.46886210569088, 'log_learning_rate_D': -2.2252652512591045, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(482.4135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  10 training error:  tensor(321.8069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  20 training error:  tensor(149.2436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  30 training error:  tensor(34.8310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  40 training error:  tensor(146.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  50 training error:  tensor(26708.9590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  60 training error:  tensor(7170.6870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  70 training error:  tensor(6755.2471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  80 training error:  tensor(5670.2236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
	 epoch  90 training error:  tensor(4503.6470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.96337890625
Memory cached:  170.0
[I 2023-12-04 21:20:32,177] Trial 21 finished with value: 4476.05810546875 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -4.46886210569088, 'log_learning_rate_D': -2.2252652512591045, 'training_batch_size': 7, 'training_p': 4}. Best is trial 10 with value: 7.686084270477295.
Time for this trial:  82.97718143463135
Memory status after this trial: 
Memory allocated:  178.89208984375
Memory cached:  198.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.3095132636356395, 'log_learning_rate_D': -3.170984545768266, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(346.3628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  170.0
	 epoch  10 training error:  tensor(174.2089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  20 training error:  tensor(46.4886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  30 training error:  tensor(15.5883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  40 training error:  tensor(3.5162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  50 training error:  tensor(3.5932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  60 training error:  tensor(2.6757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  70 training error:  tensor(4.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  80 training error:  tensor(2.0992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
	 epoch  90 training error:  tensor(2.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  97.67822265625
Memory cached:  172.0
[I 2023-12-04 21:21:28,008] Trial 22 finished with value: 3.9679219722747803 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.3095132636356395, 'log_learning_rate_D': -3.170984545768266, 'training_batch_size': 10, 'training_p': 6}. Best is trial 22 with value: 3.9679219722747803.
res:  tensor(3.9679, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(7.6861, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  55.649335861206055
Memory status after this trial: 
Memory allocated:  115.2041015625
Memory cached:  208.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.5269041173905515, 'log_learning_rate_D': -1.2319138857075802, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(450.5875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
[W 2023-12-04 21:21:31,027] Trial 23 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.5269041173905515, 'log_learning_rate_D': -1.2319138857075802, 'training_batch_size': 10, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:21:31,027] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8419504165649414
Memory status after this trial: 
Memory allocated:  279.82861328125
Memory cached:  300.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.499838614845819, 'log_learning_rate_D': -3.2066561034455336, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(479.4980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  10 training error:  tensor(158.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  20 training error:  tensor(77.3387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  30 training error:  tensor(42.9087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  40 training error:  tensor(16.0337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  50 training error:  tensor(11.2419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  60 training error:  tensor(3.4427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  70 training error:  tensor(2.1745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  80 training error:  tensor(4.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
	 epoch  90 training error:  tensor(2.6297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.31591796875
Memory cached:  230.0
[I 2023-12-04 21:22:32,034] Trial 24 finished with value: 3.1439833641052246 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.499838614845819, 'log_learning_rate_D': -3.2066561034455336, 'training_batch_size': 10, 'training_p': 4}. Best is trial 24 with value: 3.1439833641052246.
res:  tensor(3.1440, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(3.9679, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  60.817816972732544
Memory status after this trial: 
Memory allocated:  164.625
Memory cached:  246.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.350276451476643, 'log_learning_rate_D': -3.0001487982519692, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(512.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  10 training error:  tensor(19.6115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  20 training error:  tensor(33.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  30 training error:  tensor(5.6174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  40 training error:  tensor(20.8438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  50 training error:  tensor(9.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  60 training error:  tensor(3.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  70 training error:  tensor(13.8351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  80 training error:  tensor(12.3131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
	 epoch  90 training error:  tensor(14.9155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  177.87744140625
Memory cached:  248.0
[I 2023-12-04 21:23:34,924] Trial 25 finished with value: 20.48334312438965 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.350276451476643, 'log_learning_rate_D': -3.0001487982519692, 'training_batch_size': 11, 'training_p': 2}. Best is trial 24 with value: 3.1439833641052246.
Time for this trial:  62.70429849624634
Memory status after this trial: 
Memory allocated:  340.92138671875
Memory cached:  356.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.491111572305566, 'log_learning_rate_D': -3.1888888667913315, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(506.0771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  10 training error:  tensor(354.7259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  20 training error:  tensor(162.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  30 training error:  tensor(54.3137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  40 training error:  tensor(17.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  50 training error:  tensor(13.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  60 training error:  tensor(7.2978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  70 training error:  tensor(5.7608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  80 training error:  tensor(7.5219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
	 epoch  90 training error:  tensor(4.4263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  175.02783203125
Memory cached:  248.0
[I 2023-12-04 21:24:38,024] Trial 26 finished with value: 8.430461883544922 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.491111572305566, 'log_learning_rate_D': -3.1888888667913315, 'training_batch_size': 10, 'training_p': 6}. Best is trial 24 with value: 3.1439833641052246.
Time for this trial:  62.91063570976257
Memory status after this trial: 
Memory allocated:  359.71142578125
Memory cached:  382.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.8492764227369802, 'log_learning_rate_D': -1.2769199033075487, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(450.1659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  248.0
[W 2023-12-04 21:24:41,168] Trial 27 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.8492764227369802, 'log_learning_rate_D': -1.2769199033075487, 'training_batch_size': 10, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:24:41,169] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.957453489303589
Memory status after this trial: 
Memory allocated:  245.90283203125
Memory cached:  264.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.811875931613126, 'log_learning_rate_D': -1.0595939056682377, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(468.6483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.99462890625
Memory cached:  248.0
[W 2023-12-04 21:24:44,269] Trial 28 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.811875931613126, 'log_learning_rate_D': -1.0595939056682377, 'training_batch_size': 10, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:24:44,269] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.9181411266326904
Memory status after this trial: 
Memory allocated:  258.65478515625
Memory cached:  278.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.797306312606664, 'log_learning_rate_D': -1.3689709278445505, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(446.5508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  248.0
[W 2023-12-04 21:24:47,310] Trial 29 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.797306312606664, 'log_learning_rate_D': -1.3689709278445505, 'training_batch_size': 10, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:24:47,311] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8667733669281006
Memory status after this trial: 
Memory allocated:  245.90283203125
Memory cached:  264.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.827711294572228, 'log_learning_rate_D': -4.223178073800677, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(410.6500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  248.0
	 epoch  10 training error:  tensor(133.6437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  20 training error:  tensor(51.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  30 training error:  tensor(29.4591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  40 training error:  tensor(7.9821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  50 training error:  tensor(22.6416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  60 training error:  tensor(9.1486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  70 training error:  tensor(7.5874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  80 training error:  tensor(9.8406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
	 epoch  90 training error:  tensor(3.9708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.92822265625
Memory cached:  250.0
[I 2023-12-04 21:25:40,557] Trial 30 finished with value: 5.3445563316345215 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.827711294572228, 'log_learning_rate_D': -4.223178073800677, 'training_batch_size': 10, 'training_p': 3}. Best is trial 24 with value: 3.1439833641052246.
Time for this trial:  53.05153727531433
Memory status after this trial: 
Memory allocated:  245.90283203125
Memory cached:  264.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.550094847607202, 'log_learning_rate_D': -1.166429585291107, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(417.9599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  248.0
[W 2023-12-04 21:25:43,202] Trial 31 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.550094847607202, 'log_learning_rate_D': -1.166429585291107, 'training_batch_size': 12, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:25:43,202] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.435784101486206
Memory status after this trial: 
Memory allocated:  379.51171875
Memory cached:  404.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.9748853388565504, 'log_learning_rate_D': -3.230720174931236, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(577.8470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  248.0
	 epoch  10 training error:  tensor(17.5875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  20 training error:  tensor(25.5688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  30 training error:  tensor(50.1505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  40 training error:  tensor(40.5541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  50 training error:  tensor(7.3449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  60 training error:  tensor(15.0434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  70 training error:  tensor(4.3549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  80 training error:  tensor(28.5537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
	 epoch  90 training error:  tensor(7.5022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  178.46142578125
Memory cached:  250.0
[I 2023-12-04 21:26:52,081] Trial 32 finished with value: 1.2454394102096558 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.9748853388565504, 'log_learning_rate_D': -3.230720174931236, 'training_batch_size': 12, 'training_p': 5}. Best is trial 32 with value: 1.2454394102096558.
res:  tensor(1.2454, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(3.1440, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  68.6797776222229
Memory status after this trial: 
Memory allocated:  214.88720703125
Memory cached:  342.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.5955347472581316, 'log_learning_rate_D': -4.19928849323151, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(289.9463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  10 training error:  tensor(110.8909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  20 training error:  tensor(29.7516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  30 training error:  tensor(57.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  40 training error:  tensor(11.5961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  50 training error:  tensor(2.9468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  60 training error:  tensor(31.4167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  70 training error:  tensor(7.2260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  80 training error:  tensor(3.5127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
	 epoch  90 training error:  tensor(10.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  225.4267578125
Memory cached:  344.0
[I 2023-12-04 21:27:57,963] Trial 33 finished with value: 6.983907222747803 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.5955347472581316, 'log_learning_rate_D': -4.19928849323151, 'training_batch_size': 12, 'training_p': 3}. Best is trial 32 with value: 1.2454394102096558.
Time for this trial:  65.68792462348938
Memory status after this trial: 
Memory allocated:  399.60498046875
Memory cached:  406.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.8277675198052745, 'log_learning_rate_D': -2.021081537169295, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(427.5525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  10 training error:  tensor(20.7969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  20 training error:  tensor(32.5941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:15,579] Trial 34 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.8277675198052745, 'log_learning_rate_D': -2.021081537169295, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:15,580] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  17.397680521011353
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.697705357204568, 'log_learning_rate_D': -1.3029650627340366, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(508.4058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:18,550] Trial 35 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.697705357204568, 'log_learning_rate_D': -1.3029650627340366, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:18,550] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.765606641769409
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7886493538312345, 'log_learning_rate_D': -2.0599681521017175, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(423.1353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  10 training error:  tensor(13.0250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:27,544] Trial 36 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7886493538312345, 'log_learning_rate_D': -2.0599681521017175, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:27,545] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.790263175964355
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.8732209167736826, 'log_learning_rate_D': -2.014030070858118, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(401.9360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  10 training error:  tensor(47.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  20 training error:  tensor(53.1935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:44,430] Trial 37 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.8732209167736826, 'log_learning_rate_D': -2.014030070858118, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:44,432] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  16.672311782836914
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6339646136280783, 'log_learning_rate_D': -1.1026772991496796, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(473.7850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:46,741] Trial 38 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6339646136280783, 'log_learning_rate_D': -1.1026772991496796, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:46,742] Trial 38 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0897762775421143
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.756142903523329, 'log_learning_rate_D': -1.0979750594065179, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(542.2302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:49,125] Trial 39 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.756142903523329, 'log_learning_rate_D': -1.0979750594065179, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:49,126] Trial 39 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.179921865463257
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6393218652345567, 'log_learning_rate_D': -1.1155012401321045, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(366.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:51,448] Trial 40 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6393218652345567, 'log_learning_rate_D': -1.1155012401321045, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:51,449] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1335887908935547
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7632919885846814, 'log_learning_rate_D': -1.0237763401836104, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(493.8396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:53,857] Trial 41 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7632919885846814, 'log_learning_rate_D': -1.0237763401836104, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:53,858] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2056472301483154
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.85512885651568, 'log_learning_rate_D': -1.0419435752502726, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(474.2909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:56,222] Trial 42 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.85512885651568, 'log_learning_rate_D': -1.0419435752502726, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:56,223] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1567068099975586
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.832688245891992, 'log_learning_rate_D': -1.046151478432384, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(438.8800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:28:58,542] Trial 43 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.832688245891992, 'log_learning_rate_D': -1.046151478432384, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:28:58,543] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1142773628234863
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.747355487425143, 'log_learning_rate_D': -2.042157004403471, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(448.7712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
	 epoch  10 training error:  tensor(72.8494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:11,186] Trial 44 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.747355487425143, 'log_learning_rate_D': -2.042157004403471, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:11,187] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  12.44325065612793
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7054082087275786, 'log_learning_rate_D': -1.0364605684538355, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(361.9335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:13,475] Trial 45 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7054082087275786, 'log_learning_rate_D': -1.0364605684538355, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:13,476] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0852060317993164
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7488325142943912, 'log_learning_rate_D': -1.2349401754424778, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(436.4297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:15,719] Trial 46 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7488325142943912, 'log_learning_rate_D': -1.2349401754424778, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:15,720] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0562572479248047
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.652883303421919, 'log_learning_rate_D': -1.0649101806373444, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(466.7940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:18,043] Trial 47 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.652883303421919, 'log_learning_rate_D': -1.0649101806373444, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:18,044] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1313345432281494
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7386154465069934, 'log_learning_rate_D': -1.2749659749546787, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(445.5527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:20,372] Trial 48 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.7386154465069934, 'log_learning_rate_D': -1.2749659749546787, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:20,373] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.124762773513794
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.816728965642914, 'log_learning_rate_D': -1.276301450022304, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(447.4362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  224.0615234375
Memory cached:  344.0
[W 2023-12-04 21:29:22,723] Trial 49 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.816728965642914, 'log_learning_rate_D': -1.276301450022304, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-04 21:29:22,724] Trial 49 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1580629348754883
Memory status after this trial: 
Memory allocated:  349.154296875
Memory cached:  356.0
