/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-06 11:25:40,794] A new study created in memory with name: no-name-887f677c-bf4f-4027-9448-e34d377677e5
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1204_smallDRS_Burigede.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.4176362612597537, 'log_learning_rate_D': -4.024045710103833, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.5526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.4721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.4654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.21484375
Memory cached:  10.0
[I 2023-12-06 11:26:15,321] Trial 0 finished with value: 0.3219096064567566 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.4176362612597537, 'log_learning_rate_D': -4.024045710103833, 'training_batch_size': 12, 'training_p': 8}. Best is trial 0 with value: 0.3219096064567566.
res:  tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  34.436261892318726
Memory status after this trial: 
Memory allocated:  10.1416015625
Memory cached:  12.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.991790144779612, 'log_learning_rate_D': -3.498054533321168, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  10 training error:  tensor(0.8083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.7306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  30 training error:  tensor(0.6545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.5866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  50 training error:  tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  60 training error:  tensor(0.4988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  70 training error:  tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
	 epoch  90 training error:  tensor(0.4298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.83837890625
Memory cached:  68.0
[I 2023-12-06 11:27:12,071] Trial 1 finished with value: 0.3079459071159363 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.991790144779612, 'log_learning_rate_D': -3.498054533321168, 'training_batch_size': 11, 'training_p': 8}. Best is trial 1 with value: 0.3079459071159363.
res:  tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  56.66471719741821
Memory status after this trial: 
Memory allocated:  153.10595703125
Memory cached:  180.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.3755972317117053, 'log_learning_rate_D': -3.386941661611516, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  10 training error:  tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  20 training error:  tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  30 training error:  tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  40 training error:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  50 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  60 training error:  tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  70 training error:  tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  80 training error:  tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
	 epoch  90 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  158.513671875
Memory cached:  182.0
[I 2023-12-06 11:27:51,990] Trial 2 finished with value: 0.17534096539020538 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.3755972317117053, 'log_learning_rate_D': -3.386941661611516, 'training_batch_size': 7, 'training_p': 2}. Best is trial 2 with value: 0.17534096539020538.
res:  tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  39.83426284790039
Memory status after this trial: 
Memory allocated:  48.51416015625
Memory cached:  176.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.5798241691764505, 'log_learning_rate_D': -3.8631308198004017, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  178.0
	 epoch  10 training error:  tensor(1.3548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.7129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.7089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.7365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.6783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.759765625
Memory cached:  180.0
[I 2023-12-06 11:28:41,307] Trial 3 finished with value: 0.36627742648124695 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.5798241691764505, 'log_learning_rate_D': -3.8631308198004017, 'training_batch_size': 8, 'training_p': 2}. Best is trial 2 with value: 0.17534096539020538.
Time for this trial:  49.20996046066284
Memory status after this trial: 
Memory allocated:  120.1240234375
Memory cached:  180.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.937395324345879, 'log_learning_rate_D': -4.769658860840423, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  178.0
	 epoch  10 training error:  tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  20 training error:  tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  30 training error:  tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  40 training error:  tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  50 training error:  tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  60 training error:  tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  70 training error:  tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  80 training error:  tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
	 epoch  90 training error:  tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.767578125
Memory cached:  182.0
[I 2023-12-06 11:29:33,408] Trial 4 finished with value: 0.3375468850135803 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.937395324345879, 'log_learning_rate_D': -4.769658860840423, 'training_batch_size': 8, 'training_p': 3}. Best is trial 2 with value: 0.17534096539020538.
Time for this trial:  51.981762647628784
Memory status after this trial: 
Memory allocated:  120.146484375
Memory cached:  180.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.391695779056728, 'log_learning_rate_D': -1.9051298107571562, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.2890625
Memory cached:  180.0
[I 2023-12-06 11:30:24,923] Trial 5 finished with value: 0.1626095026731491 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.391695779056728, 'log_learning_rate_D': -1.9051298107571562, 'training_batch_size': 10, 'training_p': 2}. Best is trial 5 with value: 0.1626095026731491.
res:  tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  51.410744428634644
Memory status after this trial: 
Memory allocated:  105.943359375
Memory cached:  156.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.3644577991379077, 'log_learning_rate_D': -4.1234308598135705, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  10 training error:  tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  20 training error:  tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  30 training error:  tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  40 training error:  tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  50 training error:  tensor(0.4570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  60 training error:  tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  70 training error:  tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  80 training error:  tensor(0.4464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
	 epoch  90 training error:  tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  106.45263671875
Memory cached:  158.0
[I 2023-12-06 11:31:02,038] Trial 6 finished with value: 0.3406122028827667 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.3644577991379077, 'log_learning_rate_D': -4.1234308598135705, 'training_batch_size': 10, 'training_p': 7}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  37.020803689956665
Memory status after this trial: 
Memory allocated:  122.79443359375
Memory cached:  156.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.0571831818844282, 'log_learning_rate_D': -1.0111273979242066, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(17.8840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.37744140625
Memory cached:  176.0
[W 2023-12-06 11:31:03,940] Trial 7 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -1.0571831818844282, 'log_learning_rate_D': -1.0111273979242066, 'training_batch_size': 6, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:31:03,942] Trial 7 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7827811241149902
Memory status after this trial: 
Memory allocated:  166.5185546875
Memory cached:  184.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.674415041915376, 'log_learning_rate_D': -2.1482662674580117, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  158.0
	 epoch  10 training error:  tensor(0.9615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
	 epoch  20 training error:  tensor(0.8801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
	 epoch  30 training error:  tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
	 epoch  40 training error:  tensor(0.7037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
	 epoch  50 training error:  tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
	 epoch  60 training error:  tensor(0.6501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.21240234375
Memory cached:  160.0
[W 2023-12-06 11:31:42,242] Trial 8 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.674415041915376, 'log_learning_rate_D': -2.1482662674580117, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:31:42,243] Trial 8 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  38.20166778564453
Memory status after this trial: 
Memory allocated:  186.6826171875
Memory cached:  192.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8972480612532747, 'log_learning_rate_D': -4.465808698881273, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  158.0
	 epoch  10 training error:  tensor(0.5318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.3996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.3816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.3767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.3737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.01123046875
Memory cached:  162.0
[I 2023-12-06 11:32:42,671] Trial 9 finished with value: 0.3381420075893402 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8972480612532747, 'log_learning_rate_D': -4.465808698881273, 'training_batch_size': 10, 'training_p': 2}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  60.3047137260437
Memory status after this trial: 
Memory allocated:  199.65625
Memory cached:  208.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -4.450082375995593, 'log_learning_rate_D': -2.158063237211555, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  160.0
	 epoch  10 training error:  tensor(0.8515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.7507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.6617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.5801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.37255859375
Memory cached:  162.0
[I 2023-12-06 11:33:22,753] Trial 10 finished with value: 0.3367895483970642 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -4.450082375995593, 'log_learning_rate_D': -2.158063237211555, 'training_batch_size': 10, 'training_p': 7}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  39.98499941825867
Memory status after this trial: 
Memory allocated:  141.3115234375
Memory cached:  160.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.614430837728721, 'log_learning_rate_D': -4.878686194116721, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  20 training error:  tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  30 training error:  tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  40 training error:  tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  50 training error:  tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  60 training error:  tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  70 training error:  tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  80 training error:  tensor(0.3466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
	 epoch  90 training error:  tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.04833984375
Memory cached:  176.0
[I 2023-12-06 11:34:01,038] Trial 11 finished with value: 0.3242749273777008 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.614430837728721, 'log_learning_rate_D': -4.878686194116721, 'training_batch_size': 7, 'training_p': 2}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  38.17970824241638
Memory status after this trial: 
Memory allocated:  167.5908203125
Memory cached:  188.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8475819274774046, 'log_learning_rate_D': -1.3320522297922641, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.80810546875
Memory cached:  160.0
[W 2023-12-06 11:34:03,196] Trial 12 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8475819274774046, 'log_learning_rate_D': -1.3320522297922641, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:03,197] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9923045635223389
Memory status after this trial: 
Memory allocated:  226.68408203125
Memory cached:  232.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9581887507434685, 'log_learning_rate_D': -1.3232561153236604, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:34:05,889] Trial 13 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9581887507434685, 'log_learning_rate_D': -1.3232561153236604, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:05,889] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.477477788925171
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8136602643473045, 'log_learning_rate_D': -1.0752610200950397, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:08,178] Trial 14 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8136602643473045, 'log_learning_rate_D': -1.0752610200950397, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:08,178] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.090579032897949
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8318510018931375, 'log_learning_rate_D': -1.199427204183202, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:10,437] Trial 15 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8318510018931375, 'log_learning_rate_D': -1.199427204183202, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:10,438] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0869667530059814
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7359427917453294, 'log_learning_rate_D': -1.0603677626558499, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.3990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.12060546875
Memory cached:  180.0
[W 2023-12-06 11:34:13,240] Trial 16 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7359427917453294, 'log_learning_rate_D': -1.0603677626558499, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:13,241] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.6164233684539795
Memory status after this trial: 
Memory allocated:  230.8251953125
Memory cached:  246.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7534358066939966, 'log_learning_rate_D': -1.0574651002191446, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:34:15,425] Trial 17 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7534358066939966, 'log_learning_rate_D': -1.0574651002191446, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:15,426] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.996103286743164
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7629513700147665, 'log_learning_rate_D': -1.0658776980794635, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.34326171875
Memory cached:  160.0
[W 2023-12-06 11:34:19,192] Trial 18 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.7629513700147665, 'log_learning_rate_D': -1.0658776980794635, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:19,193] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.5701498985290527
Memory status after this trial: 
Memory allocated:  200.16845703125
Memory cached:  202.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9831015384692106, 'log_learning_rate_D': -1.0655184386684686, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.41162109375
Memory cached:  180.0
[W 2023-12-06 11:34:21,465] Trial 19 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9831015384692106, 'log_learning_rate_D': -1.0655184386684686, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:21,466] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.084921360015869
Memory status after this trial: 
Memory allocated:  220.751953125
Memory cached:  238.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8473892774714056, 'log_learning_rate_D': -1.096257454814726, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:34:23,659] Trial 20 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8473892774714056, 'log_learning_rate_D': -1.096257454814726, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:23,660] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0185859203338623
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7988613404209945, 'log_learning_rate_D': -1.0946580871011127, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.80810546875
Memory cached:  160.0
[W 2023-12-06 11:34:25,877] Trial 21 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7988613404209945, 'log_learning_rate_D': -1.0946580871011127, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:25,878] Trial 21 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0302040576934814
Memory status after this trial: 
Memory allocated:  226.68408203125
Memory cached:  232.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.870961075963743, 'log_learning_rate_D': -1.0417577027975626, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.79638671875
Memory cached:  178.0
[W 2023-12-06 11:34:28,044] Trial 22 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.870961075963743, 'log_learning_rate_D': -1.0417577027975626, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:28,045] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9787898063659668
Memory status after this trial: 
Memory allocated:  256.1611328125
Memory cached:  274.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.820768177163888, 'log_learning_rate_D': -1.1281105622715841, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:30,201] Trial 23 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.820768177163888, 'log_learning_rate_D': -1.1281105622715841, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:30,202] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9639980792999268
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.92579903579464, 'log_learning_rate_D': -1.080057779340243, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.57373046875
Memory cached:  200.0
[W 2023-12-06 11:34:32,477] Trial 24 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.92579903579464, 'log_learning_rate_D': -1.080057779340243, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:32,478] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.089674472808838
Memory status after this trial: 
Memory allocated:  286.81787109375
Memory cached:  316.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8207821879823483, 'log_learning_rate_D': -1.299188981684386, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:34,722] Trial 25 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8207821879823483, 'log_learning_rate_D': -1.299188981684386, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:34,723] Trial 25 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.052361011505127
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.857009596407044, 'log_learning_rate_D': -1.3761581928473658, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.80615234375
Memory cached:  202.0
[W 2023-12-06 11:34:36,817] Trial 26 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.857009596407044, 'log_learning_rate_D': -1.3761581928473658, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:36,818] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9168870449066162
Memory status after this trial: 
Memory allocated:  262.26416015625
Memory cached:  290.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8591219317460377, 'log_learning_rate_D': -1.0359349268167444, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:39,150] Trial 27 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8591219317460377, 'log_learning_rate_D': -1.0359349268167444, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:39,151] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.139493227005005
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.827560235661627, 'log_learning_rate_D': -1.037146997406207, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:34:41,314] Trial 28 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.827560235661627, 'log_learning_rate_D': -1.037146997406207, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:41,315] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9758789539337158
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.011276912501216, 'log_learning_rate_D': -1.0966530146172901, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  141.24365234375
Memory cached:  200.0
[W 2023-12-06 11:34:43,622] Trial 29 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.011276912501216, 'log_learning_rate_D': -1.0966530146172901, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:43,622] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1284947395324707
Memory status after this trial: 
Memory allocated:  256.2890625
Memory cached:  284.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9407454688839545, 'log_learning_rate_D': -1.1277176735486378, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:45,904] Trial 30 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9407454688839545, 'log_learning_rate_D': -1.1277176735486378, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:45,905] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0833539962768555
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.0026265742484108, 'log_learning_rate_D': -1.010893991053988, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:48,132] Trial 31 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.0026265742484108, 'log_learning_rate_D': -1.010893991053988, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:48,133] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0294623374938965
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9921897108904068, 'log_learning_rate_D': -1.3419231022042108, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.81787109375
Memory cached:  200.0
[W 2023-12-06 11:34:50,568] Trial 32 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9921897108904068, 'log_learning_rate_D': -1.3419231022042108, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:50,569] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2274885177612305
Memory status after this trial: 
Memory allocated:  288.2099609375
Memory cached:  318.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.768424369902261, 'log_learning_rate_D': -1.0595867739602474, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:52,775] Trial 33 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.768424369902261, 'log_learning_rate_D': -1.0595867739602474, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:52,776] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0148673057556152
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8701848804002283, 'log_learning_rate_D': -1.2610233514286175, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:34:55,016] Trial 34 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8701848804002283, 'log_learning_rate_D': -1.2610233514286175, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:55,016] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0517420768737793
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8968833687383078, 'log_learning_rate_D': -1.6098718391033189, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.82177734375
Memory cached:  198.0
[W 2023-12-06 11:34:57,798] Trial 35 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8968833687383078, 'log_learning_rate_D': -1.6098718391033189, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:34:57,799] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.5954551696777344
Memory status after this trial: 
Memory allocated:  263.44384765625
Memory cached:  292.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9043960838395653, 'log_learning_rate_D': -1.0607572024463143, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.04443359375
Memory cached:  180.0
[W 2023-12-06 11:35:00,089] Trial 36 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.9043960838395653, 'log_learning_rate_D': -1.0607572024463143, 'training_batch_size': 12, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:35:00,089] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.092907428741455
Memory status after this trial: 
Memory allocated:  232.787109375
Memory cached:  250.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8190180556379008, 'log_learning_rate_D': -1.4022955046687713, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  10 training error:  tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  20 training error:  tensor(0.6393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  30 training error:  tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  40 training error:  tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  50 training error:  tensor(0.5605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  60 training error:  tensor(0.5437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  70 training error:  tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  80 training error:  tensor(0.5348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
	 epoch  90 training error:  tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.46240234375
Memory cached:  160.0
[I 2023-12-06 11:35:57,448] Trial 37 finished with value: 0.47321873903274536 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8190180556379008, 'log_learning_rate_D': -1.4022955046687713, 'training_batch_size': 12, 'training_p': 4}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  57.158522605895996
Memory status after this trial: 
Memory allocated:  211.50732421875
Memory cached:  214.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.1330533090896657, 'log_learning_rate_D': -2.8485525187092744, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.6158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.7282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.4298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.89111328125
Memory cached:  162.0
[I 2023-12-06 11:37:20,083] Trial 38 finished with value: 0.4600546956062317 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.1330533090896657, 'log_learning_rate_D': -2.8485525187092744, 'training_batch_size': 6, 'training_p': 5}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  82.4621889591217
Memory status after this trial: 
Memory allocated:  240.84375
Memory cached:  248.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.0787168416044728, 'log_learning_rate_D': -2.7794660202237615, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  10 training error:  tensor(1592.8303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  20 training error:  tensor(87.0939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  30 training error:  tensor(34.0240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  40 training error:  tensor(25.1272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  50 training error:  tensor(32.1071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  60 training error:  tensor(39.6099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  70 training error:  tensor(46.5168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  80 training error:  tensor(51.5943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
	 epoch  90 training error:  tensor(50.3489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.96630859375
Memory cached:  158.0
[I 2023-12-06 11:38:01,670] Trial 39 finished with value: 60.33402633666992 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.0787168416044728, 'log_learning_rate_D': -2.7794660202237615, 'training_batch_size': 8, 'training_p': 4}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  41.44206237792969
Memory status after this trial: 
Memory allocated:  162.4970703125
Memory cached:  166.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.972964641393599, 'log_learning_rate_D': -1.0871392549580725, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  114.89111328125
Memory cached:  176.0
[W 2023-12-06 11:38:04,347] Trial 40 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.972964641393599, 'log_learning_rate_D': -1.0871392549580725, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:38:04,348] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4928178787231445
Memory status after this trial: 
Memory allocated:  173.31201171875
Memory cached:  190.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.9899973543749603, 'log_learning_rate_D': -2.1850312150511435, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  10 training error:  tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  20 training error:  tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  30 training error:  tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  40 training error:  tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  60 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  70 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  80 training error:  tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
	 epoch  90 training error:  tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.16064453125
Memory cached:  178.0
[I 2023-12-06 11:39:19,173] Trial 41 finished with value: 0.17116914689540863 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.9899973543749603, 'log_learning_rate_D': -2.1850312150511435, 'training_batch_size': 6, 'training_p': 3}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  74.63891530036926
Memory status after this trial: 
Memory allocated:  196.15185546875
Memory cached:  214.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.050117061412371, 'log_learning_rate_D': -1.8620275246171458, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  178.0
	 epoch  10 training error:  tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.55615234375
Memory cached:  180.0
[W 2023-12-06 11:39:50,030] Trial 42 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.050117061412371, 'log_learning_rate_D': -1.8620275246171458, 'training_batch_size': 9, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:39:50,031] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  30.675300359725952
Memory status after this trial: 
Memory allocated:  211.16357421875
Memory cached:  230.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.0008394173710835, 'log_learning_rate_D': -1.881067737710546, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.52490234375
Memory cached:  180.0
[I 2023-12-06 11:40:42,991] Trial 43 finished with value: 0.3260714113712311 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.0008394173710835, 'log_learning_rate_D': -1.881067737710546, 'training_batch_size': 9, 'training_p': 4}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  52.776777029037476
Memory status after this trial: 
Memory allocated:  209.69775390625
Memory cached:  228.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.149473144541422, 'log_learning_rate_D': -1.1009130733837424, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.3333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:40:45,230] Trial 44 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.149473144541422, 'log_learning_rate_D': -1.1009130733837424, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:45,231] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.023817300796509
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.093302375861381, 'log_learning_rate_D': -1.0933813046196421, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(15035.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:40:47,438] Trial 45 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.093302375861381, 'log_learning_rate_D': -1.0933813046196421, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:47,440] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.025353193283081
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.126001934120625, 'log_learning_rate_D': -1.1826278345720667, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.8782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.39892578125
Memory cached:  162.0
[W 2023-12-06 11:40:49,636] Trial 46 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.126001934120625, 'log_learning_rate_D': -1.1826278345720667, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:49,637] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.017780065536499
Memory status after this trial: 
Memory allocated:  196.12744140625
Memory cached:  202.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.137952119804272, 'log_learning_rate_D': -1.2023133224045406, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.39892578125
Memory cached:  162.0
[W 2023-12-06 11:40:51,787] Trial 47 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.137952119804272, 'log_learning_rate_D': -1.2023133224045406, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:51,788] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9612696170806885
Memory status after this trial: 
Memory allocated:  196.12744140625
Memory cached:  202.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.199261670206523, 'log_learning_rate_D': -1.0233302573845369, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:40:54,077] Trial 48 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.199261670206523, 'log_learning_rate_D': -1.0233302573845369, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:54,078] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0959584712982178
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2298171902543924, 'log_learning_rate_D': -1.0031187147825968, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.45654296875
Memory cached:  164.0
[W 2023-12-06 11:40:56,146] Trial 49 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2298171902543924, 'log_learning_rate_D': -1.0031187147825968, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:56,147] Trial 49 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8630237579345703
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2259060137372497, 'log_learning_rate_D': -1.2832875556946337, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:40:59,217] Trial 50 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2259060137372497, 'log_learning_rate_D': -1.2832875556946337, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:40:59,219] Trial 50 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.866455316543579
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.111011565942482, 'log_learning_rate_D': -1.2358466869396405, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
[W 2023-12-06 11:41:01,194] Trial 51 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.111011565942482, 'log_learning_rate_D': -1.2358466869396405, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:01,195] Trial 51 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.756356954574585
Memory status after this trial: 
Memory allocated:  168.99267578125
Memory cached:  174.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2819421179582924, 'log_learning_rate_D': -1.046206909869742, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(3306855.7500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.54150390625
Memory cached:  162.0
[W 2023-12-06 11:41:03,524] Trial 52 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2819421179582924, 'log_learning_rate_D': -1.046206909869742, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:03,525] Trial 52 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1368720531463623
Memory status after this trial: 
Memory allocated:  202.58935546875
Memory cached:  210.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1609472146500903, 'log_learning_rate_D': -1.0536344182650668, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:05,778] Trial 53 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1609472146500903, 'log_learning_rate_D': -1.0536344182650668, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:05,779] Trial 53 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0409677028656006
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.134514559033854, 'log_learning_rate_D': -1.2155914202589142, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:08,091] Trial 54 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.134514559033854, 'log_learning_rate_D': -1.2155914202589142, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:08,092] Trial 54 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.085468292236328
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.143950661220588, 'log_learning_rate_D': -1.274404381918205, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:10,337] Trial 55 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.143950661220588, 'log_learning_rate_D': -1.274404381918205, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:10,338] Trial 55 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0528676509857178
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1454215918065054, 'log_learning_rate_D': -1.1503968112935694, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:12,608] Trial 56 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1454215918065054, 'log_learning_rate_D': -1.1503968112935694, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:12,608] Trial 56 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.083526372909546
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.177378735936124, 'log_learning_rate_D': -1.344745401680806, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.36181640625
Memory cached:  162.0
[W 2023-12-06 11:41:14,826] Trial 57 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.177378735936124, 'log_learning_rate_D': -1.344745401680806, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:14,827] Trial 57 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0296578407287598
Memory status after this trial: 
Memory allocated:  197.07958984375
Memory cached:  204.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.144499077872818, 'log_learning_rate_D': -1.0383374825472242, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3751e+08, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.41650390625
Memory cached:  160.0
[W 2023-12-06 11:41:17,080] Trial 58 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.144499077872818, 'log_learning_rate_D': -1.0383374825472242, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:17,081] Trial 58 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0537827014923096
Memory status after this trial: 
Memory allocated:  187.43505859375
Memory cached:  194.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2158717404141077, 'log_learning_rate_D': -1.0550515755797671, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:19,341] Trial 59 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2158717404141077, 'log_learning_rate_D': -1.0550515755797671, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:19,342] Trial 59 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0659096240997314
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2085825604055405, 'log_learning_rate_D': -1.05345699380713, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:21,497] Trial 60 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.2085825604055405, 'log_learning_rate_D': -1.05345699380713, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:21,498] Trial 60 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.966174840927124
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1645178057241483, 'log_learning_rate_D': -1.1276269073502825, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:23,658] Trial 61 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1645178057241483, 'log_learning_rate_D': -1.1276269073502825, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:23,659] Trial 61 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.967052936553955
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1242873949658514, 'log_learning_rate_D': -1.0312635345051464, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:25,740] Trial 62 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1242873949658514, 'log_learning_rate_D': -1.0312635345051464, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:25,740] Trial 62 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8842873573303223
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.154836240347463, 'log_learning_rate_D': -1.1040685236346306, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.6647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:28,029] Trial 63 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.154836240347463, 'log_learning_rate_D': -1.1040685236346306, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:28,029] Trial 63 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.092233419418335
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.019210831130018, 'log_learning_rate_D': -1.0041687928023217, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.45654296875
Memory cached:  164.0
[W 2023-12-06 11:41:30,158] Trial 64 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.019210831130018, 'log_learning_rate_D': -1.0041687928023217, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:30,159] Trial 64 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9464421272277832
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1493260155374037, 'log_learning_rate_D': -1.0413422308009368, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:32,346] Trial 65 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1493260155374037, 'log_learning_rate_D': -1.0413422308009368, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:32,347] Trial 65 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.994173288345337
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.094669079452614, 'log_learning_rate_D': -1.0560517820145674, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(6.5853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:34,594] Trial 66 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.094669079452614, 'log_learning_rate_D': -1.0560517820145674, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:34,595] Trial 66 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.054941177368164
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.1247275082546526, 'log_learning_rate_D': -1.2824312752444382, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  115.52587890625
Memory cached:  160.0
[W 2023-12-06 11:41:36,813] Trial 67 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.1247275082546526, 'log_learning_rate_D': -1.2824312752444382, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:36,814] Trial 67 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0112216472625732
Memory status after this trial: 
Memory allocated:  189.97998046875
Memory cached:  196.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.078564892460617, 'log_learning_rate_D': -1.051463589548941, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:39,029] Trial 68 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.078564892460617, 'log_learning_rate_D': -1.051463589548941, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:39,030] Trial 68 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0329504013061523
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.18237178367686, 'log_learning_rate_D': -1.265244484824226, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:41,320] Trial 69 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.18237178367686, 'log_learning_rate_D': -1.265244484824226, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:41,321] Trial 69 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0964910984039307
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.043581109244607, 'log_learning_rate_D': -1.0452032935883593, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(3321.1470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.54150390625
Memory cached:  162.0
[W 2023-12-06 11:41:43,522] Trial 70 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.043581109244607, 'log_learning_rate_D': -1.0452032935883593, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:43,523] Trial 70 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.011991500854492
Memory status after this trial: 
Memory allocated:  202.58935546875
Memory cached:  210.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1607768234189275, 'log_learning_rate_D': -1.0253888284917996, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(7.6510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:45,670] Trial 71 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1607768234189275, 'log_learning_rate_D': -1.0253888284917996, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:45,671] Trial 71 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.939826250076294
Memory status after this trial: 
Memory allocated:  200.04443359375
Memory cached:  206.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1047789538750186, 'log_learning_rate_D': -1.189487052730487, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.91650390625
Memory cached:  162.0
[W 2023-12-06 11:41:47,821] Trial 72 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.1047789538750186, 'log_learning_rate_D': -1.189487052730487, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:47,821] Trial 72 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9508898258209229
Memory status after this trial: 
Memory allocated:  199.05419921875
Memory cached:  206.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.278906050680025, 'log_learning_rate_D': -1.1502771925862814, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  116.43212890625
Memory cached:  162.0
[W 2023-12-06 11:41:49,984] Trial 73 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.278906050680025, 'log_learning_rate_D': -1.1502771925862814, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:41:49,984] Trial 73 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9698584079742432
Memory status after this trial: 
Memory allocated:  198.07958984375
Memory cached:  204.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.172921507838367, 'log_learning_rate_D': -2.2432703617212866, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  10 training error:  tensor(0.4403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  20 training error:  tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  30 training error:  tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  40 training error:  tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  50 training error:  tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  60 training error:  tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  70 training error:  tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  80 training error:  tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
	 epoch  90 training error:  tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  113.33642578125
Memory cached:  160.0
[I 2023-12-06 11:43:10,437] Trial 74 finished with value: 0.20928917825222015 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.172921507838367, 'log_learning_rate_D': -2.2432703617212866, 'training_batch_size': 6, 'training_p': 3}. Best is trial 5 with value: 0.1626095026731491.
Time for this trial:  80.27609300613403
Memory status after this trial: 
Memory allocated:  168.99267578125
Memory cached:  174.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8266146407428803, 'log_learning_rate_D': -1.018823091298524, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:12,435] Trial 75 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8266146407428803, 'log_learning_rate_D': -1.018823091298524, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:12,436] Trial 75 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8148245811462402
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8088088834402574, 'log_learning_rate_D': -1.0162964944372779, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:43:14,694] Trial 76 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8088088834402574, 'log_learning_rate_D': -1.0162964944372779, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:14,695] Trial 76 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0597662925720215
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8128466625294757, 'log_learning_rate_D': -1.2326044556814943, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.56201171875
Memory cached:  160.0
[W 2023-12-06 11:43:16,886] Trial 77 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8128466625294757, 'log_learning_rate_D': -1.2326044556814943, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:16,887] Trial 77 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9934020042419434
Memory status after this trial: 
Memory allocated:  182.44140625
Memory cached:  186.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.84692993446805, 'log_learning_rate_D': -1.1225886624942834, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:18,878] Trial 78 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.84692993446805, 'log_learning_rate_D': -1.1225886624942834, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:18,879] Trial 78 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.808422565460205
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8638430334512175, 'log_learning_rate_D': -1.0262483592281537, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:20,992] Trial 79 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8638430334512175, 'log_learning_rate_D': -1.0262483592281537, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:20,993] Trial 79 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9284038543701172
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8190105721041867, 'log_learning_rate_D': -1.073193064260242, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:43:23,083] Trial 80 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8190105721041867, 'log_learning_rate_D': -1.073193064260242, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:23,084] Trial 80 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8959968090057373
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8959985448154946, 'log_learning_rate_D': -1.1330780986467557, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:43:25,260] Trial 81 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8959985448154946, 'log_learning_rate_D': -1.1330780986467557, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:25,261] Trial 81 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9821021556854248
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.4918224601857055, 'log_learning_rate_D': -1.0258941844988736, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:27,335] Trial 82 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.4918224601857055, 'log_learning_rate_D': -1.0258941844988736, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:27,337] Trial 82 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8857829570770264
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8865023213714442, 'log_learning_rate_D': -1.0168825628081846, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:29,355] Trial 83 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8865023213714442, 'log_learning_rate_D': -1.0168825628081846, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:29,356] Trial 83 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8532028198242188
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9891050038995246, 'log_learning_rate_D': -1.0279304606805577, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:31,448] Trial 84 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9891050038995246, 'log_learning_rate_D': -1.0279304606805577, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:31,449] Trial 84 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9052414894104004
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0055539963358, 'log_learning_rate_D': -1.2385637191847858, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:34,463] Trial 85 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0055539963358, 'log_learning_rate_D': -1.2385637191847858, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:34,464] Trial 85 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8460614681243896
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7723070739147793, 'log_learning_rate_D': -1.1902936824914119, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:36,499] Trial 86 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7723070739147793, 'log_learning_rate_D': -1.1902936824914119, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:36,500] Trial 86 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8424131870269775
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7273781549504443, 'log_learning_rate_D': -1.1469044070089516, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:43:38,642] Trial 87 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7273781549504443, 'log_learning_rate_D': -1.1469044070089516, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:38,643] Trial 87 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.954308032989502
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8459489748704296, 'log_learning_rate_D': -1.1272792789158865, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:41,322] Trial 88 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8459489748704296, 'log_learning_rate_D': -1.1272792789158865, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:41,323] Trial 88 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4910805225372314
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.841074618514445, 'log_learning_rate_D': -1.0290263440334346, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:43,368] Trial 89 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.841074618514445, 'log_learning_rate_D': -1.0290263440334346, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:43,369] Trial 89 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8722493648529053
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.862974260952612, 'log_learning_rate_D': -1.1468015272923182, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:45,368] Trial 90 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.862974260952612, 'log_learning_rate_D': -1.1468015272923182, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:45,369] Trial 90 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8023698329925537
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.788391194371446, 'log_learning_rate_D': -1.3004441312176624, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:43:47,617] Trial 91 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.788391194371446, 'log_learning_rate_D': -1.3004441312176624, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:47,618] Trial 91 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0176923274993896
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.851884632603423, 'log_learning_rate_D': -1.1373255581560924, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:49,708] Trial 92 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.851884632603423, 'log_learning_rate_D': -1.1373255581560924, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:49,709] Trial 92 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9019198417663574
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.840749516052279, 'log_learning_rate_D': -1.2363899779558352, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:51,830] Trial 93 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.840749516052279, 'log_learning_rate_D': -1.2363899779558352, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:51,831] Trial 93 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9262526035308838
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8144915630663982, 'log_learning_rate_D': -1.1846589666156853, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:54,429] Trial 94 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8144915630663982, 'log_learning_rate_D': -1.1846589666156853, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:54,430] Trial 94 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.405513286590576
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7454872661790226, 'log_learning_rate_D': -1.0627390433263142, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:43:56,567] Trial 95 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.7454872661790226, 'log_learning_rate_D': -1.0627390433263142, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:56,568] Trial 95 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9570205211639404
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.822535783611831, 'log_learning_rate_D': -1.2610943141396433, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  109.33544921875
Memory cached:  160.0
[W 2023-12-06 11:43:59,111] Trial 96 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.822535783611831, 'log_learning_rate_D': -1.2610943141396433, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:43:59,112] Trial 96 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.350792169570923
Memory status after this trial: 
Memory allocated:  160.9375
Memory cached:  164.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8125945189477655, 'log_learning_rate_D': -1.0342847758833744, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.15966796875
Memory cached:  180.0
[W 2023-12-06 11:44:01,242] Trial 97 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8125945189477655, 'log_learning_rate_D': -1.0342847758833744, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:44:01,243] Trial 97 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9426829814910889
Memory status after this trial: 
Memory allocated:  204.21923828125
Memory cached:  220.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.697183115546689, 'log_learning_rate_D': -1.19132865077072, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.14013671875
Memory cached:  160.0
[W 2023-12-06 11:44:03,846] Trial 98 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.697183115546689, 'log_learning_rate_D': -1.19132865077072, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:44:03,847] Trial 98 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4277286529541016
Memory status after this trial: 
Memory allocated:  171.244140625
Memory cached:  174.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8821152738833185, 'log_learning_rate_D': -1.0645756169411202, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  111.35107421875
Memory cached:  160.0
[W 2023-12-06 11:44:05,793] Trial 99 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.8821152738833185, 'log_learning_rate_D': -1.0645756169411202, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-06 11:44:05,794] Trial 99 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
[I 2023-12-06 11:44:05,815] A new study created in memory with name: no-name-6d1b5fc7-cf28-4f99-9c34-849c668076bc
Time for this trial:  1.7615575790405273
Memory status after this trial: 
Memory allocated:  173.546875
Memory cached:  178.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2048761427096841, 'log_learning_rate_D': -3.3005976119670803, 'training_batch_size': 8, 'training_p': 2}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  12.0
	 epoch  10 training error:  tensor(50.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  20 training error:  tensor(15.1737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(4.1276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(4.9889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  50 training error:  tensor(5.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.8527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  70 training error:  tensor(2.4674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  80 training error:  tensor(3.3707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
	 epoch  90 training error:  tensor(1.5686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.56005859375
Memory cached:  16.0
[I 2023-12-06 11:44:22,458] Trial 0 finished with value: 1.894212007522583 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2048761427096841, 'log_learning_rate_D': -3.3005976119670803, 'training_batch_size': 8, 'training_p': 2}. Best is trial 0 with value: 1.894212007522583.
res:  tensor(1.8942, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  16.546847581863403
Memory status after this trial: 
Memory allocated:  59.990234375
Memory cached:  70.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.4514706352561988, 'log_learning_rate_D': -2.2752655362432703, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  10 training error:  tensor(1.2304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.5769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.89404296875
Memory cached:  72.0
[I 2023-12-06 11:44:38,124] Trial 1 finished with value: 0.4134994447231293 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -1.4514706352561988, 'log_learning_rate_D': -2.2752655362432703, 'training_batch_size': 9, 'training_p': 6}. Best is trial 1 with value: 0.4134994447231293.
res:  tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(1.8942, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.58188009262085
Memory status after this trial: 
Memory allocated:  11.9033203125
Memory cached:  20.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.237318926300053, 'log_learning_rate_D': -1.3319078084090776, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.7209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.71826171875
Memory cached:  20.0
[I 2023-12-06 11:44:53,464] Trial 2 finished with value: 0.353657066822052 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.237318926300053, 'log_learning_rate_D': -1.3319078084090776, 'training_batch_size': 9, 'training_p': 7}. Best is trial 2 with value: 0.353657066822052.
res:  tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.25446629524231
Memory status after this trial: 
Memory allocated:  9.2666015625
Memory cached:  40.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5691573302187196, 'log_learning_rate_D': -3.679476394522708, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  20 training error:  tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  50 training error:  tensor(0.4184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.3954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.20849609375
Memory cached:  60.0
[I 2023-12-06 11:45:09,727] Trial 3 finished with value: 0.3470582664012909 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5691573302187196, 'log_learning_rate_D': -3.679476394522708, 'training_batch_size': 9, 'training_p': 3}. Best is trial 3 with value: 0.3470582664012909.
res:  tensor(0.3471, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.16745376586914
Memory status after this trial: 
Memory allocated:  51.2841796875
Memory cached:  96.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.0313613805121586, 'log_learning_rate_D': -3.8220105347921494, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  10 training error:  tensor(1.5482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  20 training error:  tensor(0.8725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  30 training error:  tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  40 training error:  tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  50 training error:  tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  60 training error:  tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  70 training error:  tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  80 training error:  tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
	 epoch  90 training error:  tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  100.0
[I 2023-12-06 11:45:25,605] Trial 4 finished with value: 0.34888097643852234 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.0313613805121586, 'log_learning_rate_D': -3.8220105347921494, 'training_batch_size': 9, 'training_p': 5}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  15.771662473678589
Memory status after this trial: 
Memory allocated:  91.53662109375
Memory cached:  116.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.038797418761993, 'log_learning_rate_D': -3.1070691133647936, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  10 training error:  tensor(2.7293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.4938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.4284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.83154296875
Memory cached:  116.0
[I 2023-12-06 11:45:43,029] Trial 5 finished with value: 0.39551517367362976 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.038797418761993, 'log_learning_rate_D': -3.1070691133647936, 'training_batch_size': 8, 'training_p': 8}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  17.32134437561035
Memory status after this trial: 
Memory allocated:  127.93408203125
Memory cached:  158.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.148936389015476, 'log_learning_rate_D': -4.635421785464082, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.1865234375
Memory cached:  96.0
[I 2023-12-06 11:45:58,836] Trial 6 finished with value: 0.3638627827167511 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.148936389015476, 'log_learning_rate_D': -4.635421785464082, 'training_batch_size': 8, 'training_p': 6}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  15.712486743927002
Memory status after this trial: 
Memory allocated:  71.39599609375
Memory cached:  96.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.404298225365453, 'log_learning_rate_D': -1.8546415592867564, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.5570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.4489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.365234375
Memory cached:  96.0
[I 2023-12-06 11:46:15,444] Trial 7 finished with value: 0.3703419268131256 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.404298225365453, 'log_learning_rate_D': -1.8546415592867564, 'training_batch_size': 8, 'training_p': 5}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  16.50836420059204
Memory status after this trial: 
Memory allocated:  123.31494140625
Memory cached:  176.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8707030918668526, 'log_learning_rate_D': -2.1153490927725933, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(2.1570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  10 training error:  tensor(2.4574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.9797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.9365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.7726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.7323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.91796875
Memory cached:  96.0
[I 2023-12-06 11:46:33,853] Trial 8 finished with value: 0.35671481490135193 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8707030918668526, 'log_learning_rate_D': -2.1153490927725933, 'training_batch_size': 6, 'training_p': 6}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  18.31505537033081
Memory status after this trial: 
Memory allocated:  107.01513671875
Memory cached:  120.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.3553920699753075, 'log_learning_rate_D': -3.002389827947742, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.3954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.66455078125
Memory cached:  96.0
[I 2023-12-06 11:46:50,117] Trial 9 finished with value: 0.3679475486278534 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.3553920699753075, 'log_learning_rate_D': -3.002389827947742, 'training_batch_size': 11, 'training_p': 2}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  16.14938521385193
Memory status after this trial: 
Memory allocated:  82.63525390625
Memory cached:  118.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.916797259836727, 'log_learning_rate_D': -4.5358884576615255, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.5230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  78.38720703125
Memory cached:  96.0
[I 2023-12-06 11:47:07,003] Trial 10 finished with value: 0.39457982778549194 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.916797259836727, 'log_learning_rate_D': -4.5358884576615255, 'training_batch_size': 12, 'training_p': 3}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  16.703805685043335
Memory status after this trial: 
Memory allocated:  116.13330078125
Memory cached:  156.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.561622639504049, 'log_learning_rate_D': -3.8825570567737713, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.3686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.6001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.5172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.4275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.51708984375
Memory cached:  96.0
[I 2023-12-06 11:47:23,152] Trial 11 finished with value: 0.3612153232097626 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.561622639504049, 'log_learning_rate_D': -3.8825570567737713, 'training_batch_size': 10, 'training_p': 4}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  16.012075662612915
Memory status after this trial: 
Memory allocated:  83.44091796875
Memory cached:  116.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.619499378503085, 'log_learning_rate_D': -3.8666481058073896, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.3146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.9570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.38525390625
Memory cached:  102.0
[I 2023-12-06 11:47:41,031] Trial 12 finished with value: 0.35215136408805847 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.619499378503085, 'log_learning_rate_D': -3.8666481058073896, 'training_batch_size': 6, 'training_p': 4}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  17.703120470046997
Memory status after this trial: 
Memory allocated:  115.35302734375
Memory cached:  158.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.633150700934463, 'log_learning_rate_D': -4.999037908391548, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.6393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  10 training error:  tensor(1.5735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.5832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.3955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.65380859375
Memory cached:  96.0
[I 2023-12-06 11:47:56,475] Trial 13 finished with value: 0.3490370512008667 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.633150700934463, 'log_learning_rate_D': -4.999037908391548, 'training_batch_size': 10, 'training_p': 4}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  15.289618492126465
Memory status after this trial: 
Memory allocated:  59.20458984375
Memory cached:  96.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5711334975792477, 'log_learning_rate_D': -3.698358657567602, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.36181640625
Memory cached:  96.0
[I 2023-12-06 11:48:12,648] Trial 14 finished with value: 0.35045820474624634 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.5711334975792477, 'log_learning_rate_D': -3.698358657567602, 'training_batch_size': 10, 'training_p': 3}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  16.016034364700317
Memory status after this trial: 
Memory allocated:  86.96240234375
Memory cached:  98.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.7961843815891014, 'log_learning_rate_D': -4.213583547183593, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.4333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.4275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.39306640625
Memory cached:  96.0
[I 2023-12-06 11:48:28,433] Trial 15 finished with value: 0.3567012846469879 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.7961843815891014, 'log_learning_rate_D': -4.213583547183593, 'training_batch_size': 7, 'training_p': 5}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  15.630147933959961
Memory status after this trial: 
Memory allocated:  75.81689453125
Memory cached:  96.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7196937512344173, 'log_learning_rate_D': -3.495019884421996, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.8192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.4779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1015625
Memory cached:  98.0
[I 2023-12-06 11:48:44,351] Trial 16 finished with value: 0.35460758209228516 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.7196937512344173, 'log_learning_rate_D': -3.495019884421996, 'training_batch_size': 11, 'training_p': 3}. Best is trial 3 with value: 0.3470582664012909.
Time for this trial:  15.771984338760376
Memory status after this trial: 
Memory allocated:  79.05419921875
Memory cached:  96.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.94478214289113, 'log_learning_rate_D': -2.8586245100145806, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.654296875
Memory cached:  96.0
[I 2023-12-06 11:49:01,442] Trial 17 finished with value: 0.34324413537979126 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.94478214289113, 'log_learning_rate_D': -2.8586245100145806, 'training_batch_size': 9, 'training_p': 8}. Best is trial 17 with value: 0.34324413537979126.
res:  tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3471, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.923757076263428
Memory status after this trial: 
Memory allocated:  54.236328125
Memory cached:  116.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.259009284315029, 'log_learning_rate_D': -2.586152108348773, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.6148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.50048828125
Memory cached:  116.0
[I 2023-12-06 11:49:18,182] Trial 18 finished with value: 0.3461906313896179 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.259009284315029, 'log_learning_rate_D': -2.586152108348773, 'training_batch_size': 7, 'training_p': 8}. Best is trial 17 with value: 0.34324413537979126.
Time for this trial:  16.554319143295288
Memory status after this trial: 
Memory allocated:  108.34814453125
Memory cached:  136.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.368703282638859, 'log_learning_rate_D': -2.625766331290051, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  10 training error:  tensor(0.4862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  20 training error:  tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  30 training error:  tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  40 training error:  tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  50 training error:  tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  60 training error:  tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  70 training error:  tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  80 training error:  tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
	 epoch  90 training error:  tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.6826171875
Memory cached:  116.0
[I 2023-12-06 11:49:34,624] Trial 19 finished with value: 0.3425348401069641 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.368703282638859, 'log_learning_rate_D': -2.625766331290051, 'training_batch_size': 7, 'training_p': 8}. Best is trial 19 with value: 0.3425348401069641.
res:  tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.25125479698181
Memory status after this trial: 
Memory allocated:  52.115234375
Memory cached:  114.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.311553963740822, 'log_learning_rate_D': -2.723104995760403, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  20 training error:  tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  30 training error:  tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  40 training error:  tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  50 training error:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  60 training error:  tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  70 training error:  tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  80 training error:  tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
	 epoch  90 training error:  tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.61865234375
Memory cached:  114.0
[I 2023-12-06 11:49:51,541] Trial 20 finished with value: 0.33899202942848206 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.311553963740822, 'log_learning_rate_D': -2.723104995760403, 'training_batch_size': 7, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
res:  tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.72530174255371
Memory status after this trial: 
Memory allocated:  41.076171875
Memory cached:  72.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.3156765147668787, 'log_learning_rate_D': -2.71259212043343, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.3907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.4070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.57958984375
Memory cached:  72.0
[I 2023-12-06 11:50:08,667] Trial 21 finished with value: 0.34877634048461914 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.3156765147668787, 'log_learning_rate_D': -2.71259212043343, 'training_batch_size': 7, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.94339632987976
Memory status after this trial: 
Memory allocated:  81.40185546875
Memory cached:  92.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.604632386702269, 'log_learning_rate_D': -2.7238212190635394, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(6.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  10 training error:  tensor(58.6015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  20 training error:  tensor(16.4083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  30 training error:  tensor(2.7969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  40 training error:  tensor(2.7510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  50 training error:  tensor(4.8826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  60 training error:  tensor(9.2054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  70 training error:  tensor(6.1141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  80 training error:  tensor(4.4733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
	 epoch  90 training error:  tensor(6.5367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.02880859375
Memory cached:  74.0
[I 2023-12-06 11:50:27,383] Trial 22 finished with value: 14.559671401977539 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.604632386702269, 'log_learning_rate_D': -2.7238212190635394, 'training_batch_size': 6, 'training_p': 8}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  18.527345180511475
Memory status after this trial: 
Memory allocated:  100.85888671875
Memory cached:  116.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.3896568627009436, 'log_learning_rate_D': -3.229937013299833, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9404296875
Memory cached:  72.0
[I 2023-12-06 11:50:44,041] Trial 23 finished with value: 0.3555907607078552 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.3896568627009436, 'log_learning_rate_D': -3.229937013299833, 'training_batch_size': 7, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.470900297164917
Memory status after this trial: 
Memory allocated:  65.18408203125
Memory cached:  74.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.8048655990057982, 'log_learning_rate_D': -2.77792251563991, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.6195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  20 training error:  tensor(1.3343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.5791015625
Memory cached:  72.0
[I 2023-12-06 11:51:01,167] Trial 24 finished with value: 0.3486090302467346 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.8048655990057982, 'log_learning_rate_D': -2.77792251563991, 'training_batch_size': 7, 'training_p': 8}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.932398557662964
Memory status after this trial: 
Memory allocated:  93.30615234375
Memory cached:  114.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.8850787756195815, 'log_learning_rate_D': -2.3858210757238543, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.9765625
Memory cached:  76.0
[I 2023-12-06 11:51:17,940] Trial 25 finished with value: 0.41696521639823914 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.8850787756195815, 'log_learning_rate_D': -2.3858210757238543, 'training_batch_size': 8, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.590909719467163
Memory status after this trial: 
Memory allocated:  87.58642578125
Memory cached:  114.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.1761610329824834, 'log_learning_rate_D': -2.9495052504076114, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.2235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.9072265625
Memory cached:  72.0
[I 2023-12-06 11:51:35,211] Trial 26 finished with value: 0.3643242418766022 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.1761610329824834, 'log_learning_rate_D': -2.9495052504076114, 'training_batch_size': 6, 'training_p': 8}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  17.09351396560669
Memory status after this trial: 
Memory allocated:  71.72314453125
Memory cached:  74.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.4864046039553105, 'log_learning_rate_D': -1.8519649898929123, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.5053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  74.0
	 epoch  30 training error:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  74.0
	 epoch  60 training error:  tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  74.0
	 epoch  90 training error:  tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.83642578125
Memory cached:  72.0
[I 2023-12-06 11:51:52,101] Trial 27 finished with value: 0.3567732870578766 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -2.4864046039553105, 'log_learning_rate_D': -1.8519649898929123, 'training_batch_size': 7, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.692954778671265
Memory status after this trial: 
Memory allocated:  60.51904296875
Memory cached:  76.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.8169525248345497, 'log_learning_rate_D': -2.50375998736658, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.95556640625
Memory cached:  72.0
[I 2023-12-06 11:52:08,363] Trial 28 finished with value: 0.3426206707954407 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.8169525248345497, 'log_learning_rate_D': -2.50375998736658, 'training_batch_size': 11, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.06438183784485
Memory status after this trial: 
Memory allocated:  61.87451171875
Memory cached:  72.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.3422855858691833, 'log_learning_rate_D': -3.3741161421183095, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  10 training error:  tensor(8.6314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  20 training error:  tensor(2.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  30 training error:  tensor(3.1596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  40 training error:  tensor(4.2825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  50 training error:  tensor(3.9550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  60 training error:  tensor(3.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  70 training error:  tensor(2.0085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  80 training error:  tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
	 epoch  90 training error:  tensor(0.7616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.7294921875
Memory cached:  74.0
[I 2023-12-06 11:52:25,138] Trial 29 finished with value: 0.7045730948448181 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.3422855858691833, 'log_learning_rate_D': -3.3741161421183095, 'training_batch_size': 12, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.581483602523804
Memory status after this trial: 
Memory allocated:  88.14990234375
Memory cached:  114.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.0011374859774813, 'log_learning_rate_D': -2.4842200884560173, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.1767578125
Memory cached:  72.0
[I 2023-12-06 11:52:40,867] Trial 30 finished with value: 0.3473241329193115 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.0011374859774813, 'log_learning_rate_D': -2.4842200884560173, 'training_batch_size': 11, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  15.547977447509766
Memory status after this trial: 
Memory allocated:  54.43798828125
Memory cached:  74.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.814194928999181, 'log_learning_rate_D': -2.9878821638325332, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  10 training error:  tensor(0.5186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  20 training error:  tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  30 training error:  tensor(0.4059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  40 training error:  tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  50 training error:  tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  60 training error:  tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  70 training error:  tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  80 training error:  tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
	 epoch  90 training error:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.38232421875
Memory cached:  74.0
[I 2023-12-06 11:52:57,934] Trial 31 finished with value: 0.3555174767971039 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.814194928999181, 'log_learning_rate_D': -2.9878821638325332, 'training_batch_size': 10, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.88687229156494
Memory status after this trial: 
Memory allocated:  83.33642578125
Memory cached:  94.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.5051390611502096, 'log_learning_rate_D': -2.3515966276580915, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  10 training error:  tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  20 training error:  tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  30 training error:  tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  40 training error:  tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  50 training error:  tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  60 training error:  tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  70 training error:  tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  80 training error:  tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
	 epoch  90 training error:  tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.326171875
Memory cached:  74.0
[I 2023-12-06 11:53:14,821] Trial 32 finished with value: 0.35087862610816956 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.5051390611502096, 'log_learning_rate_D': -2.3515966276580915, 'training_batch_size': 8, 'training_p': 8}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.68851137161255
Memory status after this trial: 
Memory allocated:  77.03662109375
Memory cached:  94.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.1671676977479737, 'log_learning_rate_D': -2.8236314857889147, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  10 training error:  tensor(13.4832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.9119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.8038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.6425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.6873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.6432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.04931640625
Memory cached:  72.0
[I 2023-12-06 11:53:31,234] Trial 33 finished with value: 0.6115544438362122 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -1.1671676977479737, 'log_learning_rate_D': -2.8236314857889147, 'training_batch_size': 11, 'training_p': 7}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.19286584854126
Memory status after this trial: 
Memory allocated:  70.99462890625
Memory cached:  74.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.8761689581088685, 'log_learning_rate_D': -2.1190842236388825, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.25537109375
Memory cached:  72.0
[I 2023-12-06 11:53:47,097] Trial 34 finished with value: 0.3431023061275482 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.8761689581088685, 'log_learning_rate_D': -2.1190842236388825, 'training_batch_size': 9, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  15.682435750961304
Memory status after this trial: 
Memory allocated:  59.46142578125
Memory cached:  74.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.1417896754202177, 'log_learning_rate_D': -2.016832315149709, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.9970703125
Memory cached:  72.0
[I 2023-12-06 11:54:03,345] Trial 35 finished with value: 0.3428877890110016 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.1417896754202177, 'log_learning_rate_D': -2.016832315149709, 'training_batch_size': 9, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  16.078784227371216
Memory status after this trial: 
Memory allocated:  58.67822265625
Memory cached:  72.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.0632769483583573, 'log_learning_rate_D': -1.3644382257332257, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.3744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  41.89111328125
Memory cached:  72.0
[I 2023-12-06 11:54:18,944] Trial 36 finished with value: 0.36822646856307983 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.0632769483583573, 'log_learning_rate_D': -1.3644382257332257, 'training_batch_size': 9, 'training_p': 6}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  15.420045375823975
Memory status after this trial: 
Memory allocated:  52.80517578125
Memory cached:  72.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.6560626975218833, 'log_learning_rate_D': -2.577180121689118, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.4541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  10 training error:  tensor(1.3450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.162109375
Memory cached:  72.0
[I 2023-12-06 11:54:35,099] Trial 37 finished with value: 0.339854896068573 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.6560626975218833, 'log_learning_rate_D': -2.577180121689118, 'training_batch_size': 12, 'training_p': 5}. Best is trial 20 with value: 0.33899202942848206.
Time for this trial:  15.974514245986938
Memory status after this trial: 
Memory allocated:  58.65576171875
Memory cached:  72.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.6201193490990675, 'log_learning_rate_D': -2.5339908571335363, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  10 training error:  tensor(0.9415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8876953125
Memory cached:  72.0
[I 2023-12-06 11:54:50,735] Trial 38 finished with value: 0.3381211757659912 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.6201193490990675, 'log_learning_rate_D': -2.5339908571335363, 'training_batch_size': 12, 'training_p': 5}. Best is trial 38 with value: 0.3381211757659912.
res:  tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.435645580291748
Memory status after this trial: 
Memory allocated:  12.8115234375
Memory cached:  38.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.0079925321705594, 'log_learning_rate_D': -2.6221146938871365, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  10 training error:  tensor(4.5838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  20 training error:  tensor(7.8260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  30 training error:  tensor(6.4492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  40 training error:  tensor(2.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  50 training error:  tensor(1.5410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  60 training error:  tensor(2.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  70 training error:  tensor(1.4889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  80 training error:  tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.62744140625
Memory cached:  38.0
[I 2023-12-06 11:55:05,985] Trial 39 finished with value: 1.0835198163986206 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.0079925321705594, 'log_learning_rate_D': -2.6221146938871365, 'training_batch_size': 12, 'training_p': 5}. Best is trial 38 with value: 0.3381211757659912.
Time for this trial:  15.065364360809326
Memory status after this trial: 
Memory allocated:  25.62255859375
Memory cached:  38.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.5818825107759396, 'log_learning_rate_D': -3.155985562221584, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  10 training error:  tensor(10.5609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  20 training error:  tensor(2.6741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  30 training error:  tensor(2.9583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  40 training error:  tensor(1.3231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  50 training error:  tensor(1.0096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.7427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.6529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.89697265625
Memory cached:  38.0
[I 2023-12-06 11:55:22,061] Trial 40 finished with value: 0.45040321350097656 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.5818825107759396, 'log_learning_rate_D': -3.155985562221584, 'training_batch_size': 12, 'training_p': 5}. Best is trial 38 with value: 0.3381211757659912.
Time for this trial:  15.878665447235107
Memory status after this trial: 
Memory allocated:  33.11181640625
Memory cached:  46.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.7416983429560586, 'log_learning_rate_D': -2.4791823378248816, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.8758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.6640625
Memory cached:  38.0
[I 2023-12-06 11:55:38,129] Trial 41 finished with value: 0.34451571106910706 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.7416983429560586, 'log_learning_rate_D': -2.4791823378248816, 'training_batch_size': 12, 'training_p': 5}. Best is trial 38 with value: 0.3381211757659912.
Time for this trial:  15.880934000015259
Memory status after this trial: 
Memory allocated:  30.76904296875
Memory cached:  58.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.8883617841454274, 'log_learning_rate_D': -2.3083729077452038, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.50439453125
Memory cached:  38.0
[I 2023-12-06 11:55:54,000] Trial 42 finished with value: 0.333601713180542 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.8883617841454274, 'log_learning_rate_D': -2.3083729077452038, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
res:  tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.687296628952026
Memory status after this trial: 
Memory allocated:  12.447265625
Memory cached:  38.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.4499454273865977, 'log_learning_rate_D': -2.231119658641573, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  10 training error:  tensor(11.2101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.4519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.154296875
Memory cached:  40.0
[I 2023-12-06 11:56:09,858] Trial 43 finished with value: 0.37760108709335327 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.4499454273865977, 'log_learning_rate_D': -2.231119658641573, 'training_batch_size': 12, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.672056198120117
Memory status after this trial: 
Memory allocated:  30.57666015625
Memory cached:  40.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.9429687440761043, 'log_learning_rate_D': -2.29041060250003, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.6077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.6923828125
Memory cached:  38.0
[I 2023-12-06 11:56:25,702] Trial 44 finished with value: 0.33727073669433594 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.9429687440761043, 'log_learning_rate_D': -2.29041060250003, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.655494213104248
Memory status after this trial: 
Memory allocated:  24.94775390625
Memory cached:  38.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.8716245786409254, 'log_learning_rate_D': -2.2229539196013066, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.42236328125
Memory cached:  38.0
[I 2023-12-06 11:56:41,421] Trial 45 finished with value: 0.33565276861190796 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.8716245786409254, 'log_learning_rate_D': -2.2229539196013066, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.528503894805908
Memory status after this trial: 
Memory allocated:  26.06982421875
Memory cached:  38.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.923171963170267, 'log_learning_rate_D': -2.261637579085704, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5185546875
Memory cached:  38.0
[I 2023-12-06 11:56:57,301] Trial 46 finished with value: 0.3372584283351898 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.923171963170267, 'log_learning_rate_D': -2.261637579085704, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.683036088943481
Memory status after this trial: 
Memory allocated:  26.81787109375
Memory cached:  40.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.9403044236310252, 'log_learning_rate_D': -1.8920003958272231, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.8372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.705078125
Memory cached:  38.0
[I 2023-12-06 11:57:12,943] Trial 47 finished with value: 0.3488090932369232 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.9403044236310252, 'log_learning_rate_D': -1.8920003958272231, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.462899208068848
Memory status after this trial: 
Memory allocated:  26.05322265625
Memory cached:  40.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.8862202547388898, 'log_learning_rate_D': -2.200237535286332, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.27197265625
Memory cached:  38.0
[I 2023-12-06 11:57:28,968] Trial 48 finished with value: 0.3366450369358063 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.8862202547388898, 'log_learning_rate_D': -2.200237535286332, 'training_batch_size': 10, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.848412036895752
Memory status after this trial: 
Memory allocated:  30.10498046875
Memory cached:  38.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.8734382294839207, 'log_learning_rate_D': -2.2326007979626246, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.7568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.20751953125
Memory cached:  38.0
[I 2023-12-06 11:57:44,729] Trial 49 finished with value: 0.34333881735801697 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.8734382294839207, 'log_learning_rate_D': -2.2326007979626246, 'training_batch_size': 10, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.582057476043701
Memory status after this trial: 
Memory allocated:  27.14306640625
Memory cached:  38.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.9157005219580436, 'log_learning_rate_D': -1.7410105203790391, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.91064453125
Memory cached:  38.0
[I 2023-12-06 11:58:01,084] Trial 50 finished with value: 0.33829325437545776 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.9157005219580436, 'log_learning_rate_D': -1.7410105203790391, 'training_batch_size': 11, 'training_p': 2}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  16.179717540740967
Memory status after this trial: 
Memory allocated:  35.20556640625
Memory cached:  58.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.7007611664659699, 'log_learning_rate_D': -2.3253440420729983, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.9339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.17138671875
Memory cached:  38.0
[I 2023-12-06 11:58:16,593] Trial 51 finished with value: 0.3409774899482727 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.7007611664659699, 'log_learning_rate_D': -2.3253440420729983, 'training_batch_size': 10, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.323168516159058
Memory status after this trial: 
Memory allocated:  24.07861328125
Memory cached:  38.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.4938108629637377, 'log_learning_rate_D': -2.1101989116406252, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.8353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.6315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.8896484375
Memory cached:  38.0
[I 2023-12-06 11:58:32,551] Trial 52 finished with value: 0.6107120513916016 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.4938108629637377, 'log_learning_rate_D': -2.1101989116406252, 'training_batch_size': 11, 'training_p': 3}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.798181772232056
Memory status after this trial: 
Memory allocated:  24.43212890625
Memory cached:  38.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.0298635426572416, 'log_learning_rate_D': -2.24048264469206, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.849609375
Memory cached:  38.0
[I 2023-12-06 11:58:48,464] Trial 53 finished with value: 0.34269455075263977 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.0298635426572416, 'log_learning_rate_D': -2.24048264469206, 'training_batch_size': 11, 'training_p': 4}. Best is trial 42 with value: 0.333601713180542.
Time for this trial:  15.723621368408203
Memory status after this trial: 
Memory allocated:  31.46142578125
Memory cached:  38.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.7516497657432855, 'log_learning_rate_D': -1.6990968722196365, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  10 training error:  tensor(1.0238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.76318359375
Memory cached:  38.0
[I 2023-12-06 11:59:04,131] Trial 54 finished with value: 0.3324073851108551 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.7516497657432855, 'log_learning_rate_D': -1.6990968722196365, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
res:  tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.489070177078247
Memory status after this trial: 
Memory allocated:  10.53515625
Memory cached:  38.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.7647053574499738, 'log_learning_rate_D': -1.675507012911611, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.51123046875
Memory cached:  38.0
[I 2023-12-06 11:59:19,689] Trial 55 finished with value: 0.3368934988975525 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.7647053574499738, 'log_learning_rate_D': -1.675507012911611, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.393069505691528
Memory status after this trial: 
Memory allocated:  18.77294921875
Memory cached:  38.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.7380927673654125, 'log_learning_rate_D': -1.6396268134153773, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6943359375
Memory cached:  38.0
[I 2023-12-06 11:59:35,567] Trial 56 finished with value: 0.3392699360847473 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.7380927673654125, 'log_learning_rate_D': -1.6396268134153773, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.712992191314697
Memory status after this trial: 
Memory allocated:  36.73193359375
Memory cached:  58.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.136964159966263, 'log_learning_rate_D': -1.5880592322996252, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.61865234375
Memory cached:  38.0
[I 2023-12-06 11:59:51,068] Trial 57 finished with value: 0.34259891510009766 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.136964159966263, 'log_learning_rate_D': -1.5880592322996252, 'training_batch_size': 10, 'training_p': 2}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.339009046554565
Memory status after this trial: 
Memory allocated:  18.82666015625
Memory cached:  38.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.3657195713429293, 'log_learning_rate_D': -1.1261545003279307, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.6691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.5341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.4283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.67236328125
Memory cached:  38.0
[I 2023-12-06 12:00:06,471] Trial 58 finished with value: 0.368353009223938 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.3657195713429293, 'log_learning_rate_D': -1.1261545003279307, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.223930835723877
Memory status after this trial: 
Memory allocated:  18.77294921875
Memory cached:  38.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.8340586704417468, 'log_learning_rate_D': -2.0202523879809173, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.7910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.43701171875
Memory cached:  38.0
[I 2023-12-06 12:00:22,211] Trial 59 finished with value: 0.3362296521663666 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.8340586704417468, 'log_learning_rate_D': -2.0202523879809173, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.561792612075806
Memory status after this trial: 
Memory allocated:  24.63427734375
Memory cached:  38.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.243549323735346, 'log_learning_rate_D': -2.0258951730006194, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.20068359375
Memory cached:  38.0
[I 2023-12-06 12:00:37,849] Trial 60 finished with value: 0.3386245667934418 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.243549323735346, 'log_learning_rate_D': -2.0258951730006194, 'training_batch_size': 9, 'training_p': 2}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.460539102554321
Memory status after this trial: 
Memory allocated:  24.63427734375
Memory cached:  38.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.8054538354436387, 'log_learning_rate_D': -1.9007402262528585, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.8233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.7140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.6421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.6336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.69580078125
Memory cached:  38.0
[I 2023-12-06 12:00:53,358] Trial 61 finished with value: 0.6107246279716492 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.8054538354436387, 'log_learning_rate_D': -1.9007402262528585, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.351192235946655
Memory status after this trial: 
Memory allocated:  35.00830078125
Memory cached:  58.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.863447811006852, 'log_learning_rate_D': -1.523377509306521, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.48876953125
Memory cached:  38.0
[I 2023-12-06 12:01:08,854] Trial 62 finished with value: 0.33520933985710144 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.863447811006852, 'log_learning_rate_D': -1.523377509306521, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.332152128219604
Memory status after this trial: 
Memory allocated:  18.37158203125
Memory cached:  38.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.7877740844823446, 'log_learning_rate_D': -1.4995033335084758, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  10 training error:  tensor(1.3407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.03271484375
Memory cached:  38.0
[I 2023-12-06 12:01:24,629] Trial 63 finished with value: 0.34058311581611633 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.7877740844823446, 'log_learning_rate_D': -1.4995033335084758, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.608845233917236
Memory status after this trial: 
Memory allocated:  25.49951171875
Memory cached:  38.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.0936926048502653, 'log_learning_rate_D': -1.7156151984836723, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.30029296875
Memory cached:  38.0
[I 2023-12-06 12:01:39,505] Trial 64 finished with value: 0.3387869894504547 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.0936926048502653, 'log_learning_rate_D': -1.7156151984836723, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  14.71913743019104
Memory status after this trial: 
Memory allocated:  17.97412109375
Memory cached:  38.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.5027646628944038, 'log_learning_rate_D': -1.5054778603613839, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.6791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.6670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.6655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.6518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.6388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.6329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.28125
Memory cached:  38.0
[I 2023-12-06 12:01:54,988] Trial 65 finished with value: 0.6100220680236816 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.5027646628944038, 'log_learning_rate_D': -1.5054778603613839, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.325179815292358
Memory status after this trial: 
Memory allocated:  24.01806640625
Memory cached:  38.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.6082873643599966, 'log_learning_rate_D': -1.792340093629083, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  10 training error:  tensor(5.2975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  20 training error:  tensor(2.7328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.7410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.6378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.775390625
Memory cached:  38.0
[I 2023-12-06 12:02:10,750] Trial 66 finished with value: 0.6546172499656677 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.6082873643599966, 'log_learning_rate_D': -1.792340093629083, 'training_batch_size': 9, 'training_p': 2}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  15.60546064376831
Memory status after this trial: 
Memory allocated:  31.95458984375
Memory cached:  58.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.200765285485877, 'log_learning_rate_D': -1.928396114879584, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.63623046875
Memory cached:  38.0
[I 2023-12-06 12:02:25,699] Trial 67 finished with value: 0.33842816948890686 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.200765285485877, 'log_learning_rate_D': -1.928396114879584, 'training_batch_size': 10, 'training_p': 3}. Best is trial 54 with value: 0.3324073851108551.
Time for this trial:  14.773422002792358
Memory status after this trial: 
Memory allocated:  16.15771484375
Memory cached:  38.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8186619069380137, 'log_learning_rate_D': -1.6635266828448185, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  10 training error:  tensor(2.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
[I 2023-12-06 12:02:41,535] Trial 68 finished with value: 0.3323483467102051 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8186619069380137, 'log_learning_rate_D': -1.6635266828448185, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
res:  tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.67564082145691
Memory status after this trial: 
Memory allocated:  26.197265625
Memory cached:  50.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -1.3212558409359663, 'log_learning_rate_D': -1.783570533968593, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  10 training error:  tensor(41.8437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  20 training error:  tensor(7.8558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  30 training error:  tensor(2.0045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  40 training error:  tensor(3.8495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  50 training error:  tensor(2.1933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  60 training error:  tensor(2.9761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  70 training error:  tensor(2.1647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  80 training error:  tensor(2.4692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
	 epoch  90 training error:  tensor(1.8898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.03662109375
Memory cached:  50.0
[I 2023-12-06 12:02:58,310] Trial 69 finished with value: 2.419456958770752 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -1.3212558409359663, 'log_learning_rate_D': -1.783570533968593, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.606071710586548
Memory status after this trial: 
Memory allocated:  64.19580078125
Memory cached:  90.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.0146915121792337, 'log_learning_rate_D': -2.0415421323569287, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.6165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.7246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.119140625
Memory cached:  50.0
[I 2023-12-06 12:03:14,783] Trial 70 finished with value: 0.3335835933685303 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.0146915121792337, 'log_learning_rate_D': -2.0415421323569287, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.25905156135559
Memory status after this trial: 
Memory allocated:  60.94775390625
Memory cached:  70.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.984965183978519, 'log_learning_rate_D': -2.0715509641635013, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.8279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.376953125
Memory cached:  50.0
[I 2023-12-06 12:03:31,625] Trial 71 finished with value: 0.3466048836708069 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -1.984965183978519, 'log_learning_rate_D': -2.0715509641635013, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.660948753356934
Memory status after this trial: 
Memory allocated:  66.56103515625
Memory cached:  90.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.8512917341540234, 'log_learning_rate_D': -1.9605589890854846, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  10 training error:  tensor(3.3475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  20 training error:  tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.033203125
Memory cached:  50.0
[I 2023-12-06 12:03:48,089] Trial 72 finished with value: 0.3381791114807129 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.8512917341540234, 'log_learning_rate_D': -1.9605589890854846, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.289061307907104
Memory status after this trial: 
Memory allocated:  60.01220703125
Memory cached:  68.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.0518303479931963, 'log_learning_rate_D': -1.8176958437397592, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.986328125
Memory cached:  50.0
[I 2023-12-06 12:04:04,081] Trial 73 finished with value: 0.34872278571128845 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.0518303479931963, 'log_learning_rate_D': -1.8176958437397592, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.816043138504028
Memory status after this trial: 
Memory allocated:  53.61767578125
Memory cached:  70.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.6958437310723362, 'log_learning_rate_D': -2.166414506241082, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.8825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.7310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.6330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.6365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.6065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.4360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.0703125
Memory cached:  50.0
[I 2023-12-06 12:04:19,818] Trial 74 finished with value: 0.3373222053050995 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.6958437310723362, 'log_learning_rate_D': -2.166414506241082, 'training_batch_size': 11, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.558385848999023
Memory status after this trial: 
Memory allocated:  41.00634765625
Memory cached:  48.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.3241998244478483, 'log_learning_rate_D': -2.016220817333964, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.8643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.4931640625
Memory cached:  50.0
[I 2023-12-06 12:04:36,473] Trial 75 finished with value: 0.3384873867034912 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.3241998244478483, 'log_learning_rate_D': -2.016220817333964, 'training_batch_size': 10, 'training_p': 5}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.45132875442505
Memory status after this trial: 
Memory allocated:  63.72705078125
Memory cached:  88.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.166175117066822, 'log_learning_rate_D': -2.4076034833647886, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7900390625
Memory cached:  50.0
[I 2023-12-06 12:04:52,193] Trial 76 finished with value: 0.33551889657974243 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.166175117066822, 'log_learning_rate_D': -2.4076034833647886, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.56298828125
Memory status after this trial: 
Memory allocated:  40.08935546875
Memory cached:  48.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.2199973782458198, 'log_learning_rate_D': -2.429497282195149, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.2978515625
Memory cached:  50.0
[I 2023-12-06 12:05:08,370] Trial 77 finished with value: 0.34128904342651367 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.2199973782458198, 'log_learning_rate_D': -2.429497282195149, 'training_batch_size': 11, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.01285433769226
Memory status after this trial: 
Memory allocated:  52.02392578125
Memory cached:  70.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.4034414467995466, 'log_learning_rate_D': -2.371989868643803, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  10 training error:  tensor(4.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  20 training error:  tensor(0.5802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  30 training error:  tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  40 training error:  tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  50 training error:  tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  60 training error:  tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  70 training error:  tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  80 training error:  tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
	 epoch  90 training error:  tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.40625
Memory cached:  70.0
[I 2023-12-06 12:05:25,135] Trial 78 finished with value: 0.4202592968940735 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.4034414467995466, 'log_learning_rate_D': -2.371989868643803, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.590845823287964
Memory status after this trial: 
Memory allocated:  83.11767578125
Memory cached:  108.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.133453921320955, 'log_learning_rate_D': -1.9730839172202455, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.4326171875
Memory cached:  50.0
[I 2023-12-06 12:05:40,440] Trial 79 finished with value: 0.3422916829586029 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.133453921320955, 'log_learning_rate_D': -1.9730839172202455, 'training_batch_size': 12, 'training_p': 5}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.140328407287598
Memory status after this trial: 
Memory allocated:  30.31884765625
Memory cached:  50.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.5742360395207375, 'log_learning_rate_D': -2.084644775583509, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.7474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.091796875
Memory cached:  48.0
[I 2023-12-06 12:05:55,597] Trial 80 finished with value: 0.35060569643974304 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.5742360395207375, 'log_learning_rate_D': -2.084644775583509, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  14.97760796546936
Memory status after this trial: 
Memory allocated:  29.55419921875
Memory cached:  50.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8898626604268562, 'log_learning_rate_D': -2.165313967890351, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.36474609375
Memory cached:  48.0
[I 2023-12-06 12:06:11,488] Trial 81 finished with value: 0.36139175295829773 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8898626604268562, 'log_learning_rate_D': -2.165313967890351, 'training_batch_size': 10, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.698124885559082
Memory status after this trial: 
Memory allocated:  43.42431640625
Memory cached:  70.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.033232081529807, 'log_learning_rate_D': -1.8863029824807829, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.97998046875
Memory cached:  48.0
[I 2023-12-06 12:06:27,226] Trial 82 finished with value: 0.3350197970867157 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.033232081529807, 'log_learning_rate_D': -1.8863029824807829, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.571772813796997
Memory status after this trial: 
Memory allocated:  43.52392578125
Memory cached:  50.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.0503629480053434, 'log_learning_rate_D': -1.886097731093899, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.943359375
Memory cached:  48.0
[I 2023-12-06 12:06:42,560] Trial 83 finished with value: 0.3357658088207245 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.0503629480053434, 'log_learning_rate_D': -1.886097731093899, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.160812377929688
Memory status after this trial: 
Memory allocated:  39.14404296875
Memory cached:  54.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.0183014193779387, 'log_learning_rate_D': -1.8566219121538436, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.5702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.31640625
Memory cached:  48.0
[I 2023-12-06 12:06:58,170] Trial 84 finished with value: 0.35527902841567993 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.0183014193779387, 'log_learning_rate_D': -1.8566219121538436, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.451947927474976
Memory status after this trial: 
Memory allocated:  45.34130859375
Memory cached:  54.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.2655995344773294, 'log_learning_rate_D': -1.5555170762832016, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.947265625
Memory cached:  48.0
[I 2023-12-06 12:07:13,436] Trial 85 finished with value: 0.34594210982322693 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.2655995344773294, 'log_learning_rate_D': -1.5555170762832016, 'training_batch_size': 12, 'training_p': 5}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.098707914352417
Memory status after this trial: 
Memory allocated:  36.19775390625
Memory cached:  50.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.063269599996105, 'log_learning_rate_D': -1.4165261123549766, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  20 training error:  tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  30 training error:  tensor(0.3949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  40 training error:  tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.037109375
Memory cached:  52.0
[I 2023-12-06 12:07:29,093] Trial 86 finished with value: 0.3367815613746643 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.063269599996105, 'log_learning_rate_D': -1.4165261123549766, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.481543064117432
Memory status after this trial: 
Memory allocated:  39.55712890625
Memory cached:  54.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.676597503223628, 'log_learning_rate_D': -1.6806734972454744, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  10 training error:  tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.642578125
Memory cached:  48.0
[I 2023-12-06 12:07:45,242] Trial 87 finished with value: 0.35550743341445923 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.676597503223628, 'log_learning_rate_D': -1.6806734972454744, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.977325916290283
Memory status after this trial: 
Memory allocated:  52.51318359375
Memory cached:  68.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.989538401603861, 'log_learning_rate_D': -1.7744039642592688, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.9419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.015625
Memory cached:  50.0
[I 2023-12-06 12:08:00,963] Trial 88 finished with value: 0.3413098454475403 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.989538401603861, 'log_learning_rate_D': -1.7744039642592688, 'training_batch_size': 12, 'training_p': 5}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.554221630096436
Memory status after this trial: 
Memory allocated:  39.52783203125
Memory cached:  54.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.421125195062475, 'log_learning_rate_D': -1.6209226630396554, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.69140625
Memory cached:  48.0
[I 2023-12-06 12:08:16,618] Trial 89 finished with value: 0.3420986235141754 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.421125195062475, 'log_learning_rate_D': -1.6209226630396554, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.489102602005005
Memory status after this trial: 
Memory allocated:  40.50048828125
Memory cached:  48.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.537281766108369, 'log_learning_rate_D': -1.22616850330979, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.7882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.4134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.5556640625
Memory cached:  48.0
[I 2023-12-06 12:08:32,953] Trial 90 finished with value: 0.34153690934181213 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.537281766108369, 'log_learning_rate_D': -1.22616850330979, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.147085905075073
Memory status after this trial: 
Memory allocated:  50.90087890625
Memory cached:  74.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.8161040230001737, 'log_learning_rate_D': -1.9405702073989604, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.6467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7392578125
Memory cached:  50.0
[I 2023-12-06 12:08:48,967] Trial 91 finished with value: 0.33622869849205017 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.8161040230001737, 'log_learning_rate_D': -1.9405702073989604, 'training_batch_size': 11, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.85782766342163
Memory status after this trial: 
Memory allocated:  42.66650390625
Memory cached:  50.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.8024383804903792, 'log_learning_rate_D': -1.9335979968947261, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.6643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7060546875
Memory cached:  50.0
[I 2023-12-06 12:09:05,134] Trial 92 finished with value: 0.375302791595459 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.8024383804903792, 'log_learning_rate_D': -1.9335979968947261, 'training_batch_size': 11, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.002112865447998
Memory status after this trial: 
Memory allocated:  39.72021484375
Memory cached:  50.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.1456839164129398, 'log_learning_rate_D': -1.7224893852813976, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.7954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.11279296875
Memory cached:  50.0
[I 2023-12-06 12:09:21,266] Trial 93 finished with value: 0.33339977264404297 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.1456839164129398, 'log_learning_rate_D': -1.7224893852813976, 'training_batch_size': 11, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.961078882217407
Memory status after this trial: 
Memory allocated:  54.10791015625
Memory cached:  70.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.1402149410034443, 'log_learning_rate_D': -1.4391130591104093, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  10 training error:  tensor(1.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.6225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.08154296875
Memory cached:  50.0
[I 2023-12-06 12:09:37,878] Trial 94 finished with value: 0.3896786868572235 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.1402149410034443, 'log_learning_rate_D': -1.4391130591104093, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.440861463546753
Memory status after this trial: 
Memory allocated:  57.52392578125
Memory cached:  70.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.312422478625368, 'log_learning_rate_D': -1.312787068057333, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.7577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.4412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.39404296875
Memory cached:  50.0
[I 2023-12-06 12:09:54,241] Trial 95 finished with value: 0.3395117223262787 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.312422478625368, 'log_learning_rate_D': -1.312787068057333, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.19001531600952
Memory status after this trial: 
Memory allocated:  54.61474609375
Memory cached:  72.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.9660859532664443, 'log_learning_rate_D': -1.7106460334679368, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  10 training error:  tensor(1.2769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.443359375
Memory cached:  48.0
[I 2023-12-06 12:10:10,948] Trial 96 finished with value: 0.33776453137397766 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.9660859532664443, 'log_learning_rate_D': -1.7106460334679368, 'training_batch_size': 12, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.482774257659912
Memory status after this trial: 
Memory allocated:  64.05908203125
Memory cached:  74.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.177336699320214, 'log_learning_rate_D': -1.5807720775795853, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.7826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.5869140625
Memory cached:  48.0
[I 2023-12-06 12:10:26,835] Trial 97 finished with value: 0.34106630086898804 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -2.177336699320214, 'log_learning_rate_D': -1.5807720775795853, 'training_batch_size': 11, 'training_p': 2}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.694372415542603
Memory status after this trial: 
Memory allocated:  41.78662109375
Memory cached:  50.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.7075305563984344, 'log_learning_rate_D': -1.8297296257807107, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  10 training error:  tensor(0.6399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  20 training error:  tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  30 training error:  tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  40 training error:  tensor(0.6452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  50 training error:  tensor(0.6504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  60 training error:  tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  70 training error:  tensor(0.6382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  80 training error:  tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
	 epoch  90 training error:  tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.04638671875
Memory cached:  50.0
[I 2023-12-06 12:10:43,053] Trial 98 finished with value: 0.6102336049079895 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -1.7075305563984344, 'log_learning_rate_D': -1.8297296257807107, 'training_batch_size': 11, 'training_p': 4}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  16.066553592681885
Memory status after this trial: 
Memory allocated:  51.16162109375
Memory cached:  68.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.075990172046261, 'log_learning_rate_D': -2.1163620261031535, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.92578125
Memory cached:  48.0
[I 2023-12-06 12:10:58,483] Trial 99 finished with value: 0.3364015519618988 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.075990172046261, 'log_learning_rate_D': -2.1163620261031535, 'training_batch_size': 12, 'training_p': 3}. Best is trial 68 with value: 0.3323483467102051.
Time for this trial:  15.251045227050781
Memory status after this trial: 
Memory allocated:  31.45166015625
Memory cached:  50.0
