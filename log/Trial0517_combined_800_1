[I 2024-05-17 16:02:52,510] A new study created in RDB with name: my_study1
Cuda is available:  True
Device is:  cuda
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial0517_combined_800.pt
Vs.shape:  torch.Size([800, 100])
thetas.shape:  torch.Size([800, 100])
fs.shape:  torch.Size([800, 100])
ts.shape:  torch.Size([800, 100])
Xs.shape:  torch.Size([800, 100])
No pruned database has been founded.
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.884073928190038, 'log_learning_rate_D': -1.0255323274571042, 'log_learning_rate_D_dagger': -2.2686430712451346, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1988, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  184.0
	 epoch  10 training error:  tensor(0.8077, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  238.0
	 epoch  20 training error:  tensor(0.7218, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  236.0
	 epoch  30 training error:  tensor(0.6780, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  228.0
	 epoch  40 training error:  tensor(0.6530, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  234.0
	 epoch  50 training error:  tensor(0.6434, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  236.0
	 epoch  60 training error:  tensor(0.6432, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  240.0
	 epoch  70 training error:  tensor(0.6428, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  236.0
	 epoch  80 training error:  tensor(0.6422, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  226.0
	 epoch  90 training error:  tensor(0.6422, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  7.61767578125
Memory cached:  226.0
[I 2024-05-17 16:07:21,197] Trial 0 finished with value: 0.44261184334754944 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.884073928190038, 'log_learning_rate_D': -1.0255323274571042, 'log_learning_rate_D_dagger': -2.2686430712451346, 'training_batch_size': 10, 'training_p': 3}. Best is trial 0 with value: 0.44261184334754944.
res:  tensor(0.4426, grad_fn=<ToCopyBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  268.3785288333893
Memory status after this trial: 
Memory allocated:  1798.4345703125
Memory cached:  1810.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -2.048313118350797, 'log_learning_rate_D': -1.871862520966515, 'log_learning_rate_D_dagger': -3.8243952693577747, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0362, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1809.66845703125
Memory cached:  1836.0
	 epoch  10 training error:  tensor(0.4822, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1809.66845703125
Memory cached:  1838.0
	 epoch  20 training error:  tensor(0.3870, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  1809.66845703125
Memory cached:  1838.0
