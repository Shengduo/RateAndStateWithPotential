/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-02 22:43:00,335] A new study created in memory with name: no-name-2ae08697-53a4-4639-9b24-be1ed2c48508
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1108_bigDRS_Burigede.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1349518944598014, 'log_learning_rate_D': -2.643919235275282, 'training_batch_size': 11, 'training_p': 8}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4794921875
Memory cached:  40.0
[I 2023-12-02 22:43:16,081] Trial 0 finished with value: 0.07152646780014038 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1349518944598014, 'log_learning_rate_D': -2.643919235275282, 'training_batch_size': 11, 'training_p': 8}. Best is trial 0 with value: 0.07152646780014038.
res:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  15.625044345855713
Memory status after this trial: 
Memory allocated:  50.30078125
Memory cached:  64.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.5217377720073664, 'log_learning_rate_D': -1.8035641486157274, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  10 training error:  tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.80517578125
Memory cached:  66.0
[I 2023-12-02 22:43:28,586] Trial 1 finished with value: 0.07910563051700592 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.5217377720073664, 'log_learning_rate_D': -1.8035641486157274, 'training_batch_size': 10, 'training_p': 5}. Best is trial 0 with value: 0.07152646780014038.
Time for this trial:  12.389510869979858
Memory status after this trial: 
Memory allocated:  60.07568359375
Memory cached:  68.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.3321939903795386, 'log_learning_rate_D': -4.660810989798333, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  10 training error:  tensor(0.7875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  20 training error:  tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  50 training error:  tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  60 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  80 training error:  tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
	 epoch  90 training error:  tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.5546875
Memory cached:  82.0
[I 2023-12-02 22:43:42,260] Trial 2 finished with value: 0.0916667953133583 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.3321939903795386, 'log_learning_rate_D': -4.660810989798333, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 0.07152646780014038.
Time for this trial:  13.55133581161499
Memory status after this trial: 
Memory allocated:  123.23681640625
Memory cached:  140.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.608933156313997, 'log_learning_rate_D': -1.5501941244454929, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(2.2448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  10 training error:  tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  50 training error:  tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  70 training error:  tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  80 training error:  tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
	 epoch  90 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.69873046875
Memory cached:  64.0
[I 2023-12-02 22:43:54,901] Trial 3 finished with value: 0.08129741251468658 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.608933156313997, 'log_learning_rate_D': -1.5501941244454929, 'training_batch_size': 12, 'training_p': 5}. Best is trial 0 with value: 0.07152646780014038.
Time for this trial:  12.516819477081299
Memory status after this trial: 
Memory allocated:  74.65771484375
Memory cached:  104.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.472584900903988, 'log_learning_rate_D': -4.501290593182744, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  10 training error:  tensor(0.8227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  20 training error:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  30 training error:  tensor(0.5452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  40 training error:  tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  50 training error:  tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  60 training error:  tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  70 training error:  tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  80 training error:  tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
	 epoch  90 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.19921875
Memory cached:  70.0
[I 2023-12-02 22:44:08,521] Trial 4 finished with value: 0.06874580681324005 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.472584900903988, 'log_learning_rate_D': -4.501290593182744, 'training_batch_size': 12, 'training_p': 8}. Best is trial 4 with value: 0.06874580681324005.
res:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  13.500769138336182
Memory status after this trial: 
Memory allocated:  47.408203125
Memory cached:  96.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.5517080647471695, 'log_learning_rate_D': -2.1302564475834935, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(2.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.9747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.623046875
Memory cached:  96.0
[I 2023-12-02 22:44:20,309] Trial 5 finished with value: 0.11848662048578262 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.5517080647471695, 'log_learning_rate_D': -2.1302564475834935, 'training_batch_size': 11, 'training_p': 2}. Best is trial 4 with value: 0.06874580681324005.
Time for this trial:  11.672616004943848
Memory status after this trial: 
Memory allocated:  53.80810546875
Memory cached:  96.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.6552542434676747, 'log_learning_rate_D': -3.282200512933091, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  10 training error:  tensor(42.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  20 training error:  tensor(2.4088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.8770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  40 training error:  tensor(2.3364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  50 training error:  tensor(2.1769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  60 training error:  tensor(1.7531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  70 training error:  tensor(1.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  80 training error:  tensor(2.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
	 epoch  90 training error:  tensor(1.9691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.08544921875
Memory cached:  98.0
[I 2023-12-02 22:44:33,136] Trial 6 finished with value: 2.0582826137542725 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.6552542434676747, 'log_learning_rate_D': -3.282200512933091, 'training_batch_size': 8, 'training_p': 7}. Best is trial 4 with value: 0.06874580681324005.
Time for this trial:  12.714040040969849
Memory status after this trial: 
Memory allocated:  74.69189453125
Memory cached:  100.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2640085614352436, 'log_learning_rate_D': -2.6990296608947273, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  10 training error:  tensor(634.7781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  20 training error:  tensor(45.5574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  30 training error:  tensor(51.7123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  40 training error:  tensor(51.7261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  50 training error:  tensor(49.3743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  60 training error:  tensor(46.1002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  70 training error:  tensor(42.4647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  80 training error:  tensor(38.6835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
	 epoch  90 training error:  tensor(34.8390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  60.7890625
Memory cached:  116.0
[I 2023-12-02 22:44:46,374] Trial 7 finished with value: 32.215553283691406 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.2640085614352436, 'log_learning_rate_D': -2.6990296608947273, 'training_batch_size': 11, 'training_p': 8}. Best is trial 4 with value: 0.06874580681324005.
Time for this trial:  13.114305019378662
Memory status after this trial: 
Memory allocated:  97.91259765625
Memory cached:  122.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -1.5713690114844385, 'log_learning_rate_D': -1.5499723251017308, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  10 training error:  tensor(7.5262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  20 training error:  tensor(9.7720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  30 training error:  tensor(4.9161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.3803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  60 training error:  tensor(1.2054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  70 training error:  tensor(1.4088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.8664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.6712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.59375
Memory cached:  98.0
[I 2023-12-02 22:44:59,546] Trial 8 finished with value: 0.45201078057289124 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -1.5713690114844385, 'log_learning_rate_D': -1.5499723251017308, 'training_batch_size': 12, 'training_p': 8}. Best is trial 4 with value: 0.06874580681324005.
Time for this trial:  13.044759035110474
Memory status after this trial: 
Memory allocated:  79.66748046875
Memory cached:  98.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3939655379288425, 'log_learning_rate_D': -4.021471541095835, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.31298828125
Memory cached:  98.0
[I 2023-12-02 22:45:12,904] Trial 9 finished with value: 0.08365026116371155 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.3939655379288425, 'log_learning_rate_D': -4.021471541095835, 'training_batch_size': 10, 'training_p': 5}. Best is trial 4 with value: 0.06874580681324005.
Time for this trial:  13.235323429107666
Memory status after this trial: 
Memory allocated:  97.80029296875
Memory cached:  120.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.405205823522083, 'log_learning_rate_D': -4.774590966395399, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.81494140625
Memory cached:  96.0
[I 2023-12-02 22:45:27,866] Trial 10 finished with value: 0.06874288618564606 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.405205823522083, 'log_learning_rate_D': -4.774590966395399, 'training_batch_size': 6, 'training_p': 3}. Best is trial 10 with value: 0.06874288618564606.
res:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  14.777755975723267
Memory status after this trial: 
Memory allocated:  39.8193359375
Memory cached:  98.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.470095222712242, 'log_learning_rate_D': -4.981886540870889, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.9008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.36669921875
Memory cached:  98.0
[I 2023-12-02 22:45:42,796] Trial 11 finished with value: 0.09930847585201263 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.470095222712242, 'log_learning_rate_D': -4.981886540870889, 'training_batch_size': 6, 'training_p': 2}. Best is trial 10 with value: 0.06874288618564606.
Time for this trial:  14.744771718978882
Memory status after this trial: 
Memory allocated:  80.10693359375
Memory cached:  100.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.222745063688886, 'log_learning_rate_D': -4.201283558890607, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(2.4773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.44677734375
Memory cached:  98.0
[I 2023-12-02 22:45:58,062] Trial 12 finished with value: 0.13050149381160736 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.222745063688886, 'log_learning_rate_D': -4.201283558890607, 'training_batch_size': 6, 'training_p': 3}. Best is trial 10 with value: 0.06874288618564606.
Time for this trial:  15.082387447357178
Memory status after this trial: 
Memory allocated:  104.05810546875
Memory cached:  144.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.174867881393798, 'log_learning_rate_D': -3.754956977879038, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.4951171875
Memory cached:  98.0
[I 2023-12-02 22:46:11,229] Trial 13 finished with value: 0.06987134367227554 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.174867881393798, 'log_learning_rate_D': -3.754956977879038, 'training_batch_size': 8, 'training_p': 6}. Best is trial 10 with value: 0.06874288618564606.
Time for this trial:  12.971530199050903
Memory status after this trial: 
Memory allocated:  74.96533203125
Memory cached:  98.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.9367948445982877, 'log_learning_rate_D': -4.542179091853436, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.6326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.17626953125
Memory cached:  98.0
[I 2023-12-02 22:46:24,243] Trial 14 finished with value: 0.06846974045038223 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.9367948445982877, 'log_learning_rate_D': -4.542179091853436, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.06846974045038223.
res:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  12.82456374168396
Memory status after this trial: 
Memory allocated:  24.8974609375
Memory cached:  62.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.547705673942776, 'log_learning_rate_D': -4.959163251154325, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.86572265625
Memory cached:  62.0
[I 2023-12-02 22:46:37,332] Trial 15 finished with value: 0.07413072884082794 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.547705673942776, 'log_learning_rate_D': -4.959163251154325, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.06846974045038223.
Time for this trial:  12.912562131881714
Memory status after this trial: 
Memory allocated:  51.54150390625
Memory cached:  62.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.798076608722433, 'log_learning_rate_D': -3.826211983618313, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.7666015625
Memory cached:  62.0
[I 2023-12-02 22:46:50,053] Trial 16 finished with value: 0.07420124858617783 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.798076608722433, 'log_learning_rate_D': -3.826211983618313, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.06846974045038223.
Time for this trial:  12.536552906036377
Memory status after this trial: 
Memory allocated:  47.89990234375
Memory cached:  62.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.8757471169704116, 'log_learning_rate_D': -4.371889437133465, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.6630859375
Memory cached:  62.0
[I 2023-12-02 22:47:03,606] Trial 17 finished with value: 0.08433093130588531 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.8757471169704116, 'log_learning_rate_D': -4.371889437133465, 'training_batch_size': 7, 'training_p': 4}. Best is trial 14 with value: 0.06846974045038223.
Time for this trial:  13.355863332748413
Memory status after this trial: 
Memory allocated:  63.81494140625
Memory cached:  84.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9931400156482435, 'log_learning_rate_D': -3.4753092366047507, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.07177734375
Memory cached:  62.0
[I 2023-12-02 22:47:17,555] Trial 18 finished with value: 0.07045003026723862 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.9931400156482435, 'log_learning_rate_D': -3.4753092366047507, 'training_batch_size': 6, 'training_p': 4}. Best is trial 14 with value: 0.06846974045038223.
Time for this trial:  13.75872254371643
Memory status after this trial: 
Memory allocated:  54.48876953125
Memory cached:  82.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.92779801087874, 'log_learning_rate_D': -4.544499219985475, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.7572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.6602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.40673828125
Memory cached:  62.0
[I 2023-12-02 22:47:30,421] Trial 19 finished with value: 0.44952869415283203 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -4.92779801087874, 'log_learning_rate_D': -4.544499219985475, 'training_batch_size': 9, 'training_p': 2}. Best is trial 14 with value: 0.06846974045038223.
Time for this trial:  12.683615684509277
Memory status after this trial: 
Memory allocated:  41.27392578125
Memory cached:  62.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.8703746298418196, 'log_learning_rate_D': -4.118564637445272, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  10 training error:  tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  30 training error:  tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  40 training error:  tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  60 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  80 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.2451171875
Memory cached:  62.0
[I 2023-12-02 22:47:43,513] Trial 20 finished with value: 0.06837578117847443 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.8703746298418196, 'log_learning_rate_D': -4.118564637445272, 'training_batch_size': 7, 'training_p': 3}. Best is trial 20 with value: 0.06837578117847443.
res:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  12.898591756820679
Memory status after this trial: 
Memory allocated:  27.298828125
Memory cached:  60.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.9196487512350062, 'log_learning_rate_D': -4.114469372551554, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  20 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  30 training error:  tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  40 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  50 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  60 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  70 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  80 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
	 epoch  90 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.6494140625
Memory cached:  60.0
[I 2023-12-02 22:47:56,629] Trial 21 finished with value: 0.06807418167591095 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.9196487512350062, 'log_learning_rate_D': -4.114469372551554, 'training_batch_size': 7, 'training_p': 3}. Best is trial 21 with value: 0.06807418167591095.
res:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  12.923902034759521
Memory status after this trial: 
Memory allocated:  27.298828125
Memory cached:  80.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.870982586844168, 'log_learning_rate_D': -4.135536571024169, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.615234375
Memory cached:  80.0
[I 2023-12-02 22:48:09,620] Trial 22 finished with value: 0.07005328685045242 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.870982586844168, 'log_learning_rate_D': -4.135536571024169, 'training_batch_size': 7, 'training_p': 4}. Best is trial 21 with value: 0.06807418167591095.
Time for this trial:  12.79039716720581
Memory status after this trial: 
Memory allocated:  55.42529296875
Memory cached:  80.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.206249907250275, 'log_learning_rate_D': -3.7476713655716947, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.0869140625
Memory cached:  80.0
[I 2023-12-02 22:48:22,142] Trial 23 finished with value: 0.07557268440723419 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.206249907250275, 'log_learning_rate_D': -3.7476713655716947, 'training_batch_size': 8, 'training_p': 3}. Best is trial 21 with value: 0.06807418167591095.
Time for this trial:  12.276705026626587
Memory status after this trial: 
Memory allocated:  46.45947265625
Memory cached:  82.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.8671112385293274, 'log_learning_rate_D': -4.3188220663581, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.1650390625
Memory cached:  80.0
[I 2023-12-02 22:48:35,373] Trial 24 finished with value: 0.07289707660675049 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.8671112385293274, 'log_learning_rate_D': -4.3188220663581, 'training_batch_size': 9, 'training_p': 2}. Best is trial 21 with value: 0.06807418167591095.
Time for this trial:  13.03270936012268
Memory status after this trial: 
Memory allocated:  54.48388671875
Memory cached:  82.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.0681014976371803, 'log_learning_rate_D': -3.43544441697093, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  20 training error:  tensor(2.9932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  30 training error:  tensor(1.0167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  40 training error:  tensor(1.0065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  50 training error:  tensor(1.5580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.7187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.15185546875
Memory cached:  80.0
[I 2023-12-02 22:48:48,671] Trial 25 finished with value: 0.5375936627388 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.0681014976371803, 'log_learning_rate_D': -3.43544441697093, 'training_batch_size': 7, 'training_p': 4}. Best is trial 21 with value: 0.06807418167591095.
Time for this trial:  13.103583335876465
Memory status after this trial: 
Memory allocated:  73.18701171875
Memory cached:  104.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6845583368586396, 'log_learning_rate_D': -4.113520571875097, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.6401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.298828125
Memory cached:  80.0
[I 2023-12-02 22:49:02,011] Trial 26 finished with value: 0.06941971927881241 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6845583368586396, 'log_learning_rate_D': -4.113520571875097, 'training_batch_size': 8, 'training_p': 6}. Best is trial 21 with value: 0.06807418167591095.
Time for this trial:  13.149784803390503
Memory status after this trial: 
Memory allocated:  55.94384765625
Memory cached:  80.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.320241204478245, 'log_learning_rate_D': -4.636495451533904, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  10 training error:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  30 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  40 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  70 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.447265625
Memory cached:  80.0
[I 2023-12-02 22:49:15,532] Trial 27 finished with value: 0.06754851341247559 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.320241204478245, 'log_learning_rate_D': -4.636495451533904, 'training_batch_size': 7, 'training_p': 3}. Best is trial 27 with value: 0.06754851341247559.
res:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  13.322712182998657
Memory status after this trial: 
Memory allocated:  38.994140625
Memory cached:  98.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.4239161359212646, 'log_learning_rate_D': -4.715553419239762, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.013671875
Memory cached:  98.0
[I 2023-12-02 22:49:29,449] Trial 28 finished with value: 0.07923900336027145 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.4239161359212646, 'log_learning_rate_D': -4.715553419239762, 'training_batch_size': 6, 'training_p': 2}. Best is trial 27 with value: 0.06754851341247559.
Time for this trial:  13.730806350708008
Memory status after this trial: 
Memory allocated:  78.35205078125
Memory cached:  98.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.114053576179075, 'log_learning_rate_D': -3.0222247525254353, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.31884765625
Memory cached:  98.0
[I 2023-12-02 22:49:42,707] Trial 29 finished with value: 0.07413670420646667 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.114053576179075, 'log_learning_rate_D': -3.0222247525254353, 'training_batch_size': 9, 'training_p': 4}. Best is trial 27 with value: 0.06754851341247559.
Time for this trial:  12.999754428863525
Memory status after this trial: 
Memory allocated:  84.13330078125
Memory cached:  118.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.810538226041093, 'log_learning_rate_D': -3.9034983979123017, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.818359375
Memory cached:  98.0
[I 2023-12-02 22:49:56,291] Trial 30 finished with value: 0.07793604582548141 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.810538226041093, 'log_learning_rate_D': -3.9034983979123017, 'training_batch_size': 7, 'training_p': 3}. Best is trial 27 with value: 0.06754851341247559.
Time for this trial:  13.345258951187134
Memory status after this trial: 
Memory allocated:  95.07861328125
Memory cached:  120.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.2154123959154033, 'log_learning_rate_D': -4.465558375790163, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6943359375
Memory cached:  98.0
[I 2023-12-02 22:50:09,120] Trial 31 finished with value: 0.07242856174707413 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.2154123959154033, 'log_learning_rate_D': -4.465558375790163, 'training_batch_size': 7, 'training_p': 3}. Best is trial 27 with value: 0.06754851341247559.
Time for this trial:  12.609931230545044
Memory status after this trial: 
Memory allocated:  62.95556640625
Memory cached:  100.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.0082390239340446, 'log_learning_rate_D': -4.234028095866634, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  10 training error:  tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  20 training error:  tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  30 training error:  tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  40 training error:  tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  50 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  60 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  70 training error:  tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  80 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
	 epoch  90 training error:  tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.3984375
Memory cached:  100.0
[I 2023-12-02 22:50:22,388] Trial 32 finished with value: 0.07057445496320724 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.0082390239340446, 'log_learning_rate_D': -4.234028095866634, 'training_batch_size': 8, 'training_p': 3}. Best is trial 27 with value: 0.06754851341247559.
Time for this trial:  13.077889442443848
Memory status after this trial: 
Memory allocated:  80.11474609375
Memory cached:  104.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.76611676699241, 'log_learning_rate_D': -4.755240801459667, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  10 training error:  tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  45.6455078125
Memory cached:  98.0
[I 2023-12-02 22:50:35,301] Trial 33 finished with value: 0.06666743755340576 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.76611676699241, 'log_learning_rate_D': -4.755240801459667, 'training_batch_size': 7, 'training_p': 2}. Best is trial 33 with value: 0.06666743755340576.
res:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  12.692197322845459
Memory status after this trial: 
Memory allocated:  25.177734375
Memory cached:  56.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.7000834407014285, 'log_learning_rate_D': -4.837853452277111, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.9189453125
Memory cached:  56.0
[I 2023-12-02 22:50:49,138] Trial 34 finished with value: 0.07059898972511292 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.7000834407014285, 'log_learning_rate_D': -4.837853452277111, 'training_batch_size': 6, 'training_p': 2}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  13.611121654510498
Memory status after this trial: 
Memory allocated:  48.20458984375
Memory cached:  56.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.3395452087388744, 'log_learning_rate_D': -4.634672600031397, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.1689453125
Memory cached:  56.0
[I 2023-12-02 22:51:02,103] Trial 35 finished with value: 0.0767495334148407 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.3395452087388744, 'log_learning_rate_D': -4.634672600031397, 'training_batch_size': 8, 'training_p': 2}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  12.768250465393066
Memory status after this trial: 
Memory allocated:  59.27197265625
Memory cached:  78.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.719626717634398, 'log_learning_rate_D': -4.376086184226974, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.8076171875
Memory cached:  76.0
[I 2023-12-02 22:51:15,578] Trial 36 finished with value: 0.07184453308582306 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.719626717634398, 'log_learning_rate_D': -4.376086184226974, 'training_batch_size': 7, 'training_p': 4}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  13.277370929718018
Memory status after this trial: 
Memory allocated:  94.64501953125
Memory cached:  136.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.1303722339965763, 'log_learning_rate_D': -4.993605021237745, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.1083984375
Memory cached:  56.0
[I 2023-12-02 22:51:27,579] Trial 37 finished with value: 0.08299154788255692 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.1303722339965763, 'log_learning_rate_D': -4.993605021237745, 'training_batch_size': 9, 'training_p': 2}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  11.83056902885437
Memory status after this trial: 
Memory allocated:  34.26513671875
Memory cached:  56.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.4286632586270693, 'log_learning_rate_D': -4.724253268196651, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.7666015625
Memory cached:  56.0
[I 2023-12-02 22:51:40,199] Trial 38 finished with value: 0.0799151137471199 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.4286632586270693, 'log_learning_rate_D': -4.724253268196651, 'training_batch_size': 8, 'training_p': 5}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  12.432079553604126
Memory status after this trial: 
Memory allocated:  43.74462890625
Memory cached:  56.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6224805392452013, 'log_learning_rate_D': -4.021752000478066, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.1845703125
Memory cached:  56.0
[I 2023-12-02 22:51:54,732] Trial 39 finished with value: 0.07506563514471054 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.6224805392452013, 'log_learning_rate_D': -4.021752000478066, 'training_batch_size': 6, 'training_p': 6}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  14.330178499221802
Memory status after this trial: 
Memory allocated:  50.11962890625
Memory cached:  56.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6755587687534024, 'log_learning_rate_D': -4.416594713462804, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(2.1553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.509765625
Memory cached:  56.0
[I 2023-12-02 22:52:07,032] Trial 40 finished with value: 0.07253506034612656 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6755587687534024, 'log_learning_rate_D': -4.416594713462804, 'training_batch_size': 10, 'training_p': 2}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  12.121907472610474
Memory status after this trial: 
Memory allocated:  39.03564453125
Memory cached:  56.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.9836992742335773, 'log_learning_rate_D': -4.589986577930136, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.5541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.95556640625
Memory cached:  56.0
[I 2023-12-02 22:52:20,136] Trial 41 finished with value: 0.06728212535381317 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.9836992742335773, 'log_learning_rate_D': -4.589986577930136, 'training_batch_size': 7, 'training_p': 3}. Best is trial 33 with value: 0.06666743755340576.
Time for this trial:  12.900536298751831
Memory status after this trial: 
Memory allocated:  49.88720703125
Memory cached:  60.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.0583981113518597, 'log_learning_rate_D': -4.600608753324331, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  32.2431640625
Memory cached:  56.0
[I 2023-12-02 22:52:33,325] Trial 42 finished with value: 0.06510788202285767 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.0583981113518597, 'log_learning_rate_D': -4.600608753324331, 'training_batch_size': 7, 'training_p': 3}. Best is trial 42 with value: 0.06510788202285767.
res:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  13.011418581008911
Memory status after this trial: 
Memory allocated:  28.142578125
Memory cached:  76.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.2497461958892293, 'log_learning_rate_D': -4.606214503766109, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.2802734375
Memory cached:  76.0
[I 2023-12-02 22:52:46,579] Trial 43 finished with value: 0.07147899270057678 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.2497461958892293, 'log_learning_rate_D': -4.606214503766109, 'training_batch_size': 8, 'training_p': 3}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  13.047853946685791
Memory status after this trial: 
Memory allocated:  73.93212890625
Memory cached:  100.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.509286272578551, 'log_learning_rate_D': -4.802828011729035, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.7001953125
Memory cached:  76.0
[I 2023-12-02 22:52:59,028] Trial 44 finished with value: 0.06547071784734726 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.509286272578551, 'log_learning_rate_D': -4.802828011729035, 'training_batch_size': 7, 'training_p': 4}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  12.25052285194397
Memory status after this trial: 
Memory allocated:  46.99267578125
Memory cached:  76.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.3276171257618143, 'log_learning_rate_D': -4.859032890103584, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.7206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  31.2841796875
Memory cached:  76.0
[I 2023-12-02 22:53:12,596] Trial 45 finished with value: 0.09512565284967422 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.3276171257618143, 'log_learning_rate_D': -4.859032890103584, 'training_batch_size': 6, 'training_p': 5}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  13.400393009185791
Memory status after this trial: 
Memory allocated:  48.46533203125
Memory cached:  78.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.5423360646962756, 'log_learning_rate_D': -4.747923363180044, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(2.2064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.3369140625
Memory cached:  76.0
[I 2023-12-02 22:53:25,214] Trial 46 finished with value: 0.07405410706996918 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.5423360646962756, 'log_learning_rate_D': -4.747923363180044, 'training_batch_size': 7, 'training_p': 4}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  12.40852427482605
Memory status after this trial: 
Memory allocated:  43.02197265625
Memory cached:  78.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.4889756441235367, 'log_learning_rate_D': -4.571121908231817, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.9179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.6721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  35.27685546875
Memory cached:  76.0
[I 2023-12-02 22:53:39,595] Trial 47 finished with value: 0.09229210764169693 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.4889756441235367, 'log_learning_rate_D': -4.571121908231817, 'training_batch_size': 6, 'training_p': 4}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  14.183425903320312
Memory status after this trial: 
Memory allocated:  68.80712890625
Memory cached:  96.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.092252438225017, 'log_learning_rate_D': -4.8329032255806785, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  10 training error:  tensor(1.6205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.28125
Memory cached:  76.0
[I 2023-12-02 22:53:53,817] Trial 48 finished with value: 0.12901847064495087 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.092252438225017, 'log_learning_rate_D': -4.8329032255806785, 'training_batch_size': 8, 'training_p': 2}. Best is trial 42 with value: 0.06510788202285767.
Time for this trial:  14.010005950927734
Memory status after this trial: 
Memory allocated:  81.41943359375
Memory cached:  102.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.05808293881488, 'log_learning_rate_D': -4.280861258678858, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  10 training error:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  20 training error:  tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  30 training error:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  40 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  50 training error:  tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  60 training error:  tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  70 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  80 training error:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
	 epoch  90 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.01220703125
Memory cached:  76.0
[I 2023-12-02 22:54:06,427] Trial 49 finished with value: 0.06962890923023224 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.05808293881488, 'log_learning_rate_D': -4.280861258678858, 'training_batch_size': 7, 'training_p': 3}. Best is trial 42 with value: 0.06510788202285767.
[I 2023-12-02 22:54:06,428] A new study created in memory with name: no-name-e3133144-1181-48ff-b916-ad975abc3af3
Time for this trial:  12.40198802947998
Memory status after this trial: 
Memory allocated:  49.11376953125
Memory cached:  80.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.4286238115650853, 'log_learning_rate_D': -3.9071345720499195, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  26.0
	 epoch  10 training error:  tensor(1.6437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.11328125
Memory cached:  30.0
[I 2023-12-02 22:54:55,569] Trial 0 finished with value: 0.13130612671375275 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.4286238115650853, 'log_learning_rate_D': -3.9071345720499195, 'training_batch_size': 10, 'training_p': 4}. Best is trial 0 with value: 0.13130612671375275.
res:  tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  49.01761293411255
Memory status after this trial: 
Memory allocated:  85.333984375
Memory cached:  98.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.437474430220725, 'log_learning_rate_D': -2.3662995598471968, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(2.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  104.0
	 epoch  10 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  20 training error:  tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  30 training error:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  40 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  50 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  60 training error:  tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  70 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  80 training error:  tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
	 epoch  90 training error:  tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.67138671875
Memory cached:  106.0
[I 2023-12-02 22:55:45,681] Trial 1 finished with value: 0.039891041815280914 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.437474430220725, 'log_learning_rate_D': -2.3662995598471968, 'training_batch_size': 9, 'training_p': 4}. Best is trial 1 with value: 0.039891041815280914.
res:  tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  49.9927077293396
Memory status after this trial: 
Memory allocated:  53.025390625
Memory cached:  130.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.4812767560997546, 'log_learning_rate_D': -1.9885794397304912, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.23974609375
Memory cached:  152.0
	 epoch  10 training error:  tensor(23.4743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.23974609375
Memory cached:  154.0
	 epoch  20 training error:  tensor(14.8692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.23974609375
Memory cached:  154.0
[W 2023-12-02 22:56:00,200] Trial 2 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.4812767560997546, 'log_learning_rate_D': -1.9885794397304912, 'training_batch_size': 8, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-02 22:56:00,201] Trial 2 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  14.398038387298584
Memory status after this trial: 
Memory allocated:  150.90966796875
Memory cached:  172.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.317878177776137, 'log_learning_rate_D': -2.5165540431660736, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  134.0
	 epoch  10 training error:  tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  20 training error:  tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  30 training error:  tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  40 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  50 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  60 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  70 training error:  tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  80 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
	 epoch  90 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.81201171875
Memory cached:  136.0
[I 2023-12-02 22:57:01,890] Trial 3 finished with value: 0.05049261450767517 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.317878177776137, 'log_learning_rate_D': -2.5165540431660736, 'training_batch_size': 8, 'training_p': 5}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  61.55611753463745
Memory status after this trial: 
Memory allocated:  135.412109375
Memory cached:  138.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.249261910241137, 'log_learning_rate_D': -3.0805825864975533, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.5539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  134.0
	 epoch  10 training error:  tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  20 training error:  tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  30 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  40 training error:  tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  50 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  60 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  70 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  80 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
	 epoch  90 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.81591796875
Memory cached:  136.0
[I 2023-12-02 22:57:45,229] Trial 4 finished with value: 0.04705343395471573 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.249261910241137, 'log_learning_rate_D': -3.0805825864975533, 'training_batch_size': 11, 'training_p': 2}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  43.22230005264282
Memory status after this trial: 
Memory allocated:  93.50146484375
Memory cached:  132.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.106983310269947, 'log_learning_rate_D': -2.9308780905957947, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  10 training error:  tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  20 training error:  tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.14404296875
Memory cached:  132.0
[I 2023-12-02 22:58:30,403] Trial 5 finished with value: 0.1296425461769104 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.106983310269947, 'log_learning_rate_D': -2.9308780905957947, 'training_batch_size': 11, 'training_p': 7}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  45.04028940200806
Memory status after this trial: 
Memory allocated:  120.669921875
Memory cached:  132.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.219440227237649, 'log_learning_rate_D': -3.012538522079453, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.3634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  134.0
	 epoch  10 training error:  tensor(0.9187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  20 training error:  tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.72021484375
Memory cached:  132.0
[I 2023-12-02 22:59:20,102] Trial 6 finished with value: 0.07033988833427429 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.219440227237649, 'log_learning_rate_D': -3.012538522079453, 'training_batch_size': 10, 'training_p': 8}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  49.569122076034546
Memory status after this trial: 
Memory allocated:  125.556640625
Memory cached:  132.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.9696868193032024, 'log_learning_rate_D': -1.3204013122722134, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.95849609375
Memory cached:  174.0
[W 2023-12-02 22:59:22,652] Trial 7 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.9696868193032024, 'log_learning_rate_D': -1.3204013122722134, 'training_batch_size': 8, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-02 22:59:22,653] Trial 7 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4314522743225098
Memory status after this trial: 
Memory allocated:  164.93408203125
Memory cached:  172.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.163322445106711, 'log_learning_rate_D': -3.5320166069984147, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  10 training error:  tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  20 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  30 training error:  tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  40 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  50 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  60 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  70 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  80 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
	 epoch  90 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.52490234375
Memory cached:  134.0
[I 2023-12-02 23:00:15,867] Trial 8 finished with value: 0.05131523683667183 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.163322445106711, 'log_learning_rate_D': -3.5320166069984147, 'training_batch_size': 7, 'training_p': 8}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  53.0638587474823
Memory status after this trial: 
Memory allocated:  119.81396484375
Memory cached:  132.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.5434938710149142, 'log_learning_rate_D': -4.14494865837571, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(6.1935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  10 training error:  tensor(11.2305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  20 training error:  tensor(1.1714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.8554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.85205078125
Memory cached:  130.0
[I 2023-12-02 23:01:11,068] Trial 9 finished with value: 0.05386148765683174 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.5434938710149142, 'log_learning_rate_D': -4.14494865837571, 'training_batch_size': 6, 'training_p': 8}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  55.072333097457886
Memory status after this trial: 
Memory allocated:  91.21875
Memory cached:  130.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.9495103908387903, 'log_learning_rate_D': -3.5066135701401655, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.3767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  10 training error:  tensor(4.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  20 training error:  tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.42724609375
Memory cached:  132.0
[I 2023-12-02 23:02:01,836] Trial 10 finished with value: 0.13259494304656982 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -1.9495103908387903, 'log_learning_rate_D': -3.5066135701401655, 'training_batch_size': 11, 'training_p': 5}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  50.642258167266846
Memory status after this trial: 
Memory allocated:  124.96923828125
Memory cached:  132.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.279734714635154, 'log_learning_rate_D': -4.775584707756857, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  10 training error:  tensor(0.7011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  20 training error:  tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.14013671875
Memory cached:  132.0
[I 2023-12-02 23:02:33,865] Trial 11 finished with value: 0.05262642726302147 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.279734714635154, 'log_learning_rate_D': -4.775584707756857, 'training_batch_size': 11, 'training_p': 7}. Best is trial 1 with value: 0.039891041815280914.
Time for this trial:  31.894949674606323
Memory status after this trial: 
Memory allocated:  82.490234375
Memory cached:  132.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.862835929973448, 'log_learning_rate_D': -1.3885235937948512, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:35,773] Trial 12 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.862835929973448, 'log_learning_rate_D': -1.3885235937948512, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:35,774] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7260873317718506
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.91105457956146, 'log_learning_rate_D': -1.549763826322481, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.35107421875
Memory cached:  156.0
[W 2023-12-02 23:02:38,343] Trial 13 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.91105457956146, 'log_learning_rate_D': -1.549763826322481, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:38,348] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.376356601715088
Memory status after this trial: 
Memory allocated:  143.1005859375
Memory cached:  162.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.62393371412588, 'log_learning_rate_D': -1.4433949323291935, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.39208984375
Memory cached:  154.0
[W 2023-12-02 23:02:40,414] Trial 14 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.62393371412588, 'log_learning_rate_D': -1.4433949323291935, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:40,415] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8684167861938477
Memory status after this trial: 
Memory allocated:  162.15234375
Memory cached:  178.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.817367300056352, 'log_learning_rate_D': -1.3045385774092657, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:42,496] Trial 15 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.817367300056352, 'log_learning_rate_D': -1.3045385774092657, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:42,497] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8749871253967285
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.758763342591761, 'log_learning_rate_D': -1.4776866565861213, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.39208984375
Memory cached:  154.0
[W 2023-12-02 23:02:44,701] Trial 16 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.758763342591761, 'log_learning_rate_D': -1.4776866565861213, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:44,701] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0005581378936768
Memory status after this trial: 
Memory allocated:  162.15234375
Memory cached:  178.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.563034863362305, 'log_learning_rate_D': -1.3275631346446923, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.82763671875
Memory cached:  154.0
[W 2023-12-02 23:02:46,586] Trial 17 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.563034863362305, 'log_learning_rate_D': -1.3275631346446923, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:46,586] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7126963138580322
Memory status after this trial: 
Memory allocated:  147.3388671875
Memory cached:  164.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.93572690542139, 'log_learning_rate_D': -1.629283661946633, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:49,210] Trial 18 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.93572690542139, 'log_learning_rate_D': -1.629283661946633, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:49,210] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4452879428863525
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.921308215990525, 'log_learning_rate_D': -1.4952606775015391, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:51,250] Trial 19 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.921308215990525, 'log_learning_rate_D': -1.4952606775015391, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:51,251] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8448576927185059
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.943198153728565, 'log_learning_rate_D': -1.4546121605727471, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:53,214] Trial 20 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.943198153728565, 'log_learning_rate_D': -1.4546121605727471, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:53,215] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7785563468933105
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.934880947861461, 'log_learning_rate_D': -1.4653019917920571, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.3987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.86083984375
Memory cached:  156.0
[W 2023-12-02 23:02:55,542] Trial 21 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.934880947861461, 'log_learning_rate_D': -1.4653019917920571, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:55,543] Trial 21 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1563501358032227
Memory status after this trial: 
Memory allocated:  150.78515625
Memory cached:  168.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.907948397074884, 'log_learning_rate_D': -1.4827375170030268, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.7771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:57,455] Trial 22 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.907948397074884, 'log_learning_rate_D': -1.4827375170030268, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:57,456] Trial 22 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7280309200286865
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.73402327117577, 'log_learning_rate_D': -1.3943330482370166, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:02:59,424] Trial 23 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.73402327117577, 'log_learning_rate_D': -1.3943330482370166, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:02:59,425] Trial 23 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7815935611724854
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.79415473299416, 'log_learning_rate_D': -1.120912304132958, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:01,245] Trial 24 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.79415473299416, 'log_learning_rate_D': -1.120912304132958, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:01,246] Trial 24 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6298794746398926
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.899621781739375, 'log_learning_rate_D': -1.4885520905785163, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:03,194] Trial 25 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.899621781739375, 'log_learning_rate_D': -1.4885520905785163, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:03,196] Trial 25 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7634809017181396
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.7346647626867435, 'log_learning_rate_D': -1.3830909721096063, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.2042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.82763671875
Memory cached:  154.0
[W 2023-12-02 23:03:05,080] Trial 26 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.7346647626867435, 'log_learning_rate_D': -1.3830909721096063, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:05,082] Trial 26 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6977148056030273
Memory status after this trial: 
Memory allocated:  147.3388671875
Memory cached:  164.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.950245166312055, 'log_learning_rate_D': -1.5885767733283562, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:07,099] Trial 27 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.950245166312055, 'log_learning_rate_D': -1.5885767733283562, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:07,100] Trial 27 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8463921546936035
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.977022784142224, 'log_learning_rate_D': -1.5157580164118254, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:09,183] Trial 28 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.977022784142224, 'log_learning_rate_D': -1.5157580164118254, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:09,184] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8896253108978271
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.29087782490322, 'log_learning_rate_D': -1.4389263978193356, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:11,063] Trial 29 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.29087782490322, 'log_learning_rate_D': -1.4389263978193356, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:11,064] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6940934658050537
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.929079451708249, 'log_learning_rate_D': -1.4939662093599633, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:12,988] Trial 30 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.929079451708249, 'log_learning_rate_D': -1.4939662093599633, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:12,989] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.72784423828125
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.900277704394154, 'log_learning_rate_D': -1.518294018263322, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:15,461] Trial 31 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.900277704394154, 'log_learning_rate_D': -1.518294018263322, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:15,462] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.28509783744812
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.942521148105352, 'log_learning_rate_D': -1.3950861583599297, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:17,406] Trial 32 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.942521148105352, 'log_learning_rate_D': -1.3950861583599297, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:17,407] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7642180919647217
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.949597577963567, 'log_learning_rate_D': -1.4772515009318608, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:20,021] Trial 33 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.949597577963567, 'log_learning_rate_D': -1.4772515009318608, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:20,022] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4188873767852783
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.991572817568612, 'log_learning_rate_D': -1.5143434351146952, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:22,557] Trial 34 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.991572817568612, 'log_learning_rate_D': -1.5143434351146952, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:22,558] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.3297152519226074
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.671050696082792, 'log_learning_rate_D': -1.691304645675824, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:25,970] Trial 35 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.671050696082792, 'log_learning_rate_D': -1.691304645675824, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:25,971] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.223672866821289
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.516902656567211, 'log_learning_rate_D': -1.4143941061502685, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:27,996] Trial 36 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.516902656567211, 'log_learning_rate_D': -1.4143941061502685, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:27,997] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8330967426300049
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.974168021091531, 'log_learning_rate_D': -1.3160536522738782, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:29,976] Trial 37 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.974168021091531, 'log_learning_rate_D': -1.3160536522738782, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:29,977] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.795137643814087
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.926645431492963, 'log_learning_rate_D': -1.3566804150797926, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:31,928] Trial 38 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.926645431492963, 'log_learning_rate_D': -1.3566804150797926, 'training_batch_size': 8, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:31,929] Trial 38 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.765578269958496
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.655791858145887, 'log_learning_rate_D': -1.435151180200737, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.6146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.79638671875
Memory cached:  154.0
[W 2023-12-02 23:03:33,809] Trial 39 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.655791858145887, 'log_learning_rate_D': -1.435151180200737, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:33,810] Trial 39 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6944985389709473
Memory status after this trial: 
Memory allocated:  158.19970703125
Memory cached:  174.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.93400404966458, 'log_learning_rate_D': -1.2983579437178485, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.85498046875
Memory cached:  154.0
[W 2023-12-02 23:03:35,723] Trial 40 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.93400404966458, 'log_learning_rate_D': -1.2983579437178485, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:35,724] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7201364040374756
Memory status after this trial: 
Memory allocated:  152.5947265625
Memory cached:  168.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.8974933738054265, 'log_learning_rate_D': -1.6396118078281408, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.6682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.35107421875
Memory cached:  154.0
[W 2023-12-02 23:03:37,601] Trial 41 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.8974933738054265, 'log_learning_rate_D': -1.6396118078281408, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:37,602] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.6760036945343018
Memory status after this trial: 
Memory allocated:  143.1005859375
Memory cached:  162.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.808019749972518, 'log_learning_rate_D': -1.5103555378203883, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.9031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.82763671875
Memory cached:  156.0
[W 2023-12-02 23:03:39,965] Trial 42 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.808019749972518, 'log_learning_rate_D': -1.5103555378203883, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:39,966] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.173884391784668
Memory status after this trial: 
Memory allocated:  147.3388671875
Memory cached:  164.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.8750668535227755, 'log_learning_rate_D': -1.4421959807623517, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.39208984375
Memory cached:  154.0
[W 2023-12-02 23:03:42,095] Trial 43 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.8750668535227755, 'log_learning_rate_D': -1.4421959807623517, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:42,095] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.9296669960021973
Memory status after this trial: 
Memory allocated:  162.15234375
Memory cached:  178.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.859395636151717, 'log_learning_rate_D': -1.7914266521730848, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:48,123] Trial 44 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.859395636151717, 'log_learning_rate_D': -1.7914266521730848, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:48,124] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.840277671813965
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.99021764976778, 'log_learning_rate_D': -1.6657273642428359, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:50,564] Trial 45 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.99021764976778, 'log_learning_rate_D': -1.6657273642428359, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:50,566] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.268301010131836
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.999164735215609, 'log_learning_rate_D': -1.5646186105845659, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.6362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:52,571] Trial 46 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.999164735215609, 'log_learning_rate_D': -1.5646186105845659, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:52,571] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8329403400421143
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.7027728404892075, 'log_learning_rate_D': -1.4943002394082323, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.7095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:54,516] Trial 47 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.7027728404892075, 'log_learning_rate_D': -1.4943002394082323, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:54,517] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.7567083835601807
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.85079346809139, 'log_learning_rate_D': -1.5023229500620534, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:56,426] Trial 48 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.85079346809139, 'log_learning_rate_D': -1.5023229500620534, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:56,427] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.711785078048706
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.73993148549648, 'log_learning_rate_D': -1.475830734523131, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.35888671875
Memory cached:  154.0
[W 2023-12-02 23:03:58,308] Trial 49 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.73993148549648, 'log_learning_rate_D': -1.475830734523131, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:03:58,309] Trial 49 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
[I 2023-12-02 23:03:58,332] A new study created in memory with name: no-name-0efcbbc6-06ea-4524-b50c-12b7c0ffd7db
Time for this trial:  1.6852476596832275
Memory status after this trial: 
Memory allocated:  159.2060546875
Memory cached:  176.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.54003497736818, 'log_learning_rate_D': -4.486378287490266, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.5747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.8682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.7350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.107421875
Memory cached:  12.0
[I 2023-12-02 23:04:44,070] Trial 0 finished with value: 0.04481872171163559 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.54003497736818, 'log_learning_rate_D': -4.486378287490266, 'training_batch_size': 10, 'training_p': 3}. Best is trial 0 with value: 0.04481872171163559.
res:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  45.628013134002686
Memory status after this trial: 
Memory allocated:  37.95947265625
Memory cached:  40.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.858875704519524, 'log_learning_rate_D': -4.36667046679581, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  64.0
	 epoch  10 training error:  tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.8814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.7143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.5221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.3203125
Memory cached:  66.0
[I 2023-12-02 23:05:30,224] Trial 1 finished with value: 0.10690043121576309 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.858875704519524, 'log_learning_rate_D': -4.36667046679581, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  46.039466857910156
Memory status after this trial: 
Memory allocated:  104.75634765625
Memory cached:  120.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.8649794316808466, 'log_learning_rate_D': -4.860155589600653, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  42.0
	 epoch  10 training error:  tensor(2.4499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  20 training error:  tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.30859375
Memory cached:  46.0
[I 2023-12-02 23:06:03,654] Trial 2 finished with value: 0.06203735992312431 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.8649794316808466, 'log_learning_rate_D': -4.860155589600653, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  33.3208954334259
Memory status after this trial: 
Memory allocated:  49.62548828125
Memory cached:  50.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.5344768529839734, 'log_learning_rate_D': -1.1441610559688948, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  39.556640625
Memory cached:  46.0
[W 2023-12-02 23:06:06,082] Trial 3 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.5344768529839734, 'log_learning_rate_D': -1.1441610559688948, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:06:06,087] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2981905937194824
Memory status after this trial: 
Memory allocated:  92.33740234375
Memory cached:  94.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.2752431206043866, 'log_learning_rate_D': -3.386591826192336, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.5487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  10 training error:  tensor(1.4892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  20 training error:  tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
	 epoch  90 training error:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.3984375
Memory cached:  66.0
[I 2023-12-02 23:06:55,839] Trial 4 finished with value: 0.18966372311115265 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.2752431206043866, 'log_learning_rate_D': -3.386591826192336, 'training_batch_size': 10, 'training_p': 4}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  49.62290668487549
Memory status after this trial: 
Memory allocated:  118.046875
Memory cached:  136.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.089720484580441, 'log_learning_rate_D': -4.27428524231958, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  70.0
	 epoch  10 training error:  tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.546875
Memory cached:  72.0
[I 2023-12-02 23:07:57,862] Trial 5 finished with value: 0.050875186920166016 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.089720484580441, 'log_learning_rate_D': -4.27428524231958, 'training_batch_size': 12, 'training_p': 3}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  61.91473865509033
Memory status after this trial: 
Memory allocated:  145.80078125
Memory cached:  168.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.760787417483575, 'log_learning_rate_D': -3.0840738001351826, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.7597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.451171875
Memory cached:  48.0
[I 2023-12-02 23:08:42,779] Trial 6 finished with value: 0.05643312260508537 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.760787417483575, 'log_learning_rate_D': -3.0840738001351826, 'training_batch_size': 9, 'training_p': 7}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  44.787070989608765
Memory status after this trial: 
Memory allocated:  85.25341796875
Memory cached:  88.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.530423393448543, 'log_learning_rate_D': -2.595566738506001, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  10 training error:  tensor(1.9071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.966796875
Memory cached:  72.0
[I 2023-12-02 23:09:45,960] Trial 7 finished with value: 0.0723036676645279 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.530423393448543, 'log_learning_rate_D': -2.595566738506001, 'training_batch_size': 7, 'training_p': 5}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  63.05543279647827
Memory status after this trial: 
Memory allocated:  123.27294921875
Memory cached:  144.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.2750953655324504, 'log_learning_rate_D': -4.089151701843882, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.30078125
Memory cached:  48.0
[I 2023-12-02 23:10:38,853] Trial 8 finished with value: 0.06260768324136734 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.2750953655324504, 'log_learning_rate_D': -4.089151701843882, 'training_batch_size': 11, 'training_p': 5}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  52.7502658367157
Memory status after this trial: 
Memory allocated:  82.28125
Memory cached:  84.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.6093865314914626, 'log_learning_rate_D': -2.643249436424647, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(35.5488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  10 training error:  tensor(31.5731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  20 training error:  tensor(3.5431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.4225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  40 training error:  tensor(1.6049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  50 training error:  tensor(1.6293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  60 training error:  tensor(2.3490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  70 training error:  tensor(2.0343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  80 training error:  tensor(2.2686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
	 epoch  90 training error:  tensor(2.3894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.8486328125
Memory cached:  72.0
[I 2023-12-02 23:12:08,929] Trial 9 finished with value: 2.948164463043213 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -1.6093865314914626, 'log_learning_rate_D': -2.643249436424647, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  89.93796467781067
Memory status after this trial: 
Memory allocated:  154.51513671875
Memory cached:  176.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0785123234628675, 'log_learning_rate_D': -1.9536607151826284, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.30859375
Memory cached:  68.0
	 epoch  10 training error:  tensor(2044.1273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.30859375
Memory cached:  70.0
[W 2023-12-02 23:12:20,312] Trial 10 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -1.0785123234628675, 'log_learning_rate_D': -1.9536607151826284, 'training_batch_size': 9, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:12:20,314] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  11.24446725845337
Memory status after this trial: 
Memory allocated:  149.162109375
Memory cached:  164.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.249355793772546, 'log_learning_rate_D': -3.408945339451139, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(2.0101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  46.0
	 epoch  10 training error:  tensor(3.1532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.5850, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.123046875
Memory cached:  48.0
[I 2023-12-02 23:13:00,058] Trial 11 finished with value: 0.3593663275241852 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.249355793772546, 'log_learning_rate_D': -3.408945339451139, 'training_batch_size': 10, 'training_p': 5}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  39.61618256568909
Memory status after this trial: 
Memory allocated:  75.95068359375
Memory cached:  80.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.0547482859728432, 'log_learning_rate_D': -1.5633802985812122, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
[W 2023-12-02 23:13:02,456] Trial 12 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.0547482859728432, 'log_learning_rate_D': -1.5633802985812122, 'training_batch_size': 12, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:13:02,457] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1834328174591064
Memory status after this trial: 
Memory allocated:  169.61669921875
Memory cached:  184.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.0984986525945257, 'log_learning_rate_D': -1.5495335451773138, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  70.0
	 epoch  10 training error:  tensor(661731.6875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
[W 2023-12-02 23:13:10,965] Trial 13 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.0984986525945257, 'log_learning_rate_D': -1.5495335451773138, 'training_batch_size': 12, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:13:10,966] Trial 13 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.31454062461853
Memory status after this trial: 
Memory allocated:  169.61669921875
Memory cached:  184.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.1039344888745468, 'log_learning_rate_D': -1.6851553001353379, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  70.0
	 epoch  10 training error:  tensor(116008.8281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  20 training error:  tensor(623.3959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  30 training error:  tensor(43.6044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  40 training error:  tensor(531.3572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  50 training error:  tensor(226.8437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  60 training error:  tensor(151.3858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  70 training error:  tensor(286.3616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  80 training error:  tensor(138.0221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
	 epoch  90 training error:  tensor(77.4827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.0234375
Memory cached:  72.0
[I 2023-12-02 23:14:18,639] Trial 14 finished with value: 95.2545394897461 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.1039344888745468, 'log_learning_rate_D': -1.6851553001353379, 'training_batch_size': 12, 'training_p': 2}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  67.4633948802948
Memory status after this trial: 
Memory allocated:  169.61669921875
Memory cached:  184.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.405349279619728, 'log_learning_rate_D': -4.806866810859981, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.201171875
Memory cached:  56.0
[I 2023-12-02 23:15:18,861] Trial 15 finished with value: 0.05825146660208702 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.405349279619728, 'log_learning_rate_D': -4.806866810859981, 'training_batch_size': 12, 'training_p': 2}. Best is trial 0 with value: 0.04481872171163559.
Time for this trial:  60.01980471611023
Memory status after this trial: 
Memory allocated:  138.1201171875
Memory cached:  144.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3939298202719237, 'log_learning_rate_D': -3.8476854788519437, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  20 training error:  tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  30 training error:  tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  40 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  50 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  60 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  70 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  80 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
	 epoch  90 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.0
Memory cached:  52.0
[I 2023-12-02 23:16:28,716] Trial 16 finished with value: 0.03763080760836601 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3939298202719237, 'log_learning_rate_D': -3.8476854788519437, 'training_batch_size': 11, 'training_p': 3}. Best is trial 16 with value: 0.03763080760836601.
res:  tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  69.63341903686523
Memory status after this trial: 
Memory allocated:  102.94189453125
Memory cached:  144.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.1145476070845124, 'log_learning_rate_D': -3.8161736437481983, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  107.173828125
Memory cached:  148.0
[I 2023-12-02 23:17:30,301] Trial 17 finished with value: 0.04288538917899132 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.1145476070845124, 'log_learning_rate_D': -3.8161736437481983, 'training_batch_size': 10, 'training_p': 3}. Best is trial 16 with value: 0.03763080760836601.
Time for this trial:  61.37698793411255
Memory status after this trial: 
Memory allocated:  187.54736328125
Memory cached:  190.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.189689567809538, 'log_learning_rate_D': -3.742285178014071, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.6472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  108.03125
Memory cached:  148.0
[I 2023-12-02 23:18:31,564] Trial 18 finished with value: 0.05508735775947571 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.189689567809538, 'log_learning_rate_D': -3.742285178014071, 'training_batch_size': 11, 'training_p': 8}. Best is trial 16 with value: 0.03763080760836601.
Time for this trial:  61.0415301322937
Memory status after this trial: 
Memory allocated:  189.16259765625
Memory cached:  192.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6408304520435375, 'log_learning_rate_D': -3.850419691034377, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  10 training error:  tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  110.890625
Memory cached:  148.0
[I 2023-12-02 23:19:35,342] Trial 19 finished with value: 0.034339454025030136 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6408304520435375, 'log_learning_rate_D': -3.850419691034377, 'training_batch_size': 9, 'training_p': 3}. Best is trial 19 with value: 0.034339454025030136.
res:  tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  63.54137301445007
Memory status after this trial: 
Memory allocated:  116.71337890625
Memory cached:  182.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.717472195160434, 'log_learning_rate_D': -3.853000914581507, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.638671875
Memory cached:  204.0
[I 2023-12-02 23:20:40,363] Trial 20 finished with value: 0.03435218706727028 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.717472195160434, 'log_learning_rate_D': -3.853000914581507, 'training_batch_size': 9, 'training_p': 2}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  64.80965113639832
Memory status after this trial: 
Memory allocated:  258.60693359375
Memory cached:  278.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.816555039909791, 'log_learning_rate_D': -3.3847298800796057, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  206.0
	 epoch  10 training error:  tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.271484375
Memory cached:  204.0
[I 2023-12-02 23:21:40,718] Trial 21 finished with value: 0.039633192121982574 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -3.816555039909791, 'log_learning_rate_D': -3.3847298800796057, 'training_batch_size': 8, 'training_p': 2}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  60.12750244140625
Memory status after this trial: 
Memory allocated:  230.07470703125
Memory cached:  252.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.048898376725466, 'log_learning_rate_D': -4.483602272508664, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(2.3857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  10 training error:  tensor(2.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  20 training error:  tensor(1.7398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  30 training error:  tensor(1.4119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  40 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  50 training error:  tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  60 training error:  tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  70 training error:  tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  80 training error:  tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
	 epoch  90 training error:  tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.857421875
Memory cached:  184.0
[I 2023-12-02 23:22:37,240] Trial 22 finished with value: 0.06994584947824478 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.048898376725466, 'log_learning_rate_D': -4.483602272508664, 'training_batch_size': 9, 'training_p': 2}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  56.305750131607056
Memory status after this trial: 
Memory allocated:  204.72021484375
Memory cached:  212.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.711836065653881, 'log_learning_rate_D': -4.977307863715335, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.07421875
Memory cached:  204.0
[I 2023-12-02 23:23:38,009] Trial 23 finished with value: 0.03655093535780907 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.711836065653881, 'log_learning_rate_D': -4.977307863715335, 'training_batch_size': 9, 'training_p': 4}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  60.53707146644592
Memory status after this trial: 
Memory allocated:  208.8681640625
Memory cached:  230.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.371930221465104, 'log_learning_rate_D': -3.92339764727104, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.4748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  10 training error:  tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  20 training error:  tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  30 training error:  tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  40 training error:  tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  50 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  60 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  70 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  80 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
	 epoch  90 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.642578125
Memory cached:  184.0
[I 2023-12-02 23:24:41,675] Trial 24 finished with value: 0.049703847616910934 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.371930221465104, 'log_learning_rate_D': -3.92339764727104, 'training_batch_size': 8, 'training_p': 6}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  63.420337200164795
Memory status after this trial: 
Memory allocated:  213.35400390625
Memory cached:  220.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7967594563227745, 'log_learning_rate_D': -4.905963562538075, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  20 training error:  tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  30 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  40 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  50 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  60 training error:  tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  70 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  80 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
	 epoch  90 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.69921875
Memory cached:  206.0
[I 2023-12-02 23:25:43,310] Trial 25 finished with value: 0.04299285635352135 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7967594563227745, 'log_learning_rate_D': -4.905963562538075, 'training_batch_size': 9, 'training_p': 4}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  61.418699741363525
Memory status after this trial: 
Memory allocated:  206.92578125
Memory cached:  228.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.6433961706430047, 'log_learning_rate_D': -4.577643987444883, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.57421875
Memory cached:  204.0
[I 2023-12-02 23:26:48,708] Trial 26 finished with value: 0.0430339016020298 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.6433961706430047, 'log_learning_rate_D': -4.577643987444883, 'training_batch_size': 8, 'training_p': 3}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  65.18700861930847
Memory status after this trial: 
Memory allocated:  231.0673828125
Memory cached:  254.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.8440222863029545, 'log_learning_rate_D': -4.121225375915709, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  206.0
	 epoch  10 training error:  tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  20 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  30 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  40 training error:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  50 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  60 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  70 training error:  tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  80 training error:  tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
	 epoch  90 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  142.072265625
Memory cached:  208.0
[I 2023-12-02 23:27:50,918] Trial 27 finished with value: 0.038569897413253784 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.8440222863029545, 'log_learning_rate_D': -4.121225375915709, 'training_batch_size': 9, 'training_p': 4}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  61.9889178276062
Memory status after this trial: 
Memory allocated:  246.357421875
Memory cached:  264.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.6002438236922987, 'log_learning_rate_D': -4.983363337238604, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.65234375
Memory cached:  204.0
[I 2023-12-02 23:28:53,749] Trial 28 finished with value: 0.05067423731088638 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -3.6002438236922987, 'log_learning_rate_D': -4.983363337238604, 'training_batch_size': 7, 'training_p': 2}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  62.55422377586365
Memory status after this trial: 
Memory allocated:  218.1240234375
Memory cached:  240.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.1032445964440574, 'log_learning_rate_D': -4.272446795975512, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  132.478515625
Memory cached:  204.0
[I 2023-12-02 23:29:49,975] Trial 29 finished with value: 0.04005950689315796 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.1032445964440574, 'log_learning_rate_D': -4.272446795975512, 'training_batch_size': 9, 'training_p': 3}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  56.00632166862488
Memory status after this trial: 
Memory allocated:  196.86083984375
Memory cached:  218.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.377468276860995, 'log_learning_rate_D': -4.5949461168748, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  10 training error:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  20 training error:  tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  30 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.44140625
Memory cached:  204.0
[I 2023-12-02 23:30:45,882] Trial 30 finished with value: 0.04028325900435448 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.377468276860995, 'log_learning_rate_D': -4.5949461168748, 'training_batch_size': 8, 'training_p': 3}. Best is trial 19 with value: 0.034339454025030136.
Time for this trial:  55.69804644584656
Memory status after this trial: 
Memory allocated:  220.62744140625
Memory cached:  240.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.848543831341606, 'log_learning_rate_D': -3.6524778271435148, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  10 training error:  tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  20 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  30 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  40 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  50 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  60 training error:  tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  70 training error:  tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  80 training error:  tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
	 epoch  90 training error:  tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.2265625
Memory cached:  184.0
[I 2023-12-02 23:31:43,295] Trial 31 finished with value: 0.032899919897317886 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.848543831341606, 'log_learning_rate_D': -3.6524778271435148, 'training_batch_size': 9, 'training_p': 6}. Best is trial 31 with value: 0.032899919897317886.
res:  tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  57.18712854385376
Memory status after this trial: 
Memory allocated:  76.12841796875
Memory cached:  172.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.8671284269726556, 'log_learning_rate_D': -3.6394567538411877, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.6591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.7626953125
Memory cached:  172.0
[I 2023-12-02 23:32:43,729] Trial 32 finished with value: 0.048057686537504196 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.8671284269726556, 'log_learning_rate_D': -3.6394567538411877, 'training_batch_size': 10, 'training_p': 6}. Best is trial 31 with value: 0.032899919897317886.
Time for this trial:  60.21689987182617
Memory status after this trial: 
Memory allocated:  140.8818359375
Memory cached:  172.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.391981061190617, 'log_learning_rate_D': -3.991930404754487, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  10 training error:  tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  20 training error:  tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  30 training error:  tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  40 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  50 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  60 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  70 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  80 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
	 epoch  90 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.5517578125
Memory cached:  194.0
[I 2023-12-02 23:33:36,603] Trial 33 finished with value: 0.04433678090572357 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.391981061190617, 'log_learning_rate_D': -3.991930404754487, 'training_batch_size': 10, 'training_p': 7}. Best is trial 31 with value: 0.032899919897317886.
Time for this trial:  52.65580654144287
Memory status after this trial: 
Memory allocated:  150.42626953125
Memory cached:  192.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -3.2813546750846396, 'log_learning_rate_D': -3.600299263674041, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  20 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  30 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  40 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  50 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  60 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  70 training error:  tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  80 training error:  tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
	 epoch  90 training error:  tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  84.689453125
Memory cached:  170.0
[I 2023-12-02 23:35:13,515] Trial 34 finished with value: 0.03976006433367729 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -3.2813546750846396, 'log_learning_rate_D': -3.600299263674041, 'training_batch_size': 6, 'training_p': 7}. Best is trial 31 with value: 0.032899919897317886.
Time for this trial:  96.6861925125122
Memory status after this trial: 
Memory allocated:  158.03271484375
Memory cached:  170.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7959666273984114, 'log_learning_rate_D': -4.149670020429429, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.5185546875
Memory cached:  172.0
[I 2023-12-02 23:36:15,939] Trial 35 finished with value: 0.03246564790606499 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.7959666273984114, 'log_learning_rate_D': -4.149670020429429, 'training_batch_size': 9, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
res:  tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  62.198830366134644
Memory status after this trial: 
Memory allocated:  86.78271484375
Memory cached:  150.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.9592670724807024, 'log_learning_rate_D': -4.1509806968512235, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  104.4951171875
Memory cached:  152.0
[I 2023-12-02 23:37:27,691] Trial 36 finished with value: 0.05285822972655296 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.9592670724807024, 'log_learning_rate_D': -4.1509806968512235, 'training_batch_size': 9, 'training_p': 6}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  71.54350447654724
Memory status after this trial: 
Memory allocated:  199.22216796875
Memory cached:  210.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9952704343334036, 'log_learning_rate_D': -4.339837169959733, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.7275390625
Memory cached:  152.0
[I 2023-12-02 23:38:25,766] Trial 37 finished with value: 0.036381252110004425 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.9952704343334036, 'log_learning_rate_D': -4.339837169959733, 'training_batch_size': 8, 'training_p': 8}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  57.841434717178345
Memory status after this trial: 
Memory allocated:  146.67431640625
Memory cached:  152.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.4174506031261735, 'log_learning_rate_D': -3.9733467961488906, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  20 training error:  tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  30 training error:  tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  40 training error:  tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  50 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  60 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  70 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  80 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
	 epoch  90 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  93.2509765625
Memory cached:  154.0
[I 2023-12-02 23:39:25,828] Trial 38 finished with value: 0.051634132862091064 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.4174506031261735, 'log_learning_rate_D': -3.9733467961488906, 'training_batch_size': 9, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  59.82841157913208
Memory status after this trial: 
Memory allocated:  158.9814453125
Memory cached:  164.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.6099844335284565, 'log_learning_rate_D': -3.6444880434754925, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.5400390625
Memory cached:  152.0
[I 2023-12-02 23:40:28,165] Trial 39 finished with value: 0.08793419599533081 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.6099844335284565, 'log_learning_rate_D': -3.6444880434754925, 'training_batch_size': 8, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  62.12538003921509
Memory status after this trial: 
Memory allocated:  175.22021484375
Memory cached:  182.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.262636577967135, 'log_learning_rate_D': -4.221787809649343, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.6318359375
Memory cached:  172.0
[I 2023-12-02 23:41:28,811] Trial 40 finished with value: 0.03751823306083679 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.262636577967135, 'log_learning_rate_D': -4.221787809649343, 'training_batch_size': 10, 'training_p': 4}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  60.405919551849365
Memory status after this trial: 
Memory allocated:  164.86962890625
Memory cached:  184.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.5846842569229027, 'log_learning_rate_D': -3.2108223658296398, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.6611328125
Memory cached:  152.0
[I 2023-12-02 23:42:08,717] Trial 41 finished with value: 0.03892678767442703 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.5846842569229027, 'log_learning_rate_D': -3.2108223658296398, 'training_batch_size': 9, 'training_p': 7}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  39.722639322280884
Memory status after this trial: 
Memory allocated:  131.51611328125
Memory cached:  152.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.020264324832659, 'log_learning_rate_D': -3.4715864491722055, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  96.9423828125
Memory cached:  172.0
[I 2023-12-02 23:43:05,276] Trial 42 finished with value: 0.035277318209409714 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.020264324832659, 'log_learning_rate_D': -3.4715864491722055, 'training_batch_size': 7, 'training_p': 6}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  56.364898443222046
Memory status after this trial: 
Memory allocated:  160.326171875
Memory cached:  178.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.907064222414024, 'log_learning_rate_D': -3.823660087473606, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  10 training error:  tensor(0.6910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  20 training error:  tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  30 training error:  tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  40 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  50 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  60 training error:  tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  70 training error:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  80 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
	 epoch  90 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.0322265625
Memory cached:  174.0
[I 2023-12-02 23:43:58,034] Trial 43 finished with value: 0.057918816804885864 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.907064222414024, 'log_learning_rate_D': -3.823660087473606, 'training_batch_size': 11, 'training_p': 2}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  52.55143618583679
Memory status after this trial: 
Memory allocated:  161.0654296875
Memory cached:  180.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.7436296678770042, 'log_learning_rate_D': -3.1655028759453048, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
[I 2023-12-02 23:45:02,531] Trial 44 finished with value: 0.03354809805750847 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.7436296678770042, 'log_learning_rate_D': -3.1655028759453048, 'training_batch_size': 10, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  64.27819752693176
Memory status after this trial: 
Memory allocated:  206.3466796875
Memory cached:  226.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.520466419895235, 'log_learning_rate_D': -2.936444982897347, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.5908203125
Memory cached:  172.0
[I 2023-12-02 23:46:06,338] Trial 45 finished with value: 0.05577166751027107 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.520466419895235, 'log_learning_rate_D': -2.936444982897347, 'training_batch_size': 10, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  63.587027072906494
Memory status after this trial: 
Memory allocated:  206.3466796875
Memory cached:  226.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.805105036031069, 'log_learning_rate_D': -3.2218768701407092, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.6869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.0673828125
Memory cached:  172.0
[I 2023-12-02 23:47:10,003] Trial 46 finished with value: 0.03887622430920601 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.805105036031069, 'log_learning_rate_D': -3.2218768701407092, 'training_batch_size': 10, 'training_p': 5}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  63.45071005821228
Memory status after this trial: 
Memory allocated:  220.3837890625
Memory cached:  242.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.1046450566006074, 'log_learning_rate_D': -3.5322901799654387, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  20 training error:  tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  30 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  40 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  50 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  60 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  70 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  80 training error:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
	 epoch  90 training error:  tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.8037109375
Memory cached:  174.0
[I 2023-12-02 23:48:11,999] Trial 47 finished with value: 0.03822269290685654 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.1046450566006074, 'log_learning_rate_D': -3.5322901799654387, 'training_batch_size': 9, 'training_p': 6}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  61.77099132537842
Memory status after this trial: 
Memory allocated:  187.65185546875
Memory cached:  208.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.7136138428647434, 'log_learning_rate_D': -4.044419180904578, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.6513671875
Memory cached:  172.0
[I 2023-12-02 23:49:11,187] Trial 48 finished with value: 0.054655373096466064 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.7136138428647434, 'log_learning_rate_D': -4.044419180904578, 'training_batch_size': 9, 'training_p': 4}. Best is trial 35 with value: 0.03246564790606499.
Time for this trial:  58.976924896240234
Memory status after this trial: 
Memory allocated:  184.0244140625
Memory cached:  204.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.2112858250279355, 'log_learning_rate_D': -3.8208561625802098, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.9208984375
Memory cached:  152.0
[I 2023-12-02 23:50:13,906] Trial 49 finished with value: 0.029590148478746414 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.2112858250279355, 'log_learning_rate_D': -3.8208561625802098, 'training_batch_size': 8, 'training_p': 5}. Best is trial 49 with value: 0.029590148478746414.
[I 2023-12-02 23:50:13,920] A new study created in memory with name: no-name-14e89a5a-025e-4d88-90a8-a7bdc8d52c2a
res:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  62.49329471588135
Memory status after this trial: 
Memory allocated:  81.00341796875
Memory cached:  170.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.120597194648198, 'log_learning_rate_D': -4.991800019348508, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.8896484375
Memory cached:  10.0
[I 2023-12-02 23:51:23,437] Trial 0 finished with value: 0.05080590397119522 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -4.120597194648198, 'log_learning_rate_D': -4.991800019348508, 'training_batch_size': 6, 'training_p': 6}. Best is trial 0 with value: 0.05080590397119522.
res:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  69.40504455566406
Memory status after this trial: 
Memory allocated:  56.57080078125
Memory cached:  60.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.8469754854622344, 'log_learning_rate_D': -1.4758532858754827, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.587890625
Memory cached:  86.0
[W 2023-12-02 23:51:26,435] Trial 1 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.8469754854622344, 'log_learning_rate_D': -1.4758532858754827, 'training_batch_size': 9, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:51:26,436] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8847482204437256
Memory status after this trial: 
Memory allocated:  118.3837890625
Memory cached:  136.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.0976184932280408, 'log_learning_rate_D': -3.313099838726016, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  84.0
	 epoch  10 training error:  tensor(84721.8047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  20 training error:  tensor(2.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  30 training error:  tensor(1.0903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  50 training error:  tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  60 training error:  tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  80 training error:  tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
	 epoch  90 training error:  tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.427734375
Memory cached:  86.0
[I 2023-12-02 23:52:30,681] Trial 2 finished with value: 0.13276587426662445 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -1.0976184932280408, 'log_learning_rate_D': -3.313099838726016, 'training_batch_size': 9, 'training_p': 7}. Best is trial 0 with value: 0.05080590397119522.
Time for this trial:  64.12389707565308
Memory status after this trial: 
Memory allocated:  144.8173828125
Memory cached:  160.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.982574324184075, 'log_learning_rate_D': -4.670966448811283, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  68.0
	 epoch  10 training error:  tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  20 training error:  tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  30 training error:  tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  40 training error:  tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  50 training error:  tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  60 training error:  tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  70 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  80 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
	 epoch  90 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.9375
Memory cached:  72.0
[I 2023-12-02 23:53:29,165] Trial 3 finished with value: 0.05743039399385452 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.982574324184075, 'log_learning_rate_D': -4.670966448811283, 'training_batch_size': 9, 'training_p': 3}. Best is trial 0 with value: 0.05080590397119522.
Time for this trial:  58.34413766860962
Memory status after this trial: 
Memory allocated:  144.5234375
Memory cached:  150.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.6105011606442576, 'log_learning_rate_D': -2.71944625499957, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  70.0
	 epoch  10 training error:  tensor(98.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  20 training error:  tensor(125.4429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  30 training error:  tensor(65.8826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  40 training error:  tensor(50.4293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  50 training error:  tensor(35.6993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  60 training error:  tensor(34.1703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  70 training error:  tensor(33.0295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  80 training error:  tensor(3.7759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
	 epoch  90 training error:  tensor(41.0379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.439453125
Memory cached:  74.0
[I 2023-12-02 23:54:18,846] Trial 4 finished with value: 2.26318621635437 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.6105011606442576, 'log_learning_rate_D': -2.71944625499957, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 0.05080590397119522.
Time for this trial:  49.545706033706665
Memory status after this trial: 
Memory allocated:  113.9814453125
Memory cached:  118.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.387551574477994, 'log_learning_rate_D': -2.891509157936077, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  114.0
	 epoch  10 training error:  tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  101.578125
Memory cached:  118.0
[I 2023-12-02 23:55:30,453] Trial 5 finished with value: 0.039839114993810654 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.387551574477994, 'log_learning_rate_D': -2.891509157936077, 'training_batch_size': 7, 'training_p': 5}. Best is trial 5 with value: 0.039839114993810654.
res:  tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  71.47735118865967
Memory status after this trial: 
Memory allocated:  162.53564453125
Memory cached:  240.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.4017531579786464, 'log_learning_rate_D': -3.5416725005629153, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  20 training error:  tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  30 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  40 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  50 training error:  tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  60 training error:  tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  70 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  80 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
	 epoch  90 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.48046875
Memory cached:  240.0
[I 2023-12-02 23:56:11,614] Trial 6 finished with value: 0.045749273151159286 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.4017531579786464, 'log_learning_rate_D': -3.5416725005629153, 'training_batch_size': 12, 'training_p': 6}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  41.0341899394989
Memory status after this trial: 
Memory allocated:  199.6572265625
Memory cached:  240.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.055924030481669, 'log_learning_rate_D': -3.054732428336288, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  20 training error:  tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  30 training error:  tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  40 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  50 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  60 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  70 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  80 training error:  tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
	 epoch  90 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.794921875
Memory cached:  240.0
[I 2023-12-02 23:57:04,301] Trial 7 finished with value: 0.044243570417165756 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.055924030481669, 'log_learning_rate_D': -3.054732428336288, 'training_batch_size': 9, 'training_p': 6}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  52.55794596672058
Memory status after this trial: 
Memory allocated:  235.6669921875
Memory cached:  260.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.6344884577569228, 'log_learning_rate_D': -2.7280370058360806, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  10 training error:  tensor(1.5724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  20 training error:  tensor(1.1879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  30 training error:  tensor(1.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  40 training error:  tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  50 training error:  tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  60 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  70 training error:  tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  80 training error:  tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
	 epoch  90 training error:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  165.91796875
Memory cached:  240.0
[I 2023-12-02 23:57:49,363] Trial 8 finished with value: 0.09860589355230331 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.6344884577569228, 'log_learning_rate_D': -2.7280370058360806, 'training_batch_size': 11, 'training_p': 2}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  44.93851351737976
Memory status after this trial: 
Memory allocated:  212.24853515625
Memory cached:  240.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.1583567589878028, 'log_learning_rate_D': -1.5793808447765207, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.6419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.326171875
Memory cached:  242.0
	 epoch  10 training error:  tensor(279.8609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.326171875
Memory cached:  242.0
[W 2023-12-02 23:57:57,824] Trial 9 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.1583567589878028, 'log_learning_rate_D': -1.5793808447765207, 'training_batch_size': 11, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:57:57,825] Trial 9 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.319855213165283
Memory status after this trial: 
Memory allocated:  240.29150390625
Memory cached:  264.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.2795834727435116, 'log_learning_rate_D': -4.155211323805128, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  20 training error:  tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  30 training error:  tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  40 training error:  tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  50 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  70 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  80 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
	 epoch  90 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.470703125
Memory cached:  244.0
[I 2023-12-02 23:58:47,609] Trial 10 finished with value: 0.043304771184921265 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.2795834727435116, 'log_learning_rate_D': -4.155211323805128, 'training_batch_size': 12, 'training_p': 3}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  49.65217185020447
Memory status after this trial: 
Memory allocated:  207.7744140625
Memory cached:  242.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.322412052855633, 'log_learning_rate_D': -1.3142368217527243, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.2211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  40 training error:  tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  50 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  60 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  80 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
	 epoch  90 training error:  tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.072265625
Memory cached:  242.0
[I 2023-12-02 23:59:24,609] Trial 11 finished with value: 0.07436402142047882 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.322412052855633, 'log_learning_rate_D': -1.3142368217527243, 'training_batch_size': 11, 'training_p': 8}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  36.88780641555786
Memory status after this trial: 
Memory allocated:  191.5576171875
Memory cached:  240.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.8220949348879225, 'log_learning_rate_D': -1.7031795714921554, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
[W 2023-12-02 23:59:34,324] Trial 12 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.8220949348879225, 'log_learning_rate_D': -1.7031795714921554, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-02 23:59:34,326] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  9.503672122955322
Memory status after this trial: 
Memory allocated:  337.40380859375
Memory cached:  366.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.9305985177741047, 'log_learning_rate_D': -1.98016973466725, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  10 training error:  tensor(0.8947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  20 training error:  tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  30 training error:  tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  40 training error:  tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  50 training error:  tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  60 training error:  tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  70 training error:  tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  80 training error:  tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
	 epoch  90 training error:  tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  201.0009765625
Memory cached:  262.0
[I 2023-12-03 00:01:18,947] Trial 13 finished with value: 0.06422595679759979 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.9305985177741047, 'log_learning_rate_D': -1.98016973466725, 'training_batch_size': 6, 'training_p': 5}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  104.39780735969543
Memory status after this trial: 
Memory allocated:  337.40380859375
Memory cached:  366.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.5640444883209494, 'log_learning_rate_D': -4.021439711124593, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  242.0
	 epoch  10 training error:  tensor(0.6205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  20 training error:  tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  30 training error:  tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  40 training error:  tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  50 training error:  tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  70 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  80 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
	 epoch  90 training error:  tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.0859375
Memory cached:  244.0
[I 2023-12-03 00:02:11,890] Trial 14 finished with value: 0.05676552280783653 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.5640444883209494, 'log_learning_rate_D': -4.021439711124593, 'training_batch_size': 7, 'training_p': 4}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  52.72845411300659
Memory status after this trial: 
Memory allocated:  250.66259765625
Memory cached:  274.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.4471229039553446, 'log_learning_rate_D': -3.9976619655924903, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  242.0
	 epoch  10 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  20 training error:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  30 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  40 training error:  tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  50 training error:  tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  60 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  70 training error:  tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  80 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
	 epoch  90 training error:  tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.33984375
Memory cached:  246.0
[I 2023-12-03 00:02:59,843] Trial 15 finished with value: 0.09767042100429535 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.4471229039553446, 'log_learning_rate_D': -3.9976619655924903, 'training_batch_size': 11, 'training_p': 2}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  47.75508975982666
Memory status after this trial: 
Memory allocated:  200.82421875
Memory cached:  240.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.3177108153523567, 'log_learning_rate_D': -2.3059694499085293, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  260.0
	 epoch  10 training error:  tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  20 training error:  tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  30 training error:  tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  40 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  50 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  60 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  70 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  80 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
	 epoch  90 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  191.873046875
Memory cached:  264.0
[I 2023-12-03 00:03:57,872] Trial 16 finished with value: 0.05350349098443985 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.3177108153523567, 'log_learning_rate_D': -2.3059694499085293, 'training_batch_size': 7, 'training_p': 4}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  57.81879639625549
Memory status after this trial: 
Memory allocated:  280.2119140625
Memory cached:  292.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.268695536588991, 'log_learning_rate_D': -3.919355182836887, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  10 training error:  tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  40 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  50 training error:  tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  60 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  80 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
	 epoch  90 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  169.515625
Memory cached:  242.0
[I 2023-12-03 00:04:58,152] Trial 17 finished with value: 0.05021272227168083 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.268695536588991, 'log_learning_rate_D': -3.919355182836887, 'training_batch_size': 12, 'training_p': 3}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  60.06633543968201
Memory status after this trial: 
Memory allocated:  224.89453125
Memory cached:  250.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.5549809054776436, 'log_learning_rate_D': -3.5316680692276456, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  242.0
	 epoch  10 training error:  tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  20 training error:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  30 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  40 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  50 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  60 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  70 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  80 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
	 epoch  90 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  167.998046875
Memory cached:  244.0
[I 2023-12-03 00:05:47,213] Trial 18 finished with value: 0.0454082153737545 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.5549809054776436, 'log_learning_rate_D': -3.5316680692276456, 'training_batch_size': 10, 'training_p': 5}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  48.8504900932312
Memory status after this trial: 
Memory allocated:  209.1240234375
Memory cached:  242.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.856665621303292, 'log_learning_rate_D': -4.456639251841991, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  40 training error:  tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  50 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  60 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  80 training error:  tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
	 epoch  90 training error:  tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  173.6171875
Memory cached:  242.0
[I 2023-12-03 00:06:38,201] Trial 19 finished with value: 0.08209925144910812 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.856665621303292, 'log_learning_rate_D': -4.456639251841991, 'training_batch_size': 8, 'training_p': 3}. Best is trial 5 with value: 0.039839114993810654.
Time for this trial:  50.80420994758606
Memory status after this trial: 
Memory allocated:  236.40380859375
Memory cached:  264.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.7971893811402415, 'log_learning_rate_D': -3.1703245862430753, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  240.0
	 epoch  10 training error:  tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  20 training error:  tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  30 training error:  tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  40 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  50 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  60 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  70 training error:  tensor(0.0552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  80 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
	 epoch  90 training error:  tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.28515625
Memory cached:  242.0
[I 2023-12-03 00:07:27,792] Trial 20 finished with value: 0.029596377164125443 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.7971893811402415, 'log_learning_rate_D': -3.1703245862430753, 'training_batch_size': 7, 'training_p': 8}. Best is trial 20 with value: 0.029596377164125443.
res:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  49.3981773853302
Memory status after this trial: 
Memory allocated:  52.3427734375
Memory cached:  128.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.854777491788966, 'log_learning_rate_D': -3.0853662398049875, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(2.1639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  20 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  30 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  40 training error:  tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  50 training error:  tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  60 training error:  tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  70 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  80 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
	 epoch  90 training error:  tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.38720703125
Memory cached:  134.0
[I 2023-12-03 00:08:25,132] Trial 21 finished with value: 0.08001995086669922 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.854777491788966, 'log_learning_rate_D': -3.0853662398049875, 'training_batch_size': 7, 'training_p': 8}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  57.14672136306763
Memory status after this trial: 
Memory allocated:  155.96435546875
Memory cached:  164.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.819699839021925, 'log_learning_rate_D': -2.4444484611740314, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  10 training error:  tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.05126953125
Memory cached:  150.0
[I 2023-12-03 00:09:13,891] Trial 22 finished with value: 0.07232480496168137 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.819699839021925, 'log_learning_rate_D': -2.4444484611740314, 'training_batch_size': 8, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  48.55531430244446
Memory status after this trial: 
Memory allocated:  152.75732421875
Memory cached:  174.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2627976665549174, 'log_learning_rate_D': -1.841024706636611, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  10 training error:  tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  20 training error:  tensor(205.6853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  30 training error:  tensor(1.5046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  40 training error:  tensor(1.5499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  50 training error:  tensor(0.9494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  60 training error:  tensor(0.6519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  70 training error:  tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  80 training error:  tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
	 epoch  90 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.18701171875
Memory cached:  128.0
[I 2023-12-03 00:10:38,078] Trial 23 finished with value: 0.12320280075073242 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2627976665549174, 'log_learning_rate_D': -1.841024706636611, 'training_batch_size': 6, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  83.9692542552948
Memory status after this trial: 
Memory allocated:  113.72216796875
Memory cached:  128.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.851710142033431, 'log_learning_rate_D': -3.5137049649932712, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.66845703125
Memory cached:  130.0
[I 2023-12-03 00:11:27,391] Trial 24 finished with value: 0.037968121469020844 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.851710142033431, 'log_learning_rate_D': -3.5137049649932712, 'training_batch_size': 7, 'training_p': 5}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  49.10905694961548
Memory status after this trial: 
Memory allocated:  110.8037109375
Memory cached:  130.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.0563186809676983, 'log_learning_rate_D': -3.470380653618946, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.62939453125
Memory cached:  130.0
[I 2023-12-03 00:12:19,414] Trial 25 finished with value: 0.03777272626757622 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.0563186809676983, 'log_learning_rate_D': -3.470380653618946, 'training_batch_size': 7, 'training_p': 5}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  51.83070945739746
Memory status after this trial: 
Memory allocated:  123.9384765625
Memory cached:  130.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.985237169990959, 'log_learning_rate_D': -3.5664737168989196, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.30322265625
Memory cached:  130.0
[I 2023-12-03 00:13:12,056] Trial 26 finished with value: 0.03664206340909004 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.985237169990959, 'log_learning_rate_D': -3.5664737168989196, 'training_batch_size': 8, 'training_p': 5}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  52.450371503829956
Memory status after this trial: 
Memory allocated:  126.943359375
Memory cached:  132.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.106447539529075, 'log_learning_rate_D': -3.7439022747423087, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.66259765625
Memory cached:  130.0
[I 2023-12-03 00:14:00,976] Trial 27 finished with value: 0.03104335628449917 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.106447539529075, 'log_learning_rate_D': -3.7439022747423087, 'training_batch_size': 8, 'training_p': 6}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  48.71277642250061
Memory status after this trial: 
Memory allocated:  109.5166015625
Memory cached:  130.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.623927015655182, 'log_learning_rate_D': -3.7471405875805006, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  10 training error:  tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.41455078125
Memory cached:  150.0
[I 2023-12-03 00:14:48,321] Trial 28 finished with value: 0.03712383657693863 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.623927015655182, 'log_learning_rate_D': -3.7471405875805006, 'training_batch_size': 8, 'training_p': 8}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  47.14197850227356
Memory status after this trial: 
Memory allocated:  114.34423828125
Memory cached:  150.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.13130021942832, 'log_learning_rate_D': -3.1134663774980478, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.7853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.2085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  20 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  59.59228515625
Memory cached:  132.0
[I 2023-12-03 00:15:41,688] Trial 29 finished with value: 0.03353384882211685 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.13130021942832, 'log_learning_rate_D': -3.1134663774980478, 'training_batch_size': 8, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  53.15362787246704
Memory status after this trial: 
Memory allocated:  126.1142578125
Memory cached:  130.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.619762394392157, 'log_learning_rate_D': -3.207317414112555, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(2.1359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  150.0
	 epoch  10 training error:  tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.3360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.59228515625
Memory cached:  152.0
[I 2023-12-03 00:16:31,929] Trial 30 finished with value: 0.05115324258804321 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.619762394392157, 'log_learning_rate_D': -3.207317414112555, 'training_batch_size': 10, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  50.03186869621277
Memory status after this trial: 
Memory allocated:  132.1572265625
Memory cached:  152.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.29636666810024, 'log_learning_rate_D': -3.2352509458858627, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.3684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  20 training error:  tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  30 training error:  tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  40 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  50 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  60 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  70 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  80 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
	 epoch  90 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.76220703125
Memory cached:  134.0
[I 2023-12-03 00:17:21,477] Trial 31 finished with value: 0.037361856549978256 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.29636666810024, 'log_learning_rate_D': -3.2352509458858627, 'training_batch_size': 10, 'training_p': 8}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  49.326895236968994
Memory status after this trial: 
Memory allocated:  96.07861328125
Memory cached:  132.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.7381759698192107, 'log_learning_rate_D': -4.958652433530574, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  10 training error:  tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  20 training error:  tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  30 training error:  tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  40 training error:  tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  50 training error:  tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  60 training error:  tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  70 training error:  tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  80 training error:  tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
	 epoch  90 training error:  tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  73.89404296875
Memory cached:  148.0
[I 2023-12-03 00:18:32,673] Trial 32 finished with value: 0.08911790698766708 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.7381759698192107, 'log_learning_rate_D': -4.958652433530574, 'training_batch_size': 6, 'training_p': 6}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  71.00502705574036
Memory status after this trial: 
Memory allocated:  142.17626953125
Memory cached:  158.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.1675008692462145, 'log_learning_rate_D': -2.9146027762701845, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
[I 2023-12-03 00:19:19,552] Trial 33 finished with value: 0.031486041843891144 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.1675008692462145, 'log_learning_rate_D': -2.9146027762701845, 'training_batch_size': 8, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  46.670878171920776
Memory status after this trial: 
Memory allocated:  87.5205078125
Memory cached:  130.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.1234180442071557, 'log_learning_rate_D': -2.848822712412807, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.5554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  20 training error:  tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  30 training error:  tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  40 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.09619140625
Memory cached:  132.0
[I 2023-12-03 00:20:06,702] Trial 34 finished with value: 0.033353108912706375 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.1234180442071557, 'log_learning_rate_D': -2.848822712412807, 'training_batch_size': 9, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  46.92967677116394
Memory status after this trial: 
Memory allocated:  87.5205078125
Memory cached:  132.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.4781829860732256, 'log_learning_rate_D': -2.858353510240099, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.07861328125
Memory cached:  130.0
[I 2023-12-03 00:20:52,142] Trial 35 finished with value: 0.036086518317461014 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.4781829860732256, 'log_learning_rate_D': -2.858353510240099, 'training_batch_size': 9, 'training_p': 7}. Best is trial 20 with value: 0.029596377164125443.
Time for this trial:  45.236008644104004
Memory status after this trial: 
Memory allocated:  86.779296875
Memory cached:  130.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.713933043455174, 'log_learning_rate_D': -2.586311078326033, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.6981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  10 training error:  tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  20 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  30 training error:  tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  40 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  50 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.08642578125
Memory cached:  130.0
[I 2023-12-03 00:21:40,516] Trial 36 finished with value: 0.02776537649333477 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.713933043455174, 'log_learning_rate_D': -2.586311078326033, 'training_batch_size': 9, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
res:  tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  48.18096208572388
Memory status after this trial: 
Memory allocated:  44.69580078125
Memory cached:  116.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7556078793835956, 'log_learning_rate_D': -3.266690360613129, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.4559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.275390625
Memory cached:  120.0
[I 2023-12-03 00:22:24,648] Trial 37 finished with value: 0.044681157916784286 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7556078793835956, 'log_learning_rate_D': -3.266690360613129, 'training_batch_size': 9, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  43.96131229400635
Memory status after this trial: 
Memory allocated:  84.51904296875
Memory cached:  116.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.3354321791077837, 'log_learning_rate_D': -2.5907150585032497, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(3.1292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.642578125
Memory cached:  118.0
[I 2023-12-03 00:23:11,604] Trial 38 finished with value: 0.052483201026916504 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.3354321791077837, 'log_learning_rate_D': -2.5907150585032497, 'training_batch_size': 8, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  46.750041484832764
Memory status after this trial: 
Memory allocated:  82.95556640625
Memory cached:  118.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7232344856287334, 'log_learning_rate_D': -2.6301188616515536, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.646484375
Memory cached:  118.0
[I 2023-12-03 00:23:57,061] Trial 39 finished with value: 0.11556795984506607 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.7232344856287334, 'log_learning_rate_D': -2.6301188616515536, 'training_batch_size': 9, 'training_p': 8}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  45.243850231170654
Memory status after this trial: 
Memory allocated:  82.49560546875
Memory cached:  118.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.109994715067954, 'log_learning_rate_D': -2.988942488298278, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.8248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  10 training error:  tensor(0.6173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  20 training error:  tensor(0.9024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  30 training error:  tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  40 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  50 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  60 training error:  tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  70 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  80 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
	 epoch  90 training error:  tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.439453125
Memory cached:  120.0
[I 2023-12-03 00:24:45,874] Trial 40 finished with value: 0.05151417478919029 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.109994715067954, 'log_learning_rate_D': -2.988942488298278, 'training_batch_size': 10, 'training_p': 7}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  48.60375642776489
Memory status after this trial: 
Memory allocated:  101.6982421875
Memory cached:  118.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.591134333708369, 'log_learning_rate_D': -3.341248666649768, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.9074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.267578125
Memory cached:  118.0
[I 2023-12-03 00:25:29,667] Trial 41 finished with value: 0.03983655199408531 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.591134333708369, 'log_learning_rate_D': -3.341248666649768, 'training_batch_size': 8, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  43.59602165222168
Memory status after this trial: 
Memory allocated:  69.11669921875
Memory cached:  118.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.144943176021187, 'log_learning_rate_D': -3.7184800911311457, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  120.0
	 epoch  10 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.765625
Memory cached:  122.0
[I 2023-12-03 00:26:19,182] Trial 42 finished with value: 0.06374909728765488 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -3.144943176021187, 'log_learning_rate_D': -3.7184800911311457, 'training_batch_size': 9, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  49.303112268447876
Memory status after this trial: 
Memory allocated:  99.466796875
Memory cached:  120.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.0119272907702377, 'log_learning_rate_D': -2.899094852658404, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  120.0
	 epoch  10 training error:  tensor(1.9449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.326171875
Memory cached:  122.0
[I 2023-12-03 00:27:06,204] Trial 43 finished with value: 0.04669831320643425 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.0119272907702377, 'log_learning_rate_D': -2.899094852658404, 'training_batch_size': 7, 'training_p': 8}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  46.81819486618042
Memory status after this trial: 
Memory allocated:  92.92236328125
Memory cached:  118.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.016534412854886, 'log_learning_rate_D': -2.8311277804299344, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(2.5421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.44921875
Memory cached:  118.0
[I 2023-12-03 00:27:52,911] Trial 44 finished with value: 0.036468494683504105 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.016534412854886, 'log_learning_rate_D': -2.8311277804299344, 'training_batch_size': 9, 'training_p': 7}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  46.48885488510132
Memory status after this trial: 
Memory allocated:  79.87353515625
Memory cached:  118.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.737325851001305, 'log_learning_rate_D': -3.013042641863022, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(2.2879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.5390625
Memory cached:  118.0
[I 2023-12-03 00:28:39,819] Trial 45 finished with value: 0.030881209298968315 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.737325851001305, 'log_learning_rate_D': -3.013042641863022, 'training_batch_size': 8, 'training_p': 7}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  46.69017219543457
Memory status after this trial: 
Memory allocated:  79.92578125
Memory cached:  118.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.7460701959515403, 'log_learning_rate_D': -3.0724451766112266, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.529296875
Memory cached:  118.0
[I 2023-12-03 00:29:24,717] Trial 46 finished with value: 0.029468774795532227 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -2.7460701959515403, 'log_learning_rate_D': -3.0724451766112266, 'training_batch_size': 8, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  44.69411778450012
Memory status after this trial: 
Memory allocated:  78.4560546875
Memory cached:  118.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.4734025140561684, 'log_learning_rate_D': -3.0772115658494985, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.88671875
Memory cached:  118.0
[I 2023-12-03 00:30:08,978] Trial 47 finished with value: 0.03993303328752518 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.4734025140561684, 'log_learning_rate_D': -3.0772115658494985, 'training_batch_size': 8, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  44.05696988105774
Memory status after this trial: 
Memory allocated:  82.55029296875
Memory cached:  116.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.753090431388505, 'log_learning_rate_D': -3.4226168142423954, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  10 training error:  tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  20 training error:  tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  30 training error:  tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  40 training error:  tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  50 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  60 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  70 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  80 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
	 epoch  90 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  47.384765625
Memory cached:  118.0
[I 2023-12-03 00:30:51,521] Trial 48 finished with value: 0.03716055303812027 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.753090431388505, 'log_learning_rate_D': -3.4226168142423954, 'training_batch_size': 7, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
Time for this trial:  42.34871172904968
Memory status after this trial: 
Memory allocated:  75.4833984375
Memory cached:  116.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.9353232383797563, 'log_learning_rate_D': -3.220729238910897, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  10 training error:  tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  20 training error:  tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  30 training error:  tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  40 training error:  tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  50 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  60 training error:  tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  70 training error:  tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  80 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
	 epoch  90 training error:  tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  54.4775390625
Memory cached:  136.0
[I 2023-12-03 00:32:11,733] Trial 49 finished with value: 0.12640319764614105 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.9353232383797563, 'log_learning_rate_D': -3.220729238910897, 'training_batch_size': 6, 'training_p': 6}. Best is trial 36 with value: 0.02776537649333477.
[I 2023-12-03 00:32:11,758] A new study created in memory with name: no-name-98519ff1-7dca-46d6-87ae-925a53a0e73d
Time for this trial:  79.99667239189148
Memory status after this trial: 
Memory allocated:  101.26806640625
Memory cached:  136.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.4241356280527562, 'log_learning_rate_D': -1.5915975967833917, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.310546875
Memory cached:  8.0
	 epoch  10 training error:  tensor(3.9611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.310546875
Memory cached:  10.0
	 epoch  20 training error:  tensor(10.4909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.310546875
Memory cached:  10.0
	 epoch  30 training error:  tensor(11.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.310546875
Memory cached:  10.0
[W 2023-12-03 00:32:31,594] Trial 0 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.4241356280527562, 'log_learning_rate_D': -1.5915975967833917, 'training_batch_size': 9, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:32:31,594] Trial 0 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  19.712618112564087
Memory status after this trial: 
Memory allocated:  90.66064453125
Memory cached:  94.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.020106375368537, 'log_learning_rate_D': -3.2905770134950263, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.7286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  8.0
[I 2023-12-03 00:33:08,039] Trial 1 finished with value: 0.04896862804889679 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.020106375368537, 'log_learning_rate_D': -3.2905770134950263, 'training_batch_size': 10, 'training_p': 3}. Best is trial 1 with value: 0.04896862804889679.
res:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  36.3266544342041
Memory status after this trial: 
Memory allocated:  26.666015625
Memory cached:  28.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.722400504521584, 'log_learning_rate_D': -2.7818809988269524, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  49.99365234375
Memory cached:  58.0
[I 2023-12-03 00:33:59,036] Trial 2 finished with value: 0.04015466198325157 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.722400504521584, 'log_learning_rate_D': -2.7818809988269524, 'training_batch_size': 8, 'training_p': 6}. Best is trial 2 with value: 0.04015466198325157.
res:  tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  50.895748138427734
Memory status after this trial: 
Memory allocated:  116.9912109375
Memory cached:  160.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.258355823250742, 'log_learning_rate_D': -4.9741812172801865, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(2.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  182.0
	 epoch  10 training error:  tensor(1.8530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  20 training error:  tensor(1.4478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  30 training error:  tensor(1.0381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.6198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.68994140625
Memory cached:  186.0
[I 2023-12-03 00:34:49,440] Trial 3 finished with value: 0.05640412122011185 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.258355823250742, 'log_learning_rate_D': -4.9741812172801865, 'training_batch_size': 11, 'training_p': 2}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  50.292264461517334
Memory status after this trial: 
Memory allocated:  199.1533203125
Memory cached:  206.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.004270505426973, 'log_learning_rate_D': -1.2406949177912412, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  119.62939453125
Memory cached:  162.0
[W 2023-12-03 00:34:55,796] Trial 4 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.004270505426973, 'log_learning_rate_D': -1.2406949177912412, 'training_batch_size': 7, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:34:55,797] Trial 4 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.219133615493774
Memory status after this trial: 
Memory allocated:  177.79345703125
Memory cached:  192.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.601509927752373, 'log_learning_rate_D': -1.571676890378371, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.2043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  121.88525390625
Memory cached:  162.0
[W 2023-12-03 00:34:58,409] Trial 5 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -4.601509927752373, 'log_learning_rate_D': -1.571676890378371, 'training_batch_size': 9, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:34:58,410] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4731552600860596
Memory status after this trial: 
Memory allocated:  181.2783203125
Memory cached:  196.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.228770269695037, 'log_learning_rate_D': -1.0213206117617148, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.08642578125
Memory cached:  166.0
[W 2023-12-03 00:35:00,729] Trial 6 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -4.228770269695037, 'log_learning_rate_D': -1.0213206117617148, 'training_batch_size': 9, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:35:00,730] Trial 6 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.191272020339966
Memory status after this trial: 
Memory allocated:  238.3818359375
Memory cached:  256.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.2799937547299467, 'log_learning_rate_D': -3.97841247347475, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.6396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.75634765625
Memory cached:  202.0
[W 2023-12-03 00:35:05,578] Trial 7 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.2799937547299467, 'log_learning_rate_D': -3.97841247347475, 'training_batch_size': 11, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:35:05,579] Trial 7 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.709439039230347
Memory status after this trial: 
Memory allocated:  289.8857421875
Memory cached:  322.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.6923315432067145, 'log_learning_rate_D': -3.666005096266538, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.4648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.70751953125
Memory cached:  164.0
[I 2023-12-03 00:35:45,656] Trial 8 finished with value: 0.05160107836127281 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.6923315432067145, 'log_learning_rate_D': -3.666005096266538, 'training_batch_size': 9, 'training_p': 3}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  39.94885206222534
Memory status after this trial: 
Memory allocated:  163.4482421875
Memory cached:  174.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.348563459432441, 'log_learning_rate_D': -2.324137701808228, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  166.0
	 epoch  10 training error:  tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  20 training error:  tensor(0.8270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  30 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  40 training error:  tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  50 training error:  tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  60 training error:  tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  70 training error:  tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  80 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
	 epoch  90 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  128.33447265625
Memory cached:  168.0
[I 2023-12-03 00:36:52,702] Trial 9 finished with value: 0.07370220869779587 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -4.348563459432441, 'log_learning_rate_D': -2.324137701808228, 'training_batch_size': 8, 'training_p': 5}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  66.92061805725098
Memory status after this trial: 
Memory allocated:  238.576171875
Memory cached:  254.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.053493411869251, 'log_learning_rate_D': -1.9040062307303272, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  164.0
	 epoch  10 training error:  tensor(0.9122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.57666015625
Memory cached:  166.0
[I 2023-12-03 00:37:45,084] Trial 10 finished with value: 0.041596658527851105 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.053493411869251, 'log_learning_rate_D': -1.9040062307303272, 'training_batch_size': 8, 'training_p': 8}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  52.25068688392639
Memory status after this trial: 
Memory allocated:  154.623046875
Memory cached:  170.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.6892226702842676, 'log_learning_rate_D': -4.07744430639052, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(2.7486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  164.0
	 epoch  10 training error:  tensor(1.1099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  120.19189453125
Memory cached:  166.0
[I 2023-12-03 00:38:34,489] Trial 11 finished with value: 0.0804363265633583 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.6892226702842676, 'log_learning_rate_D': -4.07744430639052, 'training_batch_size': 7, 'training_p': 6}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  49.26180982589722
Memory status after this trial: 
Memory allocated:  175.158203125
Memory cached:  190.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.889424088708626, 'log_learning_rate_D': -1.1245764399643616, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.20947265625
Memory cached:  162.0
[W 2023-12-03 00:38:36,898] Trial 12 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.889424088708626, 'log_learning_rate_D': -1.1245764399643616, 'training_batch_size': 12, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:38:36,898] Trial 12 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.271670341491699
Memory status after this trial: 
Memory allocated:  240.07421875
Memory cached:  258.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.7808398654189954, 'log_learning_rate_D': -2.5817544867457167, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.82861328125
Memory cached:  164.0
[I 2023-12-03 00:39:14,844] Trial 13 finished with value: 0.049177855253219604 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.7808398654189954, 'log_learning_rate_D': -2.5817544867457167, 'training_batch_size': 7, 'training_p': 7}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  37.80819892883301
Memory status after this trial: 
Memory allocated:  139.81787109375
Memory cached:  162.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.5377609529437448, 'log_learning_rate_D': -4.226462718038957, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  162.0
	 epoch  10 training error:  tensor(45.8657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  20 training error:  tensor(9.1337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.7615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  40 training error:  tensor(2.7589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.7153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.8861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.5549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  80 training error:  tensor(1.3012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.6815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  129.99072265625
Memory cached:  164.0
[I 2023-12-03 00:39:59,928] Trial 14 finished with value: 0.60170978307724 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.5377609529437448, 'log_learning_rate_D': -4.226462718038957, 'training_batch_size': 12, 'training_p': 7}. Best is trial 2 with value: 0.04015466198325157.
Time for this trial:  44.960537910461426
Memory status after this trial: 
Memory allocated:  180.3388671875
Memory cached:  192.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0491978802657123, 'log_learning_rate_D': -3.097362888552642, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  117.87158203125
Memory cached:  162.0
[I 2023-12-03 00:40:42,550] Trial 15 finished with value: 0.03145942836999893 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0491978802657123, 'log_learning_rate_D': -3.097362888552642, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
res:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  42.497015714645386
Memory status after this trial: 
Memory allocated:  24.451171875
Memory cached:  90.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.0225027737310222, 'log_learning_rate_D': -1.0175392663180363, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(440.3847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  10 training error:  tensor(22.8796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  20 training error:  tensor(18.6755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  30 training error:  tensor(8.7606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  40 training error:  tensor(1.3749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  50 training error:  tensor(0.4865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  60 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  70 training error:  tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  80 training error:  tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
	 epoch  90 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.92236328125
Memory cached:  132.0
[I 2023-12-03 00:41:52,644] Trial 16 finished with value: 0.12959928810596466 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.0225027737310222, 'log_learning_rate_D': -1.0175392663180363, 'training_batch_size': 6, 'training_p': 5}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  69.91798710823059
Memory status after this trial: 
Memory allocated:  117.9365234375
Memory cached:  124.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.91179022683613, 'log_learning_rate_D': -2.954050686681005, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.7792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.7477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.63134765625
Memory cached:  96.0
[I 2023-12-03 00:43:24,839] Trial 17 finished with value: 0.07201412320137024 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.91179022683613, 'log_learning_rate_D': -2.954050686681005, 'training_batch_size': 6, 'training_p': 6}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  91.98994517326355
Memory status after this trial: 
Memory allocated:  151.36083984375
Memory cached:  158.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.3902992692628295, 'log_learning_rate_D': -3.0041265216768225, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.7692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  46.33544921875
Memory cached:  112.0
[I 2023-12-03 00:44:11,993] Trial 18 finished with value: 0.1464097648859024 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.3902992692628295, 'log_learning_rate_D': -3.0041265216768225, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  46.98214673995972
Memory status after this trial: 
Memory allocated:  126.33251953125
Memory cached:  142.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.972731584482229, 'log_learning_rate_D': -2.142695273313792, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.57568359375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.57568359375
Memory cached:  94.0
	 epoch  20 training error:  tensor(4.6911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  38.57568359375
Memory cached:  94.0
[W 2023-12-03 00:44:25,931] Trial 19 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.972731584482229, 'log_learning_rate_D': -2.142695273313792, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:44:25,932] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  13.74913740158081
Memory status after this trial: 
Memory allocated:  112.1767578125
Memory cached:  120.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.920537895459007, 'log_learning_rate_D': -2.114203212877347, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  20 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
[W 2023-12-03 00:44:37,145] Trial 20 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -4.920537895459007, 'log_learning_rate_D': -2.114203212877347, 'training_batch_size': 8, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:44:37,145] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  11.033785581588745
Memory status after this trial: 
Memory allocated:  115.828125
Memory cached:  124.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.264462054469682, 'log_learning_rate_D': -2.11757394184213, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  40.07763671875
Memory cached:  94.0
[I 2023-12-03 00:45:27,883] Trial 21 finished with value: 0.06624038517475128 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.264462054469682, 'log_learning_rate_D': -2.11757394184213, 'training_batch_size': 8, 'training_p': 6}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  50.551079988479614
Memory status after this trial: 
Memory allocated:  115.828125
Memory cached:  124.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.879854301405779, 'log_learning_rate_D': -3.33318616708491, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.9660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.6844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.81591796875
Memory cached:  96.0
[I 2023-12-03 00:46:23,854] Trial 22 finished with value: 0.11260014027357101 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.879854301405779, 'log_learning_rate_D': -3.33318616708491, 'training_batch_size': 7, 'training_p': 4}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  55.779402017593384
Memory status after this trial: 
Memory allocated:  88.095703125
Memory cached:  94.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.4285638822464466, 'log_learning_rate_D': -2.6644466679644054, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.4661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.94482421875
Memory cached:  94.0
[I 2023-12-03 00:47:02,112] Trial 23 finished with value: 0.040014348924160004 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.4285638822464466, 'log_learning_rate_D': -2.6644466679644054, 'training_batch_size': 10, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  38.07768797874451
Memory status after this trial: 
Memory allocated:  72.4248046875
Memory cached:  94.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.425926564783631, 'log_learning_rate_D': -1.8104137476150945, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.6593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.42724609375
Memory cached:  92.0
[I 2023-12-03 00:47:52,081] Trial 24 finished with value: 0.18371187150478363 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.425926564783631, 'log_learning_rate_D': -1.8104137476150945, 'training_batch_size': 10, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  49.77690243721008
Memory status after this trial: 
Memory allocated:  103.134765625
Memory cached:  106.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.0205736755569395, 'log_learning_rate_D': -2.5106450635332553, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.27099609375
Memory cached:  92.0
[I 2023-12-03 00:48:32,155] Trial 25 finished with value: 0.08914072811603546 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.0205736755569395, 'log_learning_rate_D': -2.5106450635332553, 'training_batch_size': 10, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  39.88453531265259
Memory status after this trial: 
Memory allocated:  71.62109375
Memory cached:  92.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.335958962275494, 'log_learning_rate_D': -3.5414653014359905, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.5996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.00146484375
Memory cached:  92.0
[I 2023-12-03 00:49:09,359] Trial 26 finished with value: 0.0510687418282032 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.335958962275494, 'log_learning_rate_D': -3.5414653014359905, 'training_batch_size': 12, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  37.023401975631714
Memory status after this trial: 
Memory allocated:  47.345703125
Memory cached:  92.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.526287727560182, 'log_learning_rate_D': -2.9705838123920003, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  94.0
	 epoch  10 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.48583984375
Memory cached:  96.0
[I 2023-12-03 00:49:56,432] Trial 27 finished with value: 0.05092230439186096 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.526287727560182, 'log_learning_rate_D': -2.9705838123920003, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  46.86554479598999
Memory status after this trial: 
Memory allocated:  80.9296875
Memory cached:  96.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0680286977730957, 'log_learning_rate_D': -2.2784378855239016, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.2613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
[I 2023-12-03 00:50:36,399] Trial 28 finished with value: 0.03596935793757439 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0680286977730957, 'log_learning_rate_D': -2.2784378855239016, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  39.77420473098755
Memory status after this trial: 
Memory allocated:  71.89892578125
Memory cached:  112.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0894283057648044, 'log_learning_rate_D': -2.3106169755816737, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.4734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  34.14794921875
Memory cached:  112.0
[I 2023-12-03 00:51:15,761] Trial 29 finished with value: 0.03879556804895401 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.0894283057648044, 'log_learning_rate_D': -2.3106169755816737, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  39.17373561859131
Memory status after this trial: 
Memory allocated:  71.89892578125
Memory cached:  112.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.065604123043001, 'log_learning_rate_D': -2.156751701218187, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  10 training error:  tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  20 training error:  tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  30 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  40 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  50 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  60 training error:  tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  70 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  80 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
	 epoch  90 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.65576171875
Memory cached:  112.0
[I 2023-12-03 00:51:56,958] Trial 30 finished with value: 0.06749925762414932 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.065604123043001, 'log_learning_rate_D': -2.156751701218187, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  41.01574921607971
Memory status after this trial: 
Memory allocated:  87.87158203125
Memory cached:  112.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.756542978439718, 'log_learning_rate_D': -1.6345154877368513, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.6452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.38623046875
Memory cached:  92.0
[I 2023-12-03 00:52:35,106] Trial 31 finished with value: 0.03821899741888046 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.756542978439718, 'log_learning_rate_D': -1.6345154877368513, 'training_batch_size': 9, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  37.96538782119751
Memory status after this trial: 
Memory allocated:  57.06689453125
Memory cached:  92.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.7940994178654845, 'log_learning_rate_D': -1.6087356881220913, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.5452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.6129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.24365234375
Memory cached:  92.0
[I 2023-12-03 00:53:14,647] Trial 32 finished with value: 0.03658725693821907 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.7940994178654845, 'log_learning_rate_D': -1.6087356881220913, 'training_batch_size': 7, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  39.35929536819458
Memory status after this trial: 
Memory allocated:  48.07421875
Memory cached:  92.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.397498414641735, 'log_learning_rate_D': -1.5413370910578652, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
[W 2023-12-03 00:53:30,418] Trial 33 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.397498414641735, 'log_learning_rate_D': -1.5413370910578652, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:53:30,419] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  15.5866117477417
Memory status after this trial: 
Memory allocated:  58.18017578125
Memory cached:  90.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.77018142116134, 'log_learning_rate_D': -1.5023788908235607, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.66455078125
Memory cached:  90.0
[W 2023-12-03 00:54:00,310] Trial 34 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.77018142116134, 'log_learning_rate_D': -1.5023788908235607, 'training_batch_size': 6, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-12-03 00:54:00,311] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  29.692652940750122
Memory status after this trial: 
Memory allocated:  58.18017578125
Memory cached:  90.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.827703643952598, 'log_learning_rate_D': -1.5415867756915071, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.7008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.88330078125
Memory cached:  90.0
[I 2023-12-03 00:55:14,726] Trial 35 finished with value: 0.09258577227592468 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.827703643952598, 'log_learning_rate_D': -1.5415867756915071, 'training_batch_size': 6, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  74.209223985672
Memory status after this trial: 
Memory allocated:  60.7548828125
Memory cached:  90.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.4162875251404667, 'log_learning_rate_D': -1.324185608447261, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.2479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.31982421875
Memory cached:  92.0
[I 2023-12-03 00:55:58,379] Trial 36 finished with value: 0.06830070167779922 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.4162875251404667, 'log_learning_rate_D': -1.324185608447261, 'training_batch_size': 7, 'training_p': 8}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  43.448838233947754
Memory status after this trial: 
Memory allocated:  48.54736328125
Memory cached:  92.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.3029718397922747, 'log_learning_rate_D': -1.9945338282504466, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.6520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.74951171875
Memory cached:  94.0
[I 2023-12-03 00:56:40,485] Trial 37 finished with value: 0.036049675196409225 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.3029718397922747, 'log_learning_rate_D': -1.9945338282504466, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  41.91756558418274
Memory status after this trial: 
Memory allocated:  72.27392578125
Memory cached:  94.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.8184561527180896, 'log_learning_rate_D': -2.0635350165747326, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.6407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.4287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.27978515625
Memory cached:  90.0
[I 2023-12-03 00:58:01,767] Trial 38 finished with value: 0.07500548660755157 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.8184561527180896, 'log_learning_rate_D': -2.0635350165747326, 'training_batch_size': 6, 'training_p': 6}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  81.08267545700073
Memory status after this trial: 
Memory allocated:  101.36865234375
Memory cached:  106.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.2579365589787606, 'log_learning_rate_D': -2.3765318886319635, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.63037109375
Memory cached:  94.0
[I 2023-12-03 00:58:51,504] Trial 39 finished with value: 0.031859464943408966 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.2579365589787606, 'log_learning_rate_D': -2.3765318886319635, 'training_batch_size': 8, 'training_p': 4}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  49.52382183074951
Memory status after this trial: 
Memory allocated:  83.52587890625
Memory cached:  94.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.147181099639174, 'log_learning_rate_D': -2.457954418535006, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78271484375
Memory cached:  96.0
[I 2023-12-03 00:59:42,651] Trial 40 finished with value: 0.1320044994354248 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.147181099639174, 'log_learning_rate_D': -2.457954418535006, 'training_batch_size': 8, 'training_p': 3}. Best is trial 15 with value: 0.03145942836999893.
Time for this trial:  50.927961349487305
Memory status after this trial: 
Memory allocated:  71.14111328125
Memory cached:  94.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.298889465696264, 'log_learning_rate_D': -2.3393892778444307, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.78662109375
Memory cached:  92.0
[I 2023-12-03 01:00:31,097] Trial 41 finished with value: 0.025145739316940308 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.298889465696264, 'log_learning_rate_D': -2.3393892778444307, 'training_batch_size': 8, 'training_p': 4}. Best is trial 41 with value: 0.025145739316940308.
res:  tensor(0.0251, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  48.24271821975708
Memory status after this trial: 
Memory allocated:  62.5830078125
Memory cached:  90.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.1970444669723737, 'log_learning_rate_D': -2.754198103982396, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.03369140625
Memory cached:  94.0
[I 2023-12-03 01:01:25,501] Trial 42 finished with value: 0.04886540025472641 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.1970444669723737, 'log_learning_rate_D': -2.754198103982396, 'training_batch_size': 8, 'training_p': 4}. Best is trial 41 with value: 0.025145739316940308.
Time for this trial:  54.22220230102539
Memory status after this trial: 
Memory allocated:  159.29736328125
Memory cached:  164.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.928863307668277, 'log_learning_rate_D': -2.3166098522167595, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  20 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  30 training error:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  40 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  50 training error:  tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  60 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  70 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  80 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
	 epoch  90 training error:  tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  71.82861328125
Memory cached:  96.0
[I 2023-12-03 01:02:18,627] Trial 43 finished with value: 0.03906930610537529 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.928863307668277, 'log_learning_rate_D': -2.3166098522167595, 'training_batch_size': 8, 'training_p': 4}. Best is trial 41 with value: 0.025145739316940308.
Time for this trial:  52.90469431877136
Memory status after this trial: 
Memory allocated:  141.21435546875
Memory cached:  148.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.518420012017106, 'log_learning_rate_D': -2.763891965987701, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.39892578125
Memory cached:  94.0
[I 2023-12-03 01:03:10,920] Trial 44 finished with value: 0.030023295432329178 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.518420012017106, 'log_learning_rate_D': -2.763891965987701, 'training_batch_size': 9, 'training_p': 4}. Best is trial 41 with value: 0.025145739316940308.
Time for this trial:  52.08709359169006
Memory status after this trial: 
Memory allocated:  125.83251953125
Memory cached:  130.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.5546077914231677, 'log_learning_rate_D': -2.8303045958360697, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.25830078125
Memory cached:  94.0
[I 2023-12-03 01:04:02,734] Trial 45 finished with value: 0.031046181917190552 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.5546077914231677, 'log_learning_rate_D': -2.8303045958360697, 'training_batch_size': 8, 'training_p': 2}. Best is trial 41 with value: 0.025145739316940308.
Time for this trial:  51.60088586807251
Memory status after this trial: 
Memory allocated:  125.46923828125
Memory cached:  130.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.0542694883217, 'log_learning_rate_D': -3.1042997239418737, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  20 training error:  tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  30 training error:  tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  40 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  50 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  60 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  70 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  80 training error:  tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
	 epoch  90 training error:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.81298828125
Memory cached:  94.0
[I 2023-12-03 01:04:55,857] Trial 46 finished with value: 0.04227359965443611 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.0542694883217, 'log_learning_rate_D': -3.1042997239418737, 'training_batch_size': 8, 'training_p': 2}. Best is trial 41 with value: 0.025145739316940308.
Time for this trial:  52.92598557472229
Memory status after this trial: 
Memory allocated:  130.22509765625
Memory cached:  134.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6033138129583397, 'log_learning_rate_D': -2.7752163531039273, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  96.0
	 epoch  10 training error:  tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  20 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  30 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  40 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  50 training error:  tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  60 training error:  tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  70 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  80 training error:  tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
	 epoch  90 training error:  tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  70.77001953125
Memory cached:  98.0
[I 2023-12-03 01:05:57,109] Trial 47 finished with value: 0.0229322649538517 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6033138129583397, 'log_learning_rate_D': -2.7752163531039273, 'training_batch_size': 7, 'training_p': 2}. Best is trial 47 with value: 0.0229322649538517.
res:  tensor(0.0229, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0251, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  61.03394269943237
Memory status after this trial: 
Memory allocated:  93.87158203125
Memory cached:  160.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.5966742132257243, 'log_learning_rate_D': -2.675661148376724, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.4851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  20 training error:  tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  30 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  40 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  50 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  60 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  70 training error:  tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  80 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
	 epoch  90 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  102.33984375
Memory cached:  166.0
[I 2023-12-03 01:06:56,580] Trial 48 finished with value: 0.037789590656757355 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.5966742132257243, 'log_learning_rate_D': -2.675661148376724, 'training_batch_size': 10, 'training_p': 2}. Best is trial 47 with value: 0.0229322649538517.
Time for this trial:  59.24839639663696
Memory status after this trial: 
Memory allocated:  188.61572265625
Memory cached:  194.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.355511122958321, 'log_learning_rate_D': -2.7475280753041584, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  10 training error:  tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  20 training error:  tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  30 training error:  tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  40 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  50 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  60 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  70 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  80 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
	 epoch  90 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.8671875
Memory cached:  162.0
[I 2023-12-03 01:07:57,707] Trial 49 finished with value: 0.04172637686133385 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -4.355511122958321, 'log_learning_rate_D': -2.7475280753041584, 'training_batch_size': 8, 'training_p': 3}. Best is trial 47 with value: 0.0229322649538517.
Time for this trial:  60.88793158531189
Memory status after this trial: 
Memory allocated:  185.0009765625
Memory cached:  190.0
