/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-05 00:34:39,590] A new study created in memory with name: no-name-7ea8a8f6-2353-40da-9a9d-26e9d0f7ed0f
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1205_smallDRS_smallA.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.401297599233391, 'log_learning_rate_D': -1.9935040977088936, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2783203125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2783203125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.7394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2783203125
Memory cached:  10.0
[W 2023-12-05 00:35:01,431] Trial 0 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -4.401297599233391, 'log_learning_rate_D': -1.9935040977088936, 'training_batch_size': 6, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:35:01,432] Trial 0 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  21.736553192138672
Memory status after this trial: 
Memory allocated:  47.37255859375
Memory cached:  50.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.387400730693207, 'log_learning_rate_D': -3.554916051016046, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.8037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.7377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.7071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.6731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.6336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.5932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.5191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.203125
Memory cached:  10.0
[I 2023-12-05 00:35:35,129] Trial 1 finished with value: 0.5246783494949341 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.387400730693207, 'log_learning_rate_D': -3.554916051016046, 'training_batch_size': 9, 'training_p': 6}. Best is trial 1 with value: 0.5246783494949341.
res:  tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  33.59538269042969
Memory status after this trial: 
Memory allocated:  25.20263671875
Memory cached:  28.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.2682091727565066, 'log_learning_rate_D': -1.0913211792185593, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.4309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  25.6162109375
Memory cached:  32.0
[W 2023-12-05 00:35:37,185] Trial 2 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.2682091727565066, 'log_learning_rate_D': -1.0913211792185593, 'training_batch_size': 12, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:35:37,186] Trial 2 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.954974889755249
Memory status after this trial: 
Memory allocated:  47.59716796875
Memory cached:  48.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.0061265769564454, 'log_learning_rate_D': -4.872494280096331, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  54.0
	 epoch  10 training error:  tensor(9.3514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  20 training error:  tensor(1.9383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  30 training error:  tensor(1.3870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  40 training error:  tensor(1.0304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  50 training error:  tensor(1.1707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  60 training error:  tensor(1.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  70 training error:  tensor(1.0042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.8875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
	 epoch  90 training error:  tensor(1.0311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.3974609375
Memory cached:  56.0
[I 2023-12-05 00:36:14,712] Trial 3 finished with value: 0.8621090054512024 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.0061265769564454, 'log_learning_rate_D': -4.872494280096331, 'training_batch_size': 12, 'training_p': 2}. Best is trial 1 with value: 0.5246783494949341.
Time for this trial:  37.41259407997131
Memory status after this trial: 
Memory allocated:  107.38525390625
Memory cached:  122.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -4.512973827459316, 'log_learning_rate_D': -3.1420029416011084, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  66.0
	 epoch  10 training error:  tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.6025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  30 training error:  tensor(0.5836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.5515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  50 training error:  tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  60 training error:  tensor(0.5708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  70 training error:  tensor(0.5273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
	 epoch  90 training error:  tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  48.2197265625
Memory cached:  68.0
[I 2023-12-05 00:37:12,532] Trial 4 finished with value: 0.37891268730163574 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -4.512973827459316, 'log_learning_rate_D': -3.1420029416011084, 'training_batch_size': 10, 'training_p': 2}. Best is trial 4 with value: 0.37891268730163574.
res:  tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  57.695648193359375
Memory status after this trial: 
Memory allocated:  129.93115234375
Memory cached:  178.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.6470176690810514, 'log_learning_rate_D': -1.6698194273350389, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  146.8759765625
Memory cached:  186.0
[W 2023-12-05 00:37:15,725] Trial 5 failed with parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.6470176690810514, 'log_learning_rate_D': -1.6698194273350389, 'training_batch_size': 12, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:37:15,725] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.0726330280303955
Memory status after this trial: 
Memory allocated:  238.73486328125
Memory cached:  258.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.4718001785797603, 'log_learning_rate_D': -3.9480109171554, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  202.0
	 epoch  10 training error:  tensor(557.9377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  20 training error:  tensor(162.5351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  30 training error:  tensor(1.6503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  40 training error:  tensor(0.7708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  50 training error:  tensor(0.8031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  60 training error:  tensor(0.7332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  70 training error:  tensor(0.7726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  80 training error:  tensor(0.8124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
	 epoch  90 training error:  tensor(0.8060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  164.3095703125
Memory cached:  204.0
[I 2023-12-05 00:38:04,688] Trial 6 finished with value: 0.4169381260871887 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.4718001785797603, 'log_learning_rate_D': -3.9480109171554, 'training_batch_size': 12, 'training_p': 4}. Best is trial 4 with value: 0.37891268730163574.
Time for this trial:  48.831292390823364
Memory status after this trial: 
Memory allocated:  230.3642578125
Memory cached:  252.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.942078773094149, 'log_learning_rate_D': -2.1880068267268746, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  10 training error:  tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  20 training error:  tensor(0.7645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  30 training error:  tensor(0.7628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  40 training error:  tensor(0.7588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  50 training error:  tensor(0.7531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  60 training error:  tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  70 training error:  tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  80 training error:  tensor(0.7593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
	 epoch  90 training error:  tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  133.6982421875
Memory cached:  182.0
[I 2023-12-05 00:38:53,228] Trial 7 finished with value: 0.6015510559082031 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.942078773094149, 'log_learning_rate_D': -2.1880068267268746, 'training_batch_size': 7, 'training_p': 5}. Best is trial 4 with value: 0.37891268730163574.
Time for this trial:  48.4369752407074
Memory status after this trial: 
Memory allocated:  176.580078125
Memory cached:  196.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.603183115350285, 'log_learning_rate_D': -4.241591077573021, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  10 training error:  tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.8846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.7961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.7848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.7566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.7258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.8779296875
Memory cached:  180.0
[I 2023-12-05 00:39:40,052] Trial 8 finished with value: 0.3599863350391388 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.603183115350285, 'log_learning_rate_D': -4.241591077573021, 'training_batch_size': 8, 'training_p': 8}. Best is trial 8 with value: 0.3599863350391388.
res:  tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  46.71007323265076
Memory status after this trial: 
Memory allocated:  77.99462890625
Memory cached:  164.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.6555626273731248, 'log_learning_rate_D': -3.7531018632327333, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  166.0
	 epoch  10 training error:  tensor(0.6015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.5858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  30 training error:  tensor(0.5553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  40 training error:  tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  50 training error:  tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  60 training error:  tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  70 training error:  tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  80 training error:  tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
	 epoch  90 training error:  tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  80.796875
Memory cached:  164.0
[I 2023-12-05 00:40:34,253] Trial 9 finished with value: 0.18149307370185852 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.6555626273731248, 'log_learning_rate_D': -3.7531018632327333, 'training_batch_size': 8, 'training_p': 8}. Best is trial 9 with value: 0.18149307370185852.
res:  tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  54.10319256782532
Memory status after this trial: 
Memory allocated:  73.40869140625
Memory cached:  154.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.4645673077033226, 'log_learning_rate_D': -3.668436156353543, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.7084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  20 training error:  tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  30 training error:  tensor(0.5542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  40 training error:  tensor(0.4588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  50 training error:  tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  60 training error:  tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  70 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  80 training error:  tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
	 epoch  90 training error:  tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  83.724609375
Memory cached:  176.0
[I 2023-12-05 00:41:20,988] Trial 10 finished with value: 0.1119605302810669 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.4645673077033226, 'log_learning_rate_D': -3.668436156353543, 'training_batch_size': 7, 'training_p': 3}. Best is trial 10 with value: 0.1119605302810669.
res:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  46.63738465309143
Memory status after this trial: 
Memory allocated:  63.50732421875
Memory cached:  154.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.1521931102015146, 'log_learning_rate_D': -1.849136870553517, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  86.46484375
Memory cached:  156.0
[W 2023-12-05 00:41:23,118] Trial 11 failed with parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -3.1521931102015146, 'log_learning_rate_D': -1.849136870553517, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:41:23,119] Trial 11 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.0277159214019775
Memory status after this trial: 
Memory allocated:  182.11181640625
Memory cached:  202.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.8168738701849447, 'log_learning_rate_D': -4.170639835884952, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  10 training error:  tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  20 training error:  tensor(0.6089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  30 training error:  tensor(0.5917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  40 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  50 training error:  tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  60 training error:  tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  70 training error:  tensor(0.5707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  80 training error:  tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
	 epoch  90 training error:  tensor(0.5529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.4658203125
Memory cached:  156.0
[I 2023-12-05 00:42:10,407] Trial 12 finished with value: 0.535443127155304 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.8168738701849447, 'log_learning_rate_D': -4.170639835884952, 'training_batch_size': 9, 'training_p': 6}. Best is trial 10 with value: 0.1119605302810669.
Time for this trial:  47.16751670837402
Memory status after this trial: 
Memory allocated:  102.3876953125
Memory cached:  156.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.242376217014291, 'log_learning_rate_D': -4.870917276816844, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  10 training error:  tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  20 training error:  tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  30 training error:  tensor(0.6014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  40 training error:  tensor(0.5891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  50 training error:  tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  60 training error:  tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  70 training error:  tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  80 training error:  tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
	 epoch  90 training error:  tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  74.8798828125
Memory cached:  154.0
[I 2023-12-05 00:42:51,425] Trial 13 finished with value: 0.2657832205295563 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.242376217014291, 'log_learning_rate_D': -4.870917276816844, 'training_batch_size': 12, 'training_p': 8}. Best is trial 10 with value: 0.1119605302810669.
Time for this trial:  40.89712977409363
Memory status after this trial: 
Memory allocated:  127.48388671875
Memory cached:  154.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.5872207994629965, 'log_learning_rate_D': -1.0593761540453155, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.80078125
Memory cached:  156.0
[W 2023-12-05 00:42:54,868] Trial 14 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.5872207994629965, 'log_learning_rate_D': -1.0593761540453155, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:42:54,869] Trial 14 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.209526538848877
Memory status after this trial: 
Memory allocated:  125.55517578125
Memory cached:  156.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.542881587992203, 'log_learning_rate_D': -1.0013033412877332, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.62890625
Memory cached:  154.0
[W 2023-12-05 00:42:57,223] Trial 15 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.542881587992203, 'log_learning_rate_D': -1.0013033412877332, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:42:57,224] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1471054553985596
Memory status after this trial: 
Memory allocated:  116.38720703125
Memory cached:  154.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.582035786899482, 'log_learning_rate_D': -1.3021506434386882, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  10 training error:  tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  20 training error:  tensor(0.6551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  30 training error:  tensor(0.6079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  40 training error:  tensor(0.5641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  50 training error:  tensor(0.5554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  60 training error:  tensor(0.5435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  70 training error:  tensor(0.5450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  80 training error:  tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
	 epoch  90 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.384765625
Memory cached:  154.0
[I 2023-12-05 00:44:26,331] Trial 16 finished with value: 0.4147079586982727 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.582035786899482, 'log_learning_rate_D': -1.3021506434386882, 'training_batch_size': 6, 'training_p': 3}. Best is trial 10 with value: 0.1119605302810669.
Time for this trial:  88.87149477005005
Memory status after this trial: 
Memory allocated:  95.99169921875
Memory cached:  154.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.976067495778476, 'log_learning_rate_D': -2.933068152585186, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  176.0
	 epoch  10 training error:  tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  20 training error:  tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  30 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  40 training error:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  50 training error:  tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  60 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  70 training error:  tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  80 training error:  tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
	 epoch  90 training error:  tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  81.6201171875
Memory cached:  180.0
[I 2023-12-05 00:45:22,400] Trial 17 finished with value: 0.07488458603620529 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.976067495778476, 'log_learning_rate_D': -2.933068152585186, 'training_batch_size': 7, 'training_p': 4}. Best is trial 17 with value: 0.07488458603620529.
res:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  55.87634348869324
Memory status after this trial: 
Memory allocated:  108.20751953125
Memory cached:  182.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.4670820349889793, 'log_learning_rate_D': -2.6183803954035616, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  10 training error:  tensor(0.6819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  20 training error:  tensor(0.6040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  30 training error:  tensor(0.5391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  40 training error:  tensor(0.5716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  50 training error:  tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  60 training error:  tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  70 training error:  tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  80 training error:  tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
	 epoch  90 training error:  tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.5107421875
Memory cached:  206.0
[I 2023-12-05 00:46:51,877] Trial 18 finished with value: 0.40106430649757385 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.4670820349889793, 'log_learning_rate_D': -2.6183803954035616, 'training_batch_size': 6, 'training_p': 4}. Best is trial 17 with value: 0.07488458603620529.
Time for this trial:  89.2869565486908
Memory status after this trial: 
Memory allocated:  197.4736328125
Memory cached:  204.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.3739619960381977, 'log_learning_rate_D': -2.8697040399164866, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  10 training error:  tensor(0.8219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  20 training error:  tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  30 training error:  tensor(0.6896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  40 training error:  tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  50 training error:  tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  60 training error:  tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  70 training error:  tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  80 training error:  tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
	 epoch  90 training error:  tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  118.2734375
Memory cached:  186.0
[I 2023-12-05 00:47:45,362] Trial 19 finished with value: 0.05131257697939873 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.3739619960381977, 'log_learning_rate_D': -2.8697040399164866, 'training_batch_size': 7, 'training_p': 4}. Best is trial 19 with value: 0.05131257697939873.
res:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  53.286842584609985
Memory status after this trial: 
Memory allocated:  60.580078125
Memory cached:  168.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.445173826817306, 'log_learning_rate_D': -2.589931336566825, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.7557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.22021484375
Memory cached:  172.0
[I 2023-12-05 00:48:38,077] Trial 20 finished with value: 0.1310364305973053 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.445173826817306, 'log_learning_rate_D': -2.589931336566825, 'training_batch_size': 7, 'training_p': 5}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  52.536224603652954
Memory status after this trial: 
Memory allocated:  107.54248046875
Memory cached:  170.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.4233269455984456, 'log_learning_rate_D': -3.1018119525077914, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  10 training error:  tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  20 training error:  tensor(0.7289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  30 training error:  tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  40 training error:  tensor(0.6506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  50 training error:  tensor(0.6387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.6344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.6007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  79.03271484375
Memory cached:  172.0
[I 2023-12-05 00:49:27,095] Trial 21 finished with value: 0.3257427215576172 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.4233269455984456, 'log_learning_rate_D': -3.1018119525077914, 'training_batch_size': 8, 'training_p': 4}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  48.820014238357544
Memory status after this trial: 
Memory allocated:  149.4248046875
Memory cached:  172.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.034018989808914, 'log_learning_rate_D': -2.205180842595624, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  10 training error:  tensor(231.1701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  20 training error:  tensor(56.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  30 training error:  tensor(50.1190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  40 training error:  tensor(1.9039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  50 training error:  tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  60 training error:  tensor(0.9228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  70 training error:  tensor(0.7772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  80 training error:  tensor(0.7846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
	 epoch  90 training error:  tensor(0.7803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.37255859375
Memory cached:  172.0
[I 2023-12-05 00:50:15,080] Trial 22 finished with value: 0.46304890513420105 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.034018989808914, 'log_learning_rate_D': -2.205180842595624, 'training_batch_size': 10, 'training_p': 6}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  47.79110836982727
Memory status after this trial: 
Memory allocated:  92.79931640625
Memory cached:  170.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.976861953766647, 'log_learning_rate_D': -1.6662211629017487, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  10 training error:  tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  20 training error:  tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  30 training error:  tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  40 training error:  tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  50 training error:  tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  60 training error:  tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  70 training error:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  80 training error:  tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
	 epoch  90 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.83251953125
Memory cached:  168.0
[I 2023-12-05 00:51:29,331] Trial 23 finished with value: 0.09173347055912018 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.976861953766647, 'log_learning_rate_D': -1.6662211629017487, 'training_batch_size': 6, 'training_p': 3}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  74.06963515281677
Memory status after this trial: 
Memory allocated:  92.24560546875
Memory cached:  168.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.820542652677424, 'log_learning_rate_D': -2.834327681557752, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.7530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  20 training error:  tensor(0.7380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  30 training error:  tensor(0.7257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  40 training error:  tensor(0.7120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  50 training error:  tensor(0.6946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  60 training error:  tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  70 training error:  tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  80 training error:  tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
	 epoch  90 training error:  tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.13427734375
Memory cached:  170.0
[I 2023-12-05 00:52:16,720] Trial 24 finished with value: 0.30724576115608215 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.820542652677424, 'log_learning_rate_D': -2.834327681557752, 'training_batch_size': 7, 'training_p': 4}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  47.202240228652954
Memory status after this trial: 
Memory allocated:  100.2421875
Memory cached:  170.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.3977949020480436, 'log_learning_rate_D': -3.2790602472720187, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  192.0
	 epoch  10 training error:  tensor(3.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  20 training error:  tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  30 training error:  tensor(0.8385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  40 training error:  tensor(0.7863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  50 training error:  tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  60 training error:  tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  70 training error:  tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  80 training error:  tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
	 epoch  90 training error:  tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  88.33154296875
Memory cached:  196.0
[I 2023-12-05 00:53:15,680] Trial 25 finished with value: 0.15952670574188232 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.3977949020480436, 'log_learning_rate_D': -3.2790602472720187, 'training_batch_size': 10, 'training_p': 7}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  58.760157108306885
Memory status after this trial: 
Memory allocated:  203.234375
Memory cached:  210.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.126165278267515, 'log_learning_rate_D': -2.3136914976116696, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  10 training error:  tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  20 training error:  tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  30 training error:  tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  40 training error:  tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  50 training error:  tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  60 training error:  tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  70 training error:  tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  80 training error:  tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
	 epoch  90 training error:  tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.06201171875
Memory cached:  168.0
[I 2023-12-05 00:53:53,335] Trial 26 finished with value: 0.17893467843532562 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.126165278267515, 'log_learning_rate_D': -2.3136914976116696, 'training_batch_size': 9, 'training_p': 5}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  37.478519439697266
Memory status after this trial: 
Memory allocated:  71.15234375
Memory cached:  168.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.069593465872398, 'log_learning_rate_D': -1.745042387313135, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  10 training error:  tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  20 training error:  tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  30 training error:  tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  40 training error:  tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  50 training error:  tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  60 training error:  tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  70 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  80 training error:  tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
	 epoch  90 training error:  tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.46142578125
Memory cached:  168.0
[I 2023-12-05 00:55:05,550] Trial 27 finished with value: 0.0864490494132042 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.069593465872398, 'log_learning_rate_D': -1.745042387313135, 'training_batch_size': 6, 'training_p': 3}. Best is trial 19 with value: 0.05131257697939873.
Time for this trial:  72.03183960914612
Memory status after this trial: 
Memory allocated:  98.41943359375
Memory cached:  168.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.0967153009249717, 'log_learning_rate_D': -1.840923616632742, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  10 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  20 training error:  tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  30 training error:  tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  40 training error:  tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  50 training error:  tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  60 training error:  tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  70 training error:  tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  80 training error:  tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
	 epoch  90 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  65.34814453125
Memory cached:  168.0
[I 2023-12-05 00:56:28,222] Trial 28 finished with value: 0.04170798510313034 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.0967153009249717, 'log_learning_rate_D': -1.840923616632742, 'training_batch_size': 6, 'training_p': 3}. Best is trial 28 with value: 0.04170798510313034.
res:  tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  82.48522281646729
Memory status after this trial: 
Memory allocated:  53.87841796875
Memory cached:  148.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.803789443180272, 'log_learning_rate_D': -2.7966355552632645, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.6015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  20 training error:  tensor(0.5866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  30 training error:  tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  40 training error:  tensor(0.5431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  50 training error:  tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  70 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.5283203125
Memory cached:  150.0
[I 2023-12-05 00:57:21,106] Trial 29 finished with value: 0.1274920254945755 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.803789443180272, 'log_learning_rate_D': -2.7966355552632645, 'training_batch_size': 7, 'training_p': 2}. Best is trial 28 with value: 0.04170798510313034.
Time for this trial:  52.694676637649536
Memory status after this trial: 
Memory allocated:  91.02490234375
Memory cached:  150.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.243636606967998, 'log_learning_rate_D': -3.33162349745811, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.5947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.4333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.4193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  58.4208984375
Memory cached:  152.0
[I 2023-12-05 00:58:10,219] Trial 30 finished with value: 0.21308103203773499 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.243636606967998, 'log_learning_rate_D': -3.33162349745811, 'training_batch_size': 8, 'training_p': 4}. Best is trial 28 with value: 0.04170798510313034.
Time for this trial:  48.92237091064453
Memory status after this trial: 
Memory allocated:  110.12890625
Memory cached:  150.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7570831306423114, 'log_learning_rate_D': -1.0933340079840237, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  77.810546875
Memory cached:  168.0
[W 2023-12-05 00:58:12,499] Trial 31 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7570831306423114, 'log_learning_rate_D': -1.0933340079840237, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:58:12,500] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.065159797668457
Memory status after this trial: 
Memory allocated:  156.94775390625
Memory cached:  174.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.748211302296272, 'log_learning_rate_D': -1.2128471664696683, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 00:58:15,708] Trial 32 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.748211302296272, 'log_learning_rate_D': -1.2128471664696683, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:58:15,709] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.9801883697509766
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.803945762093733, 'log_learning_rate_D': -1.880886299828004, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.6098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  20 training error:  tensor(0.5926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  30 training error:  tensor(0.6030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  40 training error:  tensor(0.5522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  50 training error:  tensor(0.5549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  60 training error:  tensor(0.5556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  70 training error:  tensor(0.5106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  80 training error:  tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  90 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 00:59:39,334] Trial 33 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.803945762093733, 'log_learning_rate_D': -1.880886299828004, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:59:39,335] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  83.41662096977234
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7092086654682537, 'log_learning_rate_D': -1.0434788821431762, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 00:59:41,656] Trial 34 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.7092086654682537, 'log_learning_rate_D': -1.0434788821431762, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:59:41,658] Trial 34 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1092350482940674
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.797709024540008, 'log_learning_rate_D': -1.8755774451588032, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 00:59:59,565] Trial 35 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.797709024540008, 'log_learning_rate_D': -1.8755774451588032, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 00:59:59,566] Trial 35 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  17.686480283737183
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8276109992040643, 'log_learning_rate_D': -1.0806210784100307, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  61.29296875
Memory cached:  148.0
[W 2023-12-05 01:00:02,806] Trial 36 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.8276109992040643, 'log_learning_rate_D': -1.0806210784100307, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:00:02,808] Trial 36 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.016923427581787
Memory status after this trial: 
Memory allocated:  122.38037109375
Memory cached:  148.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.6597751422116183, 'log_learning_rate_D': -1.0632273781084882, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 01:00:06,096] Trial 37 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.6597751422116183, 'log_learning_rate_D': -1.0632273781084882, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:00:06,097] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.0694031715393066
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.747524335002062, 'log_learning_rate_D': -1.1804251506845427, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  75.306640625
Memory cached:  170.0
[W 2023-12-05 01:00:09,192] Trial 38 failed with parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.747524335002062, 'log_learning_rate_D': -1.1804251506845427, 'training_batch_size': 6, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:00:09,193] Trial 38 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8865978717803955
Memory status after this trial: 
Memory allocated:  149.89501953125
Memory cached:  170.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.775515022633741, 'log_learning_rate_D': -1.9124456399687144, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  10 training error:  tensor(0.6915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  20 training error:  tensor(1.2590e+09, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  30 training error:  tensor(1.9191, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  40 training error:  tensor(948.3989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  50 training error:  tensor(104.2256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  60 training error:  tensor(24.1078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  70 training error:  tensor(52.2978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  80 training error:  tensor(75.4846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
	 epoch  90 training error:  tensor(25.9901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.70703125
Memory cached:  170.0
[I 2023-12-05 01:01:40,971] Trial 39 finished with value: 18.735107421875 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.775515022633741, 'log_learning_rate_D': -1.9124456399687144, 'training_batch_size': 6, 'training_p': 3}. Best is trial 28 with value: 0.04170798510313034.
Time for this trial:  91.57192277908325
Memory status after this trial: 
Memory allocated:  136.10888671875
Memory cached:  170.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.933908203159628, 'log_learning_rate_D': -1.206901352081816, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  150.0
[W 2023-12-05 01:01:43,044] Trial 40 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.933908203159628, 'log_learning_rate_D': -1.206901352081816, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:43,045] Trial 40 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8683547973632812
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.040579586918258, 'log_learning_rate_D': -1.163877719664594, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.1240234375
Memory cached:  150.0
[W 2023-12-05 01:01:46,842] Trial 41 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.040579586918258, 'log_learning_rate_D': -1.163877719664594, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:46,843] Trial 41 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.5908403396606445
Memory status after this trial: 
Memory allocated:  86.1728515625
Memory cached:  150.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.8810480738928805, 'log_learning_rate_D': -1.107279456191557, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
[W 2023-12-05 01:01:49,455] Trial 42 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.8810480738928805, 'log_learning_rate_D': -1.107279456191557, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:49,456] Trial 42 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.4285597801208496
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.802956885420488, 'log_learning_rate_D': -1.2428801403768204, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
[W 2023-12-05 01:01:51,957] Trial 43 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.802956885420488, 'log_learning_rate_D': -1.2428801403768204, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:51,958] Trial 43 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.297443151473999
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.9985231835981887, 'log_learning_rate_D': -1.0165155897074714, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
[W 2023-12-05 01:01:54,017] Trial 44 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.9985231835981887, 'log_learning_rate_D': -1.0165155897074714, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:54,018] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.8579514026641846
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.930876716465529, 'log_learning_rate_D': -1.0503481326231259, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.1240234375
Memory cached:  150.0
[W 2023-12-05 01:01:56,338] Trial 45 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.930876716465529, 'log_learning_rate_D': -1.0503481326231259, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:56,339] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.1298961639404297
Memory status after this trial: 
Memory allocated:  86.1728515625
Memory cached:  150.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.0189013412587595, 'log_learning_rate_D': -1.0743023678336425, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
[W 2023-12-05 01:01:58,373] Trial 46 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.0189013412587595, 'log_learning_rate_D': -1.0743023678336425, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:01:58,374] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  1.841975450515747
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.9540163589535244, 'log_learning_rate_D': -1.0429261652712656, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.1435546875
Memory cached:  152.0
[W 2023-12-05 01:02:00,835] Trial 47 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.9540163589535244, 'log_learning_rate_D': -1.0429261652712656, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:02:00,836] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.2676665782928467
Memory status after this trial: 
Memory allocated:  87.3427734375
Memory cached:  148.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.908143811699386, 'log_learning_rate_D': -1.298833381501024, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.1240234375
Memory cached:  150.0
[W 2023-12-05 01:02:04,208] Trial 48 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.908143811699386, 'log_learning_rate_D': -1.298833381501024, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-12-05 01:02:04,208] Trial 48 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.1657934188842773
Memory status after this trial: 
Memory allocated:  86.1728515625
Memory cached:  150.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.7927590536007636, 'log_learning_rate_D': -2.911908263721674, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  10 training error:  tensor(0.7519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  20 training error:  tensor(0.7025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  30 training error:  tensor(0.6658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  40 training error:  tensor(0.6024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  50 training error:  tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  60 training error:  tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  70 training error:  tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  80 training error:  tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
	 epoch  90 training error:  tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  57.1337890625
Memory cached:  152.0
[I 2023-12-05 01:02:56,323] Trial 49 finished with value: 0.15052585303783417 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.7927590536007636, 'log_learning_rate_D': -2.911908263721674, 'training_batch_size': 7, 'training_p': 5}. Best is trial 28 with value: 0.04170798510313034.
[I 2023-12-05 01:02:56,350] A new study created in memory with name: no-name-c2bae37b-feeb-4400-a1c6-5446d845ea28
Time for this trial:  51.93526220321655
Memory status after this trial: 
Memory allocated:  99.7294921875
Memory cached:  150.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.8693418501342447, 'log_learning_rate_D': -1.0117917274381036, 'training_batch_size': 12, 'training_p': 8}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.8752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.9711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.8017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.7961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.7957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.7947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.7943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.75830078125
Memory cached:  44.0
[I 2023-12-05 01:03:12,767] Trial 0 finished with value: 0.4625491797924042 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.8693418501342447, 'log_learning_rate_D': -1.0117917274381036, 'training_batch_size': 12, 'training_p': 8}. Best is trial 0 with value: 0.4625491797924042.
res:  tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  16.330169200897217
Memory status after this trial: 
Memory allocated:  57.708984375
Memory cached:  86.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.565701266154055, 'log_learning_rate_D': -2.7279550331269427, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  10 training error:  tensor(6.2105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  20 training error:  tensor(2.4775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  30 training error:  tensor(2.8423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  40 training error:  tensor(1.3126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  50 training error:  tensor(1.8944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  60 training error:  tensor(1.2335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  70 training error:  tensor(1.6596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  80 training error:  tensor(1.2156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
	 epoch  90 training error:  tensor(1.5723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  76.12451171875
Memory cached:  88.0
[I 2023-12-05 01:03:29,175] Trial 1 finished with value: 1.2990466356277466 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -1.565701266154055, 'log_learning_rate_D': -2.7279550331269427, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 0.4625491797924042.
Time for this trial:  16.326614141464233
Memory status after this trial: 
Memory allocated:  138.94482421875
Memory cached:  188.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.9326265999834256, 'log_learning_rate_D': -4.9155665094454335, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  10 training error:  tensor(4.1726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  20 training error:  tensor(3.1505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  30 training error:  tensor(1.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  40 training error:  tensor(1.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.7659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.6889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.6212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.06591796875
Memory cached:  90.0
[I 2023-12-05 01:03:44,966] Trial 2 finished with value: 0.4704669415950775 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.9326265999834256, 'log_learning_rate_D': -4.9155665094454335, 'training_batch_size': 7, 'training_p': 4}. Best is trial 0 with value: 0.4625491797924042.
Time for this trial:  15.69416880607605
Memory status after this trial: 
Memory allocated:  97.98779296875
Memory cached:  110.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.5518961580989203, 'log_learning_rate_D': -1.5178324559207228, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.6189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.6068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.5940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.5940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.5939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.5939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.3759765625
Memory cached:  92.0
[I 2023-12-05 01:04:00,848] Trial 3 finished with value: 0.619888961315155 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.5518961580989203, 'log_learning_rate_D': -1.5178324559207228, 'training_batch_size': 9, 'training_p': 7}. Best is trial 0 with value: 0.4625491797924042.
Time for this trial:  15.791252136230469
Memory status after this trial: 
Memory allocated:  103.31396484375
Memory cached:  108.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.2788378661674034, 'log_learning_rate_D': -1.4292138409006818, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  10 training error:  tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  20 training error:  tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  30 training error:  tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  40 training error:  tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  50 training error:  tensor(0.6014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  60 training error:  tensor(0.5966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  70 training error:  tensor(0.5950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  80 training error:  tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
	 epoch  90 training error:  tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.6591796875
Memory cached:  102.0
[I 2023-12-05 01:04:16,439] Trial 4 finished with value: 0.6539621949195862 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.2788378661674034, 'log_learning_rate_D': -1.4292138409006818, 'training_batch_size': 11, 'training_p': 8}. Best is trial 0 with value: 0.4625491797924042.
Time for this trial:  15.504717826843262
Memory status after this trial: 
Memory allocated:  102.96533203125
Memory cached:  126.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.218910590837329, 'log_learning_rate_D': -4.357130135959759, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  10 training error:  tensor(1103.4873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  20 training error:  tensor(82.6216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  30 training error:  tensor(14.1720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  40 training error:  tensor(28.3277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  50 training error:  tensor(18.2074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  60 training error:  tensor(16.2904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  70 training error:  tensor(14.9383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  80 training error:  tensor(5.2401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.8154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.9990234375
Memory cached:  90.0
[I 2023-12-05 01:04:32,401] Trial 5 finished with value: 0.4343257546424866 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -1.218910590837329, 'log_learning_rate_D': -4.357130135959759, 'training_batch_size': 10, 'training_p': 7}. Best is trial 5 with value: 0.4343257546424866.
res:  tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.872663736343384
Memory status after this trial: 
Memory allocated:  47.333984375
Memory cached:  90.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.1035164096835888, 'log_learning_rate_D': -4.382833607697538, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.7963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.9125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.6747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.5987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.5863, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.3701171875
Memory cached:  92.0
[I 2023-12-05 01:04:48,096] Trial 6 finished with value: 0.48648443818092346 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.1035164096835888, 'log_learning_rate_D': -4.382833607697538, 'training_batch_size': 10, 'training_p': 4}. Best is trial 5 with value: 0.4343257546424866.
Time for this trial:  15.601450443267822
Memory status after this trial: 
Memory allocated:  82.12548828125
Memory cached:  92.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.111365117477919, 'log_learning_rate_D': -1.5983800949724198, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  10 training error:  tensor(13.2259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  20 training error:  tensor(15.4253, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  30 training error:  tensor(43.1652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  40 training error:  tensor(13.3255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  50 training error:  tensor(2.6283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.8935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.6057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.15380859375
Memory cached:  92.0
[I 2023-12-05 01:05:02,851] Trial 7 finished with value: 1.2423232793807983 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.111365117477919, 'log_learning_rate_D': -1.5983800949724198, 'training_batch_size': 12, 'training_p': 5}. Best is trial 5 with value: 0.4343257546424866.
Time for this trial:  14.658485651016235
Memory status after this trial: 
Memory allocated:  63.65771484375
Memory cached:  92.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -1.8556554875990274, 'log_learning_rate_D': -2.15600646009204, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  10 training error:  tensor(0.9686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  20 training error:  tensor(0.8692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  30 training error:  tensor(0.7762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  40 training error:  tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  50 training error:  tensor(0.7606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  60 training error:  tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  70 training error:  tensor(0.7297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  80 training error:  tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
	 epoch  90 training error:  tensor(0.6738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  50.2529296875
Memory cached:  92.0
[I 2023-12-05 01:05:18,206] Trial 8 finished with value: 0.6338276267051697 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -1.8556554875990274, 'log_learning_rate_D': -2.15600646009204, 'training_batch_size': 10, 'training_p': 7}. Best is trial 5 with value: 0.4343257546424866.
Time for this trial:  15.257158756256104
Memory status after this trial: 
Memory allocated:  71.65185546875
Memory cached:  94.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.390739140793112, 'log_learning_rate_D': -3.2403403787465654, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.6112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.5930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.0068359375
Memory cached:  90.0
[I 2023-12-05 01:05:33,825] Trial 9 finished with value: 0.5872206091880798 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.390739140793112, 'log_learning_rate_D': -3.2403403787465654, 'training_batch_size': 10, 'training_p': 6}. Best is trial 5 with value: 0.4343257546424866.
Time for this trial:  15.516625165939331
Memory status after this trial: 
Memory allocated:  103.54736328125
Memory cached:  150.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.045716632160704, 'log_learning_rate_D': -3.846902393775002, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.5440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.205078125
Memory cached:  90.0
[I 2023-12-05 01:05:49,335] Trial 10 finished with value: 0.36860713362693787 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.045716632160704, 'log_learning_rate_D': -3.846902393775002, 'training_batch_size': 6, 'training_p': 2}. Best is trial 10 with value: 0.36860713362693787.
res:  tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.329338312149048
Memory status after this trial: 
Memory allocated:  6.03125
Memory cached:  14.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.0446379051768075, 'log_learning_rate_D': -3.903011407828381, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.48046875
Memory cached:  34.0
[I 2023-12-05 01:06:04,581] Trial 11 finished with value: 0.3641023337841034 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.0446379051768075, 'log_learning_rate_D': -3.903011407828381, 'training_batch_size': 6, 'training_p': 2}. Best is trial 11 with value: 0.3641023337841034.
res:  tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.096837759017944
Memory status after this trial: 
Memory allocated:  6.03125
Memory cached:  16.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.070433912581407, 'log_learning_rate_D': -3.6094629870036936, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.38671875
Memory cached:  36.0
[I 2023-12-05 01:06:19,744] Trial 12 finished with value: 0.3634127378463745 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -3.070433912581407, 'log_learning_rate_D': -3.6094629870036936, 'training_batch_size': 6, 'training_p': 2}. Best is trial 12 with value: 0.3634127378463745.
res:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  15.020618915557861
Memory status after this trial: 
Memory allocated:  4.5029296875
Memory cached:  16.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.9700434637143185, 'log_learning_rate_D': -3.4900121037305967, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.92724609375
Memory cached:  36.0
[I 2023-12-05 01:06:34,967] Trial 13 finished with value: 0.3655773103237152 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -2.9700434637143185, 'log_learning_rate_D': -3.4900121037305967, 'training_batch_size': 6, 'training_p': 2}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  15.087672233581543
Memory status after this trial: 
Memory allocated:  7.50927734375
Memory cached:  16.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.866852451147003, 'log_learning_rate_D': -2.759951625065102, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  10 training error:  tensor(1.4205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  20 training error:  tensor(1.3556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  30 training error:  tensor(1.2919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.2292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  50 training error:  tensor(1.1671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.9837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.98388671875
Memory cached:  16.0
[I 2023-12-05 01:06:49,432] Trial 14 finished with value: 0.8137838244438171 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.866852451147003, 'log_learning_rate_D': -2.759951625065102, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  14.30461573600769
Memory status after this trial: 
Memory allocated:  6.38720703125
Memory cached:  16.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.686863684937523, 'log_learning_rate_D': -3.7541150371795116, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.5752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.20947265625
Memory cached:  16.0
[I 2023-12-05 01:07:04,200] Trial 15 finished with value: 0.42991748452186584 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.686863684937523, 'log_learning_rate_D': -3.7541150371795116, 'training_batch_size': 7, 'training_p': 3}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  14.617122650146484
Memory status after this trial: 
Memory allocated:  12.06201171875
Memory cached:  16.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4961256443721727, 'log_learning_rate_D': -3.115650206676963, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.5787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.47607421875
Memory cached:  16.0
[I 2023-12-05 01:07:20,114] Trial 16 finished with value: 0.4257941246032715 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4961256443721727, 'log_learning_rate_D': -3.115650206676963, 'training_batch_size': 6, 'training_p': 3}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  15.724593877792358
Memory status after this trial: 
Memory allocated:  30.71337890625
Memory cached:  56.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.886137570925304, 'log_learning_rate_D': -4.08457449807137, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  10 training error:  tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.6808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  30 training error:  tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  40 training error:  tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  50 training error:  tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  60 training error:  tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  70 training error:  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  80 training error:  tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
	 epoch  90 training error:  tensor(0.5694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.88525390625
Memory cached:  68.0
[I 2023-12-05 01:07:35,866] Trial 17 finished with value: 0.38699766993522644 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.886137570925304, 'log_learning_rate_D': -4.08457449807137, 'training_batch_size': 8, 'training_p': 2}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  15.587123394012451
Memory status after this trial: 
Memory allocated:  55.41943359375
Memory cached:  68.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.461977290292297, 'log_learning_rate_D': -3.4811788950307676, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  10 training error:  tensor(1.3736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.8161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.5838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.62744140625
Memory cached:  16.0
[I 2023-12-05 01:07:50,844] Trial 18 finished with value: 0.4883718490600586 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.461977290292297, 'log_learning_rate_D': -3.4811788950307676, 'training_batch_size': 8, 'training_p': 4}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  14.840344190597534
Memory status after this trial: 
Memory allocated:  23.13623046875
Memory cached:  36.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.8527639350132663, 'log_learning_rate_D': -4.8528230689960665, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.6030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.5606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.5598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.521484375
Memory cached:  16.0
[I 2023-12-05 01:08:06,165] Trial 19 finished with value: 0.4323215186595917 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.8527639350132663, 'log_learning_rate_D': -4.8528230689960665, 'training_batch_size': 6, 'training_p': 3}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  15.12805461883545
Memory status after this trial: 
Memory allocated:  7.50244140625
Memory cached:  16.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.3275360010340562, 'log_learning_rate_D': -2.8033051521574, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.4267578125
Memory cached:  36.0
[I 2023-12-05 01:08:22,747] Trial 20 finished with value: 0.3645361065864563 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.3275360010340562, 'log_learning_rate_D': -2.8033051521574, 'training_batch_size': 7, 'training_p': 2}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  16.408656120300293
Memory status after this trial: 
Memory allocated:  66.63427734375
Memory cached:  80.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.2743909825177795, 'log_learning_rate_D': -2.9026832791174035, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.9296875
Memory cached:  38.0
[I 2023-12-05 01:08:39,523] Trial 21 finished with value: 0.36548128724098206 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.2743909825177795, 'log_learning_rate_D': -2.9026832791174035, 'training_batch_size': 7, 'training_p': 2}. Best is trial 12 with value: 0.3634127378463745.
Time for this trial:  16.579023838043213
Memory status after this trial: 
Memory allocated:  71.06494140625
Memory cached:  100.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.5996822243765028, 'log_learning_rate_D': -2.4280766557258797, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.6486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.5040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.5023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.15478515625
Memory cached:  36.0
[I 2023-12-05 01:08:57,103] Trial 22 finished with value: 0.3617217540740967 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -2.5996822243765028, 'log_learning_rate_D': -2.4280766557258797, 'training_batch_size': 6, 'training_p': 2}. Best is trial 22 with value: 0.3617217540740967.
res:  tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  17.40117049217224
Memory status after this trial: 
Memory allocated:  49.7939453125
Memory cached:  84.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.352483308100912, 'log_learning_rate_D': -2.4633101661252255, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.6134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  55.26904296875
Memory cached:  84.0
[I 2023-12-05 01:09:14,254] Trial 23 finished with value: 0.40563708543777466 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.352483308100912, 'log_learning_rate_D': -2.4633101661252255, 'training_batch_size': 6, 'training_p': 3}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  16.96960711479187
Memory status after this trial: 
Memory allocated:  84.45751953125
Memory cached:  110.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.58408005096954, 'log_learning_rate_D': -3.4072798023552604, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  52.63623046875
Memory cached:  84.0
[I 2023-12-05 01:09:29,981] Trial 24 finished with value: 0.36350512504577637 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.58408005096954, 'log_learning_rate_D': -3.4072798023552604, 'training_batch_size': 6, 'training_p': 2}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  15.546282768249512
Memory status after this trial: 
Memory allocated:  58.11669921875
Memory cached:  88.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.636642477330652, 'log_learning_rate_D': -3.320092035052079, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.6198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.59814453125
Memory cached:  84.0
[I 2023-12-05 01:09:44,421] Trial 25 finished with value: 0.49393153190612793 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.636642477330652, 'log_learning_rate_D': -3.320092035052079, 'training_batch_size': 8, 'training_p': 4}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  14.292747020721436
Memory status after this trial: 
Memory allocated:  58.11669921875
Memory cached:  86.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.617419483544834, 'log_learning_rate_D': -2.3060431278824147, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  51.45556640625
Memory cached:  84.0
[I 2023-12-05 01:09:59,960] Trial 26 finished with value: 0.4295986294746399 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.617419483544834, 'log_learning_rate_D': -2.3060431278824147, 'training_batch_size': 7, 'training_p': 3}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  15.355780839920044
Memory status after this trial: 
Memory allocated:  78.52880859375
Memory cached:  104.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.262696438243021, 'log_learning_rate_D': -3.165056290840367, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.33544921875
Memory cached:  84.0
[I 2023-12-05 01:10:15,483] Trial 27 finished with value: 0.36612656712532043 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -2.262696438243021, 'log_learning_rate_D': -3.165056290840367, 'training_batch_size': 9, 'training_p': 2}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  15.30112075805664
Memory status after this trial: 
Memory allocated:  78.58447265625
Memory cached:  84.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.7758992533298974, 'log_learning_rate_D': -3.5004890419819183, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  10 training error:  tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  20 training error:  tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  30 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  40 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  50 training error:  tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  60 training error:  tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  70 training error:  tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  80 training error:  tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
	 epoch  90 training error:  tensor(0.5606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.62109375
Memory cached:  84.0
[I 2023-12-05 01:10:32,190] Trial 28 finished with value: 0.4395342469215393 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.7758992533298974, 'log_learning_rate_D': -3.5004890419819183, 'training_batch_size': 6, 'training_p': 3}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  16.525867462158203
Memory status after this trial: 
Memory allocated:  73.10595703125
Memory cached:  90.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.539039839436982, 'log_learning_rate_D': -3.0414671680392225, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  10 training error:  tensor(0.7882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  20 training error:  tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  30 training error:  tensor(0.5927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  40 training error:  tensor(0.5835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  50 training error:  tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  60 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  70 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  80 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
	 epoch  90 training error:  tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  56.73046875
Memory cached:  86.0
[I 2023-12-05 01:10:48,207] Trial 29 finished with value: 0.4944038987159729 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -2.539039839436982, 'log_learning_rate_D': -3.0414671680392225, 'training_batch_size': 9, 'training_p': 4}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  15.799477100372314
Memory status after this trial: 
Memory allocated:  103.52099609375
Memory cached:  112.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.775255341568802, 'log_learning_rate_D': -2.593505605703964, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.5933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.5126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.5063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.89453125
Memory cached:  90.0
[I 2023-12-05 01:11:04,671] Trial 30 finished with value: 0.3632436692714691 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.775255341568802, 'log_learning_rate_D': -2.593505605703964, 'training_batch_size': 7, 'training_p': 2}. Best is trial 22 with value: 0.3617217540740967.
Time for this trial:  16.28205680847168
Memory status after this trial: 
Memory allocated:  135.47607421875
Memory cached:  168.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8898208445334506, 'log_learning_rate_D': -2.5678194651477093, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  10 training error:  tensor(0.5728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  20 training error:  tensor(0.5068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  30 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  40 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  50 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  60 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
	 epoch  90 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  64.8701171875
Memory cached:  90.0
[I 2023-12-05 01:11:22,379] Trial 31 finished with value: 0.36051222681999207 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8898208445334506, 'log_learning_rate_D': -2.5678194651477093, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
res:  tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  17.508824586868286
Memory status after this trial: 
Memory allocated:  85.6826171875
Memory cached:  142.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8583465989487924, 'log_learning_rate_D': -2.5527447808752024, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  10 training error:  tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  20 training error:  tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  30 training error:  tensor(0.5362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  40 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  50 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  60 training error:  tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  70 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.65771484375
Memory cached:  146.0
[I 2023-12-05 01:11:39,034] Trial 32 finished with value: 0.36609408259391785 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.8583465989487924, 'log_learning_rate_D': -2.5527447808752024, 'training_batch_size': 7, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.476840257644653
Memory status after this trial: 
Memory allocated:  171.73974609375
Memory cached:  208.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.7167045441005726, 'log_learning_rate_D': -2.064144705421224, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  98.75146484375
Memory cached:  142.0
[I 2023-12-05 01:11:55,429] Trial 33 finished with value: 0.4281575381755829 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.7167045441005726, 'log_learning_rate_D': -2.064144705421224, 'training_batch_size': 7, 'training_p': 3}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.221526861190796
Memory status after this trial: 
Memory allocated:  162.84033203125
Memory cached:  184.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.107078040059359, 'log_learning_rate_D': -2.5414668408711, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  95.2578125
Memory cached:  142.0
[I 2023-12-05 01:12:13,354] Trial 34 finished with value: 0.36564335227012634 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.107078040059359, 'log_learning_rate_D': -2.5414668408711, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  17.724892377853394
Memory status after this trial: 
Memory allocated:  138.12841796875
Memory cached:  164.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.190908637592427, 'log_learning_rate_D': -2.8980180966953015, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.470703125
Memory cached:  142.0
[I 2023-12-05 01:12:29,303] Trial 35 finished with value: 0.5877962112426758 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.190908637592427, 'log_learning_rate_D': -2.8980180966953015, 'training_batch_size': 7, 'training_p': 6}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  15.757836818695068
Memory status after this trial: 
Memory allocated:  147.31787109375
Memory cached:  182.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.4923563281375007, 'log_learning_rate_D': -1.923880363061317, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.5660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.58984375
Memory cached:  142.0
[I 2023-12-05 01:12:45,090] Trial 36 finished with value: 0.4302670955657959 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.4923563281375007, 'log_learning_rate_D': -1.923880363061317, 'training_batch_size': 8, 'training_p': 3}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  15.599605321884155
Memory status after this trial: 
Memory allocated:  122.70263671875
Memory cached:  142.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.273510943327395, 'log_learning_rate_D': -2.6179554798692273, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  89.23291015625
Memory cached:  142.0
[I 2023-12-05 01:13:02,259] Trial 37 finished with value: 0.3672637641429901 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.273510943327395, 'log_learning_rate_D': -2.6179554798692273, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.993869066238403
Memory status after this trial: 
Memory allocated:  127.97216796875
Memory cached:  146.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.128631228847433, 'log_learning_rate_D': -2.3084375932951486, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.6325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  100.46533203125
Memory cached:  142.0
[I 2023-12-05 01:13:19,818] Trial 38 finished with value: 0.4899229109287262 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.128631228847433, 'log_learning_rate_D': -2.3084375932951486, 'training_batch_size': 6, 'training_p': 4}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  17.382883548736572
Memory status after this trial: 
Memory allocated:  149.86474609375
Memory cached:  182.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.6314232909318465, 'log_learning_rate_D': -2.7425412846403794, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.7997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.7639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.6127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.6020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  92.39697265625
Memory cached:  142.0
[I 2023-12-05 01:13:35,959] Trial 39 finished with value: 0.6465020179748535 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.6314232909318465, 'log_learning_rate_D': -2.7425412846403794, 'training_batch_size': 9, 'training_p': 8}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  15.950198888778687
Memory status after this trial: 
Memory allocated:  132.84228515625
Memory cached:  144.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.8791465834799403, 'log_learning_rate_D': -2.984776789296428, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.5961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  20 training error:  tensor(0.5924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  30 training error:  tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  40 training error:  tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  50 training error:  tensor(0.5906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  60 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  70 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  80 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
	 epoch  90 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.74365234375
Memory cached:  144.0
[I 2023-12-05 01:13:52,433] Trial 40 finished with value: 0.5459024906158447 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -2.8791465834799403, 'log_learning_rate_D': -2.984776789296428, 'training_batch_size': 12, 'training_p': 5}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.26889419555664
Memory status after this trial: 
Memory allocated:  142.33154296875
Memory cached:  164.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.094249692944435, 'log_learning_rate_D': -2.4277636926729698, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  91.85498046875
Memory cached:  142.0
[I 2023-12-05 01:14:08,821] Trial 41 finished with value: 0.3674180805683136 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.094249692944435, 'log_learning_rate_D': -2.4277636926729698, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.195080518722534
Memory status after this trial: 
Memory allocated:  110.80029296875
Memory cached:  142.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.0515842914514804, 'log_learning_rate_D': -2.6977683144286444, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.5271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  10 training error:  tensor(0.5435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  94.30126953125
Memory cached:  142.0
[I 2023-12-05 01:14:25,192] Trial 42 finished with value: 0.36271458864212036 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.0515842914514804, 'log_learning_rate_D': -2.6977683144286444, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.36051222681999207.
Time for this trial:  16.19218111038208
Memory status after this trial: 
Memory allocated:  122.25341796875
Memory cached:  144.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.863655555781871, 'log_learning_rate_D': -2.618200359711879, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  10 training error:  tensor(1.0773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  20 training error:  tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  30 training error:  tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  40 training error:  tensor(0.7575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  50 training error:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  60 training error:  tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  70 training error:  tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  80 training error:  tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  99.12353515625
Memory cached:  142.0
[I 2023-12-05 01:14:41,594] Trial 43 finished with value: 0.3478904664516449 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.863655555781871, 'log_learning_rate_D': -2.618200359711879, 'training_batch_size': 7, 'training_p': 2}. Best is trial 43 with value: 0.3478904664516449.
res:  tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  16.19646716117859
Memory status after this trial: 
Memory allocated:  51.701171875
Memory cached:  122.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.822883775286725, 'log_learning_rate_D': -2.659940999552448, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  10 training error:  tensor(11.2453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.8720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.8707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.8487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.7106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.6710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  62.05029296875
Memory cached:  122.0
[I 2023-12-05 01:14:58,013] Trial 44 finished with value: 0.492025226354599 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -1.822883775286725, 'log_learning_rate_D': -2.659940999552448, 'training_batch_size': 7, 'training_p': 2}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  16.20016074180603
Memory status after this trial: 
Memory allocated:  107.67822265625
Memory cached:  126.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.4246535089127006, 'log_learning_rate_D': -1.8442780597936221, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  10 training error:  tensor(117.3975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  20 training error:  tensor(13.8982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  30 training error:  tensor(20.7148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.7903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.7826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.9653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.7176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  68.037109375
Memory cached:  122.0
[I 2023-12-05 01:15:14,333] Trial 45 finished with value: 0.48261138796806335 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.4246535089127006, 'log_learning_rate_D': -1.8442780597936221, 'training_batch_size': 11, 'training_p': 3}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  16.14432430267334
Memory status after this trial: 
Memory allocated:  108.28369140625
Memory cached:  142.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.030689584750168, 'log_learning_rate_D': -2.32025390160888, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  10 training error:  tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  67.2939453125
Memory cached:  122.0
[I 2023-12-05 01:15:30,084] Trial 46 finished with value: 0.36497703194618225 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.030689584750168, 'log_learning_rate_D': -2.32025390160888, 'training_batch_size': 8, 'training_p': 2}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  15.556941509246826
Memory status after this trial: 
Memory allocated:  83.89599609375
Memory cached:  124.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.77550955751573, 'log_learning_rate_D': -2.6927361038047213, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  10 training error:  tensor(23.1945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  20 training error:  tensor(4.8364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  30 training error:  tensor(18.4021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  40 training error:  tensor(6.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  50 training error:  tensor(1.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  60 training error:  tensor(0.6251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  70 training error:  tensor(0.5605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  80 training error:  tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
	 epoch  90 training error:  tensor(0.5605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  69.08984375
Memory cached:  130.0
[I 2023-12-05 01:15:46,487] Trial 47 finished with value: 0.43909236788749695 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -1.77550955751573, 'log_learning_rate_D': -2.6927361038047213, 'training_batch_size': 7, 'training_p': 3}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  16.217305183410645
Memory status after this trial: 
Memory allocated:  135.87548828125
Memory cached:  150.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.1552441932127895, 'log_learning_rate_D': -2.1268005457464207, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  10 training error:  tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  40 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  50 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  60 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  70 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  80 training error:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
	 epoch  90 training error:  tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  63.70166015625
Memory cached:  122.0
[I 2023-12-05 01:16:02,076] Trial 48 finished with value: 0.36349159479141235 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.1552441932127895, 'log_learning_rate_D': -2.1268005457464207, 'training_batch_size': 7, 'training_p': 2}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  15.400986909866333
Memory status after this trial: 
Memory allocated:  95.52294921875
Memory cached:  126.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.56242348528659, 'log_learning_rate_D': -2.910181377413245, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  10 training error:  tensor(19.7464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  20 training error:  tensor(0.8642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  30 training error:  tensor(0.8996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  40 training error:  tensor(2.0194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  50 training error:  tensor(2.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  60 training error:  tensor(1.3129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  70 training error:  tensor(1.8030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  80 training error:  tensor(1.2948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
	 epoch  90 training error:  tensor(1.8796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  66.34326171875
Memory cached:  122.0
[I 2023-12-05 01:16:19,840] Trial 49 finished with value: 1.8298462629318237 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -1.56242348528659, 'log_learning_rate_D': -2.910181377413245, 'training_batch_size': 6, 'training_p': 5}. Best is trial 43 with value: 0.3478904664516449.
Time for this trial:  17.56693983078003
Memory status after this trial: 
Memory allocated:  121.60107421875
Memory cached:  142.0
