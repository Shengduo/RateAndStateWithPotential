/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-10-30 11:13:20,468] A new study created in memory with name: no-name-fdd5448e-f08c-4b24-ab16-9dd653e1f4b6
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.2125791326904425, 'log_learning_rate_D': -2.3925180659178764, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7412109375
Memory cached:  8.0
[W 2023-10-30 11:13:28,516] Trial 0 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.2125791326904425, 'log_learning_rate_D': -2.3925180659178764, 'training_batch_size': 11, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:13:28,517] Trial 0 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.9312193393707275
Memory status after this trial: 
Memory allocated:  140.8505859375
Memory cached:  144.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.779113037714121, 'log_learning_rate_D': -1.7970785513101841, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6474609375
Memory cached:  40.0
[W 2023-10-30 11:13:35,278] Trial 1 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.779113037714121, 'log_learning_rate_D': -1.7970785513101841, 'training_batch_size': 7, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:13:35,279] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.625797510147095
Memory status after this trial: 
Memory allocated:  250.52685546875
Memory cached:  274.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.1171002632968126, 'log_learning_rate_D': -2.7095132871797496, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.2099609375
Memory cached:  16.0
[W 2023-10-30 11:13:38,532] Trial 2 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.1171002632968126, 'log_learning_rate_D': -2.7095132871797496, 'training_batch_size': 7, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:13:38,533] Trial 2 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.122781276702881
Memory status after this trial: 
Memory allocated:  114.3828125
Memory cached:  120.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.7828042990407496, 'log_learning_rate_D': -3.393390085538774, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.9946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.1689453125
Memory cached:  34.0
[I 2023-10-30 11:15:39,504] Trial 3 finished with value: 0.9994314312934875 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.7828042990407496, 'log_learning_rate_D': -3.393390085538774, 'training_batch_size': 7, 'training_p': 5}. Best is trial 3 with value: 0.9994314312934875.
Time for this trial:  120.85160565376282
Memory status after this trial: 
Memory allocated:  101.75
Memory cached:  120.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.402700402459821, 'log_learning_rate_D': -2.0694750936501056, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.5562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5986328125
Memory cached:  16.0
[I 2023-10-30 11:17:31,680] Trial 4 finished with value: 0.23676200211048126 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.402700402459821, 'log_learning_rate_D': -2.0694750936501056, 'training_batch_size': 11, 'training_p': 6}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  112.03994369506836
Memory status after this trial: 
Memory allocated:  98.669921875
Memory cached:  102.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.1544558178872864, 'log_learning_rate_D': -3.681086618568289, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.7108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5908203125
Memory cached:  12.0
[I 2023-10-30 11:21:15,229] Trial 5 finished with value: 0.2370581179857254 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.1544558178872864, 'log_learning_rate_D': -3.681086618568289, 'training_batch_size': 6, 'training_p': 5}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  223.39815759658813
Memory status after this trial: 
Memory allocated:  58.91064453125
Memory cached:  62.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.949363880704601, 'log_learning_rate_D': -2.187535428458802, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.9588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.9485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.7971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  50 training error:  tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.9794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.3994140625
Memory cached:  42.0
[I 2023-10-30 11:23:59,189] Trial 6 finished with value: 0.4526216685771942 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.949363880704601, 'log_learning_rate_D': -2.187535428458802, 'training_batch_size': 10, 'training_p': 8}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  163.83169722557068
Memory status after this trial: 
Memory allocated:  263.9169921875
Memory cached:  280.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0462673013477777, 'log_learning_rate_D': -1.380113500663401, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.9902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.8679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.6008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7314453125
Memory cached:  36.0
[I 2023-10-30 11:26:16,177] Trial 7 finished with value: 0.2398054599761963 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0462673013477777, 'log_learning_rate_D': -1.380113500663401, 'training_batch_size': 12, 'training_p': 5}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  136.85738515853882
Memory status after this trial: 
Memory allocated:  118.19384765625
Memory cached:  136.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.718664136012136, 'log_learning_rate_D': -2.263475954946923, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.8790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.7365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6396484375
Memory cached:  20.0
[I 2023-10-30 11:28:11,655] Trial 8 finished with value: 0.2378465235233307 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.718664136012136, 'log_learning_rate_D': -2.263475954946923, 'training_batch_size': 8, 'training_p': 7}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  115.35290718078613
Memory status after this trial: 
Memory allocated:  121.33056640625
Memory cached:  126.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -1.6382041201728295, 'log_learning_rate_D': -2.991081553194349, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7197265625
Memory cached:  16.0
[I 2023-10-30 11:31:49,893] Trial 9 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -1.6382041201728295, 'log_learning_rate_D': -2.991081553194349, 'training_batch_size': 6, 'training_p': 3}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  218.09450340270996
Memory status after this trial: 
Memory allocated:  150.7822265625
Memory cached:  156.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.8520645611227655, 'log_learning_rate_D': -1.0997442881493882, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.3818359375
Memory cached:  8.0
[W 2023-10-30 11:31:58,593] Trial 10 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.8520645611227655, 'log_learning_rate_D': -1.0997442881493882, 'training_batch_size': 8, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:31:58,595] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.549441576004028
Memory status after this trial: 
Memory allocated:  51.19677734375
Memory cached:  52.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.152730099252281, 'log_learning_rate_D': -3.507519073072814, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.8547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.6627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6318359375
Memory cached:  10.0
[I 2023-10-30 11:33:43,032] Trial 11 finished with value: 0.23731422424316406 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.152730099252281, 'log_learning_rate_D': -3.507519073072814, 'training_batch_size': 9, 'training_p': 8}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  104.31000232696533
Memory status after this trial: 
Memory allocated:  91.453125
Memory cached:  94.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.156457998794604, 'log_learning_rate_D': -4.027636052606139, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8857421875
Memory cached:  14.0
[I 2023-10-30 11:35:52,507] Trial 12 finished with value: 0.9998384714126587 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.156457998794604, 'log_learning_rate_D': -4.027636052606139, 'training_batch_size': 11, 'training_p': 6}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  129.35760617256165
Memory status after this trial: 
Memory allocated:  65.42236328125
Memory cached:  68.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.65599449575112, 'log_learning_rate_D': -3.7182793424288363, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.5448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.6611328125
Memory cached:  10.0
[I 2023-10-30 11:37:36,447] Trial 13 finished with value: 0.23743663728237152 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.65599449575112, 'log_learning_rate_D': -3.7182793424288363, 'training_batch_size': 12, 'training_p': 3}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  103.79883146286011
Memory status after this trial: 
Memory allocated:  40.30322265625
Memory cached:  42.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.802897719564425, 'log_learning_rate_D': -4.976147610766253, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  26.0
	 epoch  10 training error:  tensor(1.0008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  20 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.3837890625
Memory cached:  34.0
[I 2023-10-30 11:39:32,442] Trial 14 finished with value: 0.9967118501663208 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.802897719564425, 'log_learning_rate_D': -4.976147610766253, 'training_batch_size': 10, 'training_p': 2}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  115.79367232322693
Memory status after this trial: 
Memory allocated:  127.0068359375
Memory cached:  140.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.567038877405748, 'log_learning_rate_D': -1.335991070122561, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3466796875
Memory cached:  18.0
[W 2023-10-30 11:39:39,754] Trial 15 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.567038877405748, 'log_learning_rate_D': -1.335991070122561, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:39:39,755] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.119872808456421
Memory status after this trial: 
Memory allocated:  100.46142578125
Memory cached:  104.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.55085731010885, 'log_learning_rate_D': -1.0505657308390064, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3466796875
Memory cached:  10.0
[W 2023-10-30 11:39:44,983] Trial 16 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.55085731010885, 'log_learning_rate_D': -1.0505657308390064, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:39:44,984] Trial 16 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.016676187515259
Memory status after this trial: 
Memory allocated:  100.46142578125
Memory cached:  104.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5824139540198208, 'log_learning_rate_D': -1.3391837649612115, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3466796875
Memory cached:  14.0
[W 2023-10-30 11:39:52,245] Trial 17 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5824139540198208, 'log_learning_rate_D': -1.3391837649612115, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:39:52,246] Trial 17 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.054548501968384
Memory status after this trial: 
Memory allocated:  100.46142578125
Memory cached:  104.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5584965346093815, 'log_learning_rate_D': -1.0538887514615034, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3623046875
Memory cached:  16.0
[W 2023-10-30 11:39:57,501] Trial 18 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5584965346093815, 'log_learning_rate_D': -1.0538887514615034, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:39:57,502] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.04845929145813
Memory status after this trial: 
Memory allocated:  128.31298828125
Memory cached:  132.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.6007234218806996, 'log_learning_rate_D': -1.0235567491698836, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2138671875
Memory cached:  10.0
[W 2023-10-30 11:40:02,631] Trial 19 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.6007234218806996, 'log_learning_rate_D': -1.0235567491698836, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:40:02,632] Trial 19 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.919927597045898
Memory status after this trial: 
Memory allocated:  72.82470703125
Memory cached:  76.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5378161085047606, 'log_learning_rate_D': -1.374060918433734, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3466796875
Memory cached:  12.0
[W 2023-10-30 11:40:07,776] Trial 20 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.5378161085047606, 'log_learning_rate_D': -1.374060918433734, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:40:07,776] Trial 20 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.9438886642456055
Memory status after this trial: 
Memory allocated:  100.46142578125
Memory cached:  104.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.559435884159847, 'log_learning_rate_D': -1.1580488839457388, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3466796875
Memory cached:  10.0
[W 2023-10-30 11:40:12,955] Trial 21 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.559435884159847, 'log_learning_rate_D': -1.1580488839457388, 'training_batch_size': 6, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:40:12,956] Trial 21 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.968547821044922
Memory status after this trial: 
Memory allocated:  100.46142578125
Memory cached:  104.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.4642621603136483, 'log_learning_rate_D': -1.2771771350711836, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.7304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3857421875
Memory cached:  18.0
[I 2023-10-30 11:42:17,466] Trial 22 finished with value: 0.23717021942138672 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -3.4642621603136483, 'log_learning_rate_D': -1.2771771350711836, 'training_batch_size': 8, 'training_p': 6}. Best is trial 4 with value: 0.23676200211048126.
Time for this trial:  124.31325554847717
Memory status after this trial: 
Memory allocated:  128.31201171875
Memory cached:  132.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3496045949355104, 'log_learning_rate_D': -2.604975043305969, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0693359375
Memory cached:  8.0
[I 2023-10-30 11:45:29,833] Trial 23 finished with value: 0.23587961494922638 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3496045949355104, 'log_learning_rate_D': -2.604975043305969, 'training_batch_size': 6, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  192.16214418411255
Memory status after this trial: 
Memory allocated:  43.65771484375
Memory cached:  46.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.443205605776629, 'log_learning_rate_D': -2.215732198915403, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5712890625
Memory cached:  10.0
[I 2023-10-30 11:47:19,323] Trial 24 finished with value: 0.5111364722251892 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.443205605776629, 'log_learning_rate_D': -2.215732198915403, 'training_batch_size': 10, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  109.3019380569458
Memory status after this trial: 
Memory allocated:  63.109375
Memory cached:  66.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0151372583598959, 'log_learning_rate_D': -2.6267622960215165, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  12.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  12.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  12.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  12.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  12.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  14.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8154296875
Memory cached:  14.0
[I 2023-10-30 11:48:57,660] Trial 25 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0151372583598959, 'log_learning_rate_D': -2.6267622960215165, 'training_batch_size': 8, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  98.16859173774719
Memory status after this trial: 
Memory allocated:  48.59375
Memory cached:  50.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5233041658565565, 'log_learning_rate_D': -1.9449097185301722, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.9619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.6261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7587890625
Memory cached:  10.0
[I 2023-10-30 11:50:52,551] Trial 26 finished with value: 0.2508906424045563 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5233041658565565, 'log_learning_rate_D': -1.9449097185301722, 'training_batch_size': 11, 'training_p': 6}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  114.70858693122864
Memory status after this trial: 
Memory allocated:  52.06884765625
Memory cached:  54.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.4168657366560087, 'log_learning_rate_D': -1.594590253275734, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  20.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  20.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  20.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2880859375
Memory cached:  18.0
[I 2023-10-30 11:52:49,733] Trial 27 finished with value: 0.9999775886535645 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.4168657366560087, 'log_learning_rate_D': -1.594590253275734, 'training_batch_size': 7, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  116.963223695755
Memory status after this trial: 
Memory allocated:  145.89697265625
Memory cached:  152.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.034393510865348, 'log_learning_rate_D': -1.0658247484344505, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  8.0
[W 2023-10-30 11:52:55,732] Trial 28 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.034393510865348, 'log_learning_rate_D': -1.0658247484344505, 'training_batch_size': 9, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:52:55,733] Trial 28 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.780667781829834
Memory status after this trial: 
Memory allocated:  83.2890625
Memory cached:  86.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.027814727696956, 'log_learning_rate_D': -2.846353782488873, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.6387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.7457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.6019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.7140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.7099609375
Memory cached:  14.0
[I 2023-10-30 11:54:37,977] Trial 29 finished with value: 0.9328266382217407 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.027814727696956, 'log_learning_rate_D': -2.846353782488873, 'training_batch_size': 9, 'training_p': 7}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  102.06981086730957
Memory status after this trial: 
Memory allocated:  83.2890625
Memory cached:  86.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.724857774367313, 'log_learning_rate_D': -1.0422327592459104, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  12.0
[W 2023-10-30 11:54:41,310] Trial 30 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.724857774367313, 'log_learning_rate_D': -1.0422327592459104, 'training_batch_size': 11, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:54:41,310] Trial 30 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.1286838054656982
Memory status after this trial: 
Memory allocated:  122.3447265625
Memory cached:  128.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.33981768874313, 'log_learning_rate_D': -1.1206343825426819, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3427734375
Memory cached:  18.0
[I 2023-10-30 11:56:43,900] Trial 31 finished with value: 0.23874841630458832 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.33981768874313, 'log_learning_rate_D': -1.1206343825426819, 'training_batch_size': 11, 'training_p': 2}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  122.40077614784241
Memory status after this trial: 
Memory allocated:  122.3447265625
Memory cached:  126.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.691153892558907, 'log_learning_rate_D': -1.7627699392956118, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4091796875
Memory cached:  10.0
[I 2023-10-30 11:58:22,227] Trial 32 finished with value: 0.23718658089637756 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.691153892558907, 'log_learning_rate_D': -1.7627699392956118, 'training_batch_size': 9, 'training_p': 3}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  98.14797782897949
Memory status after this trial: 
Memory allocated:  38.35888671875
Memory cached:  40.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.438574597045833, 'log_learning_rate_D': -1.766747108119937, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  12.0
[W 2023-10-30 11:58:32,021] Trial 33 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -4.438574597045833, 'log_learning_rate_D': -1.766747108119937, 'training_batch_size': 7, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-10-30 11:58:32,022] Trial 33 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  9.582477807998657
Memory status after this trial: 
Memory allocated:  106.97509765625
Memory cached:  110.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.041843134730269, 'log_learning_rate_D': -2.4921279631730457, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.5422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1533203125
Memory cached:  16.0
[I 2023-10-30 12:00:39,547] Trial 34 finished with value: 0.23687076568603516 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.041843134730269, 'log_learning_rate_D': -2.4921279631730457, 'training_batch_size': 7, 'training_p': 7}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  127.3162133693695
Memory status after this trial: 
Memory allocated:  106.97509765625
Memory cached:  110.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.096768822776765, 'log_learning_rate_D': -2.4307107615551184, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.9033203125
Memory cached:  14.0
[I 2023-10-30 12:02:47,659] Trial 35 finished with value: 0.23796764016151428 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.096768822776765, 'log_learning_rate_D': -2.4307107615551184, 'training_batch_size': 7, 'training_p': 7}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  127.90842914581299
Memory status after this trial: 
Memory allocated:  106.17333984375
Memory cached:  108.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.844041288971457, 'log_learning_rate_D': -2.6566002553618158, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7412109375
Memory cached:  8.0
[I 2023-10-30 12:06:10,956] Trial 36 finished with value: 0.23813901841640472 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.844041288971457, 'log_learning_rate_D': -2.6566002553618158, 'training_batch_size': 6, 'training_p': 6}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  203.09575629234314
Memory status after this trial: 
Memory allocated:  40.99853515625
Memory cached:  42.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.9322976471353435, 'log_learning_rate_D': -1.9065075226678045, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4638671875
Memory cached:  12.0
[W 2023-10-30 12:06:17,973] Trial 37 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -1.9322976471353435, 'log_learning_rate_D': -1.9065075226678045, 'training_batch_size': 7, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:06:17,974] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.827041149139404
Memory status after this trial: 
Memory allocated:  99.2392578125
Memory cached:  102.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.0261275456220216, 'log_learning_rate_D': -1.872509569712352, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7099609375
Memory cached:  14.0
[I 2023-10-30 12:08:19,952] Trial 38 finished with value: 0.237111434340477 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.0261275456220216, 'log_learning_rate_D': -1.872509569712352, 'training_batch_size': 7, 'training_p': 7}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  121.77085757255554
Memory status after this trial: 
Memory allocated:  88.7109375
Memory cached:  92.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.545481979266034, 'log_learning_rate_D': -2.6392331714804302, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5439453125
Memory cached:  8.0
[I 2023-10-30 12:11:32,718] Trial 39 finished with value: 0.23634877800941467 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.545481979266034, 'log_learning_rate_D': -2.6392331714804302, 'training_batch_size': 6, 'training_p': 5}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  192.54340481758118
Memory status after this trial: 
Memory allocated:  62.4716796875
Memory cached:  64.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.202384887398434, 'log_learning_rate_D': -3.153759016201313, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7333984375
Memory cached:  6.0
[I 2023-10-30 12:14:44,357] Trial 40 finished with value: 0.9976921081542969 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.202384887398434, 'log_learning_rate_D': -3.153759016201313, 'training_batch_size': 6, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  191.4321870803833
Memory status after this trial: 
Memory allocated:  53.60693359375
Memory cached:  56.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5007558893618382, 'log_learning_rate_D': -2.0455505133826324, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5810546875
Memory cached:  16.0
[I 2023-10-30 12:18:03,523] Trial 41 finished with value: 0.23588335514068604 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.5007558893618382, 'log_learning_rate_D': -2.0455505133826324, 'training_batch_size': 6, 'training_p': 5}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  198.9576120376587
Memory status after this trial: 
Memory allocated:  116.1572265625
Memory cached:  120.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5086600871071805, 'log_learning_rate_D': -2.7835321345806623, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.8232421875
Memory cached:  14.0
[I 2023-10-30 12:21:07,024] Trial 42 finished with value: 0.24034464359283447 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.5086600871071805, 'log_learning_rate_D': -2.7835321345806623, 'training_batch_size': 6, 'training_p': 5}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  183.29986023902893
Memory status after this trial: 
Memory allocated:  103.3876953125
Memory cached:  106.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.746236464604485, 'log_learning_rate_D': -2.4720449975022887, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9169921875
Memory cached:  8.0
[I 2023-10-30 12:24:19,726] Trial 43 finished with value: 0.23728711903095245 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.746236464604485, 'log_learning_rate_D': -2.4720449975022887, 'training_batch_size': 6, 'training_p': 4}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  192.5025463104248
Memory status after this trial: 
Memory allocated:  52.02392578125
Memory cached:  54.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.918299085772993, 'log_learning_rate_D': -1.59548320314698, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  14.0
[W 2023-10-30 12:24:28,686] Trial 44 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.918299085772993, 'log_learning_rate_D': -1.59548320314698, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:24:28,688] Trial 44 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.738207340240479
Memory status after this trial: 
Memory allocated:  143.7001953125
Memory cached:  148.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3181593286897235, 'log_learning_rate_D': -1.6078883879700725, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  14.0
[W 2023-10-30 12:24:33,654] Trial 45 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3181593286897235, 'log_learning_rate_D': -1.6078883879700725, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:24:33,655] Trial 45 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.750628232955933
Memory status after this trial: 
Memory allocated:  143.7001953125
Memory cached:  148.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3627772938338762, 'log_learning_rate_D': -1.6067037925651482, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  16.0
[W 2023-10-30 12:24:37,265] Trial 46 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.3627772938338762, 'log_learning_rate_D': -1.6067037925651482, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:24:37,266] Trial 46 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.4048264026641846
Memory status after this trial: 
Memory allocated:  143.7001953125
Memory cached:  148.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.5455992493225708, 'log_learning_rate_D': -1.6201878623752157, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  12.0
[W 2023-10-30 12:24:43,590] Trial 47 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.5455992493225708, 'log_learning_rate_D': -1.6201878623752157, 'training_batch_size': 8, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:24:43,591] Trial 47 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.078868389129639
Memory status after this trial: 
Memory allocated:  143.7001953125
Memory cached:  148.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.364740869023983, 'log_learning_rate_D': -1.624534681078802, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.4136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6376953125
Memory cached:  20.0
[I 2023-10-30 12:26:57,038] Trial 48 finished with value: 0.23763418197631836 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -2.364740869023983, 'log_learning_rate_D': -1.624534681078802, 'training_batch_size': 8, 'training_p': 5}. Best is trial 23 with value: 0.23587961494922638.
Time for this trial:  133.23851776123047
Memory status after this trial: 
Memory allocated:  143.7001953125
Memory cached:  148.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.022159216819161, 'log_learning_rate_D': -2.0103276218335866, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2333984375
Memory cached:  12.0
[I 2023-10-30 12:28:37,989] Trial 49 finished with value: 0.23797635734081268 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.022159216819161, 'log_learning_rate_D': -2.0103276218335866, 'training_batch_size': 7, 'training_p': 3}. Best is trial 23 with value: 0.23587961494922638.
[I 2023-10-30 12:28:38,004] A new study created in memory with name: no-name-54b71fa6-7c74-4549-b3ee-72798f3ce27d
Time for this trial:  100.74871349334717
Memory status after this trial: 
Memory allocated:  79.5244140625
Memory cached:  82.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.24381881681787, 'log_learning_rate_D': -1.5677134208812955, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  40.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.435546875
Memory cached:  42.0
[W 2023-10-30 12:30:10,067] Trial 0 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.24381881681787, 'log_learning_rate_D': -1.5677134208812955, 'training_batch_size': 7, 'training_p': 6} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:30:10,068] Trial 0 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  91.94770765304565
Memory status after this trial: 
Memory allocated:  202.30078125
Memory cached:  226.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.6441683736599764, 'log_learning_rate_D': -1.1177809948333555, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.126953125
Memory cached:  12.0
[W 2023-10-30 12:30:14,543] Trial 1 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.6441683736599764, 'log_learning_rate_D': -1.1177809948333555, 'training_batch_size': 11, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:30:14,544] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  4.352215766906738
Memory status after this trial: 
Memory allocated:  109.01318359375
Memory cached:  112.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.6798286543699503, 'log_learning_rate_D': -3.873802556447921, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9296, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  12.0
[I 2023-10-30 12:31:54,127] Trial 2 finished with value: 0.23701313138008118 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.6798286543699503, 'log_learning_rate_D': -3.873802556447921, 'training_batch_size': 9, 'training_p': 7}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  99.42461800575256
Memory status after this trial: 
Memory allocated:  69.421875
Memory cached:  72.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.4980857754374695, 'log_learning_rate_D': -3.3582654744184426, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.466796875
Memory cached:  16.0
[W 2023-10-30 12:32:00,153] Trial 3 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.4980857754374695, 'log_learning_rate_D': -3.3582654744184426, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:32:00,153] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.895407199859619
Memory status after this trial: 
Memory allocated:  123.5205078125
Memory cached:  128.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.031605687569, 'log_learning_rate_D': -2.5755637269755063, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.8834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.58203125
Memory cached:  8.0
[I 2023-10-30 12:33:27,827] Trial 4 finished with value: 0.23745988309383392 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.031605687569, 'log_learning_rate_D': -2.5755637269755063, 'training_batch_size': 8, 'training_p': 5}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  87.54407382011414
Memory status after this trial: 
Memory allocated:  36.09423828125
Memory cached:  38.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.4898260410328765, 'log_learning_rate_D': -1.6678636972876006, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.6708984375
Memory cached:  34.0
[W 2023-10-30 12:33:50,214] Trial 5 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.4898260410328765, 'log_learning_rate_D': -1.6678636972876006, 'training_batch_size': 6, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:33:50,215] Trial 5 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  22.247183084487915
Memory status after this trial: 
Memory allocated:  214.44873046875
Memory cached:  228.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -4.210416327851867, 'log_learning_rate_D': -1.1674547908968642, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.765625
Memory cached:  28.0
[W 2023-10-30 12:33:58,482] Trial 6 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -4.210416327851867, 'log_learning_rate_D': -1.1674547908968642, 'training_batch_size': 9, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:33:58,483] Trial 6 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.136264324188232
Memory status after this trial: 
Memory allocated:  233.5732421875
Memory cached:  248.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.330388220769874, 'log_learning_rate_D': -2.708980308532384, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.166015625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  26.166015625
Memory cached:  36.0
[W 2023-10-30 12:34:18,769] Trial 7 failed with parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.330388220769874, 'log_learning_rate_D': -2.708980308532384, 'training_batch_size': 11, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:34:18,770] Trial 7 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  20.151775121688843
Memory status after this trial: 
Memory allocated:  231.3818359375
Memory cached:  250.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.983904841326805, 'log_learning_rate_D': -1.2467938510635617, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.99609375
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.99609375
Memory cached:  38.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.99609375
Memory cached:  38.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.99609375
Memory cached:  38.0
[W 2023-10-30 12:35:06,393] Trial 8 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -4.983904841326805, 'log_learning_rate_D': -1.2467938510635617, 'training_batch_size': 11, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:35:06,394] Trial 8 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  47.48813199996948
Memory status after this trial: 
Memory allocated:  189.884765625
Memory cached:  210.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.028822594991846, 'log_learning_rate_D': -4.295368292627959, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  12.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1640625
Memory cached:  14.0
[I 2023-10-30 12:37:19,362] Trial 9 finished with value: 0.9373350143432617 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.028822594991846, 'log_learning_rate_D': -4.295368292627959, 'training_batch_size': 7, 'training_p': 6}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  132.81295824050903
Memory status after this trial: 
Memory allocated:  87.1533203125
Memory cached:  90.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5676740157605047, 'log_learning_rate_D': -3.679095285691676, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.9952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.9824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.9356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.62109375
Memory cached:  38.0
[I 2023-10-30 12:39:30,231] Trial 10 finished with value: 0.23763404786586761 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.5676740157605047, 'log_learning_rate_D': -3.679095285691676, 'training_batch_size': 9, 'training_p': 7}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  130.73562693595886
Memory status after this trial: 
Memory allocated:  203.14404296875
Memory cached:  220.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.671379103582074, 'log_learning_rate_D': -2.3547043003310644, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1796875
Memory cached:  10.0
[I 2023-10-30 12:41:24,327] Trial 11 finished with value: 0.9825448989868164 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.671379103582074, 'log_learning_rate_D': -2.3547043003310644, 'training_batch_size': 11, 'training_p': 5}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  113.96025037765503
Memory status after this trial: 
Memory allocated:  125.826171875
Memory cached:  128.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.8985518421932417, 'log_learning_rate_D': -2.772217345733109, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0859375
Memory cached:  10.0
[I 2023-10-30 12:42:55,740] Trial 12 finished with value: 0.23778486251831055 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.8985518421932417, 'log_learning_rate_D': -2.772217345733109, 'training_batch_size': 9, 'training_p': 3}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  91.28124141693115
Memory status after this trial: 
Memory allocated:  62.4013671875
Memory cached:  64.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.2657541302560662, 'log_learning_rate_D': -4.646431045752035, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.103515625
Memory cached:  8.0
[I 2023-10-30 12:44:26,478] Trial 13 finished with value: 0.23724280297756195 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -1.2657541302560662, 'log_learning_rate_D': -4.646431045752035, 'training_batch_size': 12, 'training_p': 3}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  90.60984778404236
Memory status after this trial: 
Memory allocated:  61.453125
Memory cached:  64.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.557196458945236, 'log_learning_rate_D': -4.476766812220092, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.7781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.81640625
Memory cached:  12.0
[I 2023-10-30 12:46:41,754] Trial 14 finished with value: 0.23854894936084747 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.557196458945236, 'log_learning_rate_D': -4.476766812220092, 'training_batch_size': 12, 'training_p': 6}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  135.16471982002258
Memory status after this trial: 
Memory allocated:  159.6279296875
Memory cached:  164.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.4750400687046765, 'log_learning_rate_D': -3.1864500931665765, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9140625
Memory cached:  8.0
[W 2023-10-30 12:47:53,308] Trial 15 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.4750400687046765, 'log_learning_rate_D': -3.1864500931665765, 'training_batch_size': 9, 'training_p': 3} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:47:53,310] Trial 15 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  71.42060661315918
Memory status after this trial: 
Memory allocated:  44.9658203125
Memory cached:  46.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.7794685417417653, 'log_learning_rate_D': -4.815612228367161, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.9874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.9211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8134765625
Memory cached:  14.0
[I 2023-10-30 12:51:25,248] Trial 16 finished with value: 0.2370252162218094 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.7794685417417653, 'log_learning_rate_D': -4.815612228367161, 'training_batch_size': 6, 'training_p': 6}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  211.78394985198975
Memory status after this trial: 
Memory allocated:  96.08984375
Memory cached:  98.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.650208786578476, 'log_learning_rate_D': -1.4578154303883566, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  14.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.232421875
Memory cached:  16.0
[I 2023-10-30 12:53:29,639] Trial 17 finished with value: 0.9999958276748657 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -4.650208786578476, 'log_learning_rate_D': -1.4578154303883566, 'training_batch_size': 12, 'training_p': 3}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  124.2444441318512
Memory status after this trial: 
Memory allocated:  140.447265625
Memory cached:  144.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4403421552868165, 'log_learning_rate_D': -3.5367247165453835, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.705078125
Memory cached:  32.0
[W 2023-10-30 12:53:38,434] Trial 18 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.4403421552868165, 'log_learning_rate_D': -3.5367247165453835, 'training_batch_size': 10, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-10-30 12:53:38,435] Trial 18 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  8.603105545043945
Memory status after this trial: 
Memory allocated:  134.35498046875
Memory cached:  152.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.5209114372772374, 'log_learning_rate_D': -3.670269056519852, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.9622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  30 training error:  tensor(60.4502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  40 training error:  tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.8556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  70 training error:  tensor(1.0170, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.9947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.41015625
Memory cached:  40.0
[I 2023-10-30 12:55:46,718] Trial 19 finished with value: 0.9754014015197754 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.5209114372772374, 'log_learning_rate_D': -3.670269056519852, 'training_batch_size': 10, 'training_p': 8}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  128.0991826057434
Memory status after this trial: 
Memory allocated:  121.6875
Memory cached:  140.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.0936411980165595, 'log_learning_rate_D': -4.886494141600042, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5478515625
Memory cached:  10.0
[I 2023-10-30 12:58:56,935] Trial 20 finished with value: 0.9941161274909973 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.0936411980165595, 'log_learning_rate_D': -4.886494141600042, 'training_batch_size': 6, 'training_p': 8}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  190.00642108917236
Memory status after this trial: 
Memory allocated:  38.3427734375
Memory cached:  40.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.9643781402128297, 'log_learning_rate_D': -3.925075372539056, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5166015625
Memory cached:  16.0
[I 2023-10-30 13:02:27,379] Trial 21 finished with value: 0.24004928767681122 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.9643781402128297, 'log_learning_rate_D': -3.925075372539056, 'training_batch_size': 6, 'training_p': 6}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  210.25752568244934
Memory status after this trial: 
Memory allocated:  86.95068359375
Memory cached:  90.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.844753443459315, 'log_learning_rate_D': -4.964877705915224, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.84375
Memory cached:  10.0
[I 2023-10-30 13:04:21,074] Trial 22 finished with value: 0.998727023601532 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.844753443459315, 'log_learning_rate_D': -4.964877705915224, 'training_batch_size': 8, 'training_p': 7}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  113.5069968700409
Memory status after this trial: 
Memory allocated:  87.103515625
Memory cached:  90.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.879974542288177, 'log_learning_rate_D': -3.333913163035886, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.7256, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.947265625
Memory cached:  10.0
[I 2023-10-30 13:06:09,266] Trial 23 finished with value: 0.2752928137779236 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -3.879974542288177, 'log_learning_rate_D': -3.333913163035886, 'training_batch_size': 7, 'training_p': 4}. Best is trial 2 with value: 0.23701313138008118.
Time for this trial:  107.99870133399963
Memory status after this trial: 
Memory allocated:  73.83349609375
Memory cached:  76.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.155262575117784, 'log_learning_rate_D': -4.239541518692733, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.65625
Memory cached:  10.0
[I 2023-10-30 13:07:58,546] Trial 24 finished with value: 0.2367389053106308 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.155262575117784, 'log_learning_rate_D': -4.239541518692733, 'training_batch_size': 10, 'training_p': 7}. Best is trial 24 with value: 0.2367389053106308.
Time for this trial:  109.09648871421814
Memory status after this trial: 
Memory allocated:  79.15283203125
Memory cached:  82.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0154758087914293, 'log_learning_rate_D': -4.099753952758496, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.51171875
Memory cached:  38.0
[I 2023-10-30 13:10:18,486] Trial 25 finished with value: 0.2371620237827301 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0154758087914293, 'log_learning_rate_D': -4.099753952758496, 'training_batch_size': 10, 'training_p': 7}. Best is trial 24 with value: 0.2367389053106308.
Time for this trial:  139.75297284126282
Memory status after this trial: 
Memory allocated:  192.47802734375
Memory cached:  208.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4563511963292837, 'log_learning_rate_D': -3.2295129913989453, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.6631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  12.0
[I 2023-10-30 13:12:00,270] Trial 26 finished with value: 0.2366243451833725 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.4563511963292837, 'log_learning_rate_D': -3.2295129913989453, 'training_batch_size': 10, 'training_p': 8}. Best is trial 26 with value: 0.2366243451833725.
Time for this trial:  101.60422396659851
Memory status after this trial: 
Memory allocated:  58.27685546875
Memory cached:  60.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1966162029638054, 'log_learning_rate_D': -3.1858912976219114, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.5217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
[I 2023-10-30 13:13:55,493] Trial 27 finished with value: 0.23689618706703186 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1966162029638054, 'log_learning_rate_D': -3.1858912976219114, 'training_batch_size': 10, 'training_p': 8}. Best is trial 26 with value: 0.2366243451833725.
Time for this trial:  115.04925203323364
Memory status after this trial: 
Memory allocated:  100.66162109375
Memory cached:  104.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.614618037226916, 'log_learning_rate_D': -4.352562219860923, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.224609375
Memory cached:  10.0
[I 2023-10-30 13:15:45,312] Trial 28 finished with value: 0.23767609894275665 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.614618037226916, 'log_learning_rate_D': -4.352562219860923, 'training_batch_size': 11, 'training_p': 2}. Best is trial 26 with value: 0.2366243451833725.
Time for this trial:  109.62768220901489
Memory status after this trial: 
Memory allocated:  70.52685546875
Memory cached:  72.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.5832741369056704, 'log_learning_rate_D': -3.455478488827314, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  8.0
[W 2023-10-30 13:15:54,954] Trial 29 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.5832741369056704, 'log_learning_rate_D': -3.455478488827314, 'training_batch_size': 11, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-10-30 13:15:54,955] Trial 29 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  9.431675910949707
Memory status after this trial: 
Memory allocated:  58.27685546875
Memory cached:  60.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.6953054483995165, 'log_learning_rate_D': -3.4654056547280514, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.646484375
Memory cached:  14.0
[I 2023-10-30 13:17:34,138] Trial 30 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -1.6953054483995165, 'log_learning_rate_D': -3.4654056547280514, 'training_batch_size': 11, 'training_p': 8}. Best is trial 26 with value: 0.2366243451833725.
Time for this trial:  98.9989881515503
Memory status after this trial: 
Memory allocated:  58.27685546875
Memory cached:  60.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.2398472564498326, 'log_learning_rate_D': -3.1571816674374547, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.9533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.341796875
Memory cached:  18.0
[I 2023-10-30 13:19:27,202] Trial 31 finished with value: 0.23619285225868225 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.2398472564498326, 'log_learning_rate_D': -3.1571816674374547, 'training_batch_size': 10, 'training_p': 8}. Best is trial 31 with value: 0.23619285225868225.
Time for this trial:  112.87394952774048
Memory status after this trial: 
Memory allocated:  100.66162109375
Memory cached:  104.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.297103153785849, 'log_learning_rate_D': -3.0773340839821683, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.33984375
Memory cached:  12.0
[I 2023-10-30 13:21:19,153] Trial 32 finished with value: 0.23615007102489471 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.297103153785849, 'log_learning_rate_D': -3.0773340839821683, 'training_batch_size': 10, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  111.75705194473267
Memory status after this trial: 
Memory allocated:  93.32470703125
Memory cached:  98.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1606359922079985, 'log_learning_rate_D': -3.021024191624501, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.8795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.5520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.21484375
Memory cached:  18.0
[I 2023-10-30 13:23:10,190] Trial 33 finished with value: 0.23691172897815704 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.1606359922079985, 'log_learning_rate_D': -3.021024191624501, 'training_batch_size': 11, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  110.85341000556946
Memory status after this trial: 
Memory allocated:  92.58544921875
Memory cached:  96.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.5779166042476993, 'log_learning_rate_D': -2.984291616799853, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.87109375
Memory cached:  38.0
[I 2023-10-30 13:25:25,659] Trial 34 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.5779166042476993, 'log_learning_rate_D': -2.984291616799853, 'training_batch_size': 9, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  135.249445438385
Memory status after this trial: 
Memory allocated:  189.6025390625
Memory cached:  212.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.460321978673896, 'log_learning_rate_D': -2.392171303005923, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.359375
Memory cached:  26.0
[I 2023-10-30 13:27:22,240] Trial 35 finished with value: 0.23686838150024414 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.460321978673896, 'log_learning_rate_D': -2.392171303005923, 'training_batch_size': 10, 'training_p': 7}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  116.38241457939148
Memory status after this trial: 
Memory allocated:  146.63916015625
Memory cached:  160.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.074531677611069, 'log_learning_rate_D': -3.4041105664183546, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.248046875
Memory cached:  6.0
[I 2023-10-30 13:28:49,656] Trial 36 finished with value: 0.23751206696033478 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.074531677611069, 'log_learning_rate_D': -3.4041105664183546, 'training_batch_size': 8, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  87.20771217346191
Memory status after this trial: 
Memory allocated:  25.57080078125
Memory cached:  26.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1282171162938643, 'log_learning_rate_D': -2.859541056770157, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  8.0
[W 2023-10-30 13:28:52,735] Trial 37 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.1282171162938643, 'log_learning_rate_D': -2.859541056770157, 'training_batch_size': 11, 'training_p': 7} because of the following error: The value nan is not acceptable.
[W 2023-10-30 13:28:52,736] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  2.8880677223205566
Memory status after this trial: 
Memory allocated:  50.5595703125
Memory cached:  52.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.2384008935200046, 'log_learning_rate_D': -2.7679876037824434, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  12.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.259765625
Memory cached:  10.0
[I 2023-10-30 13:30:39,789] Trial 38 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -1.2384008935200046, 'log_learning_rate_D': -2.7679876037824434, 'training_batch_size': 11, 'training_p': 7}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  106.86952686309814
Memory status after this trial: 
Memory allocated:  50.5595703125
Memory cached:  52.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.3832234561200174, 'log_learning_rate_D': -3.1225772346123932, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  16.0
	 epoch  10 training error:  tensor(2.3111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0078125
Memory cached:  22.0
[I 2023-10-30 13:32:50,604] Trial 39 finished with value: 0.2368200272321701 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.3832234561200174, 'log_learning_rate_D': -3.1225772346123932, 'training_batch_size': 10, 'training_p': 6}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  130.60723209381104
Memory status after this trial: 
Memory allocated:  108.82861328125
Memory cached:  114.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.9503863166985946, 'log_learning_rate_D': -3.839071405805563, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.09375
Memory cached:  10.0
[I 2023-10-30 13:34:28,735] Trial 40 finished with value: 0.23753340542316437 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.9503863166985946, 'log_learning_rate_D': -3.839071405805563, 'training_batch_size': 9, 'training_p': 7}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  97.92908763885498
Memory status after this trial: 
Memory allocated:  87.78369140625
Memory cached:  90.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.6737725040233085, 'log_learning_rate_D': -3.543109545405416, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  32.0
[I 2023-10-30 13:36:19,832] Trial 41 finished with value: 0.2365351915359497 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.6737725040233085, 'log_learning_rate_D': -3.543109545405416, 'training_batch_size': 9, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  110.91860604286194
Memory status after this trial: 
Memory allocated:  147.416015625
Memory cached:  162.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.7209917267805688, 'log_learning_rate_D': -3.3906556673888897, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.3828125
Memory cached:  34.0
[I 2023-10-30 13:38:11,280] Trial 42 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.7209917267805688, 'log_learning_rate_D': -3.3906556673888897, 'training_batch_size': 9, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  111.25555276870728
Memory status after this trial: 
Memory allocated:  147.416015625
Memory cached:  162.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.2989077063938828, 'log_learning_rate_D': -3.660344914983244, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  30.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  34.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  38.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  36.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  38.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  36.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  38.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  36.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  38.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.154296875
Memory cached:  36.0
[I 2023-10-30 13:40:05,363] Trial 43 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.2989077063938828, 'log_learning_rate_D': -3.660344914983244, 'training_batch_size': 9, 'training_p': 8}. Best is trial 32 with value: 0.23615007102489471.
Time for this trial:  113.89061307907104
Memory status after this trial: 
Memory allocated:  157.7001953125
Memory cached:  178.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.709810964532414, 'log_learning_rate_D': -2.951963474076272, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.6934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.119140625
Memory cached:  18.0
[I 2023-10-30 13:41:48,809] Trial 44 finished with value: 0.23614917695522308 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.709810964532414, 'log_learning_rate_D': -2.951963474076272, 'training_batch_size': 10, 'training_p': 7}. Best is trial 44 with value: 0.23614917695522308.
Time for this trial:  103.25203943252563
Memory status after this trial: 
Memory allocated:  72.50830078125
Memory cached:  76.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.7939364917684433, 'log_learning_rate_D': -2.8205844576771697, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.7140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.236328125
Memory cached:  34.0
[I 2023-10-30 13:43:39,166] Trial 45 finished with value: 0.23759575188159943 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.7939364917684433, 'log_learning_rate_D': -2.8205844576771697, 'training_batch_size': 8, 'training_p': 7}. Best is trial 44 with value: 0.23614917695522308.
Time for this trial:  110.16203832626343
Memory status after this trial: 
Memory allocated:  130.54931640625
Memory cached:  150.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.711764158091451, 'log_learning_rate_D': -2.468631151870943, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.5228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.61328125
Memory cached:  12.0
[I 2023-10-30 13:45:26,925] Trial 46 finished with value: 0.23704476654529572 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.711764158091451, 'log_learning_rate_D': -2.468631151870943, 'training_batch_size': 10, 'training_p': 5}. Best is trial 44 with value: 0.23614917695522308.
Time for this trial:  107.5618314743042
Memory status after this trial: 
Memory allocated:  99.8125
Memory cached:  102.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.2956233244775914, 'log_learning_rate_D': -2.593840765453205, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.115234375
Memory cached:  32.0
[I 2023-10-30 13:47:13,409] Trial 47 finished with value: 0.2374637871980667 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.2956233244775914, 'log_learning_rate_D': -2.593840765453205, 'training_batch_size': 11, 'training_p': 7}. Best is trial 44 with value: 0.23614917695522308.
Time for this trial:  106.29401755332947
Memory status after this trial: 
Memory allocated:  102.35009765625
Memory cached:  120.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8814133962251436, 'log_learning_rate_D': -3.5628032026666667, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.4239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.412109375
Memory cached:  30.0
[I 2023-10-30 13:49:15,918] Trial 48 finished with value: 0.2372291088104248 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.8814133962251436, 'log_learning_rate_D': -3.5628032026666667, 'training_batch_size': 9, 'training_p': 6}. Best is trial 44 with value: 0.23614917695522308.
Time for this trial:  122.29903101921082
Memory status after this trial: 
Memory allocated:  109.8896484375
Memory cached:  128.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.29171389845251, 'log_learning_rate_D': -2.917837827682739, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.63671875
Memory cached:  10.0
[I 2023-10-30 13:51:15,204] Trial 49 finished with value: 0.23693092167377472 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.29171389845251, 'log_learning_rate_D': -2.917837827682739, 'training_batch_size': 8, 'training_p': 4}. Best is trial 44 with value: 0.23614917695522308.
[I 2023-10-30 13:51:15,222] A new study created in memory with name: no-name-4fc22ec4-8a77-4e31-9f3c-707927d3294f
Time for this trial:  119.06924152374268
Memory status after this trial: 
Memory allocated:  78.62451171875
Memory cached:  82.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.6309413656919243, 'log_learning_rate_D': -2.431402822255161, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  30.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6669921875
Memory cached:  36.0
[I 2023-10-30 13:53:19,157] Trial 0 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.6309413656919243, 'log_learning_rate_D': -2.431402822255161, 'training_batch_size': 12, 'training_p': 6}. Best is trial 0 with value: 1.0.
Time for this trial:  123.82337212562561
Memory status after this trial: 
Memory allocated:  189.85595703125
Memory cached:  206.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.569209084493309, 'log_learning_rate_D': -3.0383055002823816, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.9919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0791015625
Memory cached:  16.0
[I 2023-10-30 13:55:24,639] Trial 1 finished with value: 0.9995625615119934 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.569209084493309, 'log_learning_rate_D': -3.0383055002823816, 'training_batch_size': 10, 'training_p': 6}. Best is trial 1 with value: 0.9995625615119934.
Time for this trial:  125.34812378883362
Memory status after this trial: 
Memory allocated:  71.10400390625
Memory cached:  72.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.063374332237624, 'log_learning_rate_D': -3.6894996467429335, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6396484375
Memory cached:  12.0
[I 2023-10-30 13:57:30,003] Trial 2 finished with value: 0.23729009926319122 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.063374332237624, 'log_learning_rate_D': -3.6894996467429335, 'training_batch_size': 9, 'training_p': 4}. Best is trial 2 with value: 0.23729009926319122.
Time for this trial:  125.22082877159119
Memory status after this trial: 
Memory allocated:  76.8232421875
Memory cached:  80.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.449624438627724, 'log_learning_rate_D': -1.2877852027704302, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1337890625
Memory cached:  12.0
[W 2023-10-30 13:57:37,370] Trial 3 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -4.449624438627724, 'log_learning_rate_D': -1.2877852027704302, 'training_batch_size': 11, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 13:57:37,371] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  7.234133243560791
Memory status after this trial: 
Memory allocated:  117.33984375
Memory cached:  120.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.658570392930891, 'log_learning_rate_D': -1.3666188903143857, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5087890625
Memory cached:  10.0
[W 2023-10-30 13:57:42,987] Trial 4 failed with parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -1.658570392930891, 'log_learning_rate_D': -1.3666188903143857, 'training_batch_size': 8, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 13:57:42,988] Trial 4 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  5.46303653717041
Memory status after this trial: 
Memory allocated:  111.1171875
Memory cached:  114.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.8964665312770532, 'log_learning_rate_D': -4.67826293491176, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.9132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.9126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  30 training error:  tensor(2.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.9238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.8899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3603515625
Memory cached:  34.0
[I 2023-10-30 14:00:11,283] Trial 5 finished with value: 0.24602921307086945 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.8964665312770532, 'log_learning_rate_D': -4.67826293491176, 'training_batch_size': 7, 'training_p': 5}. Best is trial 2 with value: 0.23729009926319122.
Time for this trial:  148.16885590553284
Memory status after this trial: 
Memory allocated:  229.068359375
Memory cached:  250.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.036229806300982, 'log_learning_rate_D': -2.9160579789754615, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2158203125
Memory cached:  14.0
[I 2023-10-30 14:02:05,704] Trial 6 finished with value: 0.23697319626808167 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.036229806300982, 'log_learning_rate_D': -2.9160579789754615, 'training_batch_size': 8, 'training_p': 7}. Best is trial 6 with value: 0.23697319626808167.
Time for this trial:  114.28476643562317
Memory status after this trial: 
Memory allocated:  136.4365234375
Memory cached:  140.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.819658461404664, 'log_learning_rate_D': -3.642611739376823, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.9445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.0615234375
Memory cached:  40.0
[I 2023-10-30 14:04:35,409] Trial 7 finished with value: 0.286481112241745 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.819658461404664, 'log_learning_rate_D': -3.642611739376823, 'training_batch_size': 9, 'training_p': 3}. Best is trial 6 with value: 0.23697319626808167.
Time for this trial:  149.59226775169373
Memory status after this trial: 
Memory allocated:  231.5556640625
Memory cached:  246.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.883897158404116, 'log_learning_rate_D': -4.575499465765928, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.8153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5458984375
Memory cached:  18.0
[I 2023-10-30 14:06:34,312] Trial 8 finished with value: 0.23668821156024933 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.883897158404116, 'log_learning_rate_D': -4.575499465765928, 'training_batch_size': 12, 'training_p': 8}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  118.76438283920288
Memory status after this trial: 
Memory allocated:  94.28466796875
Memory cached:  96.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.4481873083726624, 'log_learning_rate_D': -2.2684477462683548, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.6561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2001953125
Memory cached:  18.0
[I 2023-10-30 14:08:43,027] Trial 9 finished with value: 0.2372458279132843 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -2.4481873083726624, 'log_learning_rate_D': -2.2684477462683548, 'training_batch_size': 9, 'training_p': 8}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  128.57787942886353
Memory status after this trial: 
Memory allocated:  98.90283203125
Memory cached:  104.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.1580290293191742, 'log_learning_rate_D': -3.0182425091049687, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8037109375
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8037109375
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8037109375
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8037109375
Memory cached:  18.0
[W 2023-10-30 14:09:30,759] Trial 10 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.1580290293191742, 'log_learning_rate_D': -3.0182425091049687, 'training_batch_size': 8, 'training_p': 4} because of the following error: The value nan is not acceptable.
[W 2023-10-30 14:09:30,760] Trial 10 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  47.5709912776947
Memory status after this trial: 
Memory allocated:  142.509765625
Memory cached:  148.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.8334577332306, 'log_learning_rate_D': -3.0614559512096924, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8701171875
Memory cached:  14.0
[I 2023-10-30 14:11:20,864] Trial 11 finished with value: 0.23698310554027557 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -2.8334577332306, 'log_learning_rate_D': -3.0614559512096924, 'training_batch_size': 10, 'training_p': 8}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  109.96402192115784
Memory status after this trial: 
Memory allocated:  95.70458984375
Memory cached:  98.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.377765056612974, 'log_learning_rate_D': -3.0105765857282263, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8466796875
Memory cached:  12.0
[I 2023-10-30 14:13:08,413] Trial 12 finished with value: 0.23728762567043304 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.377765056612974, 'log_learning_rate_D': -3.0105765857282263, 'training_batch_size': 11, 'training_p': 8}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  107.42933464050293
Memory status after this trial: 
Memory allocated:  68.3662109375
Memory cached:  70.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.161113178709567, 'log_learning_rate_D': -1.0577633993040112, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.484375
Memory cached:  10.0
[I 2023-10-30 14:16:39,106] Trial 13 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.161113178709567, 'log_learning_rate_D': -1.0577633993040112, 'training_batch_size': 6, 'training_p': 2}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  210.4865276813507
Memory status after this trial: 
Memory allocated:  90.16455078125
Memory cached:  92.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.608077157313014, 'log_learning_rate_D': -4.784649630401321, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.9931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.9873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.9791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.9507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.9268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.8443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4345703125
Memory cached:  6.0
[I 2023-10-30 14:18:14,264] Trial 14 finished with value: 0.7397855520248413 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.608077157313014, 'log_learning_rate_D': -4.784649630401321, 'training_batch_size': 7, 'training_p': 7}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  94.93012166023254
Memory status after this trial: 
Memory allocated:  27.33935546875
Memory cached:  28.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.5717325700613416, 'log_learning_rate_D': -4.145261469313363, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.2802734375
Memory cached:  6.0
[I 2023-10-30 14:19:56,861] Trial 15 finished with value: 0.9940090179443359 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.5717325700613416, 'log_learning_rate_D': -4.145261469313363, 'training_batch_size': 8, 'training_p': 7}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  102.41631841659546
Memory status after this trial: 
Memory allocated:  24.89697265625
Memory cached:  26.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.477953275734932, 'log_learning_rate_D': -4.243710908878744, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.9339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.5582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1474609375
Memory cached:  14.0
[I 2023-10-30 14:22:05,875] Trial 16 finished with value: 0.24593734741210938 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -3.477953275734932, 'log_learning_rate_D': -4.243710908878744, 'training_batch_size': 12, 'training_p': 7}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  128.84197163581848
Memory status after this trial: 
Memory allocated:  95.87158203125
Memory cached:  98.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -4.163146179807503, 'log_learning_rate_D': -4.965494108050999, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4052734375
Memory cached:  10.0
[I 2023-10-30 14:23:47,620] Trial 17 finished with value: 0.9990933537483215 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -4.163146179807503, 'log_learning_rate_D': -4.965494108050999, 'training_batch_size': 8, 'training_p': 6}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  101.5485155582428
Memory status after this trial: 
Memory allocated:  24.6689453125
Memory cached:  26.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -4.980205121835364, 'log_learning_rate_D': -3.6727523766717116, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.9981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.9837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.5801, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.4659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.1162109375
Memory cached:  34.0
[I 2023-10-30 14:25:36,902] Trial 18 finished with value: 0.26869019865989685 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -4.980205121835364, 'log_learning_rate_D': -3.6727523766717116, 'training_batch_size': 10, 'training_p': 5}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  109.1147575378418
Memory status after this trial: 
Memory allocated:  139.68212890625
Memory cached:  154.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2848107855755986, 'log_learning_rate_D': -4.269953436070267, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.8715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5126953125
Memory cached:  14.0
[I 2023-10-30 14:27:58,354] Trial 19 finished with value: 0.2378859519958496 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.2848107855755986, 'log_learning_rate_D': -4.269953436070267, 'training_batch_size': 11, 'training_p': 7}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  141.26710510253906
Memory status after this trial: 
Memory allocated:  152.388671875
Memory cached:  156.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.929438929563123, 'log_learning_rate_D': -2.477678023689121, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.9954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0029296875
Memory cached:  8.0
[I 2023-10-30 14:29:43,519] Trial 20 finished with value: 0.9994975924491882 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.929438929563123, 'log_learning_rate_D': -2.477678023689121, 'training_batch_size': 8, 'training_p': 8}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  104.97201490402222
Memory status after this trial: 
Memory allocated:  36.9306640625
Memory cached:  38.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.1270892330061173, 'log_learning_rate_D': -3.407113062949155, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.353515625
Memory cached:  12.0
[I 2023-10-30 14:32:55,641] Trial 21 finished with value: 0.236930713057518 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.1270892330061173, 'log_learning_rate_D': -3.407113062949155, 'training_batch_size': 6, 'training_p': 5}. Best is trial 8 with value: 0.23668821156024933.
Time for this trial:  191.90318822860718
Memory status after this trial: 
Memory allocated:  55.6435546875
Memory cached:  58.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.437900564558637, 'log_learning_rate_D': -4.977993054376509, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.5476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.369140625
Memory cached:  10.0
[I 2023-10-30 14:35:40,755] Trial 22 finished with value: 0.23656503856182098 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.437900564558637, 'log_learning_rate_D': -4.977993054376509, 'training_batch_size': 6, 'training_p': 4}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  164.9253807067871
Memory status after this trial: 
Memory allocated:  86.033203125
Memory cached:  90.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.871787313870748, 'log_learning_rate_D': -4.620159275804732, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  12.0
[I 2023-10-30 14:37:12,653] Trial 23 finished with value: 0.23685626685619354 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.871787313870748, 'log_learning_rate_D': -4.620159275804732, 'training_batch_size': 11, 'training_p': 3}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  91.72322988510132
Memory status after this trial: 
Memory allocated:  64.2158203125
Memory cached:  66.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.9508036586545343, 'log_learning_rate_D': -4.974349447561925, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3642578125
Memory cached:  10.0
[I 2023-10-30 14:38:45,361] Trial 24 finished with value: 0.2373708337545395 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.9508036586545343, 'log_learning_rate_D': -4.974349447561925, 'training_batch_size': 11, 'training_p': 3}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  92.53397250175476
Memory status after this trial: 
Memory allocated:  64.2158203125
Memory cached:  66.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.4336319254673686, 'log_learning_rate_D': -4.537938539986805, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8740234375
Memory cached:  12.0
[I 2023-10-30 14:40:21,034] Trial 25 finished with value: 0.23701556026935577 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -2.4336319254673686, 'log_learning_rate_D': -4.537938539986805, 'training_batch_size': 12, 'training_p': 3}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  95.48668932914734
Memory status after this trial: 
Memory allocated:  85.96533203125
Memory cached:  88.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.6240739852695083, 'log_learning_rate_D': -4.454715174659062, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.4833984375
Memory cached:  10.0
[I 2023-10-30 14:41:52,804] Trial 26 finished with value: 0.23735962808132172 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.6240739852695083, 'log_learning_rate_D': -4.454715174659062, 'training_batch_size': 11, 'training_p': 4}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  91.59618520736694
Memory status after this trial: 
Memory allocated:  58.02294921875
Memory cached:  60.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.68864533728245, 'log_learning_rate_D': -4.679133012318895, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6162109375
Memory cached:  6.0
[I 2023-10-30 14:43:25,654] Trial 27 finished with value: 0.23725949227809906 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.68864533728245, 'log_learning_rate_D': -4.679133012318895, 'training_batch_size': 12, 'training_p': 4}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  92.66605591773987
Memory status after this trial: 
Memory allocated:  59.283203125
Memory cached:  62.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.338343559779413, 'log_learning_rate_D': -3.993559810497353, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.1826171875
Memory cached:  12.0
[I 2023-10-30 14:45:02,336] Trial 28 finished with value: 0.2376023828983307 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -2.338343559779413, 'log_learning_rate_D': -3.993559810497353, 'training_batch_size': 10, 'training_p': 2}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  96.50413036346436
Memory status after this trial: 
Memory allocated:  71.572265625
Memory cached:  74.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.003029504472518, 'log_learning_rate_D': -4.965332341866529, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  40 training error:  tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  60 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  70 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  80 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
	 epoch  90 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.4130859375
Memory cached:  34.0
[I 2023-10-30 14:47:03,156] Trial 29 finished with value: 0.23703978955745697 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.003029504472518, 'log_learning_rate_D': -4.965332341866529, 'training_batch_size': 7, 'training_p': 4}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  120.63580584526062
Memory status after this trial: 
Memory allocated:  155.66015625
Memory cached:  170.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.6492200692456223, 'log_learning_rate_D': -4.471889007481656, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.3994140625
Memory cached:  8.0
[I 2023-10-30 14:48:35,901] Trial 30 finished with value: 0.23717883229255676 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.6492200692456223, 'log_learning_rate_D': -4.471889007481656, 'training_batch_size': 11, 'training_p': 3}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  92.53754687309265
Memory status after this trial: 
Memory allocated:  76.3671875
Memory cached:  78.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.1668654438363943, 'log_learning_rate_D': -3.9512006698746207, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.5439453125
Memory cached:  12.0
[W 2023-10-30 14:48:39,483] Trial 31 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.1668654438363943, 'log_learning_rate_D': -3.9512006698746207, 'training_batch_size': 12, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 14:48:39,484] Trial 31 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.38338565826416
Memory status after this trial: 
Memory allocated:  130.26904296875
Memory cached:  136.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0753246236403253, 'log_learning_rate_D': -4.019063083634777, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  16.0
[W 2023-10-30 14:48:42,986] Trial 32 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.0753246236403253, 'log_learning_rate_D': -4.019063083634777, 'training_batch_size': 12, 'training_p': 2} because of the following error: The value nan is not acceptable.
[W 2023-10-30 14:48:42,986] Trial 32 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  3.293731451034546
Memory status after this trial: 
Memory allocated:  122.93115234375
Memory cached:  128.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.2463335439305259, 'log_learning_rate_D': -3.9701397918998396, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  12.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  16.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  16.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.5400390625
Memory cached:  18.0
[I 2023-10-30 14:50:53,409] Trial 33 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.2463335439305259, 'log_learning_rate_D': -3.9701397918998396, 'training_batch_size': 12, 'training_p': 2}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  130.18029594421387
Memory status after this trial: 
Memory allocated:  122.93115234375
Memory cached:  128.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.629027496813411, 'log_learning_rate_D': -4.343134898962962, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.9116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  20 training error:  tensor(1.4726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  34.0
	 epoch  50 training error:  tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.2763671875
Memory cached:  32.0
[I 2023-10-30 14:52:47,428] Trial 34 finished with value: 0.23726136982440948 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -1.629027496813411, 'log_learning_rate_D': -4.343134898962962, 'training_batch_size': 12, 'training_p': 4}. Best is trial 22 with value: 0.23656503856182098.
Time for this trial:  113.81682419776917
Memory status after this trial: 
Memory allocated:  130.734375
Memory cached:  144.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.0773003855690644, 'log_learning_rate_D': -4.630595226549396, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.10546875
Memory cached:  12.0
[I 2023-10-30 14:55:49,612] Trial 35 finished with value: 0.23473091423511505 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.0773003855690644, 'log_learning_rate_D': -4.630595226549396, 'training_batch_size': 6, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  181.9827651977539
Memory status after this trial: 
Memory allocated:  90.8017578125
Memory cached:  94.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.0581737797322694, 'log_learning_rate_D': -4.682732035136235, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  16.0
	 epoch  10 training error:  tensor(1.6888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.107421875
Memory cached:  14.0
[I 2023-10-30 14:58:53,054] Trial 36 finished with value: 0.23583582043647766 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.0581737797322694, 'log_learning_rate_D': -4.682732035136235, 'training_batch_size': 6, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  183.24188137054443
Memory status after this trial: 
Memory allocated:  98.638671875
Memory cached:  102.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.1478390194568124, 'log_learning_rate_D': -4.788674094689798, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
[W 2023-10-30 14:58:59,479] Trial 37 failed with parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.1478390194568124, 'log_learning_rate_D': -4.788674094689798, 'training_batch_size': 6, 'training_p': 5} because of the following error: The value nan is not acceptable.
[W 2023-10-30 14:58:59,480] Trial 37 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  6.224699258804321
Memory status after this trial: 
Memory allocated:  127.005859375
Memory cached:  132.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.200357116026917, 'log_learning_rate_D': -4.812623081428421, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  12.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  16.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  12.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  16.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  12.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.154296875
Memory cached:  14.0
[I 2023-10-30 15:02:06,270] Trial 38 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.200357116026917, 'log_learning_rate_D': -4.812623081428421, 'training_batch_size': 6, 'training_p': 5}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  186.58978629112244
Memory status after this trial: 
Memory allocated:  127.005859375
Memory cached:  132.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.213457357455276, 'log_learning_rate_D': -4.503639928210525, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6015625
Memory cached:  12.0
[I 2023-10-30 15:05:08,892] Trial 39 finished with value: 0.24455229938030243 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.213457357455276, 'log_learning_rate_D': -4.503639928210525, 'training_batch_size': 6, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  182.42205119132996
Memory status after this trial: 
Memory allocated:  90.9130859375
Memory cached:  94.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.584776532498583, 'log_learning_rate_D': -4.722926529798219, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  38.0
	 epoch  30 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.9938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  42.0
	 epoch  60 training error:  tensor(1.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.6720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.6396484375
Memory cached:  38.0
[I 2023-10-30 15:07:10,120] Trial 40 finished with value: 0.26231756806373596 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.584776532498583, 'log_learning_rate_D': -4.722926529798219, 'training_batch_size': 7, 'training_p': 4}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  121.03770279884338
Memory status after this trial: 
Memory allocated:  152.3125
Memory cached:  174.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.7968587459174175, 'log_learning_rate_D': -4.083424247919161, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1123046875
Memory cached:  12.0
[I 2023-10-30 15:08:52,327] Trial 41 finished with value: 0.23729191720485687 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -1.7968587459174175, 'log_learning_rate_D': -4.083424247919161, 'training_batch_size': 7, 'training_p': 2}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  102.0072968006134
Memory status after this trial: 
Memory allocated:  84.68359375
Memory cached:  88.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.2354661996253644, 'log_learning_rate_D': -4.997292479991814, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.6175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.275390625
Memory cached:  36.0
[I 2023-10-30 15:12:13,658] Trial 42 finished with value: 0.2380450814962387 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -2.2354661996253644, 'log_learning_rate_D': -4.997292479991814, 'training_batch_size': 6, 'training_p': 4}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  201.1204957962036
Memory status after this trial: 
Memory allocated:  130.75830078125
Memory cached:  150.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.0334306526102752, 'log_learning_rate_D': -4.323597738806891, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.001953125
Memory cached:  18.0
[I 2023-10-30 15:16:03,608] Trial 43 finished with value: 0.23635677993297577 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.0334306526102752, 'log_learning_rate_D': -4.323597738806891, 'training_batch_size': 6, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  229.7142117023468
Memory status after this trial: 
Memory allocated:  130.44140625
Memory cached:  134.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.6371085242842485, 'log_learning_rate_D': -4.296865706743229, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.001953125
Memory cached:  18.0
[I 2023-10-30 15:19:53,939] Trial 44 finished with value: 0.24014225602149963 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.6371085242842485, 'log_learning_rate_D': -4.296865706743229, 'training_batch_size': 6, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  230.10377645492554
Memory status after this trial: 
Memory allocated:  128.2666015625
Memory cached:  132.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.037935953606183, 'log_learning_rate_D': -3.911808160487828, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.9182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1689453125
Memory cached:  22.0
[I 2023-10-30 15:22:14,347] Trial 45 finished with value: 0.2371806651353836 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -3.037935953606183, 'log_learning_rate_D': -3.911808160487828, 'training_batch_size': 7, 'training_p': 3}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  140.18749141693115
Memory status after this trial: 
Memory allocated:  184.1455078125
Memory cached:  190.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.1044198700312315, 'log_learning_rate_D': -4.701945512882603, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.5078125
Memory cached:  22.0
[I 2023-10-30 15:26:11,609] Trial 46 finished with value: 0.23674307763576508 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.1044198700312315, 'log_learning_rate_D': -4.701945512882603, 'training_batch_size': 6, 'training_p': 2}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  237.02672171592712
Memory status after this trial: 
Memory allocated:  173.248046875
Memory cached:  178.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7269036551756307, 'log_learning_rate_D': -4.440684275041512, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.9956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.5810546875
Memory cached:  36.0
[I 2023-10-30 15:28:45,858] Trial 47 finished with value: 0.2366621047258377 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7269036551756307, 'log_learning_rate_D': -4.440684275041512, 'training_batch_size': 7, 'training_p': 6}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  154.03469800949097
Memory status after this trial: 
Memory allocated:  238.5703125
Memory cached:  254.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7916878473941065, 'log_learning_rate_D': -4.339065406081773, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.7097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.4296875
Memory cached:  58.0
[I 2023-10-30 15:33:08,417] Trial 48 finished with value: 0.2365826666355133 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7916878473941065, 'log_learning_rate_D': -4.339065406081773, 'training_batch_size': 6, 'training_p': 6}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  262.27934741973877
Memory status after this trial: 
Memory allocated:  285.3896484375
Memory cached:  298.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.4616524026009645, 'log_learning_rate_D': -4.792212061900281, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.625
Memory cached:  40.0
[I 2023-10-30 15:36:50,282] Trial 49 finished with value: 0.2412950098514557 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.4616524026009645, 'log_learning_rate_D': -4.792212061900281, 'training_batch_size': 6, 'training_p': 5}. Best is trial 35 with value: 0.23473091423511505.
Time for this trial:  221.6481273174286
Memory status after this trial: 
Memory allocated:  181.3955078125
Memory cached:  202.0
