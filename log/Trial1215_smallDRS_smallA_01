/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-12-19 11:38:36,154] A new study created in memory with name: no-name-6e538021-e8cf-4f40-be2d-c985f0c012cf
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial1215_smallDRS_smallA.pt
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.9070820896897067, 'log_learning_rate_D': -2.5625766747953063, 'log_learning_rate_D_dagger': -4.993984879265323, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  160.0
	 epoch  10 training error:  tensor(0.6074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  164.0
	 epoch  20 training error:  tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  154.0
	 epoch  30 training error:  tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  154.0
	 epoch  40 training error:  tensor(0.5893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  154.0
	 epoch  50 training error:  tensor(0.5802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  150.0
	 epoch  60 training error:  tensor(0.5963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  156.0
	 epoch  70 training error:  tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  150.0
	 epoch  80 training error:  tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  150.0
	 epoch  90 training error:  tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.36328125
Memory cached:  152.0
[I 2023-12-19 11:44:34,210] Trial 0 finished with value: 0.5084194540977478 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 8, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.9070820896897067, 'log_learning_rate_D': -2.5625766747953063, 'log_learning_rate_D_dagger': -4.993984879265323, 'training_batch_size': 6, 'training_p': 8}. Best is trial 0 with value: 0.5084194540977478.
res:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  357.9172248840332
Memory status after this trial: 
Memory allocated:  272.71630859375
Memory cached:  294.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.8020540956461577, 'log_learning_rate_D': -2.206141758648969, 'log_learning_rate_D_dagger': -4.833861943927181, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  362.0
	 epoch  10 training error:  tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.5748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  460.0
	 epoch  30 training error:  tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  452.0
	 epoch  40 training error:  tensor(0.6415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  450.0
	 epoch  50 training error:  tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  462.0
	 epoch  60 training error:  tensor(0.5381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  450.0
	 epoch  70 training error:  tensor(0.5445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.5384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  448.0
	 epoch  90 training error:  tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  285.54052734375
Memory cached:  450.0
[I 2023-12-19 11:48:36,198] Trial 1 finished with value: 0.5079362988471985 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'D_dagger_layer_units_exponent_7': 10, 'log_learning_rate': -1.8020540956461577, 'log_learning_rate_D': -2.206141758648969, 'log_learning_rate_D_dagger': -4.833861943927181, 'training_batch_size': 12, 'training_p': 5}. Best is trial 1 with value: 0.5079362988471985.
res:  tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  241.8461184501648
Memory status after this trial: 
Memory allocated:  260.92333984375
Memory cached:  496.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -4.026705504106603, 'log_learning_rate_D': -1.5378067359355208, 'log_learning_rate_D_dagger': -4.014825947061261, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  524.0
	 epoch  10 training error:  tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  560.0
	 epoch  20 training error:  tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  560.0
	 epoch  30 training error:  tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  568.0
	 epoch  40 training error:  tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  568.0
	 epoch  50 training error:  tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  556.0
	 epoch  60 training error:  tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  560.0
	 epoch  70 training error:  tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  564.0
	 epoch  80 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  570.0
	 epoch  90 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  270.94970703125
Memory cached:  560.0
[I 2023-12-19 11:51:28,550] Trial 2 finished with value: 0.519989013671875 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -4.026705504106603, 'log_learning_rate_D': -1.5378067359355208, 'log_learning_rate_D_dagger': -4.014825947061261, 'training_batch_size': 8, 'training_p': 4}. Best is trial 1 with value: 0.5079362988471985.
Time for this trial:  172.22589302062988
Memory status after this trial: 
Memory allocated:  409.453125
Memory cached:  542.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -4.930266883227439, 'log_learning_rate_D': -1.489871270561669, 'log_learning_rate_D_dagger': -4.065639725924074, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  506.0
	 epoch  10 training error:  tensor(0.9876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  570.0
	 epoch  20 training error:  tensor(0.9623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  570.0
	 epoch  30 training error:  tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  570.0
	 epoch  40 training error:  tensor(0.8811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  568.0
	 epoch  50 training error:  tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  560.0
	 epoch  60 training error:  tensor(0.7569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  550.0
	 epoch  70 training error:  tensor(0.6469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  566.0
	 epoch  80 training error:  tensor(0.6138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  568.0
	 epoch  90 training error:  tensor(0.5298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  271.44970703125
Memory cached:  558.0
[I 2023-12-19 11:55:20,987] Trial 3 finished with value: 0.5179688334465027 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 6, 'log_learning_rate': -4.930266883227439, 'log_learning_rate_D': -1.489871270561669, 'log_learning_rate_D_dagger': -4.065639725924074, 'training_batch_size': 11, 'training_p': 2}. Best is trial 1 with value: 0.5079362988471985.
Time for this trial:  232.25274848937988
Memory status after this trial: 
Memory allocated:  564.6982421875
Memory cached:  572.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.48297064122815, 'log_learning_rate_D': -3.5989342223959104, 'log_learning_rate_D_dagger': -1.3530614349712167, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.5506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  524.0
	 epoch  10 training error:  tensor(0.7246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  560.0
	 epoch  20 training error:  tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  544.0
	 epoch  30 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  556.0
	 epoch  40 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  554.0
	 epoch  50 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  546.0
	 epoch  60 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  550.0
	 epoch  70 training error:  tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  560.0
	 epoch  80 training error:  tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  558.0
	 epoch  90 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  269.83837890625
Memory cached:  550.0
[I 2023-12-19 12:01:08,094] Trial 4 finished with value: 0.5205944180488586 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'D_dagger_layer_units_exponent_6': 8, 'D_dagger_layer_units_exponent_7': 4, 'log_learning_rate': -4.48297064122815, 'log_learning_rate_D': -3.5989342223959104, 'log_learning_rate_D_dagger': -1.3530614349712167, 'training_batch_size': 6, 'training_p': 4}. Best is trial 1 with value: 0.5079362988471985.
Time for this trial:  346.8954141139984
Memory status after this trial: 
Memory allocated:  457.15673828125
Memory cached:  534.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.4441036548415136, 'log_learning_rate_D': -2.157809341766738, 'log_learning_rate_D_dagger': -2.8697060709717377, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  562.0
	 epoch  10 training error:  tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  622.0
	 epoch  20 training error:  tensor(0.4888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  620.0
	 epoch  30 training error:  tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  622.0
	 epoch  40 training error:  tensor(0.4874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  630.0
	 epoch  50 training error:  tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  624.0
	 epoch  60 training error:  tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  626.0
	 epoch  70 training error:  tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  624.0
	 epoch  80 training error:  tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  618.0
	 epoch  90 training error:  tensor(0.5101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  309.01220703125
Memory cached:  622.0
[I 2023-12-19 12:04:59,799] Trial 5 finished with value: 0.3324589431285858 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -2.4441036548415136, 'log_learning_rate_D': -2.157809341766738, 'log_learning_rate_D_dagger': -2.8697060709717377, 'training_batch_size': 7, 'training_p': 5}. Best is trial 5 with value: 0.3324589431285858.
res:  tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  231.49914956092834
Memory status after this trial: 
Memory allocated:  375.462890625
Memory cached:  598.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -4.967523182266075, 'log_learning_rate_D': -1.1210625008523047, 'log_learning_rate_D_dagger': -2.3744613905015086, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  610.0
	 epoch  10 training error:  tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  652.0
	 epoch  20 training error:  tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  662.0
	 epoch  30 training error:  tensor(0.6226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  666.0
	 epoch  40 training error:  tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  652.0
	 epoch  50 training error:  tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  654.0
	 epoch  60 training error:  tensor(0.5675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  658.0
	 epoch  70 training error:  tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  654.0
	 epoch  80 training error:  tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  658.0
	 epoch  90 training error:  tensor(0.5659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  404.7568359375
Memory cached:  656.0
[I 2023-12-19 12:08:23,358] Trial 6 finished with value: 0.5215491652488708 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 10, 'log_learning_rate': -4.967523182266075, 'log_learning_rate_D': -1.1210625008523047, 'log_learning_rate_D_dagger': -2.3744613905015086, 'training_batch_size': 8, 'training_p': 7}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  203.42418456077576
Memory status after this trial: 
Memory allocated:  673.474609375
Memory cached:  686.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -1.7228825513805468, 'log_learning_rate_D': -1.7030466395924324, 'log_learning_rate_D_dagger': -4.5170324660571595, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  590.0
	 epoch  10 training error:  tensor(1.7555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  636.0
	 epoch  20 training error:  tensor(0.5562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  636.0
	 epoch  30 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  640.0
	 epoch  40 training error:  tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  634.0
	 epoch  50 training error:  tensor(0.4717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  636.0
	 epoch  60 training error:  tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  632.0
	 epoch  70 training error:  tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  632.0
	 epoch  80 training error:  tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  638.0
	 epoch  90 training error:  tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.6513671875
Memory cached:  632.0
[I 2023-12-19 12:11:36,894] Trial 7 finished with value: 0.5109496712684631 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 8, 'log_learning_rate': -1.7228825513805468, 'log_learning_rate_D': -1.7030466395924324, 'log_learning_rate_D_dagger': -4.5170324660571595, 'training_batch_size': 7, 'training_p': 2}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  193.36091351509094
Memory status after this trial: 
Memory allocated:  597.5634765625
Memory cached:  616.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.259106191387121, 'log_learning_rate_D': -2.8828863075479276, 'log_learning_rate_D_dagger': -3.250817478478149, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  594.0
	 epoch  10 training error:  tensor(0.6266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  640.0
	 epoch  20 training error:  tensor(0.5679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  638.0
	 epoch  30 training error:  tensor(0.5647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  646.0
	 epoch  40 training error:  tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  642.0
	 epoch  50 training error:  tensor(0.5559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  636.0
	 epoch  60 training error:  tensor(0.5522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  644.0
	 epoch  70 training error:  tensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  640.0
	 epoch  80 training error:  tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  644.0
	 epoch  90 training error:  tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  389.7666015625
Memory cached:  646.0
[I 2023-12-19 12:15:23,071] Trial 8 finished with value: 0.44439488649368286 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 8, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.259106191387121, 'log_learning_rate_D': -2.8828863075479276, 'log_learning_rate_D_dagger': -3.250817478478149, 'training_batch_size': 10, 'training_p': 8}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  225.97142720222473
Memory status after this trial: 
Memory allocated:  619.87353515625
Memory cached:  648.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.734607163666515, 'log_learning_rate_D': -1.4038952540670722, 'log_learning_rate_D_dagger': -2.640730420676088, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  602.0
	 epoch  10 training error:  tensor(55.5206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  638.0
	 epoch  20 training error:  tensor(21.8160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  636.0
	 epoch  30 training error:  tensor(0.6012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  646.0
	 epoch  40 training error:  tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  644.0
	 epoch  50 training error:  tensor(0.5927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  640.0
	 epoch  60 training error:  tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  648.0
	 epoch  70 training error:  tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  652.0
	 epoch  80 training error:  tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  652.0
	 epoch  90 training error:  tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  387.9677734375
Memory cached:  638.0
[I 2023-12-19 12:19:21,789] Trial 9 finished with value: 0.5494236350059509 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 9, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 4, 'log_learning_rate': -1.734607163666515, 'log_learning_rate_D': -1.4038952540670722, 'log_learning_rate_D_dagger': -2.640730420676088, 'training_batch_size': 12, 'training_p': 5}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  238.5297224521637
Memory status after this trial: 
Memory allocated:  571.90576171875
Memory cached:  620.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.744972687963204, 'log_learning_rate_D': -4.691220130640376, 'log_learning_rate_D_dagger': -1.7077304387410162, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  592.0
	 epoch  10 training error:  tensor(60.2213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  632.0
	 epoch  20 training error:  tensor(1.4166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  632.0
	 epoch  30 training error:  tensor(0.8707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  630.0
	 epoch  40 training error:  tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  638.0
	 epoch  50 training error:  tensor(0.5570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  632.0
	 epoch  60 training error:  tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  622.0
	 epoch  70 training error:  tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  630.0
	 epoch  80 training error:  tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  626.0
	 epoch  90 training error:  tensor(0.5275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  405.8896484375
Memory cached:  630.0
[I 2023-12-19 12:22:49,666] Trial 10 finished with value: 0.4242357313632965 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.744972687963204, 'log_learning_rate_D': -4.691220130640376, 'log_learning_rate_D_dagger': -1.7077304387410162, 'training_batch_size': 9, 'training_p': 6}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  207.54764556884766
Memory status after this trial: 
Memory allocated:  699.99853515625
Memory cached:  720.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.6591502650092957, 'log_learning_rate_D': -4.8632955890670235, 'log_learning_rate_D_dagger': -1.6866849941958777, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  612.0
	 epoch  10 training error:  tensor(543.7337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  656.0
	 epoch  20 training error:  tensor(14.6721, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  658.0
	 epoch  30 training error:  tensor(3.2050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  654.0
	 epoch  40 training error:  tensor(1.3536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  660.0
	 epoch  50 training error:  tensor(1.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  654.0
	 epoch  60 training error:  tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  656.0
	 epoch  70 training error:  tensor(1.3604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  656.0
	 epoch  80 training error:  tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  660.0
	 epoch  90 training error:  tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  412.0302734375
Memory cached:  660.0
[I 2023-12-19 12:26:23,609] Trial 11 finished with value: 0.5154143571853638 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -2.6591502650092957, 'log_learning_rate_D': -4.8632955890670235, 'log_learning_rate_D_dagger': -1.6866849941958777, 'training_batch_size': 9, 'training_p': 6}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  213.67882895469666
Memory status after this trial: 
Memory allocated:  743.94775390625
Memory cached:  780.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.488207809315235, 'log_learning_rate_D': -3.4618554606099075, 'log_learning_rate_D_dagger': -1.06269990528584, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  612.0
	 epoch  10 training error:  tensor(541.1673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  638.0
	 epoch  20 training error:  tensor(255.5374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  648.0
	 epoch  30 training error:  tensor(82.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  648.0
	 epoch  40 training error:  tensor(79.3642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  642.0
	 epoch  50 training error:  tensor(23.0295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  646.0
	 epoch  60 training error:  tensor(2.9142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  652.0
	 epoch  70 training error:  tensor(2.7857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  644.0
	 epoch  80 training error:  tensor(1.6609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  646.0
	 epoch  90 training error:  tensor(0.8149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  384.4306640625
Memory cached:  648.0
[I 2023-12-19 12:29:27,179] Trial 12 finished with value: 0.8774539828300476 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -2.488207809315235, 'log_learning_rate_D': -3.4618554606099075, 'log_learning_rate_D_dagger': -1.06269990528584, 'training_batch_size': 9, 'training_p': 6}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  183.3070089817047
Memory status after this trial: 
Memory allocated:  581.73046875
Memory cached:  628.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.017253787846558, 'log_learning_rate_D': -4.8590385154366045, 'log_learning_rate_D_dagger': -1.9257955192635623, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  608.0
	 epoch  10 training error:  tensor(9.5196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  648.0
	 epoch  20 training error:  tensor(1.5385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  646.0
	 epoch  30 training error:  tensor(0.8742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  648.0
	 epoch  40 training error:  tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  640.0
	 epoch  50 training error:  tensor(0.4853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  646.0
	 epoch  60 training error:  tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  644.0
	 epoch  70 training error:  tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  644.0
	 epoch  80 training error:  tensor(0.4664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  652.0
	 epoch  90 training error:  tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  378.9560546875
Memory cached:  644.0
[I 2023-12-19 12:32:10,016] Trial 13 finished with value: 0.37387916445732117 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.017253787846558, 'log_learning_rate_D': -4.8590385154366045, 'log_learning_rate_D_dagger': -1.9257955192635623, 'training_batch_size': 8, 'training_p': 4}. Best is trial 5 with value: 0.3324589431285858.
Time for this trial:  162.562317609787
Memory status after this trial: 
Memory allocated:  484.37841796875
Memory cached:  630.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.0678203032524607, 'log_learning_rate_D': -3.922104767297621, 'log_learning_rate_D_dagger': -2.2548545629514782, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  594.0
	 epoch  10 training error:  tensor(7431.8569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  604.0
	 epoch  20 training error:  tensor(1.7849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  606.0
	 epoch  30 training error:  tensor(0.6631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  604.0
	 epoch  40 training error:  tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  604.0
	 epoch  50 training error:  tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  602.0
	 epoch  60 training error:  tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  600.0
	 epoch  70 training error:  tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  600.0
	 epoch  80 training error:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  604.0
	 epoch  90 training error:  tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  386.9501953125
Memory cached:  600.0
[I 2023-12-19 12:34:55,602] Trial 14 finished with value: 0.31612932682037354 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -1.0678203032524607, 'log_learning_rate_D': -3.922104767297621, 'log_learning_rate_D_dagger': -2.2548545629514782, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.31612932682037354.
res:  tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  165.27695775032043
Memory status after this trial: 
Memory allocated:  162.58349609375
Memory cached:  500.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.0389623614060632, 'log_learning_rate_D': -4.067129949642122, 'log_learning_rate_D_dagger': -3.111200633048263, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  500.0
	 epoch  10 training error:  tensor(538.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  520.0
	 epoch  20 training error:  tensor(18115.7871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  524.0
	 epoch  30 training error:  tensor(10876.7637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  522.0
	 epoch  40 training error:  tensor(1744.7528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  524.0
	 epoch  50 training error:  tensor(914.1984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  522.0
	 epoch  60 training error:  tensor(41.6609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  524.0
	 epoch  70 training error:  tensor(28.6742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  528.0
	 epoch  80 training error:  tensor(7.3024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  524.0
	 epoch  90 training error:  tensor(3.0304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  174.89111328125
Memory cached:  522.0
[I 2023-12-19 12:37:45,408] Trial 15 finished with value: 2.7579095363616943 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -1.0389623614060632, 'log_learning_rate_D': -4.067129949642122, 'log_learning_rate_D_dagger': -3.111200633048263, 'training_batch_size': 7, 'training_p': 3}. Best is trial 14 with value: 0.31612932682037354.
Time for this trial:  169.59162855148315
Memory status after this trial: 
Memory allocated:  346.00390625
Memory cached:  510.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.535348957606698, 'log_learning_rate_D': -2.0984909019376143, 'log_learning_rate_D_dagger': -2.4473458361807463, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  508.0
	 epoch  10 training error:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  554.0
	 epoch  20 training error:  tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  546.0
	 epoch  30 training error:  tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  546.0
	 epoch  40 training error:  tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  546.0
	 epoch  50 training error:  tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  542.0
	 epoch  60 training error:  tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  542.0
	 epoch  70 training error:  tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  550.0
	 epoch  80 training error:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  530.0
	 epoch  90 training error:  tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  168.99658203125
Memory cached:  538.0
[I 2023-12-19 12:40:51,803] Trial 16 finished with value: 0.3062097132205963 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.535348957606698, 'log_learning_rate_D': -2.0984909019376143, 'log_learning_rate_D_dagger': -2.4473458361807463, 'training_batch_size': 7, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
res:  tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  186.13626050949097
Memory status after this trial: 
Memory allocated:  200.46923828125
Memory cached:  462.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.452710886893306, 'log_learning_rate_D': -3.1203182507641674, 'log_learning_rate_D_dagger': -2.216972621080166, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(1.3039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  504.0
	 epoch  20 training error:  tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  520.0
	 epoch  30 training error:  tensor(0.3895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  518.0
	 epoch  40 training error:  tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  512.0
	 epoch  50 training error:  tensor(0.4000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  508.0
	 epoch  60 training error:  tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  512.0
	 epoch  70 training error:  tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  508.0
	 epoch  80 training error:  tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  512.0
	 epoch  90 training error:  tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  205.27099609375
Memory cached:  510.0
[I 2023-12-19 12:46:10,594] Trial 17 finished with value: 0.34412479400634766 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -3.452710886893306, 'log_learning_rate_D': -3.1203182507641674, 'log_learning_rate_D_dagger': -2.216972621080166, 'training_batch_size': 6, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  318.5425305366516
Memory status after this trial: 
Memory allocated:  412.9365234375
Memory cached:  492.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -3.4933236623742587, 'log_learning_rate_D': -4.065444971634702, 'log_learning_rate_D_dagger': -2.2949298427394305, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  504.0
	 epoch  10 training error:  tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  532.0
	 epoch  20 training error:  tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  532.0
	 epoch  30 training error:  tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  528.0
	 epoch  40 training error:  tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  526.0
	 epoch  50 training error:  tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  532.0
	 epoch  60 training error:  tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  532.0
	 epoch  70 training error:  tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  530.0
	 epoch  80 training error:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  534.0
	 epoch  90 training error:  tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  227.73193359375
Memory cached:  536.0
[I 2023-12-19 12:49:21,540] Trial 18 finished with value: 0.3345329463481903 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -3.4933236623742587, 'log_learning_rate_D': -4.065444971634702, 'log_learning_rate_D_dagger': -2.2949298427394305, 'training_batch_size': 7, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  190.6601824760437
Memory status after this trial: 
Memory allocated:  430.62939453125
Memory cached:  498.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.3185930824315792, 'log_learning_rate_D': -2.083319458147534, 'log_learning_rate_D_dagger': -3.4289249183349098, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  472.0
	 epoch  10 training error:  tensor(0.4264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  528.0
	 epoch  20 training error:  tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  514.0
	 epoch  30 training error:  tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  512.0
	 epoch  40 training error:  tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  516.0
	 epoch  50 training error:  tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  516.0
	 epoch  60 training error:  tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  526.0
	 epoch  70 training error:  tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  514.0
	 epoch  80 training error:  tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  518.0
	 epoch  90 training error:  tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.11474609375
Memory cached:  514.0
[I 2023-12-19 12:52:31,621] Trial 19 finished with value: 0.32743528485298157 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.3185930824315792, 'log_learning_rate_D': -2.083319458147534, 'log_learning_rate_D_dagger': -3.4289249183349098, 'training_batch_size': 8, 'training_p': 2}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  189.7884349822998
Memory status after this trial: 
Memory allocated:  412.962890625
Memory cached:  496.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.8473081289776667, 'log_learning_rate_D': -2.6170064895774043, 'log_learning_rate_D_dagger': -2.7488512487088577, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  492.0
	 epoch  10 training error:  tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  530.0
	 epoch  20 training error:  tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  534.0
	 epoch  30 training error:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  534.0
	 epoch  40 training error:  tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  524.0
	 epoch  50 training error:  tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  528.0
	 epoch  60 training error:  tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  534.0
	 epoch  70 training error:  tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  532.0
	 epoch  80 training error:  tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  538.0
	 epoch  90 training error:  tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  212.99169921875
Memory cached:  528.0
[I 2023-12-19 12:55:37,325] Trial 20 finished with value: 0.34666383266448975 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.8473081289776667, 'log_learning_rate_D': -2.6170064895774043, 'log_learning_rate_D_dagger': -2.7488512487088577, 'training_batch_size': 10, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  185.42944622039795
Memory status after this trial: 
Memory allocated:  432.50244140625
Memory cached:  512.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.2656505269450053, 'log_learning_rate_D': -1.9603650064067062, 'log_learning_rate_D_dagger': -3.364392841923202, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  470.0
	 epoch  10 training error:  tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  518.0
	 epoch  20 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  526.0
	 epoch  30 training error:  tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  510.0
	 epoch  40 training error:  tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  508.0
	 epoch  50 training error:  tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  524.0
	 epoch  60 training error:  tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  516.0
	 epoch  70 training error:  tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  510.0
	 epoch  80 training error:  tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  518.0
	 epoch  90 training error:  tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  211.25537109375
Memory cached:  516.0
[I 2023-12-19 12:58:51,111] Trial 21 finished with value: 0.31824085116386414 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.2656505269450053, 'log_learning_rate_D': -1.9603650064067062, 'log_learning_rate_D_dagger': -3.364392841923202, 'training_batch_size': 8, 'training_p': 2}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  193.50453448295593
Memory status after this trial: 
Memory allocated:  436.236328125
Memory cached:  496.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.0677603749562303, 'log_learning_rate_D': -1.9787316952280356, 'log_learning_rate_D_dagger': -3.485802302716528, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  470.0
	 epoch  10 training error:  tensor(0.4777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  510.0
	 epoch  20 training error:  tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  512.0
	 epoch  30 training error:  tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  514.0
	 epoch  40 training error:  tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  510.0
	 epoch  50 training error:  tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  504.0
	 epoch  60 training error:  tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  510.0
	 epoch  70 training error:  tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  514.0
	 epoch  80 training error:  tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  512.0
	 epoch  90 training error:  tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  213.74365234375
Memory cached:  512.0
[I 2023-12-19 13:02:12,194] Trial 22 finished with value: 0.5101665258407593 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.0677603749562303, 'log_learning_rate_D': -1.9787316952280356, 'log_learning_rate_D_dagger': -3.485802302716528, 'training_batch_size': 7, 'training_p': 2}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  200.80183458328247
Memory status after this trial: 
Memory allocated:  427.76416015625
Memory cached:  496.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.7284337022906406, 'log_learning_rate_D': -1.002581862146521, 'log_learning_rate_D_dagger': -2.423124524934597, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  498.0
	 epoch  10 training error:  tensor(1.2723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  538.0
	 epoch  20 training error:  tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  536.0
	 epoch  30 training error:  tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  544.0
	 epoch  40 training error:  tensor(0.5106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  542.0
	 epoch  50 training error:  tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  544.0
	 epoch  60 training error:  tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  540.0
	 epoch  70 training error:  tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  532.0
	 epoch  80 training error:  tensor(0.4849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  536.0
	 epoch  90 training error:  tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  221.87841796875
Memory cached:  542.0
[I 2023-12-19 13:05:13,281] Trial 23 finished with value: 0.5197519659996033 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.7284337022906406, 'log_learning_rate_D': -1.002581862146521, 'log_learning_rate_D_dagger': -2.423124524934597, 'training_batch_size': 8, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  180.80097794532776
Memory status after this trial: 
Memory allocated:  414.51220703125
Memory cached:  514.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.1305123599470517, 'log_learning_rate_D': -2.3761617373640975, 'log_learning_rate_D_dagger': -2.970064005376962, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  466.0
	 epoch  10 training error:  tensor(0.5610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  478.0
	 epoch  20 training error:  tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  476.0
	 epoch  40 training error:  tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  476.0
	 epoch  60 training error:  tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  476.0
	 epoch  70 training error:  tensor(0.4664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  478.0
	 epoch  80 training error:  tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  204.72412109375
Memory cached:  474.0
[I 2023-12-19 13:10:04,598] Trial 24 finished with value: 0.34067007899284363 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.1305123599470517, 'log_learning_rate_D': -2.3761617373640975, 'log_learning_rate_D_dagger': -2.970064005376962, 'training_batch_size': 6, 'training_p': 4}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  290.9646110534668
Memory status after this trial: 
Memory allocated:  321.57080078125
Memory cached:  478.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.445274648511148, 'log_learning_rate_D': -1.7961777581488472, 'log_learning_rate_D_dagger': -2.6345262678284285, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  474.0
	 epoch  10 training error:  tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  500.0
	 epoch  20 training error:  tensor(0.4591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  498.0
	 epoch  30 training error:  tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  496.0
	 epoch  40 training error:  tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  502.0
	 epoch  50 training error:  tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  494.0
	 epoch  60 training error:  tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  500.0
	 epoch  70 training error:  tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  490.0
	 epoch  80 training error:  tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  502.0
	 epoch  90 training error:  tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.19287109375
Memory cached:  504.0
[I 2023-12-19 13:12:52,497] Trial 25 finished with value: 0.5419246554374695 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -3.445274648511148, 'log_learning_rate_D': -1.7961777581488472, 'log_learning_rate_D_dagger': -2.6345262678284285, 'training_batch_size': 7, 'training_p': 2}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  167.640202999115
Memory status after this trial: 
Memory allocated:  350.62158203125
Memory cached:  488.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.2560387636329535, 'log_learning_rate_D': -1.9109507532512988, 'log_learning_rate_D_dagger': -2.1087394997470112, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  484.0
	 epoch  10 training error:  tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  516.0
	 epoch  20 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  512.0
	 epoch  30 training error:  tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  520.0
	 epoch  40 training error:  tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  512.0
	 epoch  50 training error:  tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  510.0
	 epoch  60 training error:  tensor(0.6875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  512.0
	 epoch  70 training error:  tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  518.0
	 epoch  80 training error:  tensor(0.7437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  516.0
	 epoch  90 training error:  tensor(0.7556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  214.57177734375
Memory cached:  516.0
[I 2023-12-19 13:16:36,032] Trial 26 finished with value: 0.5796500444412231 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -2.2560387636329535, 'log_learning_rate_D': -1.9109507532512988, 'log_learning_rate_D_dagger': -2.1087394997470112, 'training_batch_size': 8, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  223.23933243751526
Memory status after this trial: 
Memory allocated:  507.7578125
Memory cached:  528.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.971594284563032, 'log_learning_rate_D': -2.351152883012756, 'log_learning_rate_D_dagger': -2.503137303441591, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  466.0
	 epoch  10 training error:  tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  494.0
	 epoch  20 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  490.0
	 epoch  30 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  488.0
	 epoch  40 training error:  tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  498.0
	 epoch  50 training error:  tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  494.0
	 epoch  60 training error:  tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  490.0
	 epoch  70 training error:  tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  496.0
	 epoch  80 training error:  tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  492.0
	 epoch  90 training error:  tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  210.34326171875
Memory cached:  500.0
[I 2023-12-19 13:19:11,920] Trial 27 finished with value: 0.3757387101650238 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -2.971594284563032, 'log_learning_rate_D': -2.351152883012756, 'log_learning_rate_D_dagger': -2.503137303441591, 'training_batch_size': 10, 'training_p': 4}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  155.62829327583313
Memory status after this trial: 
Memory allocated:  371.3251953125
Memory cached:  480.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -3.171333860166184, 'log_learning_rate_D': -2.927828894788221, 'log_learning_rate_D_dagger': -1.9622792951661618, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  486.0
	 epoch  10 training error:  tensor(0.9741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  514.0
	 epoch  20 training error:  tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  526.0
	 epoch  30 training error:  tensor(1.4874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  516.0
	 epoch  40 training error:  tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  518.0
	 epoch  50 training error:  tensor(2.7557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  520.0
	 epoch  60 training error:  tensor(10.0979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  520.0
	 epoch  70 training error:  tensor(2.6054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  518.0
	 epoch  80 training error:  tensor(2.1354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  520.0
	 epoch  90 training error:  tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  223.01904296875
Memory cached:  520.0
[I 2023-12-19 13:22:51,778] Trial 28 finished with value: 0.6138685345649719 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 10, 'log_learning_rate': -3.171333860166184, 'log_learning_rate_D': -2.927828894788221, 'log_learning_rate_D_dagger': -1.9622792951661618, 'training_batch_size': 7, 'training_p': 2}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  219.57276582717896
Memory status after this trial: 
Memory allocated:  527.76318359375
Memory cached:  552.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.9342401823069912, 'log_learning_rate_D': -2.58754995500778, 'log_learning_rate_D_dagger': -2.919090279221199, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  466.0
	 epoch  10 training error:  tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  498.0
	 epoch  20 training error:  tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  498.0
	 epoch  30 training error:  tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  494.0
	 epoch  40 training error:  tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  486.0
	 epoch  50 training error:  tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  482.0
	 epoch  60 training error:  tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  496.0
	 epoch  70 training error:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  506.0
	 epoch  80 training error:  tensor(0.3965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  494.0
	 epoch  90 training error:  tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  206.20849609375
Memory cached:  494.0
[I 2023-12-19 13:28:20,251] Trial 29 finished with value: 0.3419407308101654 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 10, 'log_learning_rate': -2.9342401823069912, 'log_learning_rate_D': -2.58754995500778, 'log_learning_rate_D_dagger': -2.919090279221199, 'training_batch_size': 6, 'training_p': 3}. Best is trial 16 with value: 0.3062097132205963.
Time for this trial:  328.16532826423645
Memory status after this trial: 
Memory allocated:  380.2841796875
Memory cached:  486.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.616873890358167, 'log_learning_rate_D': -2.5018203785390543, 'log_learning_rate_D_dagger': -3.2193642094433423, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  470.0
	 epoch  10 training error:  tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  484.0
	 epoch  20 training error:  tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  478.0
	 epoch  50 training error:  tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  486.0
	 epoch  60 training error:  tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  490.0
	 epoch  70 training error:  tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  492.0
	 epoch  80 training error:  tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  490.0
	 epoch  90 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  207.34130859375
Memory cached:  478.0
[I 2023-12-19 13:34:01,710] Trial 30 finished with value: 0.2570367753505707 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.616873890358167, 'log_learning_rate_D': -2.5018203785390543, 'log_learning_rate_D_dagger': -3.2193642094433423, 'training_batch_size': 6, 'training_p': 2}. Best is trial 30 with value: 0.2570367753505707.
res:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  341.14912724494934
Memory status after this trial: 
Memory allocated:  141.49560546875
Memory cached:  432.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.781742538208091, 'log_learning_rate_D': -2.5391815668222417, 'log_learning_rate_D_dagger': -3.2433192331378455, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  430.0
	 epoch  10 training error:  tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  446.0
	 epoch  30 training error:  tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  442.0
	 epoch  40 training error:  tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  454.0
	 epoch  50 training error:  tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  446.0
	 epoch  60 training error:  tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  454.0
	 epoch  70 training error:  tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  442.0
	 epoch  80 training error:  tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  446.0
	 epoch  90 training error:  tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.31787109375
Memory cached:  450.0
[I 2023-12-19 13:39:42,973] Trial 31 finished with value: 0.32471340894699097 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'log_learning_rate': -3.781742538208091, 'log_learning_rate_D': -2.5391815668222417, 'log_learning_rate_D_dagger': -3.2433192331378455, 'training_batch_size': 6, 'training_p': 2}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  340.98035526275635
Memory status after this trial: 
Memory allocated:  282.8603515625
Memory cached:  442.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -3.535943742819454, 'log_learning_rate_D': -2.1959883821729798, 'log_learning_rate_D_dagger': -2.699869595608872, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  428.0
	 epoch  10 training error:  tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  444.0
	 epoch  30 training error:  tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  444.0
	 epoch  40 training error:  tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  444.0
	 epoch  50 training error:  tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  444.0
	 epoch  60 training error:  tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  450.0
	 epoch  70 training error:  tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  442.0
	 epoch  80 training error:  tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  444.0
	 epoch  90 training error:  tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.32958984375
Memory cached:  442.0
[I 2023-12-19 13:45:39,519] Trial 32 finished with value: 0.33881229162216187 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -3.535943742819454, 'log_learning_rate_D': -2.1959883821729798, 'log_learning_rate_D_dagger': -2.699869595608872, 'training_batch_size': 6, 'training_p': 2}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  356.20209646224976
Memory status after this trial: 
Memory allocated:  283.73095703125
Memory cached:  430.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -4.042056988409097, 'log_learning_rate_D': -1.8074040198195955, 'log_learning_rate_D_dagger': -3.662510836256849, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  426.0
	 epoch  10 training error:  tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  440.0
	 epoch  20 training error:  tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  444.0
	 epoch  30 training error:  tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  438.0
	 epoch  40 training error:  tensor(0.3896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  444.0
	 epoch  50 training error:  tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  438.0
	 epoch  60 training error:  tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  444.0
	 epoch  70 training error:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  444.0
	 epoch  80 training error:  tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  446.0
	 epoch  90 training error:  tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  148.25927734375
Memory cached:  436.0
[I 2023-12-19 13:48:43,300] Trial 33 finished with value: 0.3457429111003876 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 6, 'log_learning_rate': -4.042056988409097, 'log_learning_rate_D': -1.8074040198195955, 'log_learning_rate_D_dagger': -3.662510836256849, 'training_batch_size': 7, 'training_p': 3}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  183.45959877967834
Memory status after this trial: 
Memory allocated:  292.3681640625
Memory cached:  430.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.327166495374957, 'log_learning_rate_D': -2.358626630495386, 'log_learning_rate_D_dagger': -3.059807903057926, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  434.0
	 epoch  10 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  452.0
	 epoch  30 training error:  tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  446.0
	 epoch  40 training error:  tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  442.0
	 epoch  50 training error:  tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  452.0
	 epoch  60 training error:  tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  446.0
	 epoch  70 training error:  tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  444.0
	 epoch  80 training error:  tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  442.0
	 epoch  90 training error:  tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  145.93896484375
Memory cached:  452.0
[I 2023-12-19 13:51:48,935] Trial 34 finished with value: 0.37435290217399597 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -3.327166495374957, 'log_learning_rate_D': -2.358626630495386, 'log_learning_rate_D_dagger': -3.059807903057926, 'training_batch_size': 8, 'training_p': 4}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  185.3284113407135
Memory status after this trial: 
Memory allocated:  263.05712890625
Memory cached:  436.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.648507218393675, 'log_learning_rate_D': -2.0435535892789654, 'log_learning_rate_D_dagger': -3.7971424014778505, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  422.0
	 epoch  10 training error:  tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  20 training error:  tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  30 training error:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  40 training error:  tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  50 training error:  tensor(0.2884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  60 training error:  tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  70 training error:  tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  80 training error:  tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
	 epoch  90 training error:  tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  144.98193359375
Memory cached:  420.0
[I 2023-12-19 13:57:12,873] Trial 35 finished with value: 0.3215857446193695 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -3.648507218393675, 'log_learning_rate_D': -2.0435535892789654, 'log_learning_rate_D_dagger': -3.7971424014778505, 'training_batch_size': 6, 'training_p': 2}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  323.6203124523163
Memory status after this trial: 
Memory allocated:  256.5439453125
Memory cached:  420.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.2308370635970025, 'log_learning_rate_D': -2.7078463875897114, 'log_learning_rate_D_dagger': -2.8008742081157942, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  442.0
	 epoch  10 training error:  tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  446.0
	 epoch  20 training error:  tensor(0.4270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  444.0
	 epoch  30 training error:  tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  452.0
	 epoch  40 training error:  tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  444.0
	 epoch  50 training error:  tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  450.0
	 epoch  60 training error:  tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  444.0
	 epoch  70 training error:  tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  448.0
	 epoch  80 training error:  tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  444.0
	 epoch  90 training error:  tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  154.13037109375
Memory cached:  442.0
[I 2023-12-19 14:00:25,155] Trial 36 finished with value: 0.27344653010368347 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 6, 'log_learning_rate': -3.2308370635970025, 'log_learning_rate_D': -2.7078463875897114, 'log_learning_rate_D_dagger': -2.8008742081157942, 'training_batch_size': 7, 'training_p': 3}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  191.97707629203796
Memory status after this trial: 
Memory allocated:  335.83837890625
Memory cached:  444.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -4.539978121450871, 'log_learning_rate_D': -2.7853124014543194, 'log_learning_rate_D_dagger': -2.4858349237623623, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  422.0
	 epoch  10 training error:  tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  444.0
	 epoch  20 training error:  tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  466.0
	 epoch  30 training error:  tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  446.0
	 epoch  40 training error:  tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  458.0
	 epoch  50 training error:  tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  454.0
	 epoch  60 training error:  tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  448.0
	 epoch  70 training error:  tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  454.0
	 epoch  80 training error:  tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  454.0
	 epoch  90 training error:  tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  150.18701171875
Memory cached:  448.0
[I 2023-12-19 14:06:26,933] Trial 37 finished with value: 0.36603352427482605 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -4.539978121450871, 'log_learning_rate_D': -2.7853124014543194, 'log_learning_rate_D_dagger': -2.4858349237623623, 'training_batch_size': 6, 'training_p': 4}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  361.4464440345764
Memory status after this trial: 
Memory allocated:  330.76171875
Memory cached:  438.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.9826782378609593, 'log_learning_rate_D': -3.085117386452458, 'log_learning_rate_D_dagger': -2.9269477669251103, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  464.0
	 epoch  10 training error:  tensor(0.7781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  488.0
	 epoch  30 training error:  tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  488.0
	 epoch  40 training error:  tensor(0.3872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  476.0
	 epoch  50 training error:  tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  492.0
	 epoch  60 training error:  tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  486.0
	 epoch  70 training error:  tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  488.0
	 epoch  80 training error:  tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  490.0
[I 2023-12-19 14:09:02,690] Trial 38 finished with value: 0.30577990412712097 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'log_learning_rate': -3.9826782378609593, 'log_learning_rate_D': -3.085117386452458, 'log_learning_rate_D_dagger': -2.9269477669251103, 'training_batch_size': 7, 'training_p': 3}. Best is trial 30 with value: 0.2570367753505707.
Time for this trial:  155.4660141468048
Memory status after this trial: 
Memory allocated:  352.32666015625
Memory cached:  474.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.003515925371291, 'log_learning_rate_D': -3.0387837377818614, 'log_learning_rate_D_dagger': -2.8818942191367842, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  452.0
	 epoch  10 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  474.0
	 epoch  20 training error:  tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  472.0
	 epoch  30 training error:  tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  474.0
	 epoch  40 training error:  tensor(0.4264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  476.0
	 epoch  50 training error:  tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  466.0
	 epoch  60 training error:  tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  466.0
	 epoch  70 training error:  tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  468.0
	 epoch  80 training error:  tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  468.0
	 epoch  90 training error:  tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  151.60693359375
Memory cached:  468.0
[I 2023-12-19 14:11:47,577] Trial 39 finished with value: 0.19869843125343323 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.003515925371291, 'log_learning_rate_D': -3.0387837377818614, 'log_learning_rate_D_dagger': -2.8818942191367842, 'training_batch_size': 7, 'training_p': 4}. Best is trial 39 with value: 0.19869843125343323.
res:  tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  164.63786458969116
Memory status after this trial: 
Memory allocated:  209.0478515625
Memory cached:  436.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.024482552260607, 'log_learning_rate_D': -3.0650488835767713, 'log_learning_rate_D_dagger': -2.8401093890500206, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  442.0
	 epoch  10 training error:  tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  458.0
	 epoch  20 training error:  tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  462.0
	 epoch  30 training error:  tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  460.0
	 epoch  40 training error:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  454.0
	 epoch  50 training error:  tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  456.0
	 epoch  60 training error:  tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  464.0
	 epoch  70 training error:  tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  462.0
	 epoch  80 training error:  tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  462.0
	 epoch  90 training error:  tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  218.791015625
Memory cached:  462.0
[I 2023-12-19 14:16:23,239] Trial 40 finished with value: 0.19488754868507385 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.024482552260607, 'log_learning_rate_D': -3.0650488835767713, 'log_learning_rate_D_dagger': -2.8401093890500206, 'training_batch_size': 6, 'training_p': 5}. Best is trial 40 with value: 0.19488754868507385.
res:  tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  275.4188220500946
Memory status after this trial: 
Memory allocated:  187.896484375
Memory cached:  436.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.021122132601578, 'log_learning_rate_D': -3.097410536932505, 'log_learning_rate_D_dagger': -2.8673101154877907, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  430.0
	 epoch  10 training error:  tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  444.0
	 epoch  20 training error:  tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  440.0
	 epoch  30 training error:  tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  440.0
	 epoch  40 training error:  tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  442.0
	 epoch  50 training error:  tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  440.0
	 epoch  60 training error:  tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  442.0
	 epoch  70 training error:  tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  440.0
	 epoch  80 training error:  tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  442.0
	 epoch  90 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.58984375
Memory cached:  442.0
[I 2023-12-19 14:20:58,944] Trial 41 finished with value: 0.15215128660202026 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.021122132601578, 'log_learning_rate_D': -3.097410536932505, 'log_learning_rate_D_dagger': -2.8673101154877907, 'training_batch_size': 6, 'training_p': 5}. Best is trial 41 with value: 0.15215128660202026.
res:  tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  275.4252219200134
Memory status after this trial: 
Memory allocated:  187.896484375
Memory cached:  418.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.23030306240011, 'log_learning_rate_D': -3.247642493173979, 'log_learning_rate_D_dagger': -3.1525649204237025, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  410.0
	 epoch  10 training error:  tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  416.0
	 epoch  20 training error:  tensor(0.5293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  420.0
	 epoch  30 training error:  tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  422.0
	 epoch  40 training error:  tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  416.0
	 epoch  50 training error:  tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  424.0
	 epoch  60 training error:  tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  410.0
	 epoch  70 training error:  tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  416.0
	 epoch  80 training error:  tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  416.0
	 epoch  90 training error:  tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  197.07421875
Memory cached:  410.0
[I 2023-12-19 14:25:38,661] Trial 42 finished with value: 0.15608945488929749 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.23030306240011, 'log_learning_rate_D': -3.247642493173979, 'log_learning_rate_D_dagger': -3.1525649204237025, 'training_batch_size': 6, 'training_p': 5}. Best is trial 41 with value: 0.15215128660202026.
Time for this trial:  279.4628083705902
Memory status after this trial: 
Memory allocated:  397.3818359375
Memory cached:  412.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.414999424522586, 'log_learning_rate_D': -3.1860123187061, 'log_learning_rate_D_dagger': -3.154152298624671, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  412.0
	 epoch  10 training error:  tensor(0.5698, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  418.0
	 epoch  20 training error:  tensor(0.4866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  412.0
	 epoch  30 training error:  tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  412.0
	 epoch  40 training error:  tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  420.0
	 epoch  50 training error:  tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  420.0
	 epoch  60 training error:  tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  412.0
	 epoch  70 training error:  tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  420.0
	 epoch  80 training error:  tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  420.0
	 epoch  90 training error:  tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  196.544921875
Memory cached:  422.0
[I 2023-12-19 14:29:56,563] Trial 43 finished with value: 0.14781831204891205 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.414999424522586, 'log_learning_rate_D': -3.1860123187061, 'log_learning_rate_D_dagger': -3.154152298624671, 'training_batch_size': 6, 'training_p': 5}. Best is trial 43 with value: 0.14781831204891205.
res:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  257.6211049556732
Memory status after this trial: 
Memory allocated:  162.232421875
Memory cached:  410.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.340935894399521, 'log_learning_rate_D': -3.2474068882536655, 'log_learning_rate_D_dagger': -3.093250224470183, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  396.0
	 epoch  10 training error:  tensor(0.5375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  406.0
	 epoch  20 training error:  tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  404.0
	 epoch  30 training error:  tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  404.0
	 epoch  40 training error:  tensor(0.4798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  396.0
	 epoch  50 training error:  tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  404.0
	 epoch  60 training error:  tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  402.0
	 epoch  70 training error:  tensor(0.4643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  398.0
	 epoch  80 training error:  tensor(0.4939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  404.0
	 epoch  90 training error:  tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.880859375
Memory cached:  400.0
[I 2023-12-19 14:34:14,877] Trial 44 finished with value: 0.361601322889328 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.340935894399521, 'log_learning_rate_D': -3.2474068882536655, 'log_learning_rate_D_dagger': -3.093250224470183, 'training_batch_size': 6, 'training_p': 5}. Best is trial 43 with value: 0.14781831204891205.
Time for this trial:  258.07234954833984
Memory status after this trial: 
Memory allocated:  324.333984375
Memory cached:  396.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.680512297640655, 'log_learning_rate_D': -3.353429223456631, 'log_learning_rate_D_dagger': -2.8469499883114975, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  10 training error:  tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  20 training error:  tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  394.0
	 epoch  30 training error:  tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  40 training error:  tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  50 training error:  tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  60 training error:  tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  70 training error:  tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  80 training error:  tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
	 epoch  90 training error:  tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  171.19921875
Memory cached:  392.0
[I 2023-12-19 14:38:57,054] Trial 45 finished with value: 0.22369776666164398 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.680512297640655, 'log_learning_rate_D': -3.353429223456631, 'log_learning_rate_D_dagger': -2.8469499883114975, 'training_batch_size': 6, 'training_p': 5}. Best is trial 43 with value: 0.14781831204891205.
Time for this trial:  281.90470576286316
Memory status after this trial: 
Memory allocated:  387.984375
Memory cached:  402.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.171471571874873, 'log_learning_rate_D': -2.9477382342289036, 'log_learning_rate_D_dagger': -3.1041131863867113, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  392.0
	 epoch  10 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  394.0
	 epoch  20 training error:  tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  396.0
	 epoch  30 training error:  tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  396.0
	 epoch  40 training error:  tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  398.0
	 epoch  50 training error:  tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  394.0
	 epoch  60 training error:  tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  392.0
	 epoch  70 training error:  tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  394.0
	 epoch  80 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  394.0
	 epoch  90 training error:  tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  170.791015625
Memory cached:  392.0
[I 2023-12-19 14:43:12,972] Trial 46 finished with value: 0.16476289927959442 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.171471571874873, 'log_learning_rate_D': -2.9477382342289036, 'log_learning_rate_D_dagger': -3.1041131863867113, 'training_batch_size': 6, 'training_p': 5}. Best is trial 43 with value: 0.14781831204891205.
Time for this trial:  255.6387643814087
Memory status after this trial: 
Memory allocated:  307.73046875
Memory cached:  392.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.24833877646275, 'log_learning_rate_D': -2.8293347772732966, 'log_learning_rate_D_dagger': -3.5751446426666647, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  394.0
	 epoch  10 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  408.0
	 epoch  20 training error:  tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  402.0
	 epoch  30 training error:  tensor(0.4819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  404.0
	 epoch  40 training error:  tensor(0.4779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  412.0
	 epoch  50 training error:  tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  416.0
	 epoch  60 training error:  tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  400.0
	 epoch  70 training error:  tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  408.0
	 epoch  80 training error:  tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  404.0
	 epoch  90 training error:  tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  166.875
Memory cached:  400.0
[I 2023-12-19 14:45:39,169] Trial 47 finished with value: 0.3931303918361664 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.24833877646275, 'log_learning_rate_D': -2.8293347772732966, 'log_learning_rate_D_dagger': -3.5751446426666647, 'training_batch_size': 12, 'training_p': 5}. Best is trial 43 with value: 0.14781831204891205.
Time for this trial:  145.94289541244507
Memory status after this trial: 
Memory allocated:  292.0634765625
Memory cached:  398.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.7806254956937355, 'log_learning_rate_D': -3.489516645859246, 'log_learning_rate_D_dagger': -3.2289527196477357, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  392.0
	 epoch  10 training error:  tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  396.0
	 epoch  20 training error:  tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  396.0
	 epoch  30 training error:  tensor(0.5166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  394.0
	 epoch  40 training error:  tensor(0.5172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  394.0
	 epoch  50 training error:  tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  394.0
	 epoch  60 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  396.0
	 epoch  70 training error:  tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  394.0
	 epoch  80 training error:  tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  392.0
	 epoch  90 training error:  tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.66015625
Memory cached:  396.0
[I 2023-12-19 14:49:48,637] Trial 48 finished with value: 0.1520291566848755 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.7806254956937355, 'log_learning_rate_D': -3.489516645859246, 'log_learning_rate_D_dagger': -3.2289527196477357, 'training_batch_size': 6, 'training_p': 6}. Best is trial 43 with value: 0.14781831204891205.
Time for this trial:  249.19146513938904
Memory status after this trial: 
Memory allocated:  254.86328125
Memory cached:  394.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.78833407763212, 'log_learning_rate_D': -3.488191271683456, 'log_learning_rate_D_dagger': -3.2465717456390126, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.6466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  394.0
	 epoch  10 training error:  tensor(0.5229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  402.0
	 epoch  20 training error:  tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  398.0
	 epoch  30 training error:  tensor(0.5186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  402.0
	 epoch  40 training error:  tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  398.0
	 epoch  50 training error:  tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  398.0
	 epoch  60 training error:  tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  402.0
	 epoch  70 training error:  tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  400.0
	 epoch  80 training error:  tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  400.0
	 epoch  90 training error:  tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  163.80859375
Memory cached:  398.0
[I 2023-12-19 14:54:04,405] Trial 49 finished with value: 0.12959282100200653 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.78833407763212, 'log_learning_rate_D': -3.488191271683456, 'log_learning_rate_D_dagger': -3.2465717456390126, 'training_batch_size': 6, 'training_p': 6}. Best is trial 49 with value: 0.12959282100200653.
res:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  255.50085186958313
Memory status after this trial: 
Memory allocated:  132.9921875
Memory cached:  364.0
--------------------  Trial  50   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.819761022456262, 'log_learning_rate_D': -3.6338703892395987, 'log_learning_rate_D_dagger': -3.2876959553338856, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  360.0
	 epoch  10 training error:  tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  370.0
	 epoch  20 training error:  tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  366.0
	 epoch  30 training error:  tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  372.0
	 epoch  40 training error:  tensor(0.5350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  364.0
	 epoch  50 training error:  tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  368.0
	 epoch  60 training error:  tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  366.0
	 epoch  70 training error:  tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  372.0
	 epoch  80 training error:  tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  368.0
	 epoch  90 training error:  tensor(0.5324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.759765625
Memory cached:  368.0
[I 2023-12-19 14:56:25,427] Trial 50 finished with value: 0.39546841382980347 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.819761022456262, 'log_learning_rate_D': -3.6338703892395987, 'log_learning_rate_D_dagger': -3.2876959553338856, 'training_batch_size': 11, 'training_p': 7}. Best is trial 49 with value: 0.12959282100200653.
Time for this trial:  140.774329662323
Memory status after this trial: 
Memory allocated:  276.71923828125
Memory cached:  364.0
--------------------  Trial  51   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.963689121561244, 'log_learning_rate_D': -3.2304142352252163, 'log_learning_rate_D_dagger': -3.372678110730876, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  10 training error:  tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  20 training error:  tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  362.0
	 epoch  30 training error:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  40 training error:  tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  50 training error:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  60 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  70 training error:  tensor(0.4966, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.044921875
Memory cached:  362.0
[I 2023-12-19 15:00:38,107] Trial 51 finished with value: 0.22425022721290588 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.963689121561244, 'log_learning_rate_D': -3.2304142352252163, 'log_learning_rate_D_dagger': -3.372678110730876, 'training_batch_size': 6, 'training_p': 6}. Best is trial 49 with value: 0.12959282100200653.
Time for this trial:  252.39586973190308
Memory status after this trial: 
Memory allocated:  249.087890625
Memory cached:  360.0
--------------------  Trial  52   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.671897828357407, 'log_learning_rate_D': -3.542795009515315, 'log_learning_rate_D_dagger': -3.1111704274424574, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  360.0
	 epoch  10 training error:  tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  360.0
	 epoch  20 training error:  tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  362.0
	 epoch  30 training error:  tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  364.0
	 epoch  40 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  362.0
	 epoch  50 training error:  tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  362.0
	 epoch  60 training error:  tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  364.0
	 epoch  70 training error:  tensor(0.3298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  360.0
	 epoch  80 training error:  tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  360.0
	 epoch  90 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.451171875
Memory cached:  362.0
[I 2023-12-19 15:04:52,610] Trial 52 finished with value: 0.12607868015766144 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.671897828357407, 'log_learning_rate_D': -3.542795009515315, 'log_learning_rate_D_dagger': -3.1111704274424574, 'training_batch_size': 6, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
res:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  254.2278754711151
Memory status after this trial: 
Memory allocated:  133.70703125
Memory cached:  320.0
--------------------  Trial  53   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.46698647687837, 'log_learning_rate_D': -3.5822514789969997, 'log_learning_rate_D_dagger': -3.189225191446552, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  318.0
	 epoch  10 training error:  tensor(0.5327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  324.0
	 epoch  20 training error:  tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  330.0
	 epoch  30 training error:  tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  330.0
	 epoch  40 training error:  tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.3671875
Memory cached:  320.0
[I 2023-12-19 15:08:58,407] Trial 53 finished with value: 0.13934658467769623 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.46698647687837, 'log_learning_rate_D': -3.5822514789969997, 'log_learning_rate_D_dagger': -3.189225191446552, 'training_batch_size': 6, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  245.54709696769714
Memory status after this trial: 
Memory allocated:  304.57763671875
Memory cached:  324.0
--------------------  Trial  54   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.536583961214566, 'log_learning_rate_D': -3.5381712944071775, 'log_learning_rate_D_dagger': -3.8101821625906216, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.5481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  332.0
	 epoch  20 training error:  tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.5341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  324.0
	 epoch  40 training error:  tensor(0.5319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.5298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  322.0
	 epoch  70 training error:  tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.73046875
Memory cached:  326.0
[I 2023-12-19 15:13:12,314] Trial 54 finished with value: 0.4189437925815582 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.536583961214566, 'log_learning_rate_D': -3.5381712944071775, 'log_learning_rate_D_dagger': -3.8101821625906216, 'training_batch_size': 6, 'training_p': 7}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  253.58708477020264
Memory status after this trial: 
Memory allocated:  256.47998046875
Memory cached:  328.0
--------------------  Trial  55   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.768941458834728, 'log_learning_rate_D': -3.7037449106285374, 'log_learning_rate_D_dagger': -3.451394874639955, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  322.0
	 epoch  10 training error:  tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  330.0
	 epoch  40 training error:  tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  332.0
	 epoch  70 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.5108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.296875
Memory cached:  332.0
[I 2023-12-19 15:17:16,118] Trial 55 finished with value: 0.369472473859787 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.768941458834728, 'log_learning_rate_D': -3.7037449106285374, 'log_learning_rate_D_dagger': -3.451394874639955, 'training_batch_size': 6, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  243.5282964706421
Memory status after this trial: 
Memory allocated:  292.82373046875
Memory cached:  332.0
--------------------  Trial  56   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.448932958978654, 'log_learning_rate_D': -3.7630732662760167, 'log_learning_rate_D_dagger': -3.009414389757902, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.5228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  322.0
	 epoch  40 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  328.0
	 epoch  60 training error:  tensor(0.4813, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.509765625
Memory cached:  322.0
[I 2023-12-19 15:21:33,360] Trial 56 finished with value: 0.1869470775127411 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.448932958978654, 'log_learning_rate_D': -3.7630732662760167, 'log_learning_rate_D_dagger': -3.009414389757902, 'training_batch_size': 6, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  256.9545650482178
Memory status after this trial: 
Memory allocated:  279.357421875
Memory cached:  320.0
--------------------  Trial  57   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.666308479881424, 'log_learning_rate_D': -3.4863270079931996, 'log_learning_rate_D_dagger': -3.239244926371407, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  332.0
	 epoch  20 training error:  tensor(0.5493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  338.0
	 epoch  30 training error:  tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  340.0
	 epoch  40 training error:  tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  336.0
	 epoch  50 training error:  tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  342.0
	 epoch  60 training error:  tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  344.0
	 epoch  80 training error:  tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  340.0
	 epoch  90 training error:  tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.267578125
Memory cached:  334.0
[I 2023-12-19 15:24:19,814] Trial 57 finished with value: 0.3339516818523407 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 7, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -4.666308479881424, 'log_learning_rate_D': -3.4863270079931996, 'log_learning_rate_D_dagger': -3.239244926371407, 'training_batch_size': 7, 'training_p': 7}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  166.11406898498535
Memory status after this trial: 
Memory allocated:  305.6943359375
Memory cached:  326.0
--------------------  Trial  58   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.863594547604199, 'log_learning_rate_D': -3.3873958558906243, 'log_learning_rate_D_dagger': -2.6137401049826083, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  10 training error:  tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  40 training error:  tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  50 training error:  tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  60 training error:  tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  80 training error:  tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
	 epoch  90 training error:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.498046875
Memory cached:  316.0
[I 2023-12-19 15:28:43,270] Trial 58 finished with value: 0.1378975659608841 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.863594547604199, 'log_learning_rate_D': -3.3873958558906243, 'log_learning_rate_D_dagger': -2.6137401049826083, 'training_batch_size': 6, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  263.1589517593384
Memory status after this trial: 
Memory allocated:  329.083984375
Memory cached:  332.0
--------------------  Trial  59   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.859247448618438, 'log_learning_rate_D': -3.4255616066844916, 'log_learning_rate_D_dagger': -2.5763548471457858, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  318.0
	 epoch  10 training error:  tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  336.0
	 epoch  20 training error:  tensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  336.0
	 epoch  30 training error:  tensor(0.5476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  340.0
	 epoch  40 training error:  tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  336.0
	 epoch  50 training error:  tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  336.0
	 epoch  60 training error:  tensor(0.5255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  334.0
	 epoch  80 training error:  tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  334.0
	 epoch  90 training error:  tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  135.580078125
Memory cached:  338.0
[I 2023-12-19 15:31:17,650] Trial 59 finished with value: 0.3500724732875824 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.859247448618438, 'log_learning_rate_D': -3.4255616066844916, 'log_learning_rate_D_dagger': -2.5763548471457858, 'training_batch_size': 7, 'training_p': 6}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  154.10759162902832
Memory status after this trial: 
Memory allocated:  307.36376953125
Memory cached:  332.0
--------------------  Trial  60   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.987450230772325, 'log_learning_rate_D': -3.729916079154696, 'log_learning_rate_D_dagger': -2.658379790198211, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  318.0
	 epoch  10 training error:  tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.5503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  322.0
	 epoch  40 training error:  tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  332.0
	 epoch  60 training error:  tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  322.0
	 epoch  70 training error:  tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.611328125
Memory cached:  322.0
[I 2023-12-19 15:35:35,648] Trial 60 finished with value: 0.15315304696559906 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.987450230772325, 'log_learning_rate_D': -3.729916079154696, 'log_learning_rate_D_dagger': -2.658379790198211, 'training_batch_size': 6, 'training_p': 8}. Best is trial 52 with value: 0.12607868015766144.
Time for this trial:  257.71659231185913
Memory status after this trial: 
Memory allocated:  282.009765625
Memory cached:  318.0
--------------------  Trial  61   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.667733688986365, 'log_learning_rate_D': -3.423589477417956, 'log_learning_rate_D_dagger': -2.9995593874705873, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  320.0
	 epoch  10 training error:  tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.5283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  328.0
	 epoch  30 training error:  tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  136.30859375
Memory cached:  324.0
[I 2023-12-19 15:40:05,236] Trial 61 finished with value: 0.12358158081769943 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.667733688986365, 'log_learning_rate_D': -3.423589477417956, 'log_learning_rate_D_dagger': -2.9995593874705873, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
res:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  269.29935669898987
Memory status after this trial: 
Memory allocated:  136.0732421875
Memory cached:  314.0
--------------------  Trial  62   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.68168519387825, 'log_learning_rate_D': -3.3690839966449646, 'log_learning_rate_D_dagger': -3.359186340907507, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  328.0
	 epoch  20 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.5152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  322.0
	 epoch  40 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  326.0
	 epoch  60 training error:  tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  320.0
	 epoch  90 training error:  tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.6748046875
Memory cached:  322.0
[I 2023-12-19 15:44:36,007] Trial 62 finished with value: 0.1763036698102951 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.68168519387825, 'log_learning_rate_D': -3.3690839966449646, 'log_learning_rate_D_dagger': -3.359186340907507, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  270.5035123825073
Memory status after this trial: 
Memory allocated:  272.015625
Memory cached:  318.0
--------------------  Trial  63   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -4.444354323412091, 'log_learning_rate_D': -3.568981656544514, 'log_learning_rate_D_dagger': -3.054831562214103, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.2670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  312.0
	 epoch  10 training error:  tensor(0.6009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  316.0
	 epoch  60 training error:  tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  320.0
	 epoch  90 training error:  tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  139.8701171875
Memory cached:  320.0
[I 2023-12-19 15:49:02,862] Trial 63 finished with value: 0.2779437005519867 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 7, 'log_learning_rate': -4.444354323412091, 'log_learning_rate_D': -3.568981656544514, 'log_learning_rate_D_dagger': -3.054831562214103, 'training_batch_size': 6, 'training_p': 7}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  266.55472135543823
Memory status after this trial: 
Memory allocated:  344.62158203125
Memory cached:  348.0
--------------------  Trial  64   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.8491169283122, 'log_learning_rate_D': -3.8410760368865144, 'log_learning_rate_D_dagger': -3.560935567494866, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  316.0
	 epoch  10 training error:  tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  334.0
	 epoch  20 training error:  tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  334.0
	 epoch  30 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  332.0
	 epoch  40 training error:  tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  332.0
	 epoch  50 training error:  tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  332.0
	 epoch  60 training error:  tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  334.0
	 epoch  70 training error:  tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.8603515625
Memory cached:  328.0
[I 2023-12-19 15:53:34,923] Trial 64 finished with value: 0.23220716416835785 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 5, 'log_learning_rate': -4.8491169283122, 'log_learning_rate_D': -3.8410760368865144, 'log_learning_rate_D_dagger': -3.560935567494866, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  271.76131224632263
Memory status after this trial: 
Memory allocated:  297.0673828125
Memory cached:  320.0
--------------------  Trial  65   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.684689301560913, 'log_learning_rate_D': -3.9626359201357557, 'log_learning_rate_D_dagger': -3.1911122975835817, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  316.0
	 epoch  10 training error:  tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  332.0
	 epoch  20 training error:  tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  330.0
	 epoch  50 training error:  tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  330.0
	 epoch  60 training error:  tensor(0.5368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  338.0
	 epoch  70 training error:  tensor(0.5314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.5308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.5350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.0869140625
Memory cached:  324.0
[I 2023-12-19 15:56:12,951] Trial 65 finished with value: 0.424567848443985 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.684689301560913, 'log_learning_rate_D': -3.9626359201357557, 'log_learning_rate_D_dagger': -3.1911122975835817, 'training_batch_size': 7, 'training_p': 7}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  157.7391757965088
Memory status after this trial: 
Memory allocated:  283.494140625
Memory cached:  316.0
--------------------  Trial  66   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.5288364659470215, 'log_learning_rate_D': -3.640734146980316, 'log_learning_rate_D_dagger': -2.745862284472275, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.5350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  318.0
	 epoch  20 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1435546875
Memory cached:  316.0
[I 2023-12-19 16:00:16,241] Trial 66 finished with value: 0.16306279599666595 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.5288364659470215, 'log_learning_rate_D': -3.640734146980316, 'log_learning_rate_D_dagger': -2.745862284472275, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  243.00367856025696
Memory status after this trial: 
Memory allocated:  284.12744140625
Memory cached:  320.0
--------------------  Trial  67   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.988160712948823, 'log_learning_rate_D': -3.532951774454241, 'log_learning_rate_D_dagger': -3.0043562411743183, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  312.0
	 epoch  10 training error:  tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.5349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.5446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  328.0
	 epoch  50 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  322.0
	 epoch  70 training error:  tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  328.0
	 epoch  90 training error:  tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.7451171875
Memory cached:  328.0
[I 2023-12-19 16:02:53,238] Trial 67 finished with value: 0.37920913100242615 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.988160712948823, 'log_learning_rate_D': -3.532951774454241, 'log_learning_rate_D_dagger': -3.0043562411743183, 'training_batch_size': 7, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  156.7109079360962
Memory status after this trial: 
Memory allocated:  280.6552734375
Memory cached:  316.0
--------------------  Trial  68   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.37068550980766, 'log_learning_rate_D': -3.342264115557106, 'log_learning_rate_D_dagger': -3.2699435413205693, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.2084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  316.0
	 epoch  10 training error:  tensor(0.6432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  318.0
	 epoch  60 training error:  tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  318.0
	 epoch  70 training error:  tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.9853515625
Memory cached:  318.0
[I 2023-12-19 16:05:40,450] Trial 68 finished with value: 0.4072940945625305 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.37068550980766, 'log_learning_rate_D': -3.342264115557106, 'log_learning_rate_D_dagger': -3.2699435413205693, 'training_batch_size': 7, 'training_p': 7}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  166.91934847831726
Memory status after this trial: 
Memory allocated:  333.1767578125
Memory cached:  336.0
--------------------  Trial  69   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -4.797169402659754, 'log_learning_rate_D': -3.445312787838993, 'log_learning_rate_D_dagger': -2.5860075622179477, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  314.0
	 epoch  10 training error:  tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  318.0
	 epoch  30 training error:  tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  318.0
	 epoch  60 training error:  tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  320.0
	 epoch  80 training error:  tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1728515625
Memory cached:  324.0
[I 2023-12-19 16:08:20,409] Trial 69 finished with value: 0.35991427302360535 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 6, 'D_dagger_layer_units_exponent_5': 6, 'D_dagger_layer_units_exponent_6': 4, 'log_learning_rate': -4.797169402659754, 'log_learning_rate_D': -3.445312787838993, 'log_learning_rate_D_dagger': -2.5860075622179477, 'training_batch_size': 9, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  159.638277053833
Memory status after this trial: 
Memory allocated:  258.92919921875
Memory cached:  314.0
--------------------  Trial  70   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.604054924026167, 'log_learning_rate_D': -3.1794367367890914, 'log_learning_rate_D_dagger': -3.33482250630026, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  20 training error:  tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  314.0
	 epoch  70 training error:  tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
[I 2023-12-19 16:12:53,153] Trial 70 finished with value: 0.3746856451034546 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.604054924026167, 'log_learning_rate_D': -3.1794367367890914, 'log_learning_rate_D_dagger': -3.33482250630026, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  272.43234634399414
Memory status after this trial: 
Memory allocated:  278.8505859375
Memory cached:  314.0
--------------------  Trial  71   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -4.4106896003595395, 'log_learning_rate_D': -3.3019210124077225, 'log_learning_rate_D_dagger': -2.9955991273867086, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  330.0
	 epoch  20 training error:  tensor(0.4908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  336.0
	 epoch  30 training error:  tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  338.0
	 epoch  50 training error:  tensor(0.4851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  336.0
	 epoch  60 training error:  tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  328.0
	 epoch  70 training error:  tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  147.0126953125
Memory cached:  342.0
[I 2023-12-19 16:18:14,540] Trial 71 finished with value: 0.3932032585144043 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 8, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'D_dagger_layer_units_exponent_4': 9, 'D_dagger_layer_units_exponent_5': 8, 'D_dagger_layer_units_exponent_6': 6, 'D_dagger_layer_units_exponent_7': 7, 'log_learning_rate': -4.4106896003595395, 'log_learning_rate_D': -3.3019210124077225, 'log_learning_rate_D_dagger': -2.9955991273867086, 'training_batch_size': 6, 'training_p': 5}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  321.0570230484009
Memory status after this trial: 
Memory allocated:  333.5576171875
Memory cached:  340.0
--------------------  Trial  72   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.5612190041010825, 'log_learning_rate_D': -3.1487248290173215, 'log_learning_rate_D_dagger': -2.761252921470061, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  314.0
	 epoch  10 training error:  tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  324.0
	 epoch  20 training error:  tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  322.0
	 epoch  50 training error:  tensor(0.3811, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  326.0
	 epoch  70 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  316.0
	 epoch  80 training error:  tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9208984375
Memory cached:  330.0
[I 2023-12-19 16:22:43,360] Trial 72 finished with value: 0.16655801236629486 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.5612190041010825, 'log_learning_rate_D': -3.1487248290173215, 'log_learning_rate_D_dagger': -2.761252921470061, 'training_batch_size': 6, 'training_p': 5}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  268.45081210136414
Memory status after this trial: 
Memory allocated:  270.46875
Memory cached:  318.0
--------------------  Trial  73   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.74494337005095, 'log_learning_rate_D': -2.982525292235537, 'log_learning_rate_D_dagger': -3.1471653169874427, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.5308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  20 training error:  tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  312.0
	 epoch  30 training error:  tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  50 training error:  tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  60 training error:  tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  70 training error:  tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
	 epoch  90 training error:  tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5712890625
Memory cached:  310.0
[I 2023-12-19 16:26:27,338] Trial 73 finished with value: 0.13200132548809052 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.74494337005095, 'log_learning_rate_D': -2.982525292235537, 'log_learning_rate_D_dagger': -3.1471653169874427, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  223.6874635219574
Memory status after this trial: 
Memory allocated:  244.58740234375
Memory cached:  310.0
--------------------  Trial  74   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.873583000548843, 'log_learning_rate_D': -2.9627758892505436, 'log_learning_rate_D_dagger': -3.105582313264933, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  312.0
	 epoch  10 training error:  tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  326.0
	 epoch  50 training error:  tensor(0.5208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.5228, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.5208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.1279296875
Memory cached:  320.0
[I 2023-12-19 16:30:26,228] Trial 74 finished with value: 0.4133307635784149 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.873583000548843, 'log_learning_rate_D': -2.9627758892505436, 'log_learning_rate_D_dagger': -3.105582313264933, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  238.49025082588196
Memory status after this trial: 
Memory allocated:  250.11572265625
Memory cached:  316.0
--------------------  Trial  75   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.759135568653205, 'log_learning_rate_D': -3.4110131402714043, 'log_learning_rate_D_dagger': -3.463586797181425, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  312.0
	 epoch  10 training error:  tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  326.0
	 epoch  40 training error:  tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  316.0
	 epoch  60 training error:  tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.5869140625
Memory cached:  316.0
[I 2023-12-19 16:34:11,799] Trial 75 finished with value: 0.14473025500774384 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.759135568653205, 'log_learning_rate_D': -3.4110131402714043, 'log_learning_rate_D_dagger': -3.463586797181425, 'training_batch_size': 6, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  225.2881565093994
Memory status after this trial: 
Memory allocated:  270.20068359375
Memory cached:  316.0
--------------------  Trial  76   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.635423445944199, 'log_learning_rate_D': -3.39965959293571, 'log_learning_rate_D_dagger': -3.4099676803315555, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  322.0
	 epoch  10 training error:  tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  334.0
	 epoch  20 training error:  tensor(0.5239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  330.0
	 epoch  30 training error:  tensor(0.5428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  332.0
	 epoch  50 training error:  tensor(0.5163, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  336.0
	 epoch  70 training error:  tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  330.0
	 epoch  80 training error:  tensor(0.5217, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  330.0
	 epoch  90 training error:  tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.9306640625
Memory cached:  336.0
[I 2023-12-19 16:36:24,735] Trial 76 finished with value: 0.384745329618454 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.635423445944199, 'log_learning_rate_D': -3.39965959293571, 'log_learning_rate_D_dagger': -3.4099676803315555, 'training_batch_size': 11, 'training_p': 6}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  132.67362141609192
Memory status after this trial: 
Memory allocated:  316.34912109375
Memory cached:  324.0
--------------------  Trial  77   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.340304893020714, 'log_learning_rate_D': -3.5952264569974233, 'log_learning_rate_D_dagger': -3.493320756360567, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  10 training error:  tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  20 training error:  tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  50 training error:  tensor(0.5415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  60 training error:  tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  70 training error:  tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
	 epoch  80 training error:  tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.9697265625
Memory cached:  310.0
[I 2023-12-19 16:40:14,263] Trial 77 finished with value: 0.41395559906959534 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.340304893020714, 'log_learning_rate_D': -3.5952264569974233, 'log_learning_rate_D_dagger': -3.493320756360567, 'training_batch_size': 6, 'training_p': 7}. Best is trial 61 with value: 0.12358158081769943.
Time for this trial:  229.13593411445618
Memory status after this trial: 
Memory allocated:  285.52880859375
Memory cached:  310.0
--------------------  Trial  78   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.7479745294998565, 'log_learning_rate_D': -3.1921264503030287, 'log_learning_rate_D_dagger': -2.9277991988949226, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  312.0
	 epoch  10 training error:  tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  322.0
	 epoch  50 training error:  tensor(0.3932, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  322.0
	 epoch  70 training error:  tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  328.0
	 epoch  80 training error:  tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  137.4638671875
Memory cached:  318.0
[I 2023-12-19 16:42:26,268] Trial 78 finished with value: 0.11363521963357925 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.7479745294998565, 'log_learning_rate_D': -3.1921264503030287, 'log_learning_rate_D_dagger': -2.9277991988949226, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
res:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  131.7421591281891
Memory status after this trial: 
Memory allocated:  123.40576171875
Memory cached:  298.0
--------------------  Trial  79   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.718688406385708, 'log_learning_rate_D': -3.818761301725922, 'log_learning_rate_D_dagger': -2.9482242585220733, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  306.0
	 epoch  10 training error:  tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  316.0
	 epoch  40 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  312.0
	 epoch  60 training error:  tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  310.0
	 epoch  80 training error:  tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  320.0
	 epoch  90 training error:  tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.09619140625
Memory cached:  322.0
[I 2023-12-19 16:44:37,937] Trial 79 finished with value: 0.30756863951683044 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.718688406385708, 'log_learning_rate_D': -3.818761301725922, 'log_learning_rate_D_dagger': -2.9482242585220733, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  131.4122598171234
Memory status after this trial: 
Memory allocated:  247.435546875
Memory cached:  312.0
--------------------  Trial  80   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.879549936794227, 'log_learning_rate_D': -2.9767459978369053, 'log_learning_rate_D_dagger': -2.7155147708733876, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9278, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  304.0
	 epoch  30 training error:  tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  306.0
	 epoch  40 training error:  tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  300.0
	 epoch  50 training error:  tensor(0.5166, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  304.0
	 epoch  70 training error:  tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  300.0
	 epoch  80 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  300.0
	 epoch  90 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.88525390625
Memory cached:  306.0
[I 2023-12-19 16:46:43,857] Trial 80 finished with value: 0.43862056732177734 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.879549936794227, 'log_learning_rate_D': -2.9767459978369053, 'log_learning_rate_D_dagger': -2.7155147708733876, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  125.6446943283081
Memory status after this trial: 
Memory allocated:  211.61328125
Memory cached:  296.0
--------------------  Trial  81   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.588124328694308, 'log_learning_rate_D': -3.2052364308618326, 'log_learning_rate_D_dagger': -3.155550252627782, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 16:50:29,734] Trial 81 finished with value: 0.13913743197917938 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.588124328694308, 'log_learning_rate_D': -3.2052364308618326, 'log_learning_rate_D_dagger': -3.155550252627782, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.59387874603271
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  82   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.584752712632287, 'log_learning_rate_D': -3.310345054678499, 'log_learning_rate_D_dagger': -2.926952511975111, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 16:54:15,748] Trial 82 finished with value: 0.1513272076845169 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.584752712632287, 'log_learning_rate_D': -3.310345054678499, 'log_learning_rate_D_dagger': -2.926952511975111, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.7255139350891
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  83   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.761787280082905, 'log_learning_rate_D': -3.2276719070707283, 'log_learning_rate_D_dagger': -3.094688867312999, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9068, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 16:58:01,008] Trial 83 finished with value: 0.16112880408763885 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.761787280082905, 'log_learning_rate_D': -3.2276719070707283, 'log_learning_rate_D_dagger': -3.094688867312999, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.971830368042
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  84   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.888093172513246, 'log_learning_rate_D': -3.4456359918748682, 'log_learning_rate_D_dagger': -3.2888906919585414, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.4957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 17:01:47,239] Trial 84 finished with value: 0.11423399299383163 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.888093172513246, 'log_learning_rate_D': -3.4456359918748682, 'log_learning_rate_D_dagger': -3.2888906919585414, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.94141697883606
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  85   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.999245666398529, 'log_learning_rate_D': -3.0873042190768833, 'log_learning_rate_D_dagger': -3.1686088103135264, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  302.0
	 epoch  10 training error:  tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  320.0
	 epoch  40 training error:  tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  310.0
	 epoch  60 training error:  tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.5023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  314.0
	 epoch  90 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84619140625
Memory cached:  314.0
[I 2023-12-19 17:03:58,556] Trial 85 finished with value: 0.24764589965343475 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.999245666398529, 'log_learning_rate_D': -3.0873042190768833, 'log_learning_rate_D_dagger': -3.1686088103135264, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  131.0416693687439
Memory status after this trial: 
Memory allocated:  246.73046875
Memory cached:  314.0
--------------------  Trial  86   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.485469088331229, 'log_learning_rate_D': -2.858081813353335, 'log_learning_rate_D_dagger': -2.8327462838029756, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  308.0
	 epoch  20 training error:  tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  30 training error:  tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  40 training error:  tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  50 training error:  tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  60 training error:  tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  70 training error:  tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  304.0
	 epoch  80 training error:  tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
	 epoch  90 training error:  tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.73681640625
Memory cached:  302.0
[I 2023-12-19 17:07:55,017] Trial 86 finished with value: 0.1583235114812851 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.485469088331229, 'log_learning_rate_D': -2.858081813353335, 'log_learning_rate_D_dagger': -2.8327462838029756, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  236.03982663154602
Memory status after this trial: 
Memory allocated:  224.0
Memory cached:  304.0
--------------------  Trial  87   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.616679780744001, 'log_learning_rate_D': -3.6727689761770623, 'log_learning_rate_D_dagger': -3.3123927021719806, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.83837890625
Memory cached:  294.0
[I 2023-12-19 17:11:25,964] Trial 87 finished with value: 0.40843692421913147 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.616679780744001, 'log_learning_rate_D': -3.6727689761770623, 'log_learning_rate_D_dagger': -3.3123927021719806, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  210.6580455303192
Memory status after this trial: 
Memory allocated:  244.810546875
Memory cached:  294.0
--------------------  Trial  88   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.899219276777326, 'log_learning_rate_D': -3.2993586094535865, 'log_learning_rate_D_dagger': -3.0071912699209533, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  308.0
	 epoch  20 training error:  tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  302.0
	 epoch  30 training error:  tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  304.0
	 epoch  40 training error:  tensor(0.5384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  308.0
	 epoch  50 training error:  tensor(0.4982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  302.0
	 epoch  60 training error:  tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.4449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  304.0
	 epoch  80 training error:  tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  304.0
	 epoch  90 training error:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.18212890625
Memory cached:  304.0
[I 2023-12-19 17:15:39,460] Trial 88 finished with value: 0.1521197110414505 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.899219276777326, 'log_learning_rate_D': -3.2993586094535865, 'log_learning_rate_D_dagger': -3.0071912699209533, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  253.19096660614014
Memory status after this trial: 
Memory allocated:  239.421875
Memory cached:  302.0
--------------------  Trial  89   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.713611457020508, 'log_learning_rate_D': -3.511179660252324, 'log_learning_rate_D_dagger': -2.7987012430626477, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.7567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  314.0
	 epoch  20 training error:  tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  324.0
	 epoch  30 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.5264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.37158203125
Memory cached:  322.0
[I 2023-12-19 17:18:04,651] Trial 89 finished with value: 0.39918217062950134 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.713611457020508, 'log_learning_rate_D': -3.511179660252324, 'log_learning_rate_D_dagger': -2.7987012430626477, 'training_batch_size': 10, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  144.9047930240631
Memory status after this trial: 
Memory allocated:  291.4677734375
Memory cached:  314.0
--------------------  Trial  90   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.902490448445444, 'log_learning_rate_D': -3.0282080842069936, 'log_learning_rate_D_dagger': -3.192229511685871, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  308.0
	 epoch  10 training error:  tensor(0.5812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.5559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.5442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  324.0
	 epoch  40 training error:  tensor(0.5362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.5350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.5346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  326.0
	 epoch  80 training error:  tensor(0.5348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  326.0
	 epoch  90 training error:  tensor(0.5333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.57470703125
Memory cached:  326.0
[I 2023-12-19 17:20:32,068] Trial 90 finished with value: 0.438566654920578 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.902490448445444, 'log_learning_rate_D': -3.0282080842069936, 'log_learning_rate_D_dagger': -3.192229511685871, 'training_batch_size': 7, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  147.12265753746033
Memory status after this trial: 
Memory allocated:  293.16650390625
Memory cached:  314.0
--------------------  Trial  91   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.776684113259283, 'log_learning_rate_D': -3.4237737692150625, 'log_learning_rate_D_dagger': -3.419213473672751, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 17:24:17,018] Trial 91 finished with value: 0.13284434378147125 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.776684113259283, 'log_learning_rate_D': -3.4237737692150625, 'log_learning_rate_D_dagger': -3.419213473672751, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.6531946659088
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  92   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.500021713450963, 'log_learning_rate_D': -3.136716218977887, 'log_learning_rate_D_dagger': -3.308842871603278, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 17:28:01,214] Trial 92 finished with value: 0.13560234010219574 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.500021713450963, 'log_learning_rate_D': -3.136716218977887, 'log_learning_rate_D_dagger': -3.308842871603278, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  223.91044735908508
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  93   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.811138900350122, 'log_learning_rate_D': -3.1452369226392927, 'log_learning_rate_D_dagger': -2.925076246646451, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 17:31:47,499] Trial 93 finished with value: 0.13731293380260468 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.811138900350122, 'log_learning_rate_D': -3.1452369226392927, 'log_learning_rate_D_dagger': -2.925076246646451, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.98906874656677
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  94   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.922964666741742, 'log_learning_rate_D': -3.129204866728981, 'log_learning_rate_D_dagger': -3.3160355793510554, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.6003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.83837890625
Memory cached:  294.0
[I 2023-12-19 17:35:18,141] Trial 94 finished with value: 0.29455068707466125 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.922964666741742, 'log_learning_rate_D': -3.129204866728981, 'log_learning_rate_D_dagger': -3.3160355793510554, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  210.34203338623047
Memory status after this trial: 
Memory allocated:  248.240234375
Memory cached:  294.0
--------------------  Trial  95   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.808355777600738, 'log_learning_rate_D': -2.8738033698734253, 'log_learning_rate_D_dagger': -2.9493449318372913, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.3039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5032, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4777, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4821, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.97705078125
Memory cached:  294.0
[I 2023-12-19 17:39:08,198] Trial 95 finished with value: 0.4172709584236145 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.808355777600738, 'log_learning_rate_D': -2.8738033698734253, 'log_learning_rate_D_dagger': -2.9493449318372913, 'training_batch_size': 6, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  229.73769068717957
Memory status after this trial: 
Memory allocated:  178.67626953125
Memory cached:  294.0
--------------------  Trial  96   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.7403594977716015, 'log_learning_rate_D': -3.461607402858151, 'log_learning_rate_D_dagger': -3.075161637520294, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0992, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.10595703125
Memory cached:  294.0
[I 2023-12-19 17:42:53,923] Trial 96 finished with value: 0.1470937728881836 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.7403594977716015, 'log_learning_rate_D': -3.461607402858151, 'log_learning_rate_D_dagger': -3.075161637520294, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.4325783252716
Memory status after this trial: 
Memory allocated:  247.3916015625
Memory cached:  294.0
--------------------  Trial  97   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.643538714821992, 'log_learning_rate_D': -3.3070701493272896, 'log_learning_rate_D_dagger': -2.886683909601823, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  20 training error:  tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  30 training error:  tensor(0.5117, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  40 training error:  tensor(0.5062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  50 training error:  tensor(0.4882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  60 training error:  tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  304.0
	 epoch  70 training error:  tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  80 training error:  tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  306.0
	 epoch  90 training error:  tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.34814453125
Memory cached:  304.0
[I 2023-12-19 17:47:04,922] Trial 97 finished with value: 0.1645670235157013 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.643538714821992, 'log_learning_rate_D': -3.3070701493272896, 'log_learning_rate_D_dagger': -2.886683909601823, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  250.67941212654114
Memory status after this trial: 
Memory allocated:  221.21533203125
Memory cached:  300.0
--------------------  Trial  98   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.833315731266429, 'log_learning_rate_D': -3.1400263036797798, 'log_learning_rate_D_dagger': -3.6303212033547694, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  302.0
	 epoch  20 training error:  tensor(0.4888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  310.0
	 epoch  30 training error:  tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  308.0
	 epoch  40 training error:  tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  304.0
	 epoch  70 training error:  tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  300.0
	 epoch  80 training error:  tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  304.0
	 epoch  90 training error:  tensor(0.4740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.67822265625
Memory cached:  302.0
[I 2023-12-19 17:49:11,958] Trial 98 finished with value: 0.3753516972064972 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.833315731266429, 'log_learning_rate_D': -3.1400263036797798, 'log_learning_rate_D_dagger': -3.6303212033547694, 'training_batch_size': 9, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  126.73812890052795
Memory status after this trial: 
Memory allocated:  222.06787109375
Memory cached:  296.0
--------------------  Trial  99   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.910296997571317, 'log_learning_rate_D': -2.727588363310928, 'log_learning_rate_D_dagger': -2.6678544129368436, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  302.0
	 epoch  10 training error:  tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.5244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.4971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  322.0
	 epoch  60 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  316.0
	 epoch  80 training error:  tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  322.0
	 epoch  90 training error:  tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.17822265625
Memory cached:  328.0
[I 2023-12-19 17:51:38,050] Trial 99 finished with value: 0.3993890881538391 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.910296997571317, 'log_learning_rate_D': -2.727588363310928, 'log_learning_rate_D_dagger': -2.6678544129368436, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  145.7921907901764
Memory status after this trial: 
Memory allocated:  255.935546875
Memory cached:  304.0
--------------------  Trial  100   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.495769952883702, 'log_learning_rate_D': -3.0345459096843626, 'log_learning_rate_D_dagger': -3.394502335435616, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.59423828125
Memory cached:  294.0
[I 2023-12-19 17:55:15,121] Trial 100 finished with value: 0.2970702350139618 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.495769952883702, 'log_learning_rate_D': -3.0345459096843626, 'log_learning_rate_D_dagger': -3.394502335435616, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  216.7720217704773
Memory status after this trial: 
Memory allocated:  189.9228515625
Memory cached:  294.0
--------------------  Trial  101   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.581562180407851, 'log_learning_rate_D': -3.235441983785338, 'log_learning_rate_D_dagger': -3.257335924681094, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 17:59:01,295] Trial 101 finished with value: 0.14226429164409637 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.581562180407851, 'log_learning_rate_D': -3.235441983785338, 'log_learning_rate_D_dagger': -3.257335924681094, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.88262176513672
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  102   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.682531840707809, 'log_learning_rate_D': -3.359821119157898, 'log_learning_rate_D_dagger': -3.161181954838578, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7406, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.5042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 18:02:47,536] Trial 102 finished with value: 0.36241358518600464 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.682531840707809, 'log_learning_rate_D': -3.359821119157898, 'log_learning_rate_D_dagger': -3.161181954838578, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.95029067993164
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  103   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.810931494496026, 'log_learning_rate_D': -3.2043989546349936, 'log_learning_rate_D_dagger': -2.9996636265063765, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.4929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 18:06:32,181] Trial 103 finished with value: 0.16780291497707367 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.810931494496026, 'log_learning_rate_D': -3.2043989546349936, 'log_learning_rate_D_dagger': -2.9996636265063765, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.3502700328827
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  104   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.574002360442958, 'log_learning_rate_D': -3.4317369427080813, 'log_learning_rate_D_dagger': -3.315616855324495, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7886, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
[I 2023-12-19 18:10:17,521] Trial 104 finished with value: 0.1902056187391281 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.574002360442958, 'log_learning_rate_D': -3.4317369427080813, 'log_learning_rate_D_dagger': -3.315616855324495, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.01346850395203
Memory status after this trial: 
Memory allocated:  246.6865234375
Memory cached:  294.0
--------------------  Trial  105   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -4.315334510205893, 'log_learning_rate_D': -2.932067233151337, 'log_learning_rate_D_dagger': -2.8825702098970716, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.6060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  302.0
	 epoch  20 training error:  tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  304.0
	 epoch  30 training error:  tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  304.0
	 epoch  40 training error:  tensor(0.4998, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  306.0
	 epoch  50 training error:  tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  308.0
	 epoch  70 training error:  tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  302.0
	 epoch  80 training error:  tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  304.0
	 epoch  90 training error:  tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.86181640625
Memory cached:  304.0
[I 2023-12-19 18:14:21,095] Trial 105 finished with value: 0.1392856240272522 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -4.315334510205893, 'log_learning_rate_D': -2.932067233151337, 'log_learning_rate_D_dagger': -2.8825702098970716, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  243.2602367401123
Memory status after this trial: 
Memory allocated:  274.76123046875
Memory cached:  298.0
--------------------  Trial  106   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.947723479951048, 'log_learning_rate_D': -3.6395887143648915, 'log_learning_rate_D_dagger': -3.0951360483327215, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  302.0
	 epoch  20 training error:  tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  302.0
	 epoch  30 training error:  tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.5066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  302.0
	 epoch  50 training error:  tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  300.0
	 epoch  70 training error:  tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  302.0
	 epoch  90 training error:  tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.78564453125
Memory cached:  302.0
[I 2023-12-19 18:18:16,484] Trial 106 finished with value: 0.17642319202423096 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 5, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.947723479951048, 'log_learning_rate_D': -3.6395887143648915, 'log_learning_rate_D_dagger': -3.0951360483327215, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  235.07647395133972
Memory status after this trial: 
Memory allocated:  217.2216796875
Memory cached:  298.0
--------------------  Trial  107   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.716042044229511, 'log_learning_rate_D': -3.5203374692113263, 'log_learning_rate_D_dagger': -3.5016924816994597, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.82275390625
Memory cached:  294.0
[I 2023-12-19 18:22:13,272] Trial 107 finished with value: 0.24915948510169983 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.716042044229511, 'log_learning_rate_D': -3.5203374692113263, 'log_learning_rate_D_dagger': -3.5016924816994597, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  236.47673654556274
Memory status after this trial: 
Memory allocated:  229.32275390625
Memory cached:  294.0
--------------------  Trial  108   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.480822403821035, 'log_learning_rate_D': -3.024496134489288, 'log_learning_rate_D_dagger': -3.259110547212974, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.4798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.85595703125
Memory cached:  294.0
[I 2023-12-19 18:25:58,376] Trial 108 finished with value: 0.16528908908367157 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.480822403821035, 'log_learning_rate_D': -3.024496134489288, 'log_learning_rate_D_dagger': -3.259110547212974, 'training_batch_size': 6, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.82304787635803
Memory status after this trial: 
Memory allocated:  246.6865234375
Memory cached:  294.0
--------------------  Trial  109   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.63014271983176, 'log_learning_rate_D': -3.157721548463396, 'log_learning_rate_D_dagger': -3.4038105334137776, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  322.0
	 epoch  20 training error:  tensor(0.5206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  320.0
	 epoch  30 training error:  tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  328.0
	 epoch  40 training error:  tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  324.0
	 epoch  50 training error:  tensor(0.5108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  324.0
	 epoch  60 training error:  tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  332.0
	 epoch  70 training error:  tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  324.0
	 epoch  80 training error:  tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  320.0
	 epoch  90 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25244140625
Memory cached:  326.0
[I 2023-12-19 18:28:28,830] Trial 109 finished with value: 0.4003579318523407 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 5, 'log_learning_rate': -4.63014271983176, 'log_learning_rate_D': -3.157721548463396, 'log_learning_rate_D_dagger': -3.4038105334137776, 'training_batch_size': 8, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  150.1870379447937
Memory status after this trial: 
Memory allocated:  241.080078125
Memory cached:  318.0
--------------------  Trial  110   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -4.996277435727033, 'log_learning_rate_D': -3.2927645812912543, 'log_learning_rate_D_dagger': -2.7968775155823207, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  314.0
	 epoch  20 training error:  tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.20166015625
Memory cached:  296.0
[I 2023-12-19 18:34:01,870] Trial 110 finished with value: 0.1430060863494873 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 6, 'log_learning_rate': -4.996277435727033, 'log_learning_rate_D': -3.2927645812912543, 'log_learning_rate_D_dagger': -2.7968775155823207, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  332.5751507282257
Memory status after this trial: 
Memory allocated:  307.5322265625
Memory cached:  312.0
--------------------  Trial  111   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.320014253454628, 'log_learning_rate_D': -2.8737357974249353, 'log_learning_rate_D_dagger': -2.8698335148990357, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.5305, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.7814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.87744140625
Memory cached:  294.0
[I 2023-12-19 18:38:08,185] Trial 111 finished with value: 0.3876180052757263 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.320014253454628, 'log_learning_rate_D': -2.8737357974249353, 'log_learning_rate_D_dagger': -2.8698335148990357, 'training_batch_size': 6, 'training_p': 8}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  245.98336553573608
Memory status after this trial: 
Memory allocated:  298.70654296875
Memory cached:  302.0
--------------------  Trial  112   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.8041187604818925, 'log_learning_rate_D': -2.9571260892543494, 'log_learning_rate_D_dagger': -3.0380598260807785, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.5449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.5380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  298.0
	 epoch  60 training error:  tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  302.0
	 epoch  70 training error:  tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.35400390625
Memory cached:  300.0
[I 2023-12-19 18:42:09,484] Trial 112 finished with value: 0.1762084662914276 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.8041187604818925, 'log_learning_rate_D': -2.9571260892543494, 'log_learning_rate_D_dagger': -3.0380598260807785, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  240.9400064945221
Memory status after this trial: 
Memory allocated:  262.78857421875
Memory cached:  294.0
--------------------  Trial  113   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.394260623571164, 'log_learning_rate_D': -3.075181240913952, 'log_learning_rate_D_dagger': -2.5473990443824226, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.3175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  298.0
	 epoch  60 training error:  tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
[I 2023-12-19 18:46:09,504] Trial 113 finished with value: 0.2559225559234619 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.394260623571164, 'log_learning_rate_D': -3.075181240913952, 'log_learning_rate_D_dagger': -2.5473990443824226, 'training_batch_size': 6, 'training_p': 8}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  239.7038300037384
Memory status after this trial: 
Memory allocated:  251.71240234375
Memory cached:  294.0
--------------------  Trial  114   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -4.524748244958473, 'log_learning_rate_D': -3.407681717085712, 'log_learning_rate_D_dagger': -2.9411280039226844, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  310.0
	 epoch  20 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  308.0
	 epoch  30 training error:  tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  302.0
	 epoch  40 training error:  tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  306.0
	 epoch  60 training error:  tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  308.0
	 epoch  80 training error:  tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  310.0
	 epoch  90 training error:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.36181640625
Memory cached:  306.0
[I 2023-12-19 18:50:12,057] Trial 114 finished with value: 0.23839621245861053 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 9, 'log_learning_rate': -4.524748244958473, 'log_learning_rate_D': -3.407681717085712, 'log_learning_rate_D_dagger': -2.9411280039226844, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  242.23489475250244
Memory status after this trial: 
Memory allocated:  270.59326171875
Memory cached:  298.0
--------------------  Trial  115   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.768285712840776, 'log_learning_rate_D': -3.2216468169683887, 'log_learning_rate_D_dagger': -3.1244210583527505, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  10 training error:  tensor(0.5658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  20 training error:  tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  50 training error:  tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  70 training error:  tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
	 epoch  90 training error:  tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  134.88134765625
Memory cached:  314.0
[I 2023-12-19 18:54:37,807] Trial 115 finished with value: 0.27103179693222046 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 9, 'D_dagger_layer_units_exponent_3': 10, 'log_learning_rate': -4.768285712840776, 'log_learning_rate_D': -3.2216468169683887, 'log_learning_rate_D_dagger': -3.1244210583527505, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  265.4225151538849
Memory status after this trial: 
Memory allocated:  328.97216796875
Memory cached:  348.0
--------------------  Trial  116   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.631832074517508, 'log_learning_rate_D': -3.56965199510401, 'log_learning_rate_D_dagger': -2.7410022795918545, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  306.0
	 epoch  20 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  300.0
	 epoch  40 training error:  tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  298.0
	 epoch  50 training error:  tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.32861328125
Memory cached:  296.0
[I 2023-12-19 18:58:25,318] Trial 116 finished with value: 0.21907329559326172 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.631832074517508, 'log_learning_rate_D': -3.56965199510401, 'log_learning_rate_D_dagger': -2.7410022795918545, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  227.19664549827576
Memory status after this trial: 
Memory allocated:  257.7626953125
Memory cached:  294.0
--------------------  Trial  117   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.281419415712698, 'log_learning_rate_D': -2.768263187993557, 'log_learning_rate_D_dagger': -2.4213564851540137, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  306.0
	 epoch  20 training error:  tensor(0.5236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  304.0
	 epoch  30 training error:  tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  306.0
	 epoch  40 training error:  tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  308.0
	 epoch  60 training error:  tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  310.0
	 epoch  80 training error:  tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  308.0
	 epoch  90 training error:  tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.84033203125
Memory cached:  308.0
[I 2023-12-19 19:00:41,341] Trial 117 finished with value: 0.13769744336605072 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.281419415712698, 'log_learning_rate_D': -2.768263187993557, 'log_learning_rate_D_dagger': -2.4213564851540137, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  135.71584939956665
Memory status after this trial: 
Memory allocated:  225.26123046875
Memory cached:  308.0
--------------------  Trial  118   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.869845474282624, 'log_learning_rate_D': -3.34743906156259, 'log_learning_rate_D_dagger': -2.328144711255864, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.5203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  50 training error:  tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  60 training error:  tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  300.0
	 epoch  90 training error:  tensor(0.4971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  123.88525390625
Memory cached:  300.0
[I 2023-12-19 19:03:00,859] Trial 118 finished with value: 0.36782652139663696 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 5, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.869845474282624, 'log_learning_rate_D': -3.34743906156259, 'log_learning_rate_D_dagger': -2.328144711255864, 'training_batch_size': 8, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  139.12930297851562
Memory status after this trial: 
Memory allocated:  196.181640625
Memory cached:  298.0
--------------------  Trial  119   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.228212006123508, 'log_learning_rate_D': -2.67504192290937, 'log_learning_rate_D_dagger': -2.4745428341074462, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9937, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  308.0
	 epoch  20 training error:  tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  308.0
	 epoch  50 training error:  tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  316.0
	 epoch  60 training error:  tensor(0.4883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.5922, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  316.0
	 epoch  90 training error:  tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.70947265625
Memory cached:  312.0
[I 2023-12-19 19:05:11,000] Trial 119 finished with value: 0.21825718879699707 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.228212006123508, 'log_learning_rate_D': -2.67504192290937, 'log_learning_rate_D_dagger': -2.4745428341074462, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  129.74613308906555
Memory status after this trial: 
Memory allocated:  192.640625
Memory cached:  306.0
--------------------  Trial  120   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.5368531264950285, 'log_learning_rate_D': -3.4654754420191485, 'log_learning_rate_D_dagger': -2.3986134695322114, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  306.0
	 epoch  20 training error:  tensor(0.5426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  308.0
	 epoch  30 training error:  tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  308.0
	 epoch  40 training error:  tensor(0.5172, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  312.0
	 epoch  50 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.4987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.05322265625
Memory cached:  310.0
[I 2023-12-19 19:07:26,120] Trial 120 finished with value: 0.3920097053050995 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.5368531264950285, 'log_learning_rate_D': -3.4654754420191485, 'log_learning_rate_D_dagger': -2.3986134695322114, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  134.7514533996582
Memory status after this trial: 
Memory allocated:  271.36376953125
Memory cached:  300.0
--------------------  Trial  121   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.712199327279509, 'log_learning_rate_D': -2.815676123267119, 'log_learning_rate_D_dagger': -2.6166575104564562, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88916015625
Memory cached:  298.0
[I 2023-12-19 19:11:25,144] Trial 121 finished with value: 0.30031928420066833 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.712199327279509, 'log_learning_rate_D': -2.815676123267119, 'log_learning_rate_D_dagger': -2.6166575104564562, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  238.67170000076294
Memory status after this trial: 
Memory allocated:  253.16650390625
Memory cached:  296.0
--------------------  Trial  122   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.325477080299427, 'log_learning_rate_D': -2.7701498283066663, 'log_learning_rate_D_dagger': -3.2137098454821253, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.88134765625
Memory cached:  294.0
[I 2023-12-19 19:15:26,161] Trial 122 finished with value: 0.1487971395254135 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.325477080299427, 'log_learning_rate_D': -2.7701498283066663, 'log_learning_rate_D_dagger': -3.2137098454821253, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  240.69003772735596
Memory status after this trial: 
Memory allocated:  251.71240234375
Memory cached:  294.0
--------------------  Trial  123   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.151673626923918, 'log_learning_rate_D': -2.9406728072898263, 'log_learning_rate_D_dagger': -3.0449876289919864, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  300.0
	 epoch  50 training error:  tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  298.0
	 epoch  90 training error:  tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  298.0
[I 2023-12-19 19:19:24,905] Trial 123 finished with value: 0.16162554919719696 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.151673626923918, 'log_learning_rate_D': -2.9406728072898263, 'log_learning_rate_D_dagger': -3.0449876289919864, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  238.4175946712494
Memory status after this trial: 
Memory allocated:  252.31396484375
Memory cached:  296.0
--------------------  Trial  124   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.453120831733237, 'log_learning_rate_D': -3.123479020033099, 'log_learning_rate_D_dagger': -2.874143775575369, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  302.0
	 epoch  10 training error:  tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  308.0
	 epoch  20 training error:  tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  310.0
	 epoch  30 training error:  tensor(0.4136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  308.0
	 epoch  40 training error:  tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  314.0
	 epoch  50 training error:  tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  308.0
	 epoch  70 training error:  tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  314.0
	 epoch  90 training error:  tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.40283203125
Memory cached:  312.0
[I 2023-12-19 19:23:43,433] Trial 124 finished with value: 0.19834335148334503 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.453120831733237, 'log_learning_rate_D': -3.123479020033099, 'log_learning_rate_D_dagger': -2.874143775575369, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  258.18571162223816
Memory status after this trial: 
Memory allocated:  277.10986328125
Memory cached:  308.0
--------------------  Trial  125   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.841337312082404, 'log_learning_rate_D': -3.2655184010370406, 'log_learning_rate_D_dagger': -2.6515393748104663, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.2088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  302.0
	 epoch  30 training error:  tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87939453125
Memory cached:  296.0
[I 2023-12-19 19:26:03,779] Trial 125 finished with value: 0.14827486872673035 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'log_learning_rate': -4.841337312082404, 'log_learning_rate_D': -3.2655184010370406, 'log_learning_rate_D_dagger': -2.6515393748104663, 'training_batch_size': 7, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  140.02345156669617
Memory status after this trial: 
Memory allocated:  256.0849609375
Memory cached:  294.0
--------------------  Trial  126   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.647137128099045, 'log_learning_rate_D': -2.904151883019758, 'log_learning_rate_D_dagger': -3.327435544020492, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  302.0
	 epoch  20 training error:  tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  314.0
	 epoch  50 training error:  tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  306.0
	 epoch  60 training error:  tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  312.0
	 epoch  70 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  306.0
	 epoch  90 training error:  tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.39697265625
Memory cached:  310.0
[I 2023-12-19 19:30:05,364] Trial 126 finished with value: 0.3987661302089691 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 10, 'log_learning_rate': -4.647137128099045, 'log_learning_rate_D': -2.904151883019758, 'log_learning_rate_D_dagger': -3.327435544020492, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  241.17763590812683
Memory status after this trial: 
Memory allocated:  258.06005859375
Memory cached:  298.0
--------------------  Trial  127   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.763900158329768, 'log_learning_rate_D': -3.0085436640105603, 'log_learning_rate_D_dagger': -3.154251970871941, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.5037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  298.0
	 epoch  90 training error:  tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.10595703125
Memory cached:  298.0
[I 2023-12-19 19:34:13,287] Trial 127 finished with value: 0.4023403823375702 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 7, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.763900158329768, 'log_learning_rate_D': -3.0085436640105603, 'log_learning_rate_D_dagger': -3.154251970871941, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  247.58482241630554
Memory status after this trial: 
Memory allocated:  195.8408203125
Memory cached:  298.0
--------------------  Trial  128   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.929706493024139, 'log_learning_rate_D': -3.1919724195995918, 'log_learning_rate_D_dagger': -2.941266076864607, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  302.0
	 epoch  30 training error:  tensor(0.5244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.5257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  310.0
	 epoch  50 training error:  tensor(0.5422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  312.0
	 epoch  60 training error:  tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  310.0
	 epoch  70 training error:  tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  310.0
	 epoch  80 training error:  tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  306.0
	 epoch  90 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.14501953125
Memory cached:  302.0
[I 2023-12-19 19:36:37,992] Trial 128 finished with value: 0.21304722130298615 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.929706493024139, 'log_learning_rate_D': -3.1919724195995918, 'log_learning_rate_D_dagger': -2.941266076864607, 'training_batch_size': 8, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  144.38264346122742
Memory status after this trial: 
Memory allocated:  283.1708984375
Memory cached:  298.0
--------------------  Trial  129   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.567393178068949, 'log_learning_rate_D': -3.383379448841831, 'log_learning_rate_D_dagger': -2.5130802512227053, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.3050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.6524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  300.0
	 epoch  70 training error:  tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.91259765625
Memory cached:  294.0
[I 2023-12-19 19:40:38,064] Trial 129 finished with value: 0.1426783949136734 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.567393178068949, 'log_learning_rate_D': -3.383379448841831, 'log_learning_rate_D_dagger': -2.5130802512227053, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  239.7153034210205
Memory status after this trial: 
Memory allocated:  252.31396484375
Memory cached:  294.0
--------------------  Trial  130   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.3796288910966625, 'log_learning_rate_D': -3.592096537550564, 'log_learning_rate_D_dagger': -2.7713934373997424, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  298.0
	 epoch  30 training error:  tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  308.0
	 epoch  40 training error:  tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  306.0
	 epoch  50 training error:  tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  300.0
	 epoch  60 training error:  tensor(0.4803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  310.0
	 epoch  70 training error:  tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  302.0
	 epoch  80 training error:  tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  308.0
	 epoch  90 training error:  tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.29150390625
Memory cached:  302.0
[I 2023-12-19 19:42:45,136] Trial 130 finished with value: 0.27896973490715027 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.3796288910966625, 'log_learning_rate_D': -3.592096537550564, 'log_learning_rate_D_dagger': -2.7713934373997424, 'training_batch_size': 7, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  126.7484483718872
Memory status after this trial: 
Memory allocated:  215.10546875
Memory cached:  296.0
--------------------  Trial  131   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.469288367369888, 'log_learning_rate_D': -3.7018557800119045, 'log_learning_rate_D_dagger': -3.224538232167074, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8659, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
[I 2023-12-19 19:46:51,551] Trial 131 finished with value: 0.18410314619541168 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.469288367369888, 'log_learning_rate_D': -3.7018557800119045, 'log_learning_rate_D_dagger': -3.224538232167074, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  245.98106861114502
Memory status after this trial: 
Memory allocated:  294.326171875
Memory cached:  296.0
--------------------  Trial  132   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.701885307920979, 'log_learning_rate_D': -3.492146495843244, 'log_learning_rate_D_dagger': -3.1688063890691978, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.49072265625
Memory cached:  294.0
[I 2023-12-19 19:50:56,787] Trial 132 finished with value: 0.164328470826149 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.701885307920979, 'log_learning_rate_D': -3.492146495843244, 'log_learning_rate_D_dagger': -3.1688063890691978, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  244.90497827529907
Memory status after this trial: 
Memory allocated:  296.564453125
Memory cached:  300.0
--------------------  Trial  133   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.602171979284588, 'log_learning_rate_D': -3.3081305559346763, 'log_learning_rate_D_dagger': -3.049052346277712, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
	 epoch  20 training error:  tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
	 epoch  30 training error:  tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
	 epoch  50 training error:  tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  298.0
	 epoch  60 training error:  tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
	 epoch  70 training error:  tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  298.0
	 epoch  80 training error:  tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
	 epoch  90 training error:  tensor(0.3466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.24853515625
Memory cached:  300.0
[I 2023-12-19 19:55:22,697] Trial 133 finished with value: 0.21336869895458221 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 10, 'D_dagger_layer_units_exponent_4': 8, 'log_learning_rate': -4.602171979284588, 'log_learning_rate_D': -3.3081305559346763, 'log_learning_rate_D_dagger': -3.049052346277712, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  265.5699791908264
Memory status after this trial: 
Memory allocated:  339.361328125
Memory cached:  344.0
--------------------  Trial  134   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.295032614438759, 'log_learning_rate_D': -3.632797966152049, 'log_learning_rate_D_dagger': -3.4068406020699946, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.11572265625
Memory cached:  294.0
[I 2023-12-19 19:59:29,054] Trial 134 finished with value: 0.21408294141292572 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.295032614438759, 'log_learning_rate_D': -3.632797966152049, 'log_learning_rate_D_dagger': -3.4068406020699946, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  246.02549409866333
Memory status after this trial: 
Memory allocated:  294.326171875
Memory cached:  296.0
--------------------  Trial  135   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.431347031149908, 'log_learning_rate_D': -3.7832932451941415, 'log_learning_rate_D_dagger': -3.27233692713785, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  300.0
	 epoch  40 training error:  tensor(0.4991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  298.0
	 epoch  50 training error:  tensor(0.4623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  298.0
[I 2023-12-19 20:03:45,874] Trial 135 finished with value: 0.14479391276836395 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.431347031149908, 'log_learning_rate_D': -3.7832932451941415, 'log_learning_rate_D_dagger': -3.27233692713785, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  256.4733736515045
Memory status after this trial: 
Memory allocated:  265.06591796875
Memory cached:  296.0
--------------------  Trial  136   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.841382353250506, 'log_learning_rate_D': -3.091322810200224, 'log_learning_rate_D_dagger': -3.00670716858126, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.19580078125
Memory cached:  294.0
[I 2023-12-19 20:07:33,244] Trial 136 finished with value: 0.22606901824474335 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 7, 'log_learning_rate': -4.841382353250506, 'log_learning_rate_D': -3.091322810200224, 'log_learning_rate_D_dagger': -3.00670716858126, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  227.03125834465027
Memory status after this trial: 
Memory allocated:  276.0361328125
Memory cached:  294.0
--------------------  Trial  137   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.133516295689244, 'log_learning_rate_D': -3.5475800054420343, 'log_learning_rate_D_dagger': -3.5379684528654685, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  10 training error:  tensor(0.5333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  20 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  50 training error:  tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  70 training error:  tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
	 epoch  90 training error:  tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  140.66845703125
Memory cached:  314.0
[I 2023-12-19 20:11:25,361] Trial 137 finished with value: 0.22181549668312073 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.133516295689244, 'log_learning_rate_D': -3.5475800054420343, 'log_learning_rate_D_dagger': -3.5379684528654685, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  231.74249649047852
Memory status after this trial: 
Memory allocated:  306.46484375
Memory cached:  320.0
--------------------  Trial  138   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.734978146372876, 'log_learning_rate_D': -3.425495754471719, 'log_learning_rate_D_dagger': -3.458630844066661, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.4985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.5323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  131.90283203125
Memory cached:  294.0
[I 2023-12-19 20:15:34,257] Trial 138 finished with value: 0.3810301721096039 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 9, 'log_learning_rate': -4.734978146372876, 'log_learning_rate_D': -3.425495754471719, 'log_learning_rate_D_dagger': -3.458630844066661, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  248.5530161857605
Memory status after this trial: 
Memory allocated:  314.787109375
Memory cached:  322.0
--------------------  Trial  139   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.8872295644327792, 'log_learning_rate_D': -3.1821773721106026, 'log_learning_rate_D_dagger': -3.124857392610746, 'training_batch_size': 7, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  308.0
	 epoch  10 training error:  tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  330.0
	 epoch  20 training error:  tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  322.0
	 epoch  30 training error:  tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  334.0
	 epoch  40 training error:  tensor(0.5190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  330.0
	 epoch  50 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  334.0
	 epoch  60 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  324.0
	 epoch  70 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  332.0
	 epoch  80 training error:  tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  332.0
	 epoch  90 training error:  tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.23486328125
Memory cached:  332.0
[I 2023-12-19 20:18:20,606] Trial 139 finished with value: 0.23573128879070282 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'log_learning_rate': -3.8872295644327792, 'log_learning_rate_D': -3.1821773721106026, 'log_learning_rate_D_dagger': -3.124857392610746, 'training_batch_size': 7, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  166.00284552574158
Memory status after this trial: 
Memory allocated:  290.97265625
Memory cached:  324.0
--------------------  Trial  140   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.49934214282222, 'log_learning_rate_D': -3.6984264164836222, 'log_learning_rate_D_dagger': -2.90792211668114, 'training_batch_size': 6, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
	 epoch  90 training error:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.86572265625
Memory cached:  294.0
[I 2023-12-19 20:22:17,968] Trial 140 finished with value: 0.2745000422000885 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.49934214282222, 'log_learning_rate_D': -3.6984264164836222, 'log_learning_rate_D_dagger': -2.90792211668114, 'training_batch_size': 6, 'training_p': 7}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  236.90724754333496
Memory status after this trial: 
Memory allocated:  225.31103515625
Memory cached:  294.0
--------------------  Trial  141   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.601846161920823, 'log_learning_rate_D': -3.2536371791212955, 'log_learning_rate_D_dagger': -3.2767622127657248, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 20:26:02,978] Trial 141 finished with value: 0.16462139785289764 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.601846161920823, 'log_learning_rate_D': -3.2536371791212955, 'log_learning_rate_D_dagger': -3.2767622127657248, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.68478775024414
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  142   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.560781057182145, 'log_learning_rate_D': -3.339769086157859, 'log_learning_rate_D_dagger': -3.243080769254515, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 20:29:48,678] Trial 142 finished with value: 0.14338523149490356 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.560781057182145, 'log_learning_rate_D': -3.339769086157859, 'log_learning_rate_D_dagger': -3.243080769254515, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.33817744255066
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  143   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.657194616214998, 'log_learning_rate_D': -3.257173088107167, 'log_learning_rate_D_dagger': -3.3740136692605938, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.4901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 20:33:34,699] Trial 143 finished with value: 0.13593506813049316 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.657194616214998, 'log_learning_rate_D': -3.257173088107167, 'log_learning_rate_D_dagger': -3.3740136692605938, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  225.6929841041565
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  144   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.920148487666554, 'log_learning_rate_D': -3.0040859889910267, 'log_learning_rate_D_dagger': -3.3328646615028292, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 20:37:19,849] Trial 144 finished with value: 0.2121569663286209 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.920148487666554, 'log_learning_rate_D': -3.0040859889910267, 'log_learning_rate_D_dagger': -3.3328646615028292, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  224.81549382209778
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  145   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.6812059440718, 'log_learning_rate_D': -3.48827519732033, 'log_learning_rate_D_dagger': -3.6070356394573495, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.4975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.87158203125
Memory cached:  296.0
[I 2023-12-19 20:41:01,537] Trial 145 finished with value: 0.3037521541118622 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.6812059440718, 'log_learning_rate_D': -3.48827519732033, 'log_learning_rate_D_dagger': -3.6070356394573495, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  221.34844970703125
Memory status after this trial: 
Memory allocated:  250.1123046875
Memory cached:  296.0
--------------------  Trial  146   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.773555710338478, 'log_learning_rate_D': -3.1266438488503936, 'log_learning_rate_D_dagger': -3.4060355088549352, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  298.0
	 epoch  20 training error:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  300.0
	 epoch  30 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  298.0
	 epoch  40 training error:  tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  304.0
	 epoch  60 training error:  tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  298.0
	 epoch  70 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.4924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  298.0
	 epoch  90 training error:  tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22119140625
Memory cached:  294.0
[I 2023-12-19 20:45:03,844] Trial 146 finished with value: 0.40937089920043945 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 6, 'D_dagger_layer_units_exponent_3': 8, 'log_learning_rate': -4.773555710338478, 'log_learning_rate_D': -3.1266438488503936, 'log_learning_rate_D_dagger': -3.4060355088549352, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  241.9624161720276
Memory status after this trial: 
Memory allocated:  264.544921875
Memory cached:  296.0
--------------------  Trial  147   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.367760537949196, 'log_learning_rate_D': -3.379590009701652, 'log_learning_rate_D_dagger': -3.1119915531759457, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  318.0
	 epoch  60 training error:  tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  320.0
	 epoch  70 training error:  tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  324.0
	 epoch  90 training error:  tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.96142578125
Memory cached:  322.0
[I 2023-12-19 20:47:26,533] Trial 147 finished with value: 0.1346120983362198 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.367760537949196, 'log_learning_rate_D': -3.379590009701652, 'log_learning_rate_D_dagger': -3.1119915531759457, 'training_batch_size': 9, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  142.36109519004822
Memory status after this trial: 
Memory allocated:  272.22314453125
Memory cached:  314.0
--------------------  Trial  148   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.397455220976776, 'log_learning_rate_D': -3.275874025756644, 'log_learning_rate_D_dagger': -3.0866715952336032, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  312.0
	 epoch  20 training error:  tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  306.0
	 epoch  30 training error:  tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  316.0
	 epoch  40 training error:  tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  308.0
	 epoch  50 training error:  tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  310.0
	 epoch  60 training error:  tensor(0.4779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  310.0
	 epoch  70 training error:  tensor(0.4643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  314.0
	 epoch  80 training error:  tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.36767578125
Memory cached:  308.0
[I 2023-12-19 20:49:49,433] Trial 148 finished with value: 0.20648503303527832 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 5, 'log_learning_rate': -4.397455220976776, 'log_learning_rate_D': -3.275874025756644, 'log_learning_rate_D_dagger': -3.0866715952336032, 'training_batch_size': 11, 'training_p': 5}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  142.56378388404846
Memory status after this trial: 
Memory allocated:  275.06298828125
Memory cached:  304.0
--------------------  Trial  149   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.230659526529743, 'log_learning_rate_D': -3.3466282796267297, 'log_learning_rate_D_dagger': -2.994629348571233, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  316.0
	 epoch  50 training error:  tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  312.0
	 epoch  60 training error:  tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  318.0
	 epoch  70 training error:  tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  318.0
	 epoch  80 training error:  tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  312.0
	 epoch  90 training error:  tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  124.93798828125
Memory cached:  314.0
[I 2023-12-19 20:52:04,968] Trial 149 finished with value: 0.36716195940971375 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 8, 'log_learning_rate': -4.230659526529743, 'log_learning_rate_D': -3.3466282796267297, 'log_learning_rate_D_dagger': -2.994629348571233, 'training_batch_size': 8, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  135.1090795993805
Memory status after this trial: 
Memory allocated:  231.55517578125
Memory cached:  302.0
--------------------  Trial  150   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.8921098047842415, 'log_learning_rate_D': -2.905995187792427, 'log_learning_rate_D_dagger': -2.822589052186631, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.5524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.5033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
	 epoch  80 training error:  tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  127.88720703125
Memory cached:  294.0
[I 2023-12-19 20:55:52,924] Trial 150 finished with value: 0.36544671654701233 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 8, 'log_learning_rate': -4.8921098047842415, 'log_learning_rate_D': -2.905995187792427, 'log_learning_rate_D_dagger': -2.822589052186631, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  227.52362370491028
Memory status after this trial: 
Memory allocated:  263.55517578125
Memory cached:  294.0
--------------------  Trial  151   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.668070956127434, 'log_learning_rate_D': -3.5654104237092388, 'log_learning_rate_D_dagger': -3.1812073001699943, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8355, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  20 training error:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  30 training error:  tensor(0.5008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  40 training error:  tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  50 training error:  tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  60 training error:  tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  70 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.25048828125
Memory cached:  296.0
[I 2023-12-19 21:00:14,443] Trial 151 finished with value: 0.11923734098672867 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.668070956127434, 'log_learning_rate_D': -3.5654104237092388, 'log_learning_rate_D_dagger': -3.1812073001699943, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  261.04080843925476
Memory status after this trial: 
Memory allocated:  295.849609375
Memory cached:  298.0
--------------------  Trial  152   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.678085632698195, 'log_learning_rate_D': -3.390819344323175, 'log_learning_rate_D_dagger': -3.20668971851171, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  298.0
	 epoch  10 training error:  tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  320.0
	 epoch  20 training error:  tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  312.0
	 epoch  30 training error:  tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  318.0
	 epoch  40 training error:  tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  316.0
	 epoch  50 training error:  tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  316.0
	 epoch  60 training error:  tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  314.0
	 epoch  70 training error:  tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  322.0
	 epoch  80 training error:  tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.22509765625
Memory cached:  320.0
[I 2023-12-19 21:02:47,246] Trial 152 finished with value: 0.22387222945690155 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.678085632698195, 'log_learning_rate_D': -3.390819344323175, 'log_learning_rate_D_dagger': -3.20668971851171, 'training_batch_size': 9, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  152.4120843410492
Memory status after this trial: 
Memory allocated:  295.7998046875
Memory cached:  318.0
--------------------  Trial  153   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.811080965483502, 'log_learning_rate_D': -3.518435128613298, 'log_learning_rate_D_dagger': -3.1383705313113213, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  300.0
	 epoch  10 training error:  tensor(0.5203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  326.0
	 epoch  20 training error:  tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  314.0
	 epoch  30 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  316.0
	 epoch  40 training error:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  318.0
	 epoch  50 training error:  tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  320.0
	 epoch  60 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  312.0
	 epoch  80 training error:  tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  130.48291015625
Memory cached:  316.0
[I 2023-12-19 21:05:32,707] Trial 153 finished with value: 0.20394770801067352 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.811080965483502, 'log_learning_rate_D': -3.518435128613298, 'log_learning_rate_D_dagger': -3.1383705313113213, 'training_batch_size': 12, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  165.0164897441864
Memory status after this trial: 
Memory allocated:  340.4677734375
Memory cached:  346.0
--------------------  Trial  154   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.7514426717667835, 'log_learning_rate_D': -3.063951832737148, 'log_learning_rate_D_dagger': -3.493125006086638, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  310.0
	 epoch  20 training error:  tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  314.0
	 epoch  40 training error:  tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  310.0
	 epoch  50 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  314.0
	 epoch  60 training error:  tensor(0.4742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  314.0
	 epoch  70 training error:  tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  310.0
	 epoch  80 training error:  tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  318.0
	 epoch  90 training error:  tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  126.09228515625
Memory cached:  312.0
[I 2023-12-19 21:08:02,714] Trial 154 finished with value: 0.1585233062505722 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.7514426717667835, 'log_learning_rate_D': -3.063951832737148, 'log_learning_rate_D_dagger': -3.493125006086638, 'training_batch_size': 9, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  149.53511238098145
Memory status after this trial: 
Memory allocated:  284.1318359375
Memory cached:  300.0
--------------------  Trial  155   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.969427341304989, 'log_learning_rate_D': -3.185624046227939, 'log_learning_rate_D_dagger': -3.3455857653076677, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  10 training error:  tensor(0.5478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  20 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  30 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  40 training error:  tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  50 training error:  tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  60 training error:  tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
	 epoch  70 training error:  tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  296.0
	 epoch  80 training error:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  296.0
	 epoch  90 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.98291015625
Memory cached:  294.0
[I 2023-12-19 21:12:05,603] Trial 155 finished with value: 0.13350962102413177 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.969427341304989, 'log_learning_rate_D': -3.185624046227939, 'log_learning_rate_D_dagger': -3.3455857653076677, 'training_batch_size': 6, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  242.40482687950134
Memory status after this trial: 
Memory allocated:  271.69091796875
Memory cached:  294.0
--------------------  Trial  156   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.966990188944992, 'log_learning_rate_D': -3.205741093926079, 'log_learning_rate_D_dagger': -3.350254626362924, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  296.0
	 epoch  10 training error:  tensor(0.5708, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
	 epoch  20 training error:  tensor(0.5094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
	 epoch  30 training error:  tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  312.0
	 epoch  40 training error:  tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  320.0
	 epoch  50 training error:  tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  312.0
	 epoch  60 training error:  tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
	 epoch  70 training error:  tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
	 epoch  80 training error:  tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
	 epoch  90 training error:  tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  125.95751953125
Memory cached:  316.0
[I 2023-12-19 21:14:26,548] Trial 156 finished with value: 0.18372593820095062 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.966990188944992, 'log_learning_rate_D': -3.205741093926079, 'log_learning_rate_D_dagger': -3.350254626362924, 'training_batch_size': 10, 'training_p': 6}. Best is trial 78 with value: 0.11363521963357925.
Time for this trial:  140.53424978256226
Memory status after this trial: 
Memory allocated:  271.64111328125
Memory cached:  316.0
--------------------  Trial  157   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.864061322221597, 'log_learning_rate_D': -3.4426265021245355, 'log_learning_rate_D_dagger': -3.3819915443036233, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  334.0
	 epoch  10 training error:  tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  352.0
	 epoch  20 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  348.0
	 epoch  30 training error:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  348.0
	 epoch  40 training error:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  352.0
	 epoch  50 training error:  tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  348.0
	 epoch  60 training error:  tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  350.0
	 epoch  70 training error:  tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  352.0
	 epoch  80 training error:  tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  346.0
	 epoch  90 training error:  tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  138.61962890625
Memory cached:  348.0
[I 2023-12-19 21:20:47,870] Trial 157 finished with value: 0.10292010754346848 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.864061322221597, 'log_learning_rate_D': -3.4426265021245355, 'log_learning_rate_D_dagger': -3.3819915443036233, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
res:  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)
self.bestValue:  tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)
Save this model!
Time for this trial:  380.8564531803131
Memory status after this trial: 
Memory allocated:  332.99365234375
Memory cached:  478.0
--------------------  Trial  158   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.998359797728064, 'log_learning_rate_D': -3.4549424553462034, 'log_learning_rate_D_dagger': -3.6630885538018543, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  498.0
	 epoch  10 training error:  tensor(0.5179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  512.0
	 epoch  20 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  514.0
	 epoch  30 training error:  tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  510.0
	 epoch  40 training error:  tensor(0.5108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  518.0
	 epoch  50 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  512.0
	 epoch  60 training error:  tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  516.0
	 epoch  70 training error:  tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  516.0
	 epoch  80 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  514.0
	 epoch  90 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  348.15771484375
Memory cached:  518.0
[I 2023-12-19 21:27:10,341] Trial 158 finished with value: 0.4294392764568329 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.998359797728064, 'log_learning_rate_D': -3.4549424553462034, 'log_learning_rate_D_dagger': -3.6630885538018543, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  382.03463315963745
Memory status after this trial: 
Memory allocated:  665.8564453125
Memory cached:  682.0
--------------------  Trial  159   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.892523085955116, 'log_learning_rate_D': -3.592979079653334, 'log_learning_rate_D_dagger': -3.38748374570034, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  496.0
	 epoch  10 training error:  tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  502.0
	 epoch  20 training error:  tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  504.0
	 epoch  30 training error:  tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  502.0
	 epoch  40 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  504.0
	 epoch  50 training error:  tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  502.0
	 epoch  60 training error:  tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  504.0
	 epoch  70 training error:  tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  502.0
	 epoch  80 training error:  tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  504.0
	 epoch  90 training error:  tensor(0.5033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  347.44287109375
Memory cached:  500.0
[I 2023-12-19 21:33:13,874] Trial 159 finished with value: 0.40851327776908875 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.892523085955116, 'log_learning_rate_D': -3.592979079653334, 'log_learning_rate_D_dagger': -3.38748374570034, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  363.0933918952942
Memory status after this trial: 
Memory allocated:  632.689453125
Memory cached:  650.0
--------------------  Trial  160   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.803464672843155, 'log_learning_rate_D': -3.4180139131726186, 'log_learning_rate_D_dagger': -3.530299831958231, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.6743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.5088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.44287109375
Memory cached:  480.0
[I 2023-12-19 21:38:48,651] Trial 160 finished with value: 0.41764625906944275 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 6, 'D_dagger_layer_units_exponent_1': 6, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.803464672843155, 'log_learning_rate_D': -3.4180139131726186, 'log_learning_rate_D_dagger': -3.530299831958231, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  334.351833820343
Memory status after this trial: 
Memory allocated:  512.3310546875
Memory cached:  530.0
--------------------  Trial  161   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.85050443575663, 'log_learning_rate_D': -3.2814175120223315, 'log_learning_rate_D_dagger': -3.2939424149852066, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  500.0
	 epoch  10 training error:  tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  508.0
	 epoch  20 training error:  tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  508.0
	 epoch  30 training error:  tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  508.0
	 epoch  40 training error:  tensor(0.5344, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  510.0
	 epoch  50 training error:  tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  506.0
	 epoch  60 training error:  tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  510.0
	 epoch  70 training error:  tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  510.0
	 epoch  80 training error:  tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  506.0
	 epoch  90 training error:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.15380859375
Memory cached:  506.0
[I 2023-12-19 21:44:56,842] Trial 161 finished with value: 0.24649031460285187 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.85050443575663, 'log_learning_rate_D': -3.2814175120223315, 'log_learning_rate_D_dagger': -3.2939424149852066, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  367.7741255760193
Memory status after this trial: 
Memory allocated:  637.2041015625
Memory cached:  660.0
--------------------  Trial  162   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.657022136436654, 'log_learning_rate_D': -3.35171095058032, 'log_learning_rate_D_dagger': -3.1975906213218135, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.91357421875
Memory cached:  482.0
[I 2023-12-19 21:49:55,087] Trial 162 finished with value: 0.16844062507152557 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.657022136436654, 'log_learning_rate_D': -3.35171095058032, 'log_learning_rate_D_dagger': -3.1975906213218135, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  297.8453917503357
Memory status after this trial: 
Memory allocated:  539.1611328125
Memory cached:  560.0
--------------------  Trial  163   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.749127815366796, 'log_learning_rate_D': -3.169868110345177, 'log_learning_rate_D_dagger': -3.3489968401917505, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  514.0
	 epoch  10 training error:  tensor(0.5323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  522.0
	 epoch  20 training error:  tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  526.0
	 epoch  30 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  524.0
	 epoch  40 training error:  tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  526.0
	 epoch  50 training error:  tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  524.0
	 epoch  60 training error:  tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  520.0
	 epoch  70 training error:  tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  522.0
	 epoch  80 training error:  tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  526.0
	 epoch  90 training error:  tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  362.95263671875
Memory cached:  522.0
[I 2023-12-19 21:55:21,315] Trial 163 finished with value: 0.23578791320323944 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.749127815366796, 'log_learning_rate_D': -3.169868110345177, 'log_learning_rate_D_dagger': -3.3489968401917505, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  325.760285615921
Memory status after this trial: 
Memory allocated:  643.47998046875
Memory cached:  672.0
--------------------  Trial  164   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.870063289404026, 'log_learning_rate_D': -3.4859689099963327, 'log_learning_rate_D_dagger': -3.0939864754474766, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  502.0
	 epoch  10 training error:  tensor(0.5333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
	 epoch  20 training error:  tensor(0.5042, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  504.0
	 epoch  30 training error:  tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  40 training error:  tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  510.0
	 epoch  50 training error:  tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
	 epoch  60 training error:  tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  70 training error:  tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  510.0
	 epoch  80 training error:  tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  510.0
	 epoch  90 training error:  tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  510.0
[I 2023-12-19 22:01:16,126] Trial 164 finished with value: 0.12052652984857559 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.870063289404026, 'log_learning_rate_D': -3.4859689099963327, 'log_learning_rate_D_dagger': -3.0939864754474766, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  354.33373641967773
Memory status after this trial: 
Memory allocated:  635.43994140625
Memory cached:  658.0
--------------------  Trial  165   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.924274755855422, 'log_learning_rate_D': -3.5597331520178686, 'log_learning_rate_D_dagger': -3.0785041609088024, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  500.0
	 epoch  10 training error:  tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  504.0
	 epoch  20 training error:  tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  30 training error:  tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
	 epoch  40 training error:  tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  50 training error:  tensor(0.4943, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  60 training error:  tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
	 epoch  70 training error:  tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
	 epoch  80 training error:  tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  508.0
	 epoch  90 training error:  tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  344.82177734375
Memory cached:  506.0
[I 2023-12-19 22:07:11,071] Trial 165 finished with value: 0.15503446757793427 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.924274755855422, 'log_learning_rate_D': -3.5597331520178686, 'log_learning_rate_D_dagger': -3.0785041609088024, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  354.45094752311707
Memory status after this trial: 
Memory allocated:  635.43994140625
Memory cached:  658.0
--------------------  Trial  166   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.808937241191879, 'log_learning_rate_D': -3.478536664719851, 'log_learning_rate_D_dagger': -3.4512774483087716, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  488.0
	 epoch  10 training error:  tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  496.0
	 epoch  20 training error:  tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  494.0
	 epoch  30 training error:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  500.0
	 epoch  40 training error:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  496.0
	 epoch  50 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  498.0
	 epoch  60 training error:  tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  496.0
	 epoch  70 training error:  tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  498.0
	 epoch  80 training error:  tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  498.0
	 epoch  90 training error:  tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  346.44873046875
Memory cached:  498.0
[I 2023-12-19 22:13:00,688] Trial 166 finished with value: 0.23701684176921844 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.808937241191879, 'log_learning_rate_D': -3.478536664719851, 'log_learning_rate_D_dagger': -3.4512774483087716, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  349.1847794055939
Memory status after this trial: 
Memory allocated:  608.7626953125
Memory cached:  624.0
--------------------  Trial  167   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.703485228068363, 'log_learning_rate_D': -3.376916984874904, 'log_learning_rate_D_dagger': -2.264585813774355, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.5118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.5062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.5384, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
[I 2023-12-19 22:17:11,004] Trial 167 finished with value: 0.4125029742717743 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.703485228068363, 'log_learning_rate_D': -3.376916984874904, 'log_learning_rate_D_dagger': -2.264585813774355, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  249.9319417476654
Memory status after this trial: 
Memory allocated:  521.35986328125
Memory cached:  542.0
--------------------  Trial  168   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.881794312035325, 'log_learning_rate_D': -3.664886451113232, 'log_learning_rate_D_dagger': -2.991756994798473, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  484.0
	 epoch  20 training error:  tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  486.0
	 epoch  30 training error:  tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  486.0
	 epoch  40 training error:  tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  484.0
	 epoch  50 training error:  tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  484.0
	 epoch  60 training error:  tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  486.0
	 epoch  70 training error:  tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  486.0
	 epoch  80 training error:  tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  484.0
	 epoch  90 training error:  tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  340.11669921875
Memory cached:  484.0
[I 2023-12-19 22:20:35,775] Trial 168 finished with value: 0.14486460387706757 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.881794312035325, 'log_learning_rate_D': -3.664886451113232, 'log_learning_rate_D_dagger': -2.991756994798473, 'training_batch_size': 8, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  204.38048481941223
Memory status after this trial: 
Memory allocated:  619.42138671875
Memory cached:  640.0
--------------------  Trial  169   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.961482802119214, 'log_learning_rate_D': -3.6127453452415406, 'log_learning_rate_D_dagger': -2.4100109973535364, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.2639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  488.0
	 epoch  10 training error:  tensor(0.5354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  496.0
	 epoch  20 training error:  tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  494.0
	 epoch  30 training error:  tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  492.0
	 epoch  40 training error:  tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  492.0
	 epoch  50 training error:  tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  492.0
	 epoch  60 training error:  tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  496.0
	 epoch  70 training error:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  492.0
	 epoch  80 training error:  tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  494.0
	 epoch  90 training error:  tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.64404296875
Memory cached:  498.0
[I 2023-12-19 22:26:30,657] Trial 169 finished with value: 0.17899024486541748 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.961482802119214, 'log_learning_rate_D': -3.6127453452415406, 'log_learning_rate_D_dagger': -2.4100109973535364, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  354.3373568058014
Memory status after this trial: 
Memory allocated:  590.423828125
Memory cached:  610.0
--------------------  Trial  170   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.6441028445536645, 'log_learning_rate_D': -3.736135622270698, 'log_learning_rate_D_dagger': -3.263930016258427, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  484.0
	 epoch  10 training error:  tensor(0.5203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  502.0
	 epoch  20 training error:  tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  494.0
	 epoch  30 training error:  tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  488.0
	 epoch  40 training error:  tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  496.0
	 epoch  50 training error:  tensor(0.5224, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  494.0
	 epoch  60 training error:  tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  494.0
	 epoch  70 training error:  tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  500.0
	 epoch  80 training error:  tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  494.0
	 epoch  90 training error:  tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  355.66162109375
Memory cached:  492.0
[I 2023-12-19 22:30:09,674] Trial 170 finished with value: 0.42094188928604126 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 10, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'log_learning_rate': -4.6441028445536645, 'log_learning_rate_D': -3.736135622270698, 'log_learning_rate_D_dagger': -3.263930016258427, 'training_batch_size': 11, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  218.6028139591217
Memory status after this trial: 
Memory allocated:  690.1083984375
Memory cached:  702.0
--------------------  Trial  171   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.522579938953918, 'log_learning_rate_D': -3.2530309856180577, 'log_learning_rate_D_dagger': -3.143505794298759, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  508.0
	 epoch  10 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  534.0
	 epoch  20 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  522.0
	 epoch  30 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  522.0
	 epoch  40 training error:  tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  514.0
	 epoch  50 training error:  tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  518.0
	 epoch  60 training error:  tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  520.0
	 epoch  70 training error:  tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  526.0
	 epoch  80 training error:  tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  520.0
	 epoch  90 training error:  tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52490234375
Memory cached:  516.0
[I 2023-12-19 22:34:14,508] Trial 171 finished with value: 0.17675071954727173 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.522579938953918, 'log_learning_rate_D': -3.2530309856180577, 'log_learning_rate_D_dagger': -3.143505794298759, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  244.41324138641357
Memory status after this trial: 
Memory allocated:  481.81103515625
Memory cached:  500.0
--------------------  Trial  172   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.800755740272388, 'log_learning_rate_D': -3.420907070468581, 'log_learning_rate_D_dagger': -3.0692731535460682, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  494.0
	 epoch  10 training error:  tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  478.0
	 epoch  50 training error:  tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  478.0
	 epoch  60 training error:  tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  478.0
	 epoch  70 training error:  tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.54833984375
Memory cached:  478.0
[I 2023-12-19 22:38:08,820] Trial 172 finished with value: 0.17498958110809326 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.800755740272388, 'log_learning_rate_D': -3.420907070468581, 'log_learning_rate_D_dagger': -3.0692731535460682, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  233.95251941680908
Memory status after this trial: 
Memory allocated:  486.17333984375
Memory cached:  504.0
--------------------  Trial  173   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.624279294750366, 'log_learning_rate_D': -3.5216994934152113, 'log_learning_rate_D_dagger': -3.187530789054674, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
[I 2023-12-19 22:41:56,164] Trial 173 finished with value: 0.11203668266534805 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.624279294750366, 'log_learning_rate_D': -3.5216994934152113, 'log_learning_rate_D_dagger': -3.187530789054674, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  226.92824029922485
Memory status after this trial: 
Memory allocated:  507.625
Memory cached:  526.0
--------------------  Trial  174   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.857081091868315, 'log_learning_rate_D': -3.4954417342376325, 'log_learning_rate_D_dagger': -2.1688384686729725, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.6731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.5414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
[I 2023-12-19 22:45:51,635] Trial 174 finished with value: 0.1784287393093109 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.857081091868315, 'log_learning_rate_D': -3.4954417342376325, 'log_learning_rate_D_dagger': -2.1688384686729725, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  235.10565376281738
Memory status after this trial: 
Memory allocated:  507.625
Memory cached:  526.0
--------------------  Trial  175   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.725910906199681, 'log_learning_rate_D': -3.5424194690885598, 'log_learning_rate_D_dagger': -3.1878441411456686, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.47021484375
Memory cached:  480.0
[I 2023-12-19 22:50:01,631] Trial 175 finished with value: 0.19856195151805878 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.725910906199681, 'log_learning_rate_D': -3.5424194690885598, 'log_learning_rate_D_dagger': -3.1878441411456686, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  249.6060562133789
Memory status after this trial: 
Memory allocated:  515.8798828125
Memory cached:  536.0
--------------------  Trial  176   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.607728222900851, 'log_learning_rate_D': -3.3375824947786508, 'log_learning_rate_D_dagger': -3.3576624762786342, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  484.0
	 epoch  10 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  484.0
	 epoch  40 training error:  tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  486.0
	 epoch  50 training error:  tensor(0.5019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  488.0
	 epoch  60 training error:  tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  486.0
	 epoch  80 training error:  tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  488.0
	 epoch  90 training error:  tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  343.41748046875
Memory cached:  486.0
[I 2023-12-19 22:53:55,366] Trial 176 finished with value: 0.17940829694271088 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.607728222900851, 'log_learning_rate_D': -3.3375824947786508, 'log_learning_rate_D_dagger': -3.3576624762786342, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  233.31632924079895
Memory status after this trial: 
Memory allocated:  534.064453125
Memory cached:  548.0
--------------------  Trial  177   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.9885572645950935, 'log_learning_rate_D': -3.4163593247064767, 'log_learning_rate_D_dagger': -3.2721748233609413, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  60 training error:  tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
[I 2023-12-19 22:58:06,765] Trial 177 finished with value: 0.12626469135284424 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.9885572645950935, 'log_learning_rate_D': -3.4163593247064767, 'log_learning_rate_D_dagger': -3.2721748233609413, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  251.02480602264404
Memory status after this trial: 
Memory allocated:  521.35986328125
Memory cached:  542.0
--------------------  Trial  178   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.9201172342640564, 'log_learning_rate_D': -3.6436915591260974, 'log_learning_rate_D_dagger': -3.447040323878015, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  10 training error:  tensor(0.5450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  20 training error:  tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  30 training error:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  40 training error:  tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  50 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  60 training error:  tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39208984375
Memory cached:  478.0
[I 2023-12-19 23:02:09,485] Trial 178 finished with value: 0.4131946563720703 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 4, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.9201172342640564, 'log_learning_rate_D': -3.6436915591260974, 'log_learning_rate_D_dagger': -3.447040323878015, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  242.34018921852112
Memory status after this trial: 
Memory allocated:  467.16455078125
Memory cached:  486.0
--------------------  Trial  179   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.985008367824362, 'log_learning_rate_D': -3.828905548321152, 'log_learning_rate_D_dagger': -3.286035514765123, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  486.0
	 epoch  10 training error:  tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  492.0
	 epoch  20 training error:  tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  496.0
	 epoch  30 training error:  tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  492.0
	 epoch  40 training error:  tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  496.0
	 epoch  50 training error:  tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  498.0
	 epoch  60 training error:  tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  494.0
	 epoch  70 training error:  tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  492.0
	 epoch  80 training error:  tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  492.0
	 epoch  90 training error:  tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.19482421875
Memory cached:  494.0
[I 2023-12-19 23:07:12,940] Trial 179 finished with value: 0.2030123770236969 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.985008367824362, 'log_learning_rate_D': -3.828905548321152, 'log_learning_rate_D_dagger': -3.286035514765123, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  303.03596234321594
Memory status after this trial: 
Memory allocated:  589.13525390625
Memory cached:  610.0
--------------------  Trial  180   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.4238776606757555, 'log_learning_rate_D': -3.4738842414228333, 'log_learning_rate_D_dagger': -3.2250714967199903, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.6499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  486.0
	 epoch  30 training error:  tensor(0.5415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  484.0
	 epoch  50 training error:  tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.5221, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  484.0
	 epoch  70 training error:  tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  484.0
	 epoch  90 training error:  tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.30419921875
Memory cached:  482.0
[I 2023-12-19 23:11:43,816] Trial 180 finished with value: 0.4209224283695221 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 9, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -3.4238776606757555, 'log_learning_rate_D': -3.4738842414228333, 'log_learning_rate_D_dagger': -3.2250714967199903, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  270.4878120422363
Memory status after this trial: 
Memory allocated:  450.9697265625
Memory cached:  480.0
--------------------  Trial  181   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.847730938635578, 'log_learning_rate_D': -3.4024460202405025, 'log_learning_rate_D_dagger': -3.1040424197810172, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.5200, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5101, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  60 training error:  tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
[I 2023-12-19 23:15:55,878] Trial 181 finished with value: 0.1703123152256012 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.847730938635578, 'log_learning_rate_D': -3.4024460202405025, 'log_learning_rate_D_dagger': -3.1040424197810172, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  251.67976093292236
Memory status after this trial: 
Memory allocated:  521.35986328125
Memory cached:  542.0
--------------------  Trial  182   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.748704250748941, 'log_learning_rate_D': -3.2679743743374865, 'log_learning_rate_D_dagger': -2.967164187084425, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  10 training error:  tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.4651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  60 training error:  tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
[I 2023-12-19 23:20:01,544] Trial 182 finished with value: 0.15942545235157013 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.748704250748941, 'log_learning_rate_D': -3.2679743743374865, 'log_learning_rate_D_dagger': -2.967164187084425, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  245.28604888916016
Memory status after this trial: 
Memory allocated:  521.35986328125
Memory cached:  542.0
--------------------  Trial  183   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.999973725137467, 'log_learning_rate_D': -3.550394768401494, 'log_learning_rate_D_dagger': -3.324161470423144, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5098, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.65576171875
Memory cached:  480.0
[I 2023-12-19 23:23:51,729] Trial 183 finished with value: 0.13901257514953613 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.999973725137467, 'log_learning_rate_D': -3.550394768401494, 'log_learning_rate_D_dagger': -3.324161470423144, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  229.81495141983032
Memory status after this trial: 
Memory allocated:  507.625
Memory cached:  526.0
--------------------  Trial  184   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.670356346645683, 'log_learning_rate_D': -3.1140695420323863, 'log_learning_rate_D_dagger': -3.2154042136651286, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  478.0
	 epoch  10 training error:  tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  478.0
	 epoch  30 training error:  tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  478.0
	 epoch  40 training error:  tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  478.0
	 epoch  80 training error:  tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  478.0
	 epoch  90 training error:  tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  335.52099609375
Memory cached:  480.0
[I 2023-12-19 23:27:57,669] Trial 184 finished with value: 0.18926595151424408 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.670356346645683, 'log_learning_rate_D': -3.1140695420323863, 'log_learning_rate_D_dagger': -3.2154042136651286, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  245.56117415428162
Memory status after this trial: 
Memory allocated:  481.22900390625
Memory cached:  500.0
--------------------  Trial  185   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -4.804100172376164, 'log_learning_rate_D': -3.3189957787625626, 'log_learning_rate_D_dagger': -3.027237448099731, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.41552734375
Memory cached:  484.0
[I 2023-12-19 23:31:59,360] Trial 185 finished with value: 0.11537482589483261 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -4.804100172376164, 'log_learning_rate_D': -3.3189957787625626, 'log_learning_rate_D_dagger': -3.027237448099731, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  241.3141303062439
Memory status after this trial: 
Memory allocated:  521.3701171875
Memory cached:  542.0
--------------------  Trial  186   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.544114768224106, 'log_learning_rate_D': -3.1810337986803283, 'log_learning_rate_D_dagger': -3.0791932535472673, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.3372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.38427734375
Memory cached:  480.0
[I 2023-12-19 23:34:23,476] Trial 186 finished with value: 0.15599629282951355 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.544114768224106, 'log_learning_rate_D': -3.1810337986803283, 'log_learning_rate_D_dagger': -3.0791932535472673, 'training_batch_size': 10, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  143.76580953598022
Memory status after this trial: 
Memory allocated:  520.2919921875
Memory cached:  540.0
--------------------  Trial  187   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.794125846587191, 'log_learning_rate_D': -3.292928716233602, 'log_learning_rate_D_dagger': -2.035144158506238, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.9827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.6287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  20 training error:  tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  40 training error:  tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  80 training error:  tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
	 epoch  90 training error:  tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  337.39404296875
Memory cached:  480.0
[I 2023-12-19 23:38:16,480] Trial 187 finished with value: 0.36802423000335693 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.794125846587191, 'log_learning_rate_D': -3.292928716233602, 'log_learning_rate_D_dagger': -2.035144158506238, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  232.6306653022766
Memory status after this trial: 
Memory allocated:  491.990234375
Memory cached:  512.0
--------------------  Trial  188   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.710443294162821, 'log_learning_rate_D': -3.4199966803506827, 'log_learning_rate_D_dagger': -3.0141352466124713, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  20 training error:  tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  40 training error:  tensor(0.4925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  60 training error:  tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  90 training error:  tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  482.0
[I 2023-12-19 23:42:13,365] Trial 188 finished with value: 0.13497582077980042 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.710443294162821, 'log_learning_rate_D': -3.4199966803506827, 'log_learning_rate_D_dagger': -3.0141352466124713, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  236.43808364868164
Memory status after this trial: 
Memory allocated:  520.341796875
Memory cached:  540.0
--------------------  Trial  189   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -4.706897247147211, 'log_learning_rate_D': -3.4487520277685717, 'log_learning_rate_D_dagger': -3.025595822210663, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5222, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  20 training error:  tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  40 training error:  tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  50 training error:  tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  480.0
	 epoch  60 training error:  tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  480.0
	 epoch  70 training error:  tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
	 epoch  90 training error:  tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.27490234375
Memory cached:  482.0
[I 2023-12-19 23:46:20,094] Trial 189 finished with value: 0.1811213195323944 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 4, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 4, 'log_learning_rate': -4.706897247147211, 'log_learning_rate_D': -3.4487520277685717, 'log_learning_rate_D_dagger': -3.025595822210663, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  246.33716654777527
Memory status after this trial: 
Memory allocated:  494.2294921875
Memory cached:  514.0
--------------------  Trial  190   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.8785952902965875, 'log_learning_rate_D': -3.357981006706794, 'log_learning_rate_D_dagger': -2.958902365335136, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  484.0
	 epoch  20 training error:  tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  482.0
	 epoch  30 training error:  tensor(0.4947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  484.0
	 epoch  40 training error:  tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  484.0
	 epoch  50 training error:  tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  484.0
	 epoch  60 training error:  tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  490.0
	 epoch  70 training error:  tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  482.0
	 epoch  80 training error:  tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  486.0
	 epoch  90 training error:  tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  342.42529296875
Memory cached:  486.0
[I 2023-12-19 23:50:52,365] Trial 190 finished with value: 0.15501995384693146 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.8785952902965875, 'log_learning_rate_D': -3.357981006706794, 'log_learning_rate_D_dagger': -2.958902365335136, 'training_batch_size': 6, 'training_p': 6}. Best is trial 157 with value: 0.10292010754346848.
Time for this trial:  271.8788676261902
Memory status after this trial: 
Memory allocated:  560.912109375
Memory cached:  582.0
--------------------  Trial  191   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 3, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 4, 'log_learning_rate': -4.605642823239076, 'log_learning_rate_D': -3.5520784912689605, 'log_learning_rate_D_dagger': -3.1296989392313526, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  10 training error:  tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  20 training error:  tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  30 training error:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  40 training error:  tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  480.0
	 epoch  50 training error:  tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  484.0
	 epoch  60 training error:  tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  482.0
	 epoch  70 training error:  tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  339.40966796875
Memory cached:  482.0
