/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2023-11-03 22:18:37,409] A new study created in memory with name: no-name-3a95dea3-31f6-4277-99de-f70636e45d7d
Cuda is available:  True
Device is:  cuda:0
Memory allocated:  0.0
Memory cached:  0.0
Vs.shape:  torch.Size([100, 100])
thetas.shape:  torch.Size([100, 100])
fs.shape:  torch.Size([100, 100])
ts.shape:  torch.Size([100, 100])
Xs.shape:  torch.Size([100, 100])
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.833805904863679, 'log_learning_rate_D': -4.433674497731268, 'training_batch_size': 8, 'training_p': 3}
/home/shengduo/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
	 epoch  0 training error:  tensor(1.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.78662109375
Memory cached:  8.0
[I 2023-11-03 22:18:56,692] Trial 0 finished with value: 0.07305078208446503 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -1.833805904863679, 'log_learning_rate_D': -4.433674497731268, 'training_batch_size': 8, 'training_p': 3}. Best is trial 0 with value: 0.07305078208446503.
Time for this trial:  19.176932096481323
Memory status after this trial: 
Memory allocated:  44.98681640625
Memory cached:  60.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.01937508603778, 'log_learning_rate_D': -2.4979132169489953, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.07275390625
Memory cached:  8.0
[I 2023-11-03 22:19:13,712] Trial 1 finished with value: 0.06039784103631973 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.01937508603778, 'log_learning_rate_D': -2.4979132169489953, 'training_batch_size': 10, 'training_p': 3}. Best is trial 1 with value: 0.06039784103631973.
Time for this trial:  16.91727375984192
Memory status after this trial: 
Memory allocated:  42.89111328125
Memory cached:  58.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.654941744168456, 'log_learning_rate_D': -1.1000191251703644, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
[I 2023-11-03 22:19:32,020] Trial 2 finished with value: 0.05181977152824402 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.654941744168456, 'log_learning_rate_D': -1.1000191251703644, 'training_batch_size': 11, 'training_p': 5}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  18.20270872116089
Memory status after this trial: 
Memory allocated:  118.85791015625
Memory cached:  146.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.4138561583093865, 'log_learning_rate_D': -4.367083582238113, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.8517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.9774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.7062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.935546875
Memory cached:  10.0
[I 2023-11-03 22:19:49,822] Trial 3 finished with value: 0.28393810987472534 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.4138561583093865, 'log_learning_rate_D': -4.367083582238113, 'training_batch_size': 11, 'training_p': 7}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  17.69919490814209
Memory status after this trial: 
Memory allocated:  93.75634765625
Memory cached:  108.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.9034662858881246, 'log_learning_rate_D': -1.1410756443533434, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(2.2412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56982421875
Memory cached:  2.0
[I 2023-11-03 22:20:05,265] Trial 4 finished with value: 0.05525432899594307 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.9034662858881246, 'log_learning_rate_D': -1.1410756443533434, 'training_batch_size': 10, 'training_p': 6}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  15.339093208312988
Memory status after this trial: 
Memory allocated:  17.34814453125
Memory cached:  26.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.666466549075121, 'log_learning_rate_D': -1.9912206949024056, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3056640625
Memory cached:  8.0
[I 2023-11-03 22:20:23,363] Trial 5 finished with value: 0.05388077720999718 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.666466549075121, 'log_learning_rate_D': -1.9912206949024056, 'training_batch_size': 11, 'training_p': 6}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  17.990578413009644
Memory status after this trial: 
Memory allocated:  113.36767578125
Memory cached:  140.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.112414564968351, 'log_learning_rate_D': -2.133819349061003, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.15673828125
Memory cached:  8.0
[I 2023-11-03 22:20:40,042] Trial 6 finished with value: 0.05764205381274223 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -3.112414564968351, 'log_learning_rate_D': -2.133819349061003, 'training_batch_size': 7, 'training_p': 3}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  16.582590103149414
Memory status after this trial: 
Memory allocated:  47.91455078125
Memory cached:  68.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.652804312038388, 'log_learning_rate_D': -2.0406927642297448, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  10 training error:  tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  20 training error:  tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  30 training error:  tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  40 training error:  tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  50 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  60 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  70 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  80 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
	 epoch  90 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  36.73095703125
Memory cached:  74.0
[I 2023-11-03 22:21:00,003] Trial 7 finished with value: 0.05584709718823433 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -4.652804312038388, 'log_learning_rate_D': -2.0406927642297448, 'training_batch_size': 10, 'training_p': 6}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  19.85241150856018
Memory status after this trial: 
Memory allocated:  261.80224609375
Memory cached:  290.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.8287811428192815, 'log_learning_rate_D': -3.553462107917836, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.8173828125
Memory cached:  6.0
[I 2023-11-03 22:21:16,784] Trial 8 finished with value: 0.0542779341340065 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'log_learning_rate': -2.8287811428192815, 'log_learning_rate_D': -3.553462107917836, 'training_batch_size': 12, 'training_p': 3}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  16.678110361099243
Memory status after this trial: 
Memory allocated:  68.33349609375
Memory cached:  76.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.672165206859101, 'log_learning_rate_D': -2.6986508477897284, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0127, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  10 training error:  tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  20 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  30 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  40 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8310546875
Memory cached:  24.0
[I 2023-11-03 22:21:32,322] Trial 9 finished with value: 1.0000194311141968 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.672165206859101, 'log_learning_rate_D': -2.6986508477897284, 'training_batch_size': 12, 'training_p': 2}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  15.444976329803467
Memory status after this trial: 
Memory allocated:  18.21142578125
Memory cached:  26.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.0203533772197972, 'log_learning_rate_D': -1.1063620807287915, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.8073, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  50.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.66064453125
Memory cached:  48.0
[I 2023-11-03 22:21:52,778] Trial 10 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.0203533772197972, 'log_learning_rate_D': -1.1063620807287915, 'training_batch_size': 6, 'training_p': 8}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  20.277825593948364
Memory status after this trial: 
Memory allocated:  100.91943359375
Memory cached:  116.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.969074080412208, 'log_learning_rate_D': -1.5763665329161984, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.9737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.9283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.8639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.4082, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.54150390625
Memory cached:  8.0
[I 2023-11-03 22:22:12,440] Trial 11 finished with value: 0.0641765221953392 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -4.969074080412208, 'log_learning_rate_D': -1.5763665329161984, 'training_batch_size': 9, 'training_p': 5}. Best is trial 2 with value: 0.05181977152824402.
Time for this trial:  19.494049549102783
Memory status after this trial: 
Memory allocated:  185.79248046875
Memory cached:  206.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.096480112510559, 'log_learning_rate_D': -1.7929510237738484, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0177, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7509765625
Memory cached:  8.0
[I 2023-11-03 22:22:31,010] Trial 12 finished with value: 0.051613569259643555 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -4.096480112510559, 'log_learning_rate_D': -1.7929510237738484, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.051613569259643555.
Time for this trial:  18.3809494972229
Memory status after this trial: 
Memory allocated:  145.71923828125
Memory cached:  162.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.797215676555408, 'log_learning_rate_D': -1.5061776920630214, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9893, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.16796875
Memory cached:  42.0
[I 2023-11-03 22:22:50,234] Trial 13 finished with value: 0.0519561767578125 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.797215676555408, 'log_learning_rate_D': -1.5061776920630214, 'training_batch_size': 11, 'training_p': 5}. Best is trial 12 with value: 0.051613569259643555.
Time for this trial:  19.027942895889282
Memory status after this trial: 
Memory allocated:  200.18115234375
Memory cached:  270.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.809761284898803, 'log_learning_rate_D': -1.0329006698600105, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.7657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.775390625
Memory cached:  8.0
[I 2023-11-03 22:23:07,126] Trial 14 finished with value: 0.05597573146224022 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -3.809761284898803, 'log_learning_rate_D': -1.0329006698600105, 'training_batch_size': 9, 'training_p': 4}. Best is trial 12 with value: 0.051613569259643555.
Time for this trial:  16.72441792488098
Memory status after this trial: 
Memory allocated:  34.63720703125
Memory cached:  42.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.35568525796568, 'log_learning_rate_D': -3.133027900324077, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0031, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.57421875
Memory cached:  30.0
[I 2023-11-03 22:23:25,422] Trial 15 finished with value: 0.05133124813437462 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.35568525796568, 'log_learning_rate_D': -3.133027900324077, 'training_batch_size': 12, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.06912136077881
Memory status after this trial: 
Memory allocated:  88.30810546875
Memory cached:  102.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.151129868555525, 'log_learning_rate_D': -3.224906731388807, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7216796875
Memory cached:  32.0
[I 2023-11-03 22:23:43,114] Trial 16 finished with value: 0.051598574966192245 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.151129868555525, 'log_learning_rate_D': -3.224906731388807, 'training_batch_size': 12, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.451643228530884
Memory status after this trial: 
Memory allocated:  69.48779296875
Memory cached:  78.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2359420240904653, 'log_learning_rate_D': -3.334680756462813, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0139, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.7783203125
Memory cached:  30.0
[I 2023-11-03 22:24:02,705] Trial 17 finished with value: 0.05196690559387207 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.2359420240904653, 'log_learning_rate_D': -3.334680756462813, 'training_batch_size': 12, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  19.393762588500977
Memory status after this trial: 
Memory allocated:  110.40576171875
Memory cached:  134.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3334508090587, 'log_learning_rate_D': -3.368787651278248, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.2109375
Memory cached:  24.0
[I 2023-11-03 22:24:19,072] Trial 18 finished with value: 0.05482390522956848 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.3334508090587, 'log_learning_rate_D': -3.368787651278248, 'training_batch_size': 12, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.181492567062378
Memory status after this trial: 
Memory allocated:  21.97021484375
Memory cached:  26.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.5919395446496862, 'log_learning_rate_D': -3.8775759995317545, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  10 training error:  tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  20 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.9908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  30.259765625
Memory cached:  64.0
[I 2023-11-03 22:24:38,528] Trial 19 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 9, 'log_learning_rate': -2.5919395446496862, 'log_learning_rate_D': -3.8775759995317545, 'training_batch_size': 8, 'training_p': 2}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  19.250389337539673
Memory status after this trial: 
Memory allocated:  182.53076171875
Memory cached:  210.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.390852329619518, 'log_learning_rate_D': -2.9465214938778734, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.85986328125
Memory cached:  10.0
[I 2023-11-03 22:24:55,632] Trial 20 finished with value: 0.0547599159181118 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.390852329619518, 'log_learning_rate_D': -2.9465214938778734, 'training_batch_size': 10, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.907663822174072
Memory status after this trial: 
Memory allocated:  49.78662109375
Memory cached:  74.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.059393452141922, 'log_learning_rate_D': -2.921450659121196, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.7008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1611328125
Memory cached:  8.0
[I 2023-11-03 22:25:13,812] Trial 21 finished with value: 0.05207369476556778 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.059393452141922, 'log_learning_rate_D': -2.921450659121196, 'training_batch_size': 12, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.97748637199402
Memory status after this trial: 
Memory allocated:  95.57373046875
Memory cached:  112.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.20762977758708, 'log_learning_rate_D': -2.4911073811442015, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.28857421875
Memory cached:  16.0
[I 2023-11-03 22:25:31,721] Trial 22 finished with value: 0.05443889647722244 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.20762977758708, 'log_learning_rate_D': -2.4911073811442015, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.71366858482361
Memory status after this trial: 
Memory allocated:  92.41552734375
Memory cached:  114.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.908168887371166, 'log_learning_rate_D': -3.171095278683907, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.333984375
Memory cached:  12.0
[I 2023-11-03 22:25:49,987] Trial 23 finished with value: 0.056215520948171616 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -2.908168887371166, 'log_learning_rate_D': -3.171095278683907, 'training_batch_size': 12, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.06213903427124
Memory status after this trial: 
Memory allocated:  81.03369140625
Memory cached:  110.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4372473424574683, 'log_learning_rate_D': -3.7199630160905897, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0197, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.080078125
Memory cached:  6.0
[I 2023-11-03 22:26:07,663] Trial 24 finished with value: 0.055119823664426804 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.4372473424574683, 'log_learning_rate_D': -3.7199630160905897, 'training_batch_size': 11, 'training_p': 6}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.466925859451294
Memory status after this trial: 
Memory allocated:  82.59619140625
Memory cached:  96.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.227874801322171, 'log_learning_rate_D': -3.9987125400309136, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0092, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.9469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.8625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.7282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.29931640625
Memory cached:  8.0
[I 2023-11-03 22:26:24,955] Trial 25 finished with value: 0.06216564401984215 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -4.227874801322171, 'log_learning_rate_D': -3.9987125400309136, 'training_batch_size': 12, 'training_p': 7}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.091405868530273
Memory status after this trial: 
Memory allocated:  48.10986328125
Memory cached:  62.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.5626417662171757, 'log_learning_rate_D': -3.1030761525664583, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7934, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  10 training error:  tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.18505859375
Memory cached:  24.0
[I 2023-11-03 22:26:41,914] Trial 26 finished with value: 0.055040474981069565 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -3.5626417662171757, 'log_learning_rate_D': -3.1030761525664583, 'training_batch_size': 11, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.77441692352295
Memory status after this trial: 
Memory allocated:  43.98583984375
Memory cached:  60.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.0944286735381623, 'log_learning_rate_D': -4.724716048763495, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.1910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.37451171875
Memory cached:  44.0
[I 2023-11-03 22:27:00,296] Trial 27 finished with value: 0.06361038982868195 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.0944286735381623, 'log_learning_rate_D': -4.724716048763495, 'training_batch_size': 10, 'training_p': 3}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.17750597000122
Memory status after this trial: 
Memory allocated:  125.96435546875
Memory cached:  150.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.556602700305519, 'log_learning_rate_D': -2.8190583501306214, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0319, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  20 training error:  tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  30 training error:  tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  50 training error:  tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  60 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  80 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  4.0
	 epoch  90 training error:  tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.62548828125
Memory cached:  6.0
[I 2023-11-03 22:27:17,866] Trial 28 finished with value: 0.055774081498384476 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.556602700305519, 'log_learning_rate_D': -2.8190583501306214, 'training_batch_size': 12, 'training_p': 7}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.362431049346924
Memory status after this trial: 
Memory allocated:  65.20361328125
Memory cached:  72.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7510046240535564, 'log_learning_rate_D': -3.4219946907484555, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.8254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  30 training error:  tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.998046875
Memory cached:  32.0
[I 2023-11-03 22:27:36,370] Trial 29 finished with value: 0.05988456681370735 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7510046240535564, 'log_learning_rate_D': -3.4219946907484555, 'training_batch_size': 8, 'training_p': 2}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.286044120788574
Memory status after this trial: 
Memory allocated:  108.97119140625
Memory cached:  114.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1529281947615786, 'log_learning_rate_D': -3.187438127089112, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.62255859375
Memory cached:  36.0
[I 2023-11-03 22:27:55,350] Trial 30 finished with value: 0.06404506415128708 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -3.1529281947615786, 'log_learning_rate_D': -3.187438127089112, 'training_batch_size': 9, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.776705741882324
Memory status after this trial: 
Memory allocated:  107.99658203125
Memory cached:  130.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.605285199635028, 'log_learning_rate_D': -1.4304625967386104, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.11669921875
Memory cached:  8.0
[I 2023-11-03 22:28:14,030] Trial 31 finished with value: 0.05183674022555351 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.605285199635028, 'log_learning_rate_D': -1.4304625967386104, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.4745934009552
Memory status after this trial: 
Memory allocated:  118.85791015625
Memory cached:  146.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.8389298018243085, 'log_learning_rate_D': -2.624123584485319, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.7011, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.81298828125
Memory cached:  10.0
[I 2023-11-03 22:28:31,864] Trial 32 finished with value: 0.05136957764625549 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.8389298018243085, 'log_learning_rate_D': -2.624123584485319, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.63786220550537
Memory status after this trial: 
Memory allocated:  63.79248046875
Memory cached:  70.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.959470816062301, 'log_learning_rate_D': -2.5502040317416554, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2919921875
Memory cached:  6.0
[I 2023-11-03 22:28:49,660] Trial 33 finished with value: 0.05164504051208496 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.959470816062301, 'log_learning_rate_D': -2.5502040317416554, 'training_batch_size': 10, 'training_p': 3}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.59222650527954
Memory status after this trial: 
Memory allocated:  76.85693359375
Memory cached:  90.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.296903380458793, 'log_learning_rate_D': -2.3485477352175748, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.47900390625
Memory cached:  6.0
[I 2023-11-03 22:29:07,411] Trial 34 finished with value: 0.051570601761341095 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.296903380458793, 'log_learning_rate_D': -2.3485477352175748, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.528561115264893
Memory status after this trial: 
Memory allocated:  60.63720703125
Memory cached:  80.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.9949825462264914, 'log_learning_rate_D': -2.5657489661170474, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7880859375
Memory cached:  8.0
[I 2023-11-03 22:29:24,957] Trial 35 finished with value: 0.05183607339859009 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -2.9949825462264914, 'log_learning_rate_D': -2.5657489661170474, 'training_batch_size': 12, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.346510410308838
Memory status after this trial: 
Memory allocated:  38.50732421875
Memory cached:  52.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.275215710466979, 'log_learning_rate_D': -2.368812412991559, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0289, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.20947265625
Memory cached:  10.0
[I 2023-11-03 22:29:42,768] Trial 36 finished with value: 0.052135683596134186 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.275215710466979, 'log_learning_rate_D': -2.368812412991559, 'training_batch_size': 11, 'training_p': 6}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.593916654586792
Memory status after this trial: 
Memory allocated:  58.69384765625
Memory cached:  78.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.708916859476421, 'log_learning_rate_D': -2.2224037061051867, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0072, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.6951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.56201171875
Memory cached:  10.0
[I 2023-11-03 22:29:59,468] Trial 37 finished with value: 0.05162796005606651 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.708916859476421, 'log_learning_rate_D': -2.2224037061051867, 'training_batch_size': 10, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.492342233657837
Memory status after this trial: 
Memory allocated:  23.37939453125
Memory cached:  26.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.5100039879884775, 'log_learning_rate_D': -2.810820339655466, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.921875
Memory cached:  10.0
[I 2023-11-03 22:30:16,688] Trial 38 finished with value: 0.07384457439184189 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.5100039879884775, 'log_learning_rate_D': -2.810820339655466, 'training_batch_size': 11, 'training_p': 3}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.959288120269775
Memory status after this trial: 
Memory allocated:  40.94189453125
Memory cached:  56.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.051524045113756, 'log_learning_rate_D': -2.2924651712912643, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.9154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  10 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  20 training error:  tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  30 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  40 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  50 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  60 training error:  tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  70 training error:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  80 training error:  tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
	 epoch  90 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.74365234375
Memory cached:  2.0
[I 2023-11-03 22:30:32,746] Trial 39 finished with value: 0.05326857790350914 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.051524045113756, 'log_learning_rate_D': -2.2924651712912643, 'training_batch_size': 12, 'training_p': 6}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  15.85841965675354
Memory status after this trial: 
Memory allocated:  31.61767578125
Memory cached:  46.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.406614901827615, 'log_learning_rate_D': -2.7151266351386503, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2451171875
Memory cached:  10.0
[I 2023-11-03 22:30:50,707] Trial 40 finished with value: 0.05284944176673889 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.406614901827615, 'log_learning_rate_D': -2.7151266351386503, 'training_batch_size': 10, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  17.755386114120483
Memory status after this trial: 
Memory allocated:  69.05712890625
Memory cached:  76.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.039321869484192, 'log_learning_rate_D': -1.8395423211546762, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4794921875
Memory cached:  10.0
[I 2023-11-03 22:31:09,654] Trial 41 finished with value: 0.052425503730773926 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.039321869484192, 'log_learning_rate_D': -1.8395423211546762, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.728492736816406
Memory status after this trial: 
Memory allocated:  115.99853515625
Memory cached:  122.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.7671535708055126, 'log_learning_rate_D': -1.9354413974083378, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.83203125
Memory cached:  6.0
[I 2023-11-03 22:31:27,982] Trial 42 finished with value: 0.05220942571759224 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -3.7671535708055126, 'log_learning_rate_D': -1.9354413974083378, 'training_batch_size': 11, 'training_p': 6}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.096564531326294
Memory status after this trial: 
Memory allocated:  103.30712890625
Memory cached:  124.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.256191035982649, 'log_learning_rate_D': -2.129811160810708, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.8768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.443359375
Memory cached:  8.0
[I 2023-11-03 22:31:46,993] Trial 43 finished with value: 0.05205690860748291 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.256191035982649, 'log_learning_rate_D': -2.129811160810708, 'training_batch_size': 12, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.777392625808716
Memory status after this trial: 
Memory allocated:  105.61279296875
Memory cached:  120.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5206255810970406, 'log_learning_rate_D': -2.974624853327235, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.85546875
Memory cached:  10.0
[I 2023-11-03 22:32:05,579] Trial 44 finished with value: 0.052276380360126495 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5206255810970406, 'log_learning_rate_D': -2.974624853327235, 'training_batch_size': 11, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  18.356264114379883
Memory status after this trial: 
Memory allocated:  113.50341796875
Memory cached:  140.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.7412375130025968, 'log_learning_rate_D': -2.4491522329524393, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.58154296875
Memory cached:  8.0
[I 2023-11-03 22:32:26,136] Trial 45 finished with value: 0.06473927199840546 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -2.7412375130025968, 'log_learning_rate_D': -2.4491522329524393, 'training_batch_size': 6, 'training_p': 5}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  20.332507848739624
Memory status after this trial: 
Memory allocated:  93.40380859375
Memory cached:  108.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.1994658478892473, 'log_learning_rate_D': -2.288694171787358, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(0.5679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.50341796875
Memory cached:  6.0
[I 2023-11-03 22:32:42,821] Trial 46 finished with value: 0.053916484117507935 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.1994658478892473, 'log_learning_rate_D': -2.288694171787358, 'training_batch_size': 12, 'training_p': 6}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  16.493632555007935
Memory status after this trial: 
Memory allocated:  43.98974609375
Memory cached:  66.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6734848705225374, 'log_learning_rate_D': -2.6847639132896086, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  10 training error:  tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  30 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  40 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  50 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  60 training error:  tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  70 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  80 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
	 epoch  90 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.166015625
Memory cached:  48.0
[I 2023-11-03 22:33:02,433] Trial 47 finished with value: 0.05140829086303711 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.6734848705225374, 'log_learning_rate_D': -2.6847639132896086, 'training_batch_size': 10, 'training_p': 4}. Best is trial 15 with value: 0.05133124813437462.
Time for this trial:  19.374481439590454
Memory status after this trial: 
Memory allocated:  153.43603515625
Memory cached:  170.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.8900834111869647, 'log_learning_rate_D': -2.6681376203906506, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.5361328125
Memory cached:  30.0
[I 2023-11-03 22:33:22,049] Trial 48 finished with value: 0.050749361515045166 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.8900834111869647, 'log_learning_rate_D': -2.6681376203906506, 'training_batch_size': 10, 'training_p': 3}. Best is trial 48 with value: 0.050749361515045166.
Time for this trial:  19.37203598022461
Memory status after this trial: 
Memory allocated:  151.89111328125
Memory cached:  172.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.8908144923610144, 'log_learning_rate_D': -2.6750095617636824, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  10 training error:  tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  20 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  60 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2158203125
Memory cached:  44.0
[I 2023-11-03 22:33:41,862] Trial 49 finished with value: 0.05130655691027641 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 4, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.8908144923610144, 'log_learning_rate_D': -2.6750095617636824, 'training_batch_size': 10, 'training_p': 3}. Best is trial 48 with value: 0.050749361515045166.
[I 2023-11-03 22:33:41,862] A new study created in memory with name: no-name-1c8f5191-3436-4661-b11f-64695c4432ae
Time for this trial:  19.57826280593872
Memory status after this trial: 
Memory allocated:  195.51220703125
Memory cached:  240.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.798964723847929, 'log_learning_rate_D': -2.2487447351511682, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9860, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.8407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.7895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.7364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.6809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.6234, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3896484375
Memory cached:  18.0
[I 2023-11-03 22:36:12,096] Trial 0 finished with value: 0.3773331046104431 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -4.798964723847929, 'log_learning_rate_D': -2.2487447351511682, 'training_batch_size': 9, 'training_p': 6}. Best is trial 0 with value: 0.3773331046104431.
Time for this trial:  150.11428332328796
Memory status after this trial: 
Memory allocated:  113.96875
Memory cached:  118.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -1.4154797336789948, 'log_learning_rate_D': -4.455021006052618, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9658, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1455078125
Memory cached:  42.0
[I 2023-11-03 22:39:01,189] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -1.4154797336789948, 'log_learning_rate_D': -4.455021006052618, 'training_batch_size': 8, 'training_p': 4}. Best is trial 0 with value: 0.3773331046104431.
Time for this trial:  168.94526171684265
Memory status after this trial: 
Memory allocated:  209.671875
Memory cached:  228.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.6017392249999047, 'log_learning_rate_D': -1.0355832044214912, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  38.0
	 epoch  10 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.9755859375
Memory cached:  40.0
[I 2023-11-03 22:41:29,995] Trial 2 finished with value: 1.0 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 8, 'log_learning_rate': -1.6017392249999047, 'log_learning_rate_D': -1.0355832044214912, 'training_batch_size': 10, 'training_p': 6}. Best is trial 0 with value: 0.3773331046104431.
Time for this trial:  148.65235805511475
Memory status after this trial: 
Memory allocated:  177.97314453125
Memory cached:  200.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.347789696738475, 'log_learning_rate_D': -2.8234014681867423, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  38.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  42.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  44.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  44.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  42.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  44.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  42.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  44.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.4091796875
Memory cached:  42.0
[I 2023-11-03 22:44:22,779] Trial 3 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -1.347789696738475, 'log_learning_rate_D': -2.8234014681867423, 'training_batch_size': 10, 'training_p': 3}. Best is trial 0 with value: 0.3773331046104431.
Time for this trial:  172.6518361568451
Memory status after this trial: 
Memory allocated:  288.91455078125
Memory cached:  308.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.531829543508565, 'log_learning_rate_D': -4.872186946327041, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  14.0
	 epoch  20 training error:  tensor(1.0015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
	 epoch  30 training error:  tensor(1.0012, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
	 epoch  40 training error:  tensor(1.0006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
	 epoch  50 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.9982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.3974609375
Memory cached:  16.0
[I 2023-11-03 22:46:21,255] Trial 4 finished with value: 0.9930117726325989 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.531829543508565, 'log_learning_rate_D': -4.872186946327041, 'training_batch_size': 8, 'training_p': 7}. Best is trial 0 with value: 0.3773331046104431.
Time for this trial:  118.3212616443634
Memory status after this trial: 
Memory allocated:  106.65966796875
Memory cached:  108.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.569358919535382, 'log_learning_rate_D': -3.968458950694785, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0138, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.9088, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.7994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.6599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.4758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.8466796875
Memory cached:  40.0
[I 2023-11-03 22:49:10,651] Trial 5 finished with value: 0.11642567068338394 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 10, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -4.569358919535382, 'log_learning_rate_D': -3.968458950694785, 'training_batch_size': 12, 'training_p': 2}. Best is trial 5 with value: 0.11642567068338394.
Time for this trial:  169.2651708126068
Memory status after this trial: 
Memory allocated:  260.1767578125
Memory cached:  278.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.747245171212851, 'log_learning_rate_D': -2.906548408205025, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.9775390625
Memory cached:  10.0
[I 2023-11-03 22:53:32,115] Trial 6 finished with value: 0.04262048751115799 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.747245171212851, 'log_learning_rate_D': -2.906548408205025, 'training_batch_size': 6, 'training_p': 4}. Best is trial 6 with value: 0.04262048751115799.
Time for this trial:  261.3000793457031
Memory status after this trial: 
Memory allocated:  61.85009765625
Memory cached:  64.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.741417830241325, 'log_learning_rate_D': -4.803597047232063, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  20 training error:  tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  34.0
	 epoch  30 training error:  tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  40 training error:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  50 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  60 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  70 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  80 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
	 epoch  90 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.5849609375
Memory cached:  32.0
[I 2023-11-03 22:57:01,416] Trial 7 finished with value: 0.04254813864827156 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -4.741417830241325, 'log_learning_rate_D': -4.803597047232063, 'training_batch_size': 6, 'training_p': 8}. Best is trial 7 with value: 0.04254813864827156.
Time for this trial:  209.148118019104
Memory status after this trial: 
Memory allocated:  124.77197265625
Memory cached:  138.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.580782417575459, 'log_learning_rate_D': -1.9936043582762926, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6669921875
Memory cached:  42.0
[I 2023-11-03 22:59:38,535] Trial 8 finished with value: 0.05185765027999878 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.580782417575459, 'log_learning_rate_D': -1.9936043582762926, 'training_batch_size': 8, 'training_p': 6}. Best is trial 7 with value: 0.04254813864827156.
Time for this trial:  156.97110962867737
Memory status after this trial: 
Memory allocated:  176.72314453125
Memory cached:  196.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.475860784539353, 'log_learning_rate_D': -1.2443838080470169, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.7589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  20 training error:  tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  30 training error:  tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  50 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  80 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
	 epoch  90 training error:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8251953125
Memory cached:  26.0
[I 2023-11-03 23:02:39,531] Trial 9 finished with value: 0.05441112443804741 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.475860784539353, 'log_learning_rate_D': -1.2443838080470169, 'training_batch_size': 10, 'training_p': 2}. Best is trial 7 with value: 0.04254813864827156.
Time for this trial:  180.83377242088318
Memory status after this trial: 
Memory allocated:  197.94580078125
Memory cached:  202.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.8843653915887275, 'log_learning_rate_D': -3.8508321212854866, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.5830078125
Memory cached:  8.0
[I 2023-11-03 23:05:47,945] Trial 10 finished with value: 0.043106935918331146 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -3.8843653915887275, 'log_learning_rate_D': -3.8508321212854866, 'training_batch_size': 6, 'training_p': 8}. Best is trial 7 with value: 0.04254813864827156.
Time for this trial:  188.20621180534363
Memory status after this trial: 
Memory allocated:  66.55078125
Memory cached:  68.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.84994544987713, 'log_learning_rate_D': -3.2860523982850602, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6708984375
Memory cached:  10.0
[I 2023-11-03 23:08:42,157] Trial 11 finished with value: 0.03036658838391304 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.84994544987713, 'log_learning_rate_D': -3.2860523982850602, 'training_batch_size': 6, 'training_p': 4}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  174.02664041519165
Memory status after this trial: 
Memory allocated:  59.25390625
Memory cached:  62.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.886042230063924, 'log_learning_rate_D': -3.688350109777818, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3154296875
Memory cached:  14.0
[I 2023-11-03 23:11:57,387] Trial 12 finished with value: 0.04018649458885193 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.886042230063924, 'log_learning_rate_D': -3.688350109777818, 'training_batch_size': 6, 'training_p': 8}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  195.04130911827087
Memory status after this trial: 
Memory allocated:  101.84375
Memory cached:  104.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.625035017723733, 'log_learning_rate_D': -3.636495205065029, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2041015625
Memory cached:  14.0
[I 2023-11-03 23:13:32,950] Trial 13 finished with value: 0.0364651195704937 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.625035017723733, 'log_learning_rate_D': -3.636495205065029, 'training_batch_size': 7, 'training_p': 4}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  95.38929677009583
Memory status after this trial: 
Memory allocated:  72.90625
Memory cached:  76.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.4005350390144464, 'log_learning_rate_D': -3.352840356278734, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.9051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1943359375
Memory cached:  10.0
[I 2023-11-03 23:15:02,010] Trial 14 finished with value: 0.03472403064370155 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -3.4005350390144464, 'log_learning_rate_D': -3.352840356278734, 'training_batch_size': 7, 'training_p': 4}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  88.88823103904724
Memory status after this trial: 
Memory allocated:  52.5986328125
Memory cached:  54.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.1656670214432587, 'log_learning_rate_D': -3.2687421380311767, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.4144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
[I 2023-11-03 23:16:40,774] Trial 15 finished with value: 0.03398986533284187 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.1656670214432587, 'log_learning_rate_D': -3.2687421380311767, 'training_batch_size': 7, 'training_p': 5}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  98.56966543197632
Memory status after this trial: 
Memory allocated:  61.3603515625
Memory cached:  64.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.853048910375032, 'log_learning_rate_D': -2.984354170831681, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2724609375
Memory cached:  14.0
[I 2023-11-03 23:18:29,020] Trial 16 finished with value: 0.05543239042162895 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -2.853048910375032, 'log_learning_rate_D': -2.984354170831681, 'training_batch_size': 7, 'training_p': 5}. Best is trial 11 with value: 0.03036658838391304.
Time for this trial:  108.05813074111938
Memory status after this trial: 
Memory allocated:  77.1572265625
Memory cached:  78.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.2432915050024813, 'log_learning_rate_D': -4.243789401504126, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3271484375
Memory cached:  12.0
[I 2023-11-03 23:20:17,233] Trial 17 finished with value: 0.028869470581412315 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.2432915050024813, 'log_learning_rate_D': -4.243789401504126, 'training_batch_size': 12, 'training_p': 5}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  108.01952648162842
Memory status after this trial: 
Memory allocated:  78.7314453125
Memory cached:  82.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.124264658907423, 'log_learning_rate_D': -4.23220356128561, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9912109375
Memory cached:  18.0
[I 2023-11-03 23:22:30,982] Trial 18 finished with value: 0.03894932195544243 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.124264658907423, 'log_learning_rate_D': -4.23220356128561, 'training_batch_size': 12, 'training_p': 3}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  133.56615352630615
Memory status after this trial: 
Memory allocated:  149.0595703125
Memory cached:  154.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.3294446997302005, 'log_learning_rate_D': -4.359062971729726, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.2138671875
Memory cached:  20.0
[I 2023-11-03 23:24:48,664] Trial 19 finished with value: 0.038208525627851486 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.3294446997302005, 'log_learning_rate_D': -4.359062971729726, 'training_batch_size': 11, 'training_p': 3}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  137.48530983924866
Memory status after this trial: 
Memory allocated:  139.4423828125
Memory cached:  144.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.9238389705191827, 'log_learning_rate_D': -4.031811973167672, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.1672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6357421875
Memory cached:  18.0
[I 2023-11-03 23:26:47,176] Trial 20 finished with value: 0.03899344429373741 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.9238389705191827, 'log_learning_rate_D': -4.031811973167672, 'training_batch_size': 11, 'training_p': 5}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  118.31031823158264
Memory status after this trial: 
Memory allocated:  108.2587890625
Memory cached:  110.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.4363459863364962, 'log_learning_rate_D': -3.3907438860978343, 'training_batch_size': 7, 'training_p': 5}
	 epoch  0 training error:  tensor(1.7039, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6962890625
Memory cached:  12.0
[I 2023-11-03 23:28:26,398] Trial 21 finished with value: 0.043804898858070374 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -3.4363459863364962, 'log_learning_rate_D': -3.3907438860978343, 'training_batch_size': 7, 'training_p': 5}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  99.03635549545288
Memory status after this trial: 
Memory allocated:  61.3603515625
Memory cached:  64.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.117221767165154, 'log_learning_rate_D': -3.3147214067102007, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4560546875
Memory cached:  14.0
[I 2023-11-03 23:30:06,132] Trial 22 finished with value: 0.03688892349600792 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.117221767165154, 'log_learning_rate_D': -3.3147214067102007, 'training_batch_size': 9, 'training_p': 5}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  99.53838872909546
Memory status after this trial: 
Memory allocated:  71.1650390625
Memory cached:  74.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.292245195539472, 'log_learning_rate_D': -4.532077392312562, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.7607421875
Memory cached:  16.0
[I 2023-11-03 23:31:53,407] Trial 23 finished with value: 0.12567733228206635 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -4.292245195539472, 'log_learning_rate_D': -4.532077392312562, 'training_batch_size': 8, 'training_p': 6}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  107.08009910583496
Memory status after this trial: 
Memory allocated:  74.150390625
Memory cached:  78.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.6865913086604576, 'log_learning_rate_D': -4.091555273082912, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.7744140625
Memory cached:  14.0
[I 2023-11-03 23:34:01,133] Trial 24 finished with value: 0.0378258153796196 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'log_learning_rate': -3.6865913086604576, 'log_learning_rate_D': -4.091555273082912, 'training_batch_size': 11, 'training_p': 7}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  127.54328942298889
Memory status after this trial: 
Memory allocated:  122.95751953125
Memory cached:  128.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.068183703023128, 'log_learning_rate_D': -3.701059050357963, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3369140625
Memory cached:  14.0
[I 2023-11-03 23:35:41,838] Trial 25 finished with value: 0.032502274960279465 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.068183703023128, 'log_learning_rate_D': -3.701059050357963, 'training_batch_size': 7, 'training_p': 4}. Best is trial 17 with value: 0.028869470581412315.
Time for this trial:  100.51249027252197
Memory status after this trial: 
Memory allocated:  80.58203125
Memory cached:  84.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.173039066987985, 'log_learning_rate_D': -3.6939345983338883, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7743, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6201171875
Memory cached:  10.0
[I 2023-11-03 23:38:53,256] Trial 26 finished with value: 0.027899861335754395 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.173039066987985, 'log_learning_rate_D': -3.6939345983338883, 'training_batch_size': 6, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  191.2187271118164
Memory status after this trial: 
Memory allocated:  66.7353515625
Memory cached:  70.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.309511840282455, 'log_learning_rate_D': -4.596270991745944, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5166015625
Memory cached:  12.0
[I 2023-11-03 23:42:04,389] Trial 27 finished with value: 0.03729453682899475 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -4.309511840282455, 'log_learning_rate_D': -4.596270991745944, 'training_batch_size': 6, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  190.91293096542358
Memory status after this trial: 
Memory allocated:  87.20849609375
Memory cached:  90.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.934865180465888, 'log_learning_rate_D': -4.180403462813774, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.7386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.6400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4326171875
Memory cached:  18.0
[I 2023-11-03 23:44:25,153] Trial 28 finished with value: 0.12094859033823013 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -4.934865180465888, 'log_learning_rate_D': -4.180403462813774, 'training_batch_size': 9, 'training_p': 2}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  140.55445861816406
Memory status after this trial: 
Memory allocated:  160.31591796875
Memory cached:  164.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.75214349813185, 'log_learning_rate_D': -2.5467134055295344, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.4853515625
Memory cached:  20.0
[I 2023-11-03 23:47:16,960] Trial 29 finished with value: 0.053659338504076004 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -3.75214349813185, 'log_learning_rate_D': -2.5467134055295344, 'training_batch_size': 12, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  171.56786012649536
Memory status after this trial: 
Memory allocated:  170.73974609375
Memory cached:  176.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.096089083162672, 'log_learning_rate_D': -3.610857509237324, 'training_batch_size': 9, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6044921875
Memory cached:  16.0
[I 2023-11-03 23:49:12,356] Trial 30 finished with value: 0.03622482344508171 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -4.096089083162672, 'log_learning_rate_D': -3.610857509237324, 'training_batch_size': 9, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  115.17590498924255
Memory status after this trial: 
Memory allocated:  137.1640625
Memory cached:  142.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.026047970731972, 'log_learning_rate_D': -3.81236646652603, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.1979, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.3134765625
Memory cached:  12.0
[I 2023-11-03 23:52:08,863] Trial 31 finished with value: 0.03531051427125931 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.026047970731972, 'log_learning_rate_D': -3.81236646652603, 'training_batch_size': 6, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  176.3034439086914
Memory status after this trial: 
Memory allocated:  80.5830078125
Memory cached:  84.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.32516153765056, 'log_learning_rate_D': -3.6176980396796217, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.6838, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6982421875
Memory cached:  10.0
[I 2023-11-03 23:53:46,443] Trial 32 finished with value: 0.039336156100034714 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.32516153765056, 'log_learning_rate_D': -3.6176980396796217, 'training_batch_size': 7, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  97.3926272392273
Memory status after this trial: 
Memory allocated:  59.2548828125
Memory cached:  62.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.5961527651827163, 'log_learning_rate_D': -4.242000351995043, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.6189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3525390625
Memory cached:  16.0
[I 2023-11-03 23:55:37,435] Trial 33 finished with value: 0.03193295747041702 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.5961527651827163, 'log_learning_rate_D': -4.242000351995043, 'training_batch_size': 8, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  110.80025339126587
Memory status after this trial: 
Memory allocated:  102.2001953125
Memory cached:  106.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.558044285757969, 'log_learning_rate_D': -4.315030609637039, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0600, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.1728515625
Memory cached:  38.0
[I 2023-11-03 23:57:45,841] Trial 34 finished with value: 0.04103023186326027 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.558044285757969, 'log_learning_rate_D': -4.315030609637039, 'training_batch_size': 8, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  128.19300246238708
Memory status after this trial: 
Memory allocated:  126.7587890625
Memory cached:  144.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.7983615835307574, 'log_learning_rate_D': -3.9797101215461033, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.3179, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  34.0
	 epoch  10 training error:  tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.6826171875
Memory cached:  38.0
[I 2023-11-03 23:59:41,464] Trial 35 finished with value: 0.03801893815398216 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.7983615835307574, 'log_learning_rate_D': -3.9797101215461033, 'training_batch_size': 10, 'training_p': 2}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  115.4070553779602
Memory status after this trial: 
Memory allocated:  156.02490234375
Memory cached:  172.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.582197690169901, 'log_learning_rate_D': -4.640105800290283, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0024, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.3994140625
Memory cached:  40.0
[I 2023-11-04 00:02:07,593] Trial 36 finished with value: 0.029401196166872978 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.582197690169901, 'log_learning_rate_D': -4.640105800290283, 'training_batch_size': 9, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  145.90102076530457
Memory status after this trial: 
Memory allocated:  147.708984375
Memory cached:  166.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.216588594009692, 'log_learning_rate_D': -4.96431136113082, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.3271484375
Memory cached:  22.0
[I 2023-11-04 00:04:33,836] Trial 37 finished with value: 0.033947449177503586 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.216588594009692, 'log_learning_rate_D': -4.96431136113082, 'training_batch_size': 9, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  146.02725172042847
Memory status after this trial: 
Memory allocated:  145.9677734375
Memory cached:  152.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.3599505216873866, 'log_learning_rate_D': -4.681227061331728, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  26.0
	 epoch  60 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.4677734375
Memory cached:  26.0
[I 2023-11-04 00:07:32,240] Trial 38 finished with value: 0.03856497257947922 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.3599505216873866, 'log_learning_rate_D': -4.681227061331728, 'training_batch_size': 10, 'training_p': 2}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  178.12307739257812
Memory status after this trial: 
Memory allocated:  219.638671875
Memory cached:  228.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.579947298653302, 'log_learning_rate_D': -4.4911895323493365, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.1435546875
Memory cached:  18.0
[I 2023-11-04 00:09:59,516] Trial 39 finished with value: 0.050714846700429916 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.579947298653302, 'log_learning_rate_D': -4.4911895323493365, 'training_batch_size': 11, 'training_p': 6}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  147.0105471611023
Memory status after this trial: 
Memory allocated:  148.74267578125
Memory cached:  154.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.2004857662049098, 'log_learning_rate_D': -4.809528292540582, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  44.0
	 epoch  40 training error:  tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  44.0
	 epoch  80 training error:  tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  15.7294921875
Memory cached:  42.0
[I 2023-11-04 00:13:01,121] Trial 40 finished with value: 0.37052351236343384 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.2004857662049098, 'log_learning_rate_D': -4.809528292540582, 'training_batch_size': 12, 'training_p': 5}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  181.3511037826538
Memory status after this trial: 
Memory allocated:  206.6123046875
Memory cached:  228.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.514106967707175, 'log_learning_rate_D': -4.442364762145049, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.1669921875
Memory cached:  18.0
[I 2023-11-04 00:15:04,478] Trial 41 finished with value: 0.041532065719366074 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.514106967707175, 'log_learning_rate_D': -4.442364762145049, 'training_batch_size': 8, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  123.10316944122314
Memory status after this trial: 
Memory allocated:  100.4326171875
Memory cached:  104.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.6294619559461636, 'log_learning_rate_D': -4.180213302853701, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.2967, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6044921875
Memory cached:  12.0
[I 2023-11-04 00:17:03,413] Trial 42 finished with value: 0.03365514054894447 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.6294619559461636, 'log_learning_rate_D': -4.180213302853701, 'training_batch_size': 9, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  118.71576642990112
Memory status after this trial: 
Memory allocated:  109.162109375
Memory cached:  114.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.9151073560001772, 'log_learning_rate_D': -4.735780284528974, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.2141, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3681640625
Memory cached:  38.0
[I 2023-11-04 00:19:14,384] Trial 43 finished with value: 0.05378330498933792 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.9151073560001772, 'log_learning_rate_D': -4.735780284528974, 'training_batch_size': 8, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  130.7485101222992
Memory status after this trial: 
Memory allocated:  153.18359375
Memory cached:  172.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.7288840921466213, 'log_learning_rate_D': -3.9172088671107064, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(1.2085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4560546875
Memory cached:  12.0
[I 2023-11-04 00:22:26,217] Trial 44 finished with value: 0.049000468105077744 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.7288840921466213, 'log_learning_rate_D': -3.9172088671107064, 'training_batch_size': 6, 'training_p': 2}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  191.619882106781
Memory status after this trial: 
Memory allocated:  75.0615234375
Memory cached:  78.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.543178998333281, 'log_learning_rate_D': -4.341273149127403, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4951171875
Memory cached:  14.0
[I 2023-11-04 00:24:47,205] Trial 45 finished with value: 0.043541718274354935 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -3.543178998333281, 'log_learning_rate_D': -4.341273149127403, 'training_batch_size': 10, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  140.75548386573792
Memory status after this trial: 
Memory allocated:  81.37890625
Memory cached:  84.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.8190826583777717, 'log_learning_rate_D': -4.978297305381413, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.8212890625
Memory cached:  6.0
[I 2023-11-04 00:26:19,645] Trial 46 finished with value: 0.048407599329948425 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.8190826583777717, 'log_learning_rate_D': -4.978297305381413, 'training_batch_size': 8, 'training_p': 3}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  92.2301139831543
Memory status after this trial: 
Memory allocated:  45.349609375
Memory cached:  46.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.275335099700175, 'log_learning_rate_D': -4.635812939653538, 'training_batch_size': 6, 'training_p': 6}
	 epoch  0 training error:  tensor(1.6175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.7841796875
Memory cached:  44.0
[I 2023-11-04 00:30:10,899] Trial 47 finished with value: 0.052952852100133896 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.275335099700175, 'log_learning_rate_D': -4.635812939653538, 'training_batch_size': 6, 'training_p': 6}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  231.02187657356262
Memory status after this trial: 
Memory allocated:  162.189453125
Memory cached:  178.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.0054459612768154, 'log_learning_rate_D': -4.041334806498372, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(8.1987, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  58.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  27.0634765625
Memory cached:  60.0
[I 2023-11-04 00:34:50,459] Trial 48 finished with value: 1.0 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.0054459612768154, 'log_learning_rate_D': -4.041334806498372, 'training_batch_size': 6, 'training_p': 4}. Best is trial 26 with value: 0.027899861335754395.
Time for this trial:  279.2965512275696
Memory status after this trial: 
Memory allocated:  208.52197265625
Memory cached:  220.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.9483687980738447, 'log_learning_rate_D': -4.2361121724611515, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.8554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4462890625
Memory cached:  12.0
[I 2023-11-04 00:36:54,200] Trial 49 finished with value: 0.04928099364042282 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.9483687980738447, 'log_learning_rate_D': -4.2361121724611515, 'training_batch_size': 9, 'training_p': 2}. Best is trial 26 with value: 0.027899861335754395.
[I 2023-11-04 00:36:54,223] A new study created in memory with name: no-name-90fa9f2b-2b9e-4906-891e-f49f84aaadcb
Time for this trial:  123.51928997039795
Memory status after this trial: 
Memory allocated:  64.255859375
Memory cached:  66.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.235625522402795, 'log_learning_rate_D': -3.5231381472682193, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.220703125
Memory cached:  18.0
[I 2023-11-04 00:39:39,664] Trial 0 finished with value: 0.07182405143976212 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.235625522402795, 'log_learning_rate_D': -3.5231381472682193, 'training_batch_size': 9, 'training_p': 6}. Best is trial 0 with value: 0.07182405143976212.
Time for this trial:  165.33138060569763
Memory status after this trial: 
Memory allocated:  168.0556640625
Memory cached:  172.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.9698046885802714, 'log_learning_rate_D': -3.377755745020088, 'training_batch_size': 10, 'training_p': 5}
	 epoch  0 training error:  tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.87109375
Memory cached:  12.0
[I 2023-11-04 00:42:13,481] Trial 1 finished with value: 0.03905489668250084 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 8, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -2.9698046885802714, 'log_learning_rate_D': -3.377755745020088, 'training_batch_size': 10, 'training_p': 5}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  153.67556977272034
Memory status after this trial: 
Memory allocated:  127.91748046875
Memory cached:  130.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.0291699378943826, 'log_learning_rate_D': -1.592023767640022, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  34.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.580078125
Memory cached:  36.0
[I 2023-11-04 00:44:40,241] Trial 2 finished with value: 1.000000238418579 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.0291699378943826, 'log_learning_rate_D': -1.592023767640022, 'training_batch_size': 11, 'training_p': 6}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  146.60035014152527
Memory status after this trial: 
Memory allocated:  172.525390625
Memory cached:  186.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.020987041728317, 'log_learning_rate_D': -1.0446730789537901, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.2421875
Memory cached:  8.0
[I 2023-11-04 00:46:24,870] Trial 3 finished with value: 0.10158040374517441 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -3.020987041728317, 'log_learning_rate_D': -1.0446730789537901, 'training_batch_size': 7, 'training_p': 2}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  104.50420832633972
Memory status after this trial: 
Memory allocated:  101.39306640625
Memory cached:  104.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.282459367451651, 'log_learning_rate_D': -2.243395532770646, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.5369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4990234375
Memory cached:  12.0
[I 2023-11-04 00:50:20,408] Trial 4 finished with value: 0.05843593552708626 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -4.282459367451651, 'log_learning_rate_D': -2.243395532770646, 'training_batch_size': 6, 'training_p': 5}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  235.38297247886658
Memory status after this trial: 
Memory allocated:  85.318359375
Memory cached:  88.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.4168396764733675, 'log_learning_rate_D': -1.8465106965610425, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.193359375
Memory cached:  20.0
[I 2023-11-04 00:52:52,747] Trial 5 finished with value: 0.05831265076994896 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.4168396764733675, 'log_learning_rate_D': -1.8465106965610425, 'training_batch_size': 10, 'training_p': 3}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  152.19176149368286
Memory status after this trial: 
Memory allocated:  143.15234375
Memory cached:  148.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.3523315523171986, 'log_learning_rate_D': -3.4877473048815655, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  40.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.9765625
Memory cached:  42.0
[I 2023-11-04 00:55:44,038] Trial 6 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 9, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'log_learning_rate': -1.3523315523171986, 'log_learning_rate_D': -3.4877473048815655, 'training_batch_size': 12, 'training_p': 5}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  171.1391785144806
Memory status after this trial: 
Memory allocated:  234.3974609375
Memory cached:  258.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.3617993105194794, 'log_learning_rate_D': -2.598470914135056, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0174, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  10.0
	 epoch  10 training error:  tensor(1.6362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.9526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.9945, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.9938, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.9898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.9779, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.8971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.123046875
Memory cached:  18.0
[I 2023-11-04 00:57:24,822] Trial 7 finished with value: 0.2709251344203949 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.3617993105194794, 'log_learning_rate_D': -2.598470914135056, 'training_batch_size': 7, 'training_p': 2}. Best is trial 1 with value: 0.03905489668250084.
Time for this trial:  100.63764357566833
Memory status after this trial: 
Memory allocated:  87.265625
Memory cached:  90.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.9317400302273002, 'log_learning_rate_D': -4.128896766706889, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0234375
Memory cached:  12.0
[I 2023-11-04 00:59:51,121] Trial 8 finished with value: 0.038074325770139694 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 9, 'log_learning_rate': -2.9317400302273002, 'log_learning_rate_D': -4.128896766706889, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  146.17382717132568
Memory status after this trial: 
Memory allocated:  91.63232421875
Memory cached:  94.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.9972952731025018, 'log_learning_rate_D': -3.7571559779123684, 'training_batch_size': 9, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  22.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  28.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.013671875
Memory cached:  26.0
[I 2023-11-04 01:02:27,081] Trial 9 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'log_learning_rate': -1.9972952731025018, 'log_learning_rate_D': -3.7571559779123684, 'training_batch_size': 9, 'training_p': 2}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  155.79802441596985
Memory status after this trial: 
Memory allocated:  190.58154296875
Memory cached:  198.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.0964326481119104, 'log_learning_rate_D': -4.642913891071147, 'training_batch_size': 12, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9773, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  40.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.251953125
Memory cached:  44.0
[I 2023-11-04 01:05:35,160] Trial 10 finished with value: 1.0 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -1.0964326481119104, 'log_learning_rate_D': -4.642913891071147, 'training_batch_size': 12, 'training_p': 8}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  187.8317894935608
Memory status after this trial: 
Memory allocated:  315.89794921875
Memory cached:  334.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.5919705156455537, 'log_learning_rate_D': -4.490913626347899, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.080078125
Memory cached:  14.0
[I 2023-11-04 01:08:01,364] Trial 11 finished with value: 0.04536014422774315 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.5919705156455537, 'log_learning_rate_D': -4.490913626347899, 'training_batch_size': 10, 'training_p': 4}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  145.98437595367432
Memory status after this trial: 
Memory allocated:  154.671875
Memory cached:  158.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.637404530064744, 'log_learning_rate_D': -3.083210165099825, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.90625
Memory cached:  16.0
[I 2023-11-04 01:10:32,973] Trial 12 finished with value: 0.0384892113506794 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.637404530064744, 'log_learning_rate_D': -3.083210165099825, 'training_batch_size': 10, 'training_p': 4}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  151.40209031105042
Memory status after this trial: 
Memory allocated:  133.65576171875
Memory cached:  136.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.966747504735354, 'log_learning_rate_D': -2.855783033654443, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9033, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.7611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.6767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.048828125
Memory cached:  18.0
[I 2023-11-04 01:13:00,733] Trial 13 finished with value: 0.13979126513004303 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -4.966747504735354, 'log_learning_rate_D': -2.855783033654443, 'training_batch_size': 11, 'training_p': 4}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  147.54464554786682
Memory status after this trial: 
Memory allocated:  156.4072265625
Memory cached:  160.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.6394354479277222, 'log_learning_rate_D': -4.423805200400609, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.04296875
Memory cached:  18.0
[I 2023-11-04 01:15:46,739] Trial 14 finished with value: 0.042501479387283325 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.6394354479277222, 'log_learning_rate_D': -4.423805200400609, 'training_batch_size': 8, 'training_p': 4}. Best is trial 8 with value: 0.038074325770139694.
Time for this trial:  165.7777714729309
Memory status after this trial: 
Memory allocated:  128.32421875
Memory cached:  132.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.579775146937977, 'log_learning_rate_D': -4.123818503723551, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.48046875
Memory cached:  14.0
[I 2023-11-04 01:17:54,892] Trial 15 finished with value: 0.03486239165067673 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'log_learning_rate': -2.579775146937977, 'log_learning_rate_D': -4.123818503723551, 'training_batch_size': 11, 'training_p': 3}. Best is trial 15 with value: 0.03486239165067673.
Time for this trial:  127.9459924697876
Memory status after this trial: 
Memory allocated:  119.58984375
Memory cached:  124.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.472157811892333, 'log_learning_rate_D': -4.923665541950875, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9664, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.4055, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.484375
Memory cached:  38.0
[I 2023-11-04 01:20:29,301] Trial 16 finished with value: 0.032101381570100784 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.472157811892333, 'log_learning_rate_D': -4.923665541950875, 'training_batch_size': 11, 'training_p': 3}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  154.20833086967468
Memory status after this trial: 
Memory allocated:  207.60546875
Memory cached:  228.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.493121075085797, 'log_learning_rate_D': -4.811311165753837, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  56.0
	 epoch  10 training error:  tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  20 training error:  tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  30 training error:  tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  40 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  50 training error:  tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  60 training error:  tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  70 training error:  tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  80 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
	 epoch  90 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  28.337890625
Memory cached:  58.0
[I 2023-11-04 01:23:06,267] Trial 17 finished with value: 0.06552202254533768 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.493121075085797, 'log_learning_rate_D': -4.811311165753837, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  156.7494077682495
Memory status after this trial: 
Memory allocated:  241.6279296875
Memory cached:  252.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8232173240937173, 'log_learning_rate_D': -4.972738134383982, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  40.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  46.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.27734375
Memory cached:  44.0
[I 2023-11-04 01:25:40,259] Trial 18 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -1.8232173240937173, 'log_learning_rate_D': -4.972738134383982, 'training_batch_size': 11, 'training_p': 3}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  153.77266597747803
Memory status after this trial: 
Memory allocated:  212.9921875
Memory cached:  234.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.419836467741623, 'log_learning_rate_D': -4.057856430875502, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.8478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.96875
Memory cached:  16.0
[I 2023-11-04 01:27:46,416] Trial 19 finished with value: 0.06012200191617012 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.419836467741623, 'log_learning_rate_D': -4.057856430875502, 'training_batch_size': 8, 'training_p': 7}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  125.95868754386902
Memory status after this trial: 
Memory allocated:  109.400390625
Memory cached:  114.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.6859273362790654, 'log_learning_rate_D': -4.049553947916975, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0140, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  62.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  68.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  68.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  70.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  44.509765625
Memory cached:  68.0
[I 2023-11-04 01:30:49,207] Trial 20 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -1.6859273362790654, 'log_learning_rate_D': -4.049553947916975, 'training_batch_size': 12, 'training_p': 3}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  182.56570506095886
Memory status after this trial: 
Memory allocated:  335.2998046875
Memory cached:  366.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.7118996627424723, 'log_learning_rate_D': -4.968596242676057, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.8452, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.625
Memory cached:  14.0
[I 2023-11-04 01:33:01,650] Trial 21 finished with value: 0.05121207982301712 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.7118996627424723, 'log_learning_rate_D': -4.968596242676057, 'training_batch_size': 11, 'training_p': 3}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  132.2180211544037
Memory status after this trial: 
Memory allocated:  100.4267578125
Memory cached:  102.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.728651037459997, 'log_learning_rate_D': -4.244518556693344, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0065, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
[I 2023-11-04 01:35:00,567] Trial 22 finished with value: 0.03697347268462181 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.728651037459997, 'log_learning_rate_D': -4.244518556693344, 'training_batch_size': 11, 'training_p': 4}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  118.72077226638794
Memory status after this trial: 
Memory allocated:  53.2138671875
Memory cached:  54.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.335055512148831, 'log_learning_rate_D': -4.412817558539733, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9734, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.189453125
Memory cached:  8.0
[I 2023-11-04 01:36:53,304] Trial 23 finished with value: 0.03796403110027313 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.335055512148831, 'log_learning_rate_D': -4.412817558539733, 'training_batch_size': 10, 'training_p': 2}. Best is trial 16 with value: 0.032101381570100784.
Time for this trial:  112.53424429893494
Memory status after this trial: 
Memory allocated:  48.0634765625
Memory cached:  50.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7151128134031404, 'log_learning_rate_D': -4.565633827749277, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0153, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.671875
Memory cached:  16.0
[I 2023-11-04 01:39:06,748] Trial 24 finished with value: 0.03180091083049774 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.7151128134031404, 'log_learning_rate_D': -4.565633827749277, 'training_batch_size': 11, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  133.222722530365
Memory status after this trial: 
Memory allocated:  112.310546875
Memory cached:  114.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.1920659342056963, 'log_learning_rate_D': -4.751335897918741, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0189, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.658203125
Memory cached:  38.0
[I 2023-11-04 01:41:39,355] Trial 25 finished with value: 0.115012027323246 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -2.1920659342056963, 'log_learning_rate_D': -4.751335897918741, 'training_batch_size': 12, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  152.37563753128052
Memory status after this trial: 
Memory allocated:  182.68798828125
Memory cached:  204.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.6037845514847797, 'log_learning_rate_D': -4.558082214369229, 'training_batch_size': 10, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.287109375
Memory cached:  14.0
[I 2023-11-04 01:43:46,154] Trial 26 finished with value: 0.09118875116109848 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.6037845514847797, 'log_learning_rate_D': -4.558082214369229, 'training_batch_size': 10, 'training_p': 2}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  126.59602642059326
Memory status after this trial: 
Memory allocated:  115.1689453125
Memory cached:  118.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.188336612917309, 'log_learning_rate_D': -3.8601599467383996, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9946, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  40.0
	 epoch  10 training error:  tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  48.0
	 epoch  20 training error:  tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  30 training error:  tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  40 training error:  tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  50 training error:  tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  60 training error:  tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  70 training error:  tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  80 training error:  tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
	 epoch  90 training error:  tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.427734375
Memory cached:  46.0
[I 2023-11-04 01:46:25,118] Trial 27 finished with value: 0.07203284651041031 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.188336612917309, 'log_learning_rate_D': -3.8601599467383996, 'training_batch_size': 9, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  158.73634934425354
Memory status after this trial: 
Memory allocated:  196.4990234375
Memory cached:  220.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6662638128596465, 'log_learning_rate_D': -4.988031185994962, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.5496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.19921875
Memory cached:  16.0
[I 2023-11-04 01:49:00,405] Trial 28 finished with value: 0.039754122495651245 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6662638128596465, 'log_learning_rate_D': -4.988031185994962, 'training_batch_size': 11, 'training_p': 6}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  155.0487060546875
Memory status after this trial: 
Memory allocated:  166.7109375
Memory cached:  170.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.669056086754463, 'log_learning_rate_D': -3.757821921097888, 'training_batch_size': 8, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.9143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  58.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  58.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  42.71484375
Memory cached:  56.0
[I 2023-11-04 01:51:53,748] Trial 29 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -1.669056086754463, 'log_learning_rate_D': -3.757821921097888, 'training_batch_size': 8, 'training_p': 2}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  173.10046863555908
Memory status after this trial: 
Memory allocated:  264.67578125
Memory cached:  288.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.2685251683655294, 'log_learning_rate_D': -4.302769985299453, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.15234375
Memory cached:  10.0
[I 2023-11-04 01:54:09,634] Trial 30 finished with value: 0.04153598099946976 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.2685251683655294, 'log_learning_rate_D': -4.302769985299453, 'training_batch_size': 12, 'training_p': 5}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  135.6595594882965
Memory status after this trial: 
Memory allocated:  71.1845703125
Memory cached:  72.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.757121401847689, 'log_learning_rate_D': -4.2832583574267655, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.291015625
Memory cached:  10.0
[I 2023-11-04 01:56:10,803] Trial 31 finished with value: 0.04045070335268974 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.757121401847689, 'log_learning_rate_D': -4.2832583574267655, 'training_batch_size': 11, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  120.94725060462952
Memory status after this trial: 
Memory allocated:  66.9814453125
Memory cached:  68.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.165209723500925, 'log_learning_rate_D': -4.640644332601191, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.876953125
Memory cached:  10.0
[I 2023-11-04 01:58:20,349] Trial 32 finished with value: 0.03893069177865982 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.165209723500925, 'log_learning_rate_D': -4.640644332601191, 'training_batch_size': 11, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  129.33936142921448
Memory status after this trial: 
Memory allocated:  76.1142578125
Memory cached:  78.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.821205932588753, 'log_learning_rate_D': -4.232928186427192, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.59765625
Memory cached:  12.0
[I 2023-11-04 02:00:11,248] Trial 33 finished with value: 0.032955873757600784 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.821205932588753, 'log_learning_rate_D': -4.232928186427192, 'training_batch_size': 10, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  110.68170714378357
Memory status after this trial: 
Memory allocated:  48.314453125
Memory cached:  50.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.8972158509000523, 'log_learning_rate_D': -4.728017444712924, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.283203125
Memory cached:  14.0
[I 2023-11-04 02:02:40,584] Trial 34 finished with value: 0.06176944449543953 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'W_layer_units_exponent_7': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.8972158509000523, 'log_learning_rate_D': -4.728017444712924, 'training_batch_size': 10, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  149.09207224845886
Memory status after this trial: 
Memory allocated:  166.517578125
Memory cached:  170.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.4840243575555276, 'log_learning_rate_D': -3.923103221889343, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.837890625
Memory cached:  10.0
[I 2023-11-04 02:04:49,137] Trial 35 finished with value: 0.047782059758901596 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -2.4840243575555276, 'log_learning_rate_D': -3.923103221889343, 'training_batch_size': 9, 'training_p': 5}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  128.33169221878052
Memory status after this trial: 
Memory allocated:  62.755859375
Memory cached:  64.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.1160759481727704, 'log_learning_rate_D': -3.340478203735846, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.7706, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.078125
Memory cached:  12.0
[I 2023-11-04 02:06:32,359] Trial 36 finished with value: 0.042517438530921936 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -2.1160759481727704, 'log_learning_rate_D': -3.340478203735846, 'training_batch_size': 10, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  103.01214361190796
Memory status after this trial: 
Memory allocated:  81.798828125
Memory cached:  84.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.1913976082964717, 'log_learning_rate_D': -4.400195818839278, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.880859375
Memory cached:  16.0
[I 2023-11-04 02:08:47,161] Trial 37 finished with value: 0.040840741246938705 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -3.1913976082964717, 'log_learning_rate_D': -4.400195818839278, 'training_batch_size': 10, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  134.57971048355103
Memory status after this trial: 
Memory allocated:  108.6982421875
Memory cached:  112.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9163849608579007, 'log_learning_rate_D': -3.6903954247252, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.650390625
Memory cached:  16.0
[I 2023-11-04 02:11:37,162] Trial 38 finished with value: 0.07472871989011765 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -2.9163849608579007, 'log_learning_rate_D': -3.6903954247252, 'training_batch_size': 9, 'training_p': 6}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  169.75520396232605
Memory status after this trial: 
Memory allocated:  202.470703125
Memory cached:  208.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.530563027156333, 'log_learning_rate_D': -4.134805328444596, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0390625
Memory cached:  22.0
[I 2023-11-04 02:13:51,453] Trial 39 finished with value: 0.04003920778632164 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -2.530563027156333, 'log_learning_rate_D': -4.134805328444596, 'training_batch_size': 11, 'training_p': 2}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  134.0699188709259
Memory status after this trial: 
Memory allocated:  139.68017578125
Memory cached:  144.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.2915987070169384, 'log_learning_rate_D': -4.581618375856356, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(1.8856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  30 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  40 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  50 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  60 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  70 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  80 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
	 epoch  90 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3701171875
Memory cached:  12.0
[I 2023-11-04 02:17:22,439] Trial 40 finished with value: 0.9999998211860657 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 9, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.2915987070169384, 'log_learning_rate_D': -4.581618375856356, 'training_batch_size': 6, 'training_p': 5}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  210.7665421962738
Memory status after this trial: 
Memory allocated:  97.265625
Memory cached:  102.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.78069030649158, 'log_learning_rate_D': -4.245403162322453, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0685, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.099609375
Memory cached:  10.0
[I 2023-11-04 02:19:24,950] Trial 41 finished with value: 0.03784606605768204 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.78069030649158, 'log_learning_rate_D': -4.245403162322453, 'training_batch_size': 11, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  122.29598045349121
Memory status after this trial: 
Memory allocated:  53.2138671875
Memory cached:  54.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6365707259892583, 'log_learning_rate_D': -4.173129616256336, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8939, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.54296875
Memory cached:  8.0
[I 2023-11-04 02:21:22,110] Trial 42 finished with value: 0.04094376415014267 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.6365707259892583, 'log_learning_rate_D': -4.173129616256336, 'training_batch_size': 11, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  116.93800449371338
Memory status after this trial: 
Memory allocated:  65.26171875
Memory cached:  68.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.033113850984796, 'log_learning_rate_D': -4.776628919176001, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  20 training error:  tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  30 training error:  tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  40 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  50 training error:  tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  60 training error:  tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  70 training error:  tensor(0.0502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  80 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
	 epoch  90 training error:  tensor(0.0419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.052734375
Memory cached:  8.0
[I 2023-11-04 02:23:30,910] Trial 43 finished with value: 0.03756610304117203 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -3.033113850984796, 'log_learning_rate_D': -4.776628919176001, 'training_batch_size': 12, 'training_p': 5}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  128.58511996269226
Memory status after this trial: 
Memory allocated:  46.40576171875
Memory cached:  48.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.9997008321401655, 'log_learning_rate_D': -3.988398722971767, 'training_batch_size': 10, 'training_p': 3}
	 epoch  0 training error:  tensor(1.5210, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.462890625
Memory cached:  10.0
[I 2023-11-04 02:25:24,244] Trial 44 finished with value: 0.04433591291308403 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -1.9997008321401655, 'log_learning_rate_D': -3.988398722971767, 'training_batch_size': 10, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  113.12817287445068
Memory status after this trial: 
Memory allocated:  89.65625
Memory cached:  94.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.320252492753123, 'log_learning_rate_D': -4.424518262958828, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9993, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.482421875
Memory cached:  16.0
[I 2023-11-04 02:27:38,071] Trial 45 finished with value: 0.06930070370435715 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.320252492753123, 'log_learning_rate_D': -4.424518262958828, 'training_batch_size': 11, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  133.56542706489563
Memory status after this trial: 
Memory allocated:  130.42919921875
Memory cached:  132.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.407843058018398, 'log_learning_rate_D': -3.581322747696746, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.859375
Memory cached:  6.0
[I 2023-11-04 02:29:19,011] Trial 46 finished with value: 0.042627330869436264 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.407843058018398, 'log_learning_rate_D': -3.581322747696746, 'training_batch_size': 10, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  100.70310306549072
Memory status after this trial: 
Memory allocated:  52.9228515625
Memory cached:  54.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.8232435460223524, 'log_learning_rate_D': -4.615329746049366, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.8230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.9375
Memory cached:  16.0
[I 2023-11-04 02:31:46,515] Trial 47 finished with value: 0.04086823761463165 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'log_learning_rate': -2.8232435460223524, 'log_learning_rate_D': -4.615329746049366, 'training_batch_size': 11, 'training_p': 2}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  147.24741911888123
Memory status after this trial: 
Memory allocated:  125.654296875
Memory cached:  130.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.9957847316102697, 'log_learning_rate_D': -4.27647420609638, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.5541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.54296875
Memory cached:  12.0
[I 2023-11-04 02:33:43,629] Trial 48 finished with value: 0.03869275376200676 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.9957847316102697, 'log_learning_rate_D': -4.27647420609638, 'training_batch_size': 12, 'training_p': 3}. Best is trial 24 with value: 0.03180091083049774.
Time for this trial:  116.86621022224426
Memory status after this trial: 
Memory allocated:  93.78759765625
Memory cached:  98.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.5246597236007324, 'log_learning_rate_D': -3.9807680539947365, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.697265625
Memory cached:  10.0
[I 2023-11-04 02:35:28,560] Trial 49 finished with value: 0.03972676768898964 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -2.5246597236007324, 'log_learning_rate_D': -3.9807680539947365, 'training_batch_size': 10, 'training_p': 4}. Best is trial 24 with value: 0.03180091083049774.
[I 2023-11-04 02:35:28,578] A new study created in memory with name: no-name-a020bd4e-c52b-4e92-8a8e-c96bc51bed40
Time for this trial:  104.71397995948792
Memory status after this trial: 
Memory allocated:  52.658203125
Memory cached:  54.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.5937498057619193, 'log_learning_rate_D': -3.824039947202208, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  16.0
	 epoch  10 training error:  tensor(31026.8496, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3115234375
Memory cached:  18.0
[I 2023-11-04 02:37:58,031] Trial 0 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -1.5937498057619193, 'log_learning_rate_D': -3.824039947202208, 'training_batch_size': 7, 'training_p': 2}. Best is trial 0 with value: 1.0.
Time for this trial:  149.33618783950806
Memory status after this trial: 
Memory allocated:  165.68505859375
Memory cached:  170.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.5311772581096554, 'log_learning_rate_D': -2.271642733225409, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  22.0
	 epoch  10 training error:  tensor(1.7713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  26.0
	 epoch  40 training error:  tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  26.0
	 epoch  70 training error:  tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  14.3876953125
Memory cached:  26.0
[I 2023-11-04 02:41:15,763] Trial 1 finished with value: 0.06714604049921036 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 7, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 8, 'log_learning_rate': -2.5311772581096554, 'log_learning_rate_D': -2.271642733225409, 'training_batch_size': 10, 'training_p': 4}. Best is trial 1 with value: 0.06714604049921036.
Time for this trial:  197.58033752441406
Memory status after this trial: 
Memory allocated:  245.9326171875
Memory cached:  254.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.852773814106612, 'log_learning_rate_D': -1.993543080789105, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.9570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.9420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.9211, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.8948, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.8279, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.7873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.7411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.2646484375
Memory cached:  16.0
[I 2023-11-04 02:43:54,144] Trial 2 finished with value: 0.6701921820640564 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 7, 'W_layer_units_exponent_6': 4, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 5, 'log_learning_rate': -4.852773814106612, 'log_learning_rate_D': -1.993543080789105, 'training_batch_size': 11, 'training_p': 5}. Best is trial 1 with value: 0.06714604049921036.
Time for this trial:  158.2199308872223
Memory status after this trial: 
Memory allocated:  74.60205078125
Memory cached:  76.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.3460458072948054, 'log_learning_rate_D': -1.0404667112621957, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(1.4338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  10 training error:  tensor(1.4556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  22.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.103515625
Memory cached:  20.0
[I 2023-11-04 02:48:27,978] Trial 3 finished with value: 1.0 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -2.3460458072948054, 'log_learning_rate_D': -1.0404667112621957, 'training_batch_size': 6, 'training_p': 4}. Best is trial 1 with value: 0.06714604049921036.
Time for this trial:  273.6502676010132
Memory status after this trial: 
Memory allocated:  149.1142578125
Memory cached:  154.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.4311538505608947, 'log_learning_rate_D': -1.1752600759914489, 'training_batch_size': 9, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  14.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  20.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  20.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  20.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7587890625
Memory cached:  18.0
[I 2023-11-04 02:50:49,219] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'log_learning_rate': -1.4311538505608947, 'log_learning_rate_D': -1.1752600759914489, 'training_batch_size': 9, 'training_p': 3}. Best is trial 1 with value: 0.06714604049921036.
Time for this trial:  141.0874536037445
Memory status after this trial: 
Memory allocated:  165.748046875
Memory cached:  170.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.58979195038192, 'log_learning_rate_D': -4.007383554004042, 'training_batch_size': 8, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.6996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.5283203125
Memory cached:  38.0
[I 2023-11-04 02:53:20,814] Trial 5 finished with value: 0.04727889224886894 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 4, 'log_learning_rate': -4.58979195038192, 'log_learning_rate_D': -4.007383554004042, 'training_batch_size': 8, 'training_p': 8}. Best is trial 5 with value: 0.04727889224886894.
Time for this trial:  151.44948840141296
Memory status after this trial: 
Memory allocated:  198.4912109375
Memory cached:  218.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.0661257934859028, 'log_learning_rate_D': -3.111749503233449, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  20.0
[I 2023-11-04 02:56:03,508] Trial 6 finished with value: 0.1283046454191208 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.0661257934859028, 'log_learning_rate_D': -3.111749503233449, 'training_batch_size': 9, 'training_p': 8}. Best is trial 5 with value: 0.04727889224886894.
Time for this trial:  162.54447221755981
Memory status after this trial: 
Memory allocated:  201.53369140625
Memory cached:  204.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.343156672553318, 'log_learning_rate_D': -3.041237935081657, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2490234375
Memory cached:  22.0
[I 2023-11-04 02:58:43,004] Trial 7 finished with value: 0.03833633288741112 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.343156672553318, 'log_learning_rate_D': -3.041237935081657, 'training_batch_size': 11, 'training_p': 6}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  159.35790061950684
Memory status after this trial: 
Memory allocated:  178.80029296875
Memory cached:  184.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.582762954476778, 'log_learning_rate_D': -2.7201160133880005, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  10 training error:  tensor(1.0114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5927734375
Memory cached:  14.0
[I 2023-11-04 03:01:33,214] Trial 8 finished with value: 0.07910274714231491 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.582762954476778, 'log_learning_rate_D': -2.7201160133880005, 'training_batch_size': 8, 'training_p': 5}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  170.0548620223999
Memory status after this trial: 
Memory allocated:  129.3212890625
Memory cached:  132.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.07767523451797, 'log_learning_rate_D': -1.3706771126871966, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  36.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  18.0966796875
Memory cached:  40.0
[I 2023-11-04 03:04:16,947] Trial 9 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 10, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -2.07767523451797, 'log_learning_rate_D': -1.3706771126871966, 'training_batch_size': 12, 'training_p': 7}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  163.58825516700745
Memory status after this trial: 
Memory allocated:  267.7138671875
Memory cached:  282.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.712062246284027, 'log_learning_rate_D': -4.826752923307424, 'training_batch_size': 12, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5439453125
Memory cached:  20.0
[I 2023-11-04 03:06:40,581] Trial 10 finished with value: 0.055563002824783325 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.712062246284027, 'log_learning_rate_D': -4.826752923307424, 'training_batch_size': 12, 'training_p': 6}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  143.4042694568634
Memory status after this trial: 
Memory allocated:  142.47412109375
Memory cached:  146.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.718530886947827, 'log_learning_rate_D': -3.635313580140885, 'training_batch_size': 10, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0944, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.9687, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.8509, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.7288, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.3542, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.6611328125
Memory cached:  14.0
[I 2023-11-04 03:08:55,436] Trial 11 finished with value: 0.07907042652368546 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -4.718530886947827, 'log_learning_rate_D': -3.635313580140885, 'training_batch_size': 10, 'training_p': 8}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  134.6496148109436
Memory status after this trial: 
Memory allocated:  129.1357421875
Memory cached:  132.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.111576989296956, 'log_learning_rate_D': -4.279928844647055, 'training_batch_size': 8, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  28.0
	 epoch  10 training error:  tensor(0.6254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  20 training error:  tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  30 training error:  tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  40 training error:  tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  50 training error:  tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  60 training error:  tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  70 training error:  tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  80 training error:  tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
	 epoch  90 training error:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.2568359375
Memory cached:  30.0
[I 2023-11-04 03:10:58,180] Trial 12 finished with value: 0.059801001101732254 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -4.111576989296956, 'log_learning_rate_D': -4.279928844647055, 'training_batch_size': 8, 'training_p': 7}. Best is trial 7 with value: 0.03833633288741112.
Time for this trial:  122.55896139144897
Memory status after this trial: 
Memory allocated:  156.80810546875
Memory cached:  170.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4642655730956293, 'log_learning_rate_D': -3.303011734863227, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0723, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9990234375
Memory cached:  16.0
[I 2023-11-04 03:13:59,209] Trial 13 finished with value: 0.03723619505763054 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4642655730956293, 'log_learning_rate_D': -3.303011734863227, 'training_batch_size': 10, 'training_p': 7}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  180.8057222366333
Memory status after this trial: 
Memory allocated:  233.34375
Memory cached:  238.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4706183422225703, 'log_learning_rate_D': -3.197687258766439, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7080078125
Memory cached:  14.0
[I 2023-11-04 03:16:26,154] Trial 14 finished with value: 0.046055857092142105 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.4706183422225703, 'log_learning_rate_D': -3.197687258766439, 'training_batch_size': 11, 'training_p': 6}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  146.73430228233337
Memory status after this trial: 
Memory allocated:  157.62841796875
Memory cached:  160.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.1840518997664122, 'log_learning_rate_D': -3.3711154173283764, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.8470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
[I 2023-11-04 03:19:03,587] Trial 15 finished with value: 0.039356451481580734 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.1840518997664122, 'log_learning_rate_D': -3.3711154173283764, 'training_batch_size': 11, 'training_p': 6}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  157.22414207458496
Memory status after this trial: 
Memory allocated:  177.12646484375
Memory cached:  198.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.966065200701613, 'log_learning_rate_D': -2.6805814496580593, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  52.0
	 epoch  10 training error:  tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  20 training error:  tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  30 training error:  tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  40 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  50 training error:  tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  60 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  70 training error:  tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  80 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
	 epoch  90 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  29.9228515625
Memory cached:  56.0
[I 2023-11-04 03:22:05,903] Trial 16 finished with value: 0.040753480046987534 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 10, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 10, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -3.966065200701613, 'log_learning_rate_D': -2.6805814496580593, 'training_batch_size': 10, 'training_p': 7}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  182.07725834846497
Memory status after this trial: 
Memory allocated:  270.181640625
Memory cached:  302.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.054950376510859, 'log_learning_rate_D': -3.49053832352617, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8076171875
Memory cached:  18.0
[I 2023-11-04 03:24:25,063] Trial 17 finished with value: 0.04640977829694748 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.054950376510859, 'log_learning_rate_D': -3.49053832352617, 'training_batch_size': 11, 'training_p': 6}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  138.92103362083435
Memory status after this trial: 
Memory allocated:  156.19775390625
Memory cached:  160.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.181174998596086, 'log_learning_rate_D': -2.8418662540752484, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0246, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.7689, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.0693359375
Memory cached:  12.0
[I 2023-11-04 03:26:48,570] Trial 18 finished with value: 0.049107298254966736 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.181174998596086, 'log_learning_rate_D': -2.8418662540752484, 'training_batch_size': 12, 'training_p': 5}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  143.28371739387512
Memory status after this trial: 
Memory allocated:  73.41748046875
Memory cached:  76.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.643682710395147, 'log_learning_rate_D': -2.405176946066391, 'training_batch_size': 9, 'training_p': 7}
	 epoch  0 training error:  tensor(1.3185, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4931640625
Memory cached:  16.0
[I 2023-11-04 03:29:27,294] Trial 19 finished with value: 0.06063053011894226 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 5, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -3.643682710395147, 'log_learning_rate_D': -2.405176946066391, 'training_batch_size': 9, 'training_p': 7}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  158.50871515274048
Memory status after this trial: 
Memory allocated:  153.65625
Memory cached:  158.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.35113520495711, 'log_learning_rate_D': -3.110056622704542, 'training_batch_size': 10, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.8420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.6717, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.4348, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.5263671875
Memory cached:  20.0
[I 2023-11-04 03:32:16,238] Trial 20 finished with value: 0.05876695737242699 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -4.35113520495711, 'log_learning_rate_D': -3.110056622704542, 'training_batch_size': 10, 'training_p': 4}. Best is trial 13 with value: 0.03723619505763054.
Time for this trial:  168.6683850288391
Memory status after this trial: 
Memory allocated:  130.89013671875
Memory cached:  134.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.152904470667057, 'log_learning_rate_D': -3.3798688771710474, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.6650390625
Memory cached:  38.0
[I 2023-11-04 03:34:53,425] Trial 21 finished with value: 0.0346318818628788 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -3.152904470667057, 'log_learning_rate_D': -3.3798688771710474, 'training_batch_size': 11, 'training_p': 6}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  156.9552516937256
Memory status after this trial: 
Memory allocated:  177.12646484375
Memory cached:  198.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.325397883560796, 'log_learning_rate_D': -3.290900849063157, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  24.2412109375
Memory cached:  42.0
[I 2023-11-04 03:37:42,580] Trial 22 finished with value: 0.06930706650018692 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 7, 'log_learning_rate': -3.325397883560796, 'log_learning_rate_D': -3.290900849063157, 'training_batch_size': 11, 'training_p': 6}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  168.9010329246521
Memory status after this trial: 
Memory allocated:  229.24072265625
Memory cached:  246.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.8960595070231707, 'log_learning_rate_D': -3.6256936269647833, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0030, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.2958984375
Memory cached:  20.0
[I 2023-11-04 03:40:27,873] Trial 23 finished with value: 0.03730907663702965 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 5, 'log_learning_rate': -2.8960595070231707, 'log_learning_rate_D': -3.6256936269647833, 'training_batch_size': 10, 'training_p': 7}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  165.05083441734314
Memory status after this trial: 
Memory allocated:  188.267578125
Memory cached:  194.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.073460886028337, 'log_learning_rate_D': -3.677285220680093, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6181640625
Memory cached:  18.0
[I 2023-11-04 03:43:11,218] Trial 24 finished with value: 0.03550564870238304 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.073460886028337, 'log_learning_rate_D': -3.677285220680093, 'training_batch_size': 10, 'training_p': 7}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  163.10749125480652
Memory status after this trial: 
Memory allocated:  172.3310546875
Memory cached:  178.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.957385539775224, 'log_learning_rate_D': -4.072049722049581, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9536, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.8212890625
Memory cached:  20.0
[I 2023-11-04 03:45:42,602] Trial 25 finished with value: 0.03897906839847565 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 8, 'log_learning_rate': -2.957385539775224, 'log_learning_rate_D': -4.072049722049581, 'training_batch_size': 9, 'training_p': 8}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  151.14556050300598
Memory status after this trial: 
Memory allocated:  136.0283203125
Memory cached:  140.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.811950718326658, 'log_learning_rate_D': -4.30019836195366, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.7294921875
Memory cached:  18.0
[I 2023-11-04 03:48:06,367] Trial 26 finished with value: 0.042673882097005844 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.811950718326658, 'log_learning_rate_D': -4.30019836195366, 'training_batch_size': 10, 'training_p': 7}. Best is trial 21 with value: 0.0346318818628788.
Time for this trial:  143.53320026397705
Memory status after this trial: 
Memory allocated:  134.43603515625
Memory cached:  140.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.4098728496160966, 'log_learning_rate_D': -3.6578131316458067, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0318, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  22.0
	 epoch  10 training error:  tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2802734375
Memory cached:  24.0
[I 2023-11-04 03:50:58,216] Trial 27 finished with value: 0.03146516904234886 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.4098728496160966, 'log_learning_rate_D': -3.6578131316458067, 'training_batch_size': 12, 'training_p': 5}. Best is trial 27 with value: 0.03146516904234886.
Time for this trial:  171.60541534423828
Memory status after this trial: 
Memory allocated:  180.455078125
Memory cached:  186.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.8221872789128266, 'log_learning_rate_D': -3.7957478769879045, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0112, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.4384765625
Memory cached:  14.0
[I 2023-11-04 03:52:59,853] Trial 28 finished with value: 0.05694000795483589 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'log_learning_rate': -2.8221872789128266, 'log_learning_rate_D': -3.7957478769879045, 'training_batch_size': 12, 'training_p': 5}. Best is trial 27 with value: 0.03146516904234886.
Time for this trial:  121.4100706577301
Memory status after this trial: 
Memory allocated:  78.56396484375
Memory cached:  80.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.251401250291662, 'log_learning_rate_D': -3.8442200495941954, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9457, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.6689453125
Memory cached:  20.0
[I 2023-11-04 03:55:42,279] Trial 29 finished with value: 0.031595535576343536 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.251401250291662, 'log_learning_rate_D': -3.8442200495941954, 'training_batch_size': 12, 'training_p': 2}. Best is trial 27 with value: 0.03146516904234886.
Time for this trial:  162.18873238563538
Memory status after this trial: 
Memory allocated:  167.23974609375
Memory cached:  174.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.4301144004070445, 'log_learning_rate_D': -3.9604923014975295, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0028, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  22.7646484375
Memory cached:  42.0
[I 2023-11-04 03:58:42,080] Trial 30 finished with value: 0.037714552134275436 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 10, 'D_layers': 6, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.4301144004070445, 'log_learning_rate_D': -3.9604923014975295, 'training_batch_size': 12, 'training_p': 2}. Best is trial 27 with value: 0.03146516904234886.
Time for this trial:  179.55609512329102
Memory status after this trial: 
Memory allocated:  241.73681640625
Memory cached:  258.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1916153369822364, 'log_learning_rate_D': -3.6584171376215604, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0293, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.2333984375
Memory cached:  24.0
[I 2023-11-04 04:01:34,236] Trial 31 finished with value: 0.028786510229110718 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1916153369822364, 'log_learning_rate_D': -3.6584171376215604, 'training_batch_size': 12, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  171.90988755226135
Memory status after this trial: 
Memory allocated:  168.537109375
Memory cached:  174.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1876893761625156, 'log_learning_rate_D': -3.4908785725850966, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3896484375
Memory cached:  18.0
[I 2023-11-04 04:04:27,011] Trial 32 finished with value: 0.030698148533701897 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.1876893761625156, 'log_learning_rate_D': -3.4908785725850966, 'training_batch_size': 12, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  172.51562309265137
Memory status after this trial: 
Memory allocated:  165.72265625
Memory cached:  172.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5823625218814903, 'log_learning_rate_D': -3.8330882874803125, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0236, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.3466796875
Memory cached:  20.0
[I 2023-11-04 04:07:12,478] Trial 33 finished with value: 0.03654458001255989 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.5823625218814903, 'log_learning_rate_D': -3.8330882874803125, 'training_batch_size': 12, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  165.2130892276764
Memory status after this trial: 
Memory allocated:  156.91845703125
Memory cached:  162.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.685765920661314, 'log_learning_rate_D': -3.5735058576837275, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9248046875
Memory cached:  22.0
[I 2023-11-04 04:10:13,729] Trial 34 finished with value: 0.05365965515375137 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.685765920661314, 'log_learning_rate_D': -3.5735058576837275, 'training_batch_size': 12, 'training_p': 3}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  180.99043440818787
Memory status after this trial: 
Memory allocated:  171.646484375
Memory cached:  176.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.244157317054821, 'log_learning_rate_D': -4.340767842036518, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
[I 2023-11-04 04:12:49,832] Trial 35 finished with value: 0.03207879140973091 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.244157317054821, 'log_learning_rate_D': -4.340767842036518, 'training_batch_size': 12, 'training_p': 3}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  155.86158156394958
Memory status after this trial: 
Memory allocated:  149.33349609375
Memory cached:  154.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.745678556714556, 'log_learning_rate_D': -3.498646233683819, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  38.0
	 epoch  10 training error:  tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  21.8671875
Memory cached:  40.0
[I 2023-11-04 04:18:39,430] Trial 36 finished with value: 0.04002947732806206 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 8, 'W_layer_units_exponent_7': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -2.745678556714556, 'log_learning_rate_D': -3.498646233683819, 'training_batch_size': 6, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  349.30845832824707
Memory status after this trial: 
Memory allocated:  294.42236328125
Memory cached:  310.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.0264485548285536, 'log_learning_rate_D': -3.8292551266778254, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9772, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  16.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6396484375
Memory cached:  20.0
[I 2023-11-04 04:21:20,200] Trial 37 finished with value: 1.0 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 6, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -1.0264485548285536, 'log_learning_rate_D': -3.8292551266778254, 'training_batch_size': 12, 'training_p': 3}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  160.4877634048462
Memory status after this trial: 
Memory allocated:  144.0009765625
Memory cached:  146.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.867920705313757, 'log_learning_rate_D': -2.920893019653906, 'training_batch_size': 11, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  20.0
	 epoch  10 training error:  tensor(0.7372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6279296875
Memory cached:  22.0
[I 2023-11-04 04:24:15,971] Trial 38 finished with value: 0.04740886017680168 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.867920705313757, 'log_learning_rate_D': -2.920893019653906, 'training_batch_size': 11, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  175.51276445388794
Memory status after this trial: 
Memory allocated:  157.0830078125
Memory cached:  162.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2869266021662296, 'log_learning_rate_D': -3.135090091697384, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  9.3095703125
Memory cached:  18.0
[I 2023-11-04 04:27:03,488] Trial 39 finished with value: 0.046208206564188004 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 5, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -3.2869266021662296, 'log_learning_rate_D': -3.135090091697384, 'training_batch_size': 11, 'training_p': 3}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  167.2517158985138
Memory status after this trial: 
Memory allocated:  200.00244140625
Memory cached:  206.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.398273908235644, 'log_learning_rate_D': -4.025379521811876, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.4443359375
Memory cached:  16.0
[I 2023-11-04 04:29:40,445] Trial 40 finished with value: 0.1016227975487709 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -2.398273908235644, 'log_learning_rate_D': -4.025379521811876, 'training_batch_size': 7, 'training_p': 4}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  156.70928263664246
Memory status after this trial: 
Memory allocated:  109.59814453125
Memory cached:  112.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.237887966283485, 'log_learning_rate_D': -4.298655868056373, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9676, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.7001953125
Memory cached:  18.0
[I 2023-11-04 04:32:01,777] Trial 41 finished with value: 0.0377320870757103 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.237887966283485, 'log_learning_rate_D': -4.298655868056373, 'training_batch_size': 12, 'training_p': 3}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  141.08383870124817
Memory status after this trial: 
Memory allocated:  120.25927734375
Memory cached:  124.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.479213590964433, 'log_learning_rate_D': -4.586797537952474, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.7080078125
Memory cached:  20.0
[I 2023-11-04 04:34:34,027] Trial 42 finished with value: 0.03661740571260452 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.479213590964433, 'log_learning_rate_D': -4.586797537952474, 'training_batch_size': 12, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  151.99572157859802
Memory status after this trial: 
Memory allocated:  149.33349609375
Memory cached:  154.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0441926312552043, 'log_learning_rate_D': -4.1314006100075495, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  70 training error:  tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0269, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.9169921875
Memory cached:  42.0
[I 2023-11-04 04:37:13,048] Trial 43 finished with value: 0.031035026535391808 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'log_learning_rate': -3.0441926312552043, 'log_learning_rate_D': -4.1314006100075495, 'training_batch_size': 12, 'training_p': 2}. Best is trial 31 with value: 0.028786510229110718.
Time for this trial:  158.7292492389679
Memory status after this trial: 
Memory allocated:  199.20263671875
Memory cached:  220.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.948208432564285, 'log_learning_rate_D': -4.136974543321445, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(1.0040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  30.0
	 epoch  10 training error:  tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  34.0
	 epoch  20 training error:  tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  40 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  50 training error:  tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  60 training error:  tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  70 training error:  tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  80 training error:  tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
	 epoch  90 training error:  tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.7099609375
Memory cached:  36.0
[I 2023-11-04 04:39:45,691] Trial 44 finished with value: 0.028253687545657158 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.948208432564285, 'log_learning_rate_D': -4.136974543321445, 'training_batch_size': 12, 'training_p': 2}. Best is trial 44 with value: 0.028253687545657158.
Time for this trial:  152.39289498329163
Memory status after this trial: 
Memory allocated:  206.84130859375
Memory cached:  220.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.926189387187504, 'log_learning_rate_D': -4.134913415016, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9817, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.5634765625
Memory cached:  20.0
[I 2023-11-04 04:42:12,462] Trial 45 finished with value: 0.037864964455366135 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'log_learning_rate': -2.926189387187504, 'log_learning_rate_D': -4.134913415016, 'training_batch_size': 12, 'training_p': 2}. Best is trial 44 with value: 0.028253687545657158.
Time for this trial:  146.53505420684814
Memory status after this trial: 
Memory allocated:  152.35205078125
Memory cached:  154.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.575337311559256, 'log_learning_rate_D': -4.59209068919027, 'training_batch_size': 11, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  60.0
	 epoch  10 training error:  tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  62.0
	 epoch  20 training error:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  64.0
	 epoch  30 training error:  tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  64.0
	 epoch  40 training error:  tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  62.0
	 epoch  50 training error:  tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  64.0
	 epoch  60 training error:  tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  62.0
	 epoch  70 training error:  tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  64.0
	 epoch  80 training error:  tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  62.0
	 epoch  90 training error:  tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  33.9228515625
Memory cached:  64.0
[I 2023-11-04 04:44:52,443] Trial 46 finished with value: 0.0700766071677208 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.575337311559256, 'log_learning_rate_D': -4.59209068919027, 'training_batch_size': 11, 'training_p': 3}. Best is trial 44 with value: 0.028253687545657158.
Time for this trial:  159.73730874061584
Memory status after this trial: 
Memory allocated:  269.63525390625
Memory cached:  276.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.0402205341456683, 'log_learning_rate_D': -3.724113015089277, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0120, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  20.9619140625
Memory cached:  38.0
[I 2023-11-04 04:47:37,666] Trial 47 finished with value: 0.07002395391464233 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 6, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -3.0402205341456683, 'log_learning_rate_D': -3.724113015089277, 'training_batch_size': 11, 'training_p': 4}. Best is trial 44 with value: 0.028253687545657158.
Time for this trial:  164.96422457695007
Memory status after this trial: 
Memory allocated:  235.67431640625
Memory cached:  252.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7665790370249117, 'log_learning_rate_D': -3.9499792715136284, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9823, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  20 training error:  tensor(0.2085, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  30 training error:  tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  40 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  50 training error:  tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  80 training error:  tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
	 epoch  90 training error:  tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6767578125
Memory cached:  40.0
[I 2023-11-04 04:50:27,543] Trial 48 finished with value: 0.05585174635052681 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 4, 'W_layer_units_exponent_6': 9, 'W_layer_units_exponent_7': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 10, 'log_learning_rate': -2.7665790370249117, 'log_learning_rate_D': -3.9499792715136284, 'training_batch_size': 12, 'training_p': 2}. Best is trial 44 with value: 0.028253687545657158.
Time for this trial:  169.62400722503662
Memory status after this trial: 
Memory allocated:  232.61865234375
Memory cached:  252.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.3567567251705377, 'log_learning_rate_D': -3.4034575071897084, 'training_batch_size': 7, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9326, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.6242, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.0419921875
Memory cached:  12.0
[I 2023-11-04 04:52:19,612] Trial 49 finished with value: 0.06642834842205048 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -2.3567567251705377, 'log_learning_rate_D': -3.4034575071897084, 'training_batch_size': 7, 'training_p': 3}. Best is trial 44 with value: 0.028253687545657158.
[I 2023-11-04 04:52:19,632] A new study created in memory with name: no-name-96d80d30-ff88-40db-a1d8-479ccb652565
Time for this trial:  111.81244969367981
Memory status after this trial: 
Memory allocated:  55.11669921875
Memory cached:  56.0
--------------------  Trial  0   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.7868208483605885, 'log_learning_rate_D': -4.1931050240293155, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  78.0
	 epoch  10 training error:  tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  80.0
	 epoch  20 training error:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  82.0
	 epoch  30 training error:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  82.0
	 epoch  40 training error:  tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  80.0
	 epoch  50 training error:  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  80.0
	 epoch  60 training error:  tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  82.0
	 epoch  70 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  80.0
	 epoch  80 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  80.0
	 epoch  90 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  53.8193359375
Memory cached:  82.0
[I 2023-11-04 04:55:02,359] Trial 0 finished with value: 0.04425015673041344 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.7868208483605885, 'log_learning_rate_D': -4.1931050240293155, 'training_batch_size': 10, 'training_p': 7}. Best is trial 0 with value: 0.04425015673041344.
Time for this trial:  162.60679054260254
Memory status after this trial: 
Memory allocated:  310.146484375
Memory cached:  330.0
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.419406774008527, 'log_learning_rate_D': -4.4501169968847964, 'training_batch_size': 9, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0255, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.7671, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  44.0
	 epoch  20 training error:  tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  44.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  13.5458984375
Memory cached:  40.0
[I 2023-11-04 04:57:30,317] Trial 1 finished with value: 1.0 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 9, 'W_layer_units_exponent_6': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -2.419406774008527, 'log_learning_rate_D': -4.4501169968847964, 'training_batch_size': 9, 'training_p': 5}. Best is trial 0 with value: 0.04425015673041344.
Time for this trial:  147.8117916584015
Memory status after this trial: 
Memory allocated:  176.89892578125
Memory cached:  196.0
--------------------  Trial  2   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.013011690617631, 'log_learning_rate_D': -2.2871623102135246, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0044, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  17.3017578125
Memory cached:  38.0
[I 2023-11-04 05:00:48,134] Trial 2 finished with value: 0.12157022953033447 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 10, 'log_learning_rate': -2.013011690617631, 'log_learning_rate_D': -2.2871623102135246, 'training_batch_size': 9, 'training_p': 8}. Best is trial 0 with value: 0.04425015673041344.
Time for this trial:  197.66440320014954
Memory status after this trial: 
Memory allocated:  269.5751953125
Memory cached:  292.0
--------------------  Trial  3   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.1933812256358944, 'log_learning_rate_D': -2.0683313221379054, 'training_batch_size': 11, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1806640625
Memory cached:  8.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1806640625
Memory cached:  10.0
	 epoch  20 training error:  tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1806640625
Memory cached:  10.0
[W 2023-11-04 05:01:14,751] Trial 3 failed with parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 5, 'log_learning_rate': -1.1933812256358944, 'log_learning_rate_D': -2.0683313221379054, 'training_batch_size': 11, 'training_p': 8} because of the following error: The value nan is not acceptable.
[W 2023-11-04 05:01:14,753] Trial 3 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).
Time for this trial:  26.46748661994934
Memory status after this trial: 
Memory allocated:  72.31494140625
Memory cached:  76.0
--------------------  Trial  4   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.8658181096596813, 'log_learning_rate_D': -3.46084927052981, 'training_batch_size': 8, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  18.0
	 epoch  10 training error:  tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  22.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  22.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.4697265625
Memory cached:  24.0
[I 2023-11-04 05:04:09,767] Trial 4 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 5, 'D_layers': 5, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -1.8658181096596813, 'log_learning_rate_D': -3.46084927052981, 'training_batch_size': 8, 'training_p': 5}. Best is trial 0 with value: 0.04425015673041344.
Time for this trial:  174.81648087501526
Memory status after this trial: 
Memory allocated:  208.9990234375
Memory cached:  212.0
--------------------  Trial  5   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.225071222754838, 'log_learning_rate_D': -4.6491405833785935, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9766, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  58.0
	 epoch  10 training error:  tensor(0.3175, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  68.0
	 epoch  20 training error:  tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  30 training error:  tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  40 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  50 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  60 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  70 training error:  tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
	 epoch  80 training error:  tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  68.0
	 epoch  90 training error:  tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  43.9677734375
Memory cached:  66.0
[I 2023-11-04 05:07:03,789] Trial 5 finished with value: 0.04093475267291069 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 10, 'log_learning_rate': -4.225071222754838, 'log_learning_rate_D': -4.6491405833785935, 'training_batch_size': 7, 'training_p': 2}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  173.86517930030823
Memory status after this trial: 
Memory allocated:  327.83056640625
Memory cached:  352.0
--------------------  Trial  6   --------------------
Start timing: 
Parameters: 
{'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.204308115640072, 'log_learning_rate_D': -2.7155834573503186, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9925, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  40.0
	 epoch  10 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  20 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  30 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  40 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  50 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  60 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  70 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  80 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
	 epoch  90 training error:  tensor(1., device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  23.5322265625
Memory cached:  44.0
[I 2023-11-04 05:10:11,669] Trial 6 finished with value: 1.0 and parameters: {'W_layers': 8, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 9, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 10, 'W_layer_units_exponent_7': 4, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -1.204308115640072, 'log_learning_rate_D': -2.7155834573503186, 'training_batch_size': 11, 'training_p': 5}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  187.72551202774048
Memory status after this trial: 
Memory allocated:  316.8095703125
Memory cached:  334.0
--------------------  Trial  7   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.061216540737338, 'log_learning_rate_D': -4.102742643207239, 'training_batch_size': 6, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9694, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  60 training error:  tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  80 training error:  tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.00390625
Memory cached:  12.0
[I 2023-11-04 05:14:51,833] Trial 7 finished with value: 0.09307752549648285 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 5, 'D_layers': 8, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 4, 'log_learning_rate': -4.061216540737338, 'log_learning_rate_D': -4.102742643207239, 'training_batch_size': 6, 'training_p': 3}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  279.998859167099
Memory status after this trial: 
Memory allocated:  89.333984375
Memory cached:  94.0
--------------------  Trial  8   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.1926197172836455, 'log_learning_rate_D': -4.370307814942956, 'training_batch_size': 6, 'training_p': 8}
	 epoch  0 training error:  tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.869140625
Memory cached:  16.0
[I 2023-11-04 05:19:04,830] Trial 8 finished with value: 0.04275559261441231 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 6, 'D_layers': 8, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.1926197172836455, 'log_learning_rate_D': -4.370307814942956, 'training_batch_size': 6, 'training_p': 8}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  252.82649540901184
Memory status after this trial: 
Memory allocated:  112.86767578125
Memory cached:  116.0
--------------------  Trial  9   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.226367886439098, 'log_learning_rate_D': -3.276279216217243, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9340, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  10 training error:  tensor(0.8748, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.7569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.6889, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.5219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  0.7119140625
Memory cached:  6.0
[I 2023-11-04 05:20:54,697] Trial 9 finished with value: 0.10793789476156235 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 5, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'log_learning_rate': -4.226367886439098, 'log_learning_rate_D': -3.276279216217243, 'training_batch_size': 8, 'training_p': 6}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  109.73371171951294
Memory status after this trial: 
Memory allocated:  43.5146484375
Memory cached:  46.0
--------------------  Trial  10   --------------------
Start timing: 
Parameters: 
{'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.418110587921708, 'log_learning_rate_D': -1.7641615879548094, 'training_batch_size': 6, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9652, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
	 epoch  10 training error:  tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
	 epoch  20 training error:  tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  44.0
	 epoch  30 training error:  tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  44.0
	 epoch  50 training error:  tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
	 epoch  60 training error:  tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  44.0
	 epoch  70 training error:  tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  44.0
	 epoch  90 training error:  tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  16.80859375
Memory cached:  42.0
[I 2023-11-04 05:26:36,905] Trial 10 finished with value: 0.07825833559036255 and parameters: {'W_layers': 7, 'W_layer_units_exponent_0': 4, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 7, 'W_layer_units_exponent_5': 10, 'W_layer_units_exponent_6': 9, 'D_layers': 8, 'D_layer_units_exponent_0': 4, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 6, 'D_layer_units_exponent_6': 9, 'D_layer_units_exponent_7': 6, 'log_learning_rate': -3.418110587921708, 'log_learning_rate_D': -1.7641615879548094, 'training_batch_size': 6, 'training_p': 4}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  342.0400228500366
Memory status after this trial: 
Memory allocated:  237.013671875
Memory cached:  258.0
--------------------  Trial  11   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.993325959849496, 'log_learning_rate_D': -4.924674183080663, 'training_batch_size': 7, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7942, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.7547, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.7151, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.6361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.5568, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.8037109375
Memory cached:  16.0
[I 2023-11-04 05:28:46,422] Trial 11 finished with value: 0.388278067111969 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 5, 'log_learning_rate': -4.993325959849496, 'log_learning_rate_D': -4.924674183080663, 'training_batch_size': 7, 'training_p': 2}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  129.31697750091553
Memory status after this trial: 
Memory allocated:  95.00634765625
Memory cached:  98.0
--------------------  Trial  12   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.0211398707677835, 'log_learning_rate_D': -4.990752519254603, 'training_batch_size': 7, 'training_p': 8}
	 epoch  0 training error:  tensor(1.0010, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.8173828125
Memory cached:  16.0
[I 2023-11-04 05:31:13,030] Trial 12 finished with value: 0.04718679189682007 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 4, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.0211398707677835, 'log_learning_rate_D': -4.990752519254603, 'training_batch_size': 7, 'training_p': 8}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  146.4015872478485
Memory status after this trial: 
Memory allocated:  187.77294921875
Memory cached:  192.0
--------------------  Trial  13   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.0800132083606133, 'log_learning_rate_D': -3.8115495074923613, 'training_batch_size': 6, 'training_p': 2}
	 epoch  0 training error:  tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.701171875
Memory cached:  16.0
[I 2023-11-04 05:35:29,034] Trial 13 finished with value: 0.043626900762319565 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 5, 'D_layer_units_exponent_2': 4, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 10, 'D_layer_units_exponent_6': 7, 'log_learning_rate': -3.0800132083606133, 'log_learning_rate_D': -3.8115495074923613, 'training_batch_size': 6, 'training_p': 2}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  255.77579760551453
Memory status after this trial: 
Memory allocated:  103.501953125
Memory cached:  106.0
--------------------  Trial  14   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.626246119061489, 'log_learning_rate_D': -4.510555270517628, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  34.0
	 epoch  10 training error:  tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  36.0
	 epoch  30 training error:  tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  19.6357421875
Memory cached:  38.0
[I 2023-11-04 05:38:09,987] Trial 14 finished with value: 0.04607469588518143 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 10, 'W_layer_units_exponent_2': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 10, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.626246119061489, 'log_learning_rate_D': -4.510555270517628, 'training_batch_size': 12, 'training_p': 3}. Best is trial 5 with value: 0.04093475267291069.
Time for this trial:  160.73544001579285
Memory status after this trial: 
Memory allocated:  229.94189453125
Memory cached:  244.0
--------------------  Trial  15   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.5582687449846704, 'log_learning_rate_D': -3.6890215987082655, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0034, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  11.6279296875
Memory cached:  22.0
[I 2023-11-04 05:40:49,574] Trial 15 finished with value: 0.03537153825163841 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 10, 'log_learning_rate': -3.5582687449846704, 'log_learning_rate_D': -3.6890215987082655, 'training_batch_size': 7, 'training_p': 7}. Best is trial 15 with value: 0.03537153825163841.
Time for this trial:  159.36996698379517
Memory status after this trial: 
Memory allocated:  215.0859375
Memory cached:  222.0
--------------------  Trial  16   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.6812991171256297, 'log_learning_rate_D': -3.6829964131362756, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0207, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.1494140625
Memory cached:  14.0
[I 2023-11-04 05:43:15,800] Trial 16 finished with value: 0.037072427570819855 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 4, 'log_learning_rate': -3.6812991171256297, 'log_learning_rate_D': -3.6829964131362756, 'training_batch_size': 8, 'training_p': 6}. Best is trial 15 with value: 0.03537153825163841.
Time for this trial:  146.00537657737732
Memory status after this trial: 
Memory allocated:  105.78076171875
Memory cached:  108.0
--------------------  Trial  17   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6142828733250747, 'log_learning_rate_D': -3.696506676694119, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.5654296875
Memory cached:  16.0
[I 2023-11-04 05:45:21,059] Trial 17 finished with value: 0.03482046723365784 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.6142828733250747, 'log_learning_rate_D': -3.696506676694119, 'training_batch_size': 8, 'training_p': 6}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  124.96539545059204
Memory status after this trial: 
Memory allocated:  95.322265625
Memory cached:  98.0
--------------------  Trial  18   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5317311283013626, 'log_learning_rate_D': -3.0239041500607997, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9856, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  16.0
[I 2023-11-04 05:47:38,276] Trial 18 finished with value: 0.036525484174489975 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5317311283013626, 'log_learning_rate_D': -3.0239041500607997, 'training_batch_size': 10, 'training_p': 7}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  137.00157761573792
Memory status after this trial: 
Memory allocated:  135.2255859375
Memory cached:  140.0
--------------------  Trial  19   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.5331741549622, 'log_learning_rate_D': -3.7454774078382846, 'training_batch_size': 8, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0161, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.1396484375
Memory cached:  18.0
[I 2023-11-04 05:49:57,279] Trial 19 finished with value: 0.038049038499593735 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 4, 'W_layer_units_exponent_5': 5, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 5, 'log_learning_rate': -2.5331741549622, 'log_learning_rate_D': -3.7454774078382846, 'training_batch_size': 8, 'training_p': 6}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  138.78381872177124
Memory status after this trial: 
Memory allocated:  89.31591796875
Memory cached:  92.0
--------------------  Trial  20   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.866665318928501, 'log_learning_rate_D': -1.208582510985603, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9633, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.9997, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7314453125
Memory cached:  14.0
[I 2023-11-04 05:51:59,502] Trial 20 finished with value: 0.9983922839164734 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.866665318928501, 'log_learning_rate_D': -1.208582510985603, 'training_batch_size': 7, 'training_p': 7}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  122.01607728004456
Memory status after this trial: 
Memory allocated:  129.5595703125
Memory cached:  134.0
--------------------  Trial  21   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.3304379785406706, 'log_learning_rate_D': -3.19024944910295, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9928, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.6728515625
Memory cached:  38.0
[I 2023-11-04 05:54:08,168] Trial 21 finished with value: 0.040258921682834625 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 9, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.3304379785406706, 'log_learning_rate_D': -3.19024944910295, 'training_batch_size': 10, 'training_p': 6}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  128.4736201763153
Memory status after this trial: 
Memory allocated:  129.2705078125
Memory cached:  148.0
--------------------  Trial  22   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.528342175542341, 'log_learning_rate_D': -2.8045221020728204, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.0830078125
Memory cached:  14.0
[I 2023-11-04 05:56:25,738] Trial 22 finished with value: 0.037170808762311935 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.528342175542341, 'log_learning_rate_D': -2.8045221020728204, 'training_batch_size': 10, 'training_p': 7}. Best is trial 17 with value: 0.03482046723365784.
Time for this trial:  137.36655807495117
Memory status after this trial: 
Memory allocated:  135.2255859375
Memory cached:  140.0
--------------------  Trial  23   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.4788232256758804, 'log_learning_rate_D': -3.0346566890701165, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9899, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  12.0
	 epoch  20 training error:  tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  40 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  70 training error:  tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4873046875
Memory cached:  10.0
[I 2023-11-04 05:58:22,269] Trial 23 finished with value: 0.03218543529510498 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.4788232256758804, 'log_learning_rate_D': -3.0346566890701165, 'training_batch_size': 11, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  116.3180480003357
Memory status after this trial: 
Memory allocated:  87.4560546875
Memory cached:  90.0
--------------------  Trial  24   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.835344332190096, 'log_learning_rate_D': -3.4281539137416046, 'training_batch_size': 12, 'training_p': 7}
	 epoch  0 training error:  tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  32.0
	 epoch  10 training error:  tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  36.0
	 epoch  20 training error:  tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  42.0
	 epoch  30 training error:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  42.0
	 epoch  40 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  42.0
	 epoch  50 training error:  tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  40.0
	 epoch  60 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  40.0
	 epoch  70 training error:  tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  42.0
	 epoch  80 training error:  tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  42.0
	 epoch  90 training error:  tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  12.3837890625
Memory cached:  44.0
[I 2023-11-04 06:00:23,744] Trial 24 finished with value: 0.07525382190942764 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -2.835344332190096, 'log_learning_rate_D': -3.4281539137416046, 'training_batch_size': 12, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  121.28307747840881
Memory status after this trial: 
Memory allocated:  135.17578125
Memory cached:  154.0
--------------------  Trial  25   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.051644851135038, 'log_learning_rate_D': -4.019221682386526, 'training_batch_size': 11, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9778, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.3115234375
Memory cached:  18.0
[I 2023-11-04 06:02:15,113] Trial 25 finished with value: 0.03819950297474861 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.051644851135038, 'log_learning_rate_D': -4.019221682386526, 'training_batch_size': 11, 'training_p': 6}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  111.17814135551453
Memory status after this trial: 
Memory allocated:  106.7353515625
Memory cached:  110.0
--------------------  Trial  26   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.388653017591011, 'log_learning_rate_D': -3.64922483679333, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9219, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  36.0
	 epoch  10 training error:  tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  20 training error:  tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  30 training error:  tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  40 training error:  tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  50 training error:  tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  60 training error:  tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  70 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  80 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
	 epoch  90 training error:  tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.4462890625
Memory cached:  38.0
[I 2023-11-04 06:04:43,377] Trial 26 finished with value: 0.043180499225854874 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 6, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -3.388653017591011, 'log_learning_rate_D': -3.64922483679333, 'training_batch_size': 9, 'training_p': 8}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  148.0365447998047
Memory status after this trial: 
Memory allocated:  148.44287109375
Memory cached:  166.0
--------------------  Trial  27   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.709760450267324, 'log_learning_rate_D': -2.9757310343344194, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.9810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.7783203125
Memory cached:  20.0
[I 2023-11-04 06:07:02,821] Trial 27 finished with value: 0.041409172117710114 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.709760450267324, 'log_learning_rate_D': -2.9757310343344194, 'training_batch_size': 11, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  139.21388053894043
Memory status after this trial: 
Memory allocated:  117.31640625
Memory cached:  120.0
--------------------  Trial  28   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.7485778098077516, 'log_learning_rate_D': -2.4857784056108847, 'training_batch_size': 9, 'training_p': 6}
	 epoch  0 training error:  tensor(1.0196, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.8466796875
Memory cached:  20.0
[I 2023-11-04 06:09:14,657] Trial 28 finished with value: 0.06246845796704292 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -2.7485778098077516, 'log_learning_rate_D': -2.4857784056108847, 'training_batch_size': 9, 'training_p': 6}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  131.617746591568
Memory status after this trial: 
Memory allocated:  108.14404296875
Memory cached:  114.0
--------------------  Trial  29   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.222485081475202, 'log_learning_rate_D': -3.425772559123803, 'training_batch_size': 8, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8877, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.0693359375
Memory cached:  20.0
[I 2023-11-04 06:11:13,666] Trial 29 finished with value: 0.03847121074795723 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 10, 'log_learning_rate': -3.222485081475202, 'log_learning_rate_D': -3.425772559123803, 'training_batch_size': 8, 'training_p': 4}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  118.81647896766663
Memory status after this trial: 
Memory allocated:  120.5126953125
Memory cached:  124.0
--------------------  Trial  30   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.8143656499041443, 'log_learning_rate_D': -4.149595730715958, 'training_batch_size': 7, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0552, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  10.8798828125
Memory cached:  22.0
[I 2023-11-04 06:13:40,445] Trial 30 finished with value: 0.04105869680643082 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 5, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.8143656499041443, 'log_learning_rate_D': -4.149595730715958, 'training_batch_size': 7, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  146.5739266872406
Memory status after this trial: 
Memory allocated:  172.158203125
Memory cached:  178.0
--------------------  Trial  31   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.913096112678308, 'log_learning_rate_D': -3.9774923712351695, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(0.9729, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  30 training error:  tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  40 training error:  tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  50 training error:  tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  60 training error:  tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  70 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  80 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.6552734375
Memory cached:  22.0
[I 2023-11-04 06:16:11,470] Trial 31 finished with value: 0.04188397154211998 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 7, 'log_learning_rate': -2.913096112678308, 'log_learning_rate_D': -3.9774923712351695, 'training_batch_size': 9, 'training_p': 8}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  150.79233026504517
Memory status after this trial: 
Memory allocated:  149.67919921875
Memory cached:  154.0
--------------------  Trial  32   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5632706239892196, 'log_learning_rate_D': -3.12184170685392, 'training_batch_size': 10, 'training_p': 7}
	 epoch  0 training error:  tensor(1.0076, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  30 training error:  tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  50 training error:  tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  60 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  80 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
	 epoch  90 training error:  tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.5751953125
Memory cached:  20.0
[I 2023-11-04 06:18:32,390] Trial 32 finished with value: 0.0375799685716629 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.5632706239892196, 'log_learning_rate_D': -3.12184170685392, 'training_batch_size': 10, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  140.70356702804565
Memory status after this trial: 
Memory allocated:  121.2998046875
Memory cached:  126.0
--------------------  Trial  33   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.5044462848794993, 'log_learning_rate_D': -3.0537068762204336, 'training_batch_size': 11, 'training_p': 7}
	 epoch  0 training error:  tensor(0.8553, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  6.0791015625
Memory cached:  18.0
[I 2023-11-04 06:20:46,116] Trial 33 finished with value: 0.0394580252468586 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 7, 'W_layer_units_exponent_4': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.5044462848794993, 'log_learning_rate_D': -3.0537068762204336, 'training_batch_size': 11, 'training_p': 7}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  133.5016167163849
Memory status after this trial: 
Memory allocated:  127.9560546875
Memory cached:  132.0
--------------------  Trial  34   --------------------
Start timing: 
Parameters: 
{'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.2294505355067993, 'log_learning_rate_D': -3.529510203650834, 'training_batch_size': 10, 'training_p': 6}
	 epoch  0 training error:  tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  10 training error:  tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.7666015625
Memory cached:  18.0
[I 2023-11-04 06:23:22,962] Trial 34 finished with value: 0.03903067857027054 and parameters: {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 6, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 7, 'D_layers': 5, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 7, 'D_layer_units_exponent_4': 7, 'log_learning_rate': -3.2294505355067993, 'log_learning_rate_D': -3.529510203650834, 'training_batch_size': 10, 'training_p': 6}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  156.6088171005249
Memory status after this trial: 
Memory allocated:  141.232421875
Memory cached:  146.0
--------------------  Trial  35   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.8582723111335704, 'log_learning_rate_D': -3.2632107576587757, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9419, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0488, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  8.6748046875
Memory cached:  18.0
[I 2023-11-04 06:25:52,266] Trial 35 finished with value: 0.03645208105444908 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'log_learning_rate': -3.8582723111335704, 'log_learning_rate_D': -3.2632107576587757, 'training_batch_size': 12, 'training_p': 5}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  149.07458019256592
Memory status after this trial: 
Memory allocated:  184.009765625
Memory cached:  190.0
--------------------  Trial  36   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.892028318203156, 'log_learning_rate_D': -3.8626635488630447, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.4091796875
Memory cached:  14.0
[I 2023-11-04 06:27:56,698] Trial 36 finished with value: 0.03484192118048668 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.892028318203156, 'log_learning_rate_D': -3.8626635488630447, 'training_batch_size': 12, 'training_p': 4}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  124.20563673973083
Memory status after this trial: 
Memory allocated:  109.2705078125
Memory cached:  112.0
--------------------  Trial  37   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.284814705070875, 'log_learning_rate_D': -3.9286316237469086, 'training_batch_size': 12, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0803, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.6142578125
Memory cached:  16.0
[I 2023-11-04 06:29:54,753] Trial 37 finished with value: 0.04281625151634216 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.284814705070875, 'log_learning_rate_D': -3.9286316237469086, 'training_batch_size': 12, 'training_p': 4}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  117.85071349143982
Memory status after this trial: 
Memory allocated:  129.35546875
Memory cached:  132.0
--------------------  Trial  38   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.988367371132676, 'log_learning_rate_D': -4.308715579398214, 'training_batch_size': 11, 'training_p': 5}
	 epoch  0 training error:  tensor(1.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  22.0
	 epoch  20 training error:  tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  20.0
	 epoch  40 training error:  tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.9287109375
Memory cached:  20.0
[I 2023-11-04 06:31:47,829] Trial 38 finished with value: 0.04441085085272789 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 10, 'W_layer_units_exponent_3': 8, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'log_learning_rate': -3.988367371132676, 'log_learning_rate_D': -4.308715579398214, 'training_batch_size': 11, 'training_p': 5}. Best is trial 23 with value: 0.03218543529510498.
Time for this trial:  112.85909295082092
Memory status after this trial: 
Memory allocated:  119.609375
Memory cached:  124.0
--------------------  Trial  39   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.677211707126687, 'log_learning_rate_D': -3.7840955563471974, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9532, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0479, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  70 training error:  tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.4169921875
Memory cached:  18.0
[I 2023-11-04 06:33:48,794] Trial 39 finished with value: 0.02909674122929573 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.677211707126687, 'log_learning_rate_D': -3.7840955563471974, 'training_batch_size': 12, 'training_p': 3}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  120.76133608818054
Memory status after this trial: 
Memory allocated:  126.1806640625
Memory cached:  130.0
--------------------  Trial  40   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.349015564499413, 'log_learning_rate_D': -4.204692020764513, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(1.0657, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  20 training error:  tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  80 training error:  tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0244140625
Memory cached:  16.0
[I 2023-11-04 06:35:38,037] Trial 40 finished with value: 0.042069368064403534 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'D_layers': 3, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'log_learning_rate': -4.349015564499413, 'log_learning_rate_D': -4.204692020764513, 'training_batch_size': 12, 'training_p': 3}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  109.02881050109863
Memory status after this trial: 
Memory allocated:  91.873046875
Memory cached:  94.0
--------------------  Trial  41   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.8919133366681287, 'log_learning_rate_D': -3.5195914112421525, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(1.0145, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.0517578125
Memory cached:  14.0
[I 2023-11-04 06:37:34,214] Trial 41 finished with value: 0.03548501804471016 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'log_learning_rate': -3.8919133366681287, 'log_learning_rate_D': -3.5195914112421525, 'training_batch_size': 11, 'training_p': 4}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  115.97578477859497
Memory status after this trial: 
Memory allocated:  139.806640625
Memory cached:  142.0
--------------------  Trial  42   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.689050496772772, 'log_learning_rate_D': -3.8612962380393623, 'training_batch_size': 12, 'training_p': 3}
	 epoch  0 training error:  tensor(0.9793, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  16.0
	 epoch  30 training error:  tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  16.0
	 epoch  50 training error:  tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  16.0
	 epoch  70 training error:  tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  16.0
	 epoch  90 training error:  tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  4.5791015625
Memory cached:  14.0
[I 2023-11-04 06:39:38,532] Trial 42 finished with value: 0.037473227828741074 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -3.689050496772772, 'log_learning_rate_D': -3.8612962380393623, 'training_batch_size': 12, 'training_p': 3}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  124.1015112400055
Memory status after this trial: 
Memory allocated:  144.330078125
Memory cached:  148.0
--------------------  Trial  43   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3949640123069345, 'log_learning_rate_D': -3.676867023834446, 'training_batch_size': 12, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9905, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  12.0
	 epoch  10 training error:  tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6416015625
Memory cached:  16.0
[I 2023-11-04 06:41:53,094] Trial 43 finished with value: 0.03660530969500542 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 5, 'D_layer_units_exponent_4': 9, 'log_learning_rate': -3.3949640123069345, 'log_learning_rate_D': -3.676867023834446, 'training_batch_size': 12, 'training_p': 5}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  134.34355115890503
Memory status after this trial: 
Memory allocated:  106.23779296875
Memory cached:  108.0
--------------------  Trial  44   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.097798957149503, 'log_learning_rate_D': -4.156023293878876, 'training_batch_size': 8, 'training_p': 3}
	 epoch  0 training error:  tensor(1.1699, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  16.0
	 epoch  10 training error:  tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  20 training error:  tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  30 training error:  tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  40 training error:  tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  50 training error:  tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  60 training error:  tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  70 training error:  tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  80 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
	 epoch  90 training error:  tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.6865234375
Memory cached:  24.0
[I 2023-11-04 06:44:00,289] Trial 44 finished with value: 0.04069320484995842 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 9, 'D_layers': 3, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 9, 'log_learning_rate': -3.097798957149503, 'log_learning_rate_D': -4.156023293878876, 'training_batch_size': 8, 'training_p': 3}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  126.9504747390747
Memory status after this trial: 
Memory allocated:  182.1396484375
Memory cached:  186.0
--------------------  Trial  45   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.628896994591065, 'log_learning_rate_D': -3.3455990416304107, 'training_batch_size': 7, 'training_p': 4}
	 epoch  0 training error:  tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  12.0
	 epoch  30 training error:  tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  12.0
	 epoch  50 training error:  tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  12.0
	 epoch  90 training error:  tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  3.9794921875
Memory cached:  14.0
[I 2023-11-04 06:45:57,241] Trial 45 finished with value: 0.03676677495241165 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 7, 'log_learning_rate': -3.628896994591065, 'log_learning_rate_D': -3.3455990416304107, 'training_batch_size': 7, 'training_p': 4}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  116.74288368225098
Memory status after this trial: 
Memory allocated:  85.2412109375
Memory cached:  88.0
--------------------  Trial  46   --------------------
Start timing: 
Parameters: 
{'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.05072209750934, 'log_learning_rate_D': -3.8668565088516393, 'training_batch_size': 11, 'training_p': 4}
	 epoch  0 training error:  tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  10.0
	 epoch  10 training error:  tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  20 training error:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  30 training error:  tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  40 training error:  tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  50 training error:  tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  60 training error:  tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  70 training error:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  80 training error:  tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
	 epoch  90 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  1.6630859375
Memory cached:  14.0
[I 2023-11-04 06:47:55,346] Trial 46 finished with value: 0.041041091084480286 and parameters: {'W_layers': 4, 'W_layer_units_exponent_0': 10, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 7, 'D_layers': 3, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 8, 'log_learning_rate': -4.05072209750934, 'log_learning_rate_D': -3.8668565088516393, 'training_batch_size': 11, 'training_p': 4}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  117.88237762451172
Memory status after this trial: 
Memory allocated:  101.48046875
Memory cached:  104.0
--------------------  Trial  47   --------------------
Start timing: 
Parameters: 
{'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2805755158192946, 'log_learning_rate_D': -4.481976396081286, 'training_batch_size': 12, 'training_p': 2}
	 epoch  0 training error:  tensor(0.7663, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  8.0
	 epoch  10 training error:  tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  20 training error:  tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  30 training error:  tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  12.0
	 epoch  40 training error:  tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  50 training error:  tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  60 training error:  tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  12.0
	 epoch  70 training error:  tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  80 training error:  tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  10.0
	 epoch  90 training error:  tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  2.9228515625
Memory cached:  12.0
[I 2023-11-04 06:49:52,785] Trial 47 finished with value: 0.04464365169405937 and parameters: {'W_layers': 2, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 6, 'D_layers': 5, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 7, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 6, 'log_learning_rate': -3.2805755158192946, 'log_learning_rate_D': -4.481976396081286, 'training_batch_size': 12, 'training_p': 2}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  117.22789216041565
Memory status after this trial: 
Memory allocated:  90.4892578125
Memory cached:  94.0
--------------------  Trial  48   --------------------
Start timing: 
Parameters: 
{'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.7870669653049194, 'log_learning_rate_D': -3.5805273868757355, 'training_batch_size': 6, 'training_p': 5}
	 epoch  0 training error:  tensor(0.9579, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  20.0
	 epoch  20 training error:  tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
	 epoch  40 training error:  tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
	 epoch  60 training error:  tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  22.0
	 epoch  90 training error:  tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  7.259765625
Memory cached:  18.0
[I 2023-11-04 06:53:24,102] Trial 48 finished with value: 0.045997150242328644 and parameters: {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 9, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 8, 'log_learning_rate': -3.7870669653049194, 'log_learning_rate_D': -3.5805273868757355, 'training_batch_size': 6, 'training_p': 5}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  211.08273100852966
Memory status after this trial: 
Memory allocated:  95.83154296875
Memory cached:  100.0
--------------------  Trial  49   --------------------
Start timing: 
Parameters: 
{'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.148540846714458, 'log_learning_rate_D': -3.7779767952119148, 'training_batch_size': 9, 'training_p': 8}
	 epoch  0 training error:  tensor(1.1006, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  14.0
	 epoch  10 training error:  tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  18.0
	 epoch  20 training error:  tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  18.0
	 epoch  30 training error:  tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  16.0
	 epoch  40 training error:  tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  18.0
	 epoch  50 training error:  tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  16.0
	 epoch  60 training error:  tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  20.0
	 epoch  70 training error:  tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  18.0
	 epoch  80 training error:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  18.0
	 epoch  90 training error:  tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)
Memory status after this epoch: 
Memory allocated:  5.3486328125
Memory cached:  16.0
[I 2023-11-04 06:55:49,310] Trial 49 finished with value: 0.04247212037444115 and parameters: {'W_layers': 3, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'D_layers': 6, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 8, 'D_layer_units_exponent_5': 6, 'log_learning_rate': -4.148540846714458, 'log_learning_rate_D': -3.7779767952119148, 'training_batch_size': 9, 'training_p': 8}. Best is trial 39 with value: 0.02909674122929573.
Time for this trial:  144.96845889091492
Memory status after this trial: 
Memory allocated:  154.353515625
Memory cached:  158.0
