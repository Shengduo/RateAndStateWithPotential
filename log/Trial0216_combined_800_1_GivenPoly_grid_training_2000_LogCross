/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[I 2024-03-31 22:10:03,162] Using an existing study with name 'my_study1' instead of creating a new one.
Cuda is available:  True
Device is:  cuda
Memory allocated:  0.0
Memory cached:  0.0
Data file:  ./data/Trial0216_combined_800.pt
Vs.shape:  torch.Size([800, 100])
thetas.shape:  torch.Size([800, 100])
fs.shape:  torch.Size([800, 100])
ts.shape:  torch.Size([800, 100])
Xs.shape:  torch.Size([800, 100])
No pruned database has been founded.
--------------------  Trial  1   --------------------
Start timing: 
Parameters: 
{'training_batch_size': 7}
	 epoch  0 training error:  tensor(0.4031, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  4.0
	 epoch  10 training error:  tensor(0.1298, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  20 training error:  tensor(0.1203, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  30 training error:  tensor(0.1261, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  40 training error:  tensor(0.1298, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  50 training error:  tensor(0.1241, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  60 training error:  tensor(0.1260, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  70 training error:  tensor(0.1259, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  80 training error:  tensor(0.1346, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  90 training error:  tensor(0.1185, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  100 training error:  tensor(0.1237, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  110 training error:  tensor(0.1239, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  120 training error:  tensor(0.1221, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  130 training error:  tensor(0.1389, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  140 training error:  tensor(0.1324, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  150 training error:  tensor(0.1208, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  160 training error:  tensor(0.1143, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  170 training error:  tensor(0.1234, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  180 training error:  tensor(0.1319, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  190 training error:  tensor(0.1232, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  200 training error:  tensor(0.1200, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  210 training error:  tensor(0.1223, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  220 training error:  tensor(0.1232, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  230 training error:  tensor(0.1165, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  240 training error:  tensor(0.1190, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  250 training error:  tensor(0.1207, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  260 training error:  tensor(0.1238, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  270 training error:  tensor(0.1160, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  280 training error:  tensor(0.1244, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  290 training error:  tensor(0.1213, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  300 training error:  tensor(0.1180, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  310 training error:  tensor(0.1463, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  320 training error:  tensor(0.1130, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  330 training error:  tensor(0.1199, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  340 training error:  tensor(0.1334, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  350 training error:  tensor(0.1131, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  360 training error:  tensor(0.1196, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  370 training error:  tensor(0.1159, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  380 training error:  tensor(0.1276, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  390 training error:  tensor(0.1241, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  400 training error:  tensor(0.1147, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  410 training error:  tensor(0.1123, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  420 training error:  tensor(0.1146, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  430 training error:  tensor(0.1326, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  440 training error:  tensor(0.1142, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  450 training error:  tensor(0.1226, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  460 training error:  tensor(0.1154, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  470 training error:  tensor(0.1170, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  480 training error:  tensor(0.1190, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  490 training error:  tensor(0.1199, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  500 training error:  tensor(0.1175, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  510 training error:  tensor(0.1108, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  520 training error:  tensor(0.1277, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  530 training error:  tensor(0.1299, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  540 training error:  tensor(0.1118, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  550 training error:  tensor(0.1167, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  560 training error:  tensor(0.1139, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  570 training error:  tensor(0.1163, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  580 training error:  tensor(0.1174, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  590 training error:  tensor(0.1114, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  600 training error:  tensor(0.1190, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  610 training error:  tensor(0.1085, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  620 training error:  tensor(0.1093, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  630 training error:  tensor(0.1251, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  640 training error:  tensor(0.1188, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  650 training error:  tensor(0.1124, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  660 training error:  tensor(0.1183, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  670 training error:  tensor(0.1160, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  680 training error:  tensor(0.1125, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  690 training error:  tensor(0.1199, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  700 training error:  tensor(0.1085, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  710 training error:  tensor(0.1168, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  720 training error:  tensor(0.1142, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  730 training error:  tensor(0.1201, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  740 training error:  tensor(0.1216, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  750 training error:  tensor(0.1226, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  760 training error:  tensor(0.1208, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  770 training error:  tensor(0.1117, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  780 training error:  tensor(0.1137, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  790 training error:  tensor(0.1170, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  800 training error:  tensor(0.1133, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  810 training error:  tensor(0.1172, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  820 training error:  tensor(0.1112, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  830 training error:  tensor(0.1228, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  840 training error:  tensor(0.1117, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  850 training error:  tensor(0.1165, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  860 training error:  tensor(0.1314, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  870 training error:  tensor(0.1113, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  880 training error:  tensor(0.1204, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  890 training error:  tensor(0.1145, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  900 training error:  tensor(0.1156, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  910 training error:  tensor(0.1150, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  920 training error:  tensor(0.1165, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  930 training error:  tensor(0.1072, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  940 training error:  tensor(0.1113, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  950 training error:  tensor(0.1214, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  960 training error:  tensor(0.1169, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  970 training error:  tensor(0.1128, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  980 training error:  tensor(0.1070, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
	 epoch  990 training error:  tensor(0.1110, grad_fn=<ToCopyBackward0>)
Memory status after this epoch: 
Memory allocated:  0.61767578125
Memory cached:  6.0
[I 2024-03-31 23:54:53,713] Trial 1 finished with value: 0.08554390072822571 and parameters: {'training_batch_size': 7}. Best is trial 1 with value: 0.08554390072822571.
res:  tensor(0.0855, grad_fn=<ToCopyBackward0>)
self.bestValue:  10000000.0
Save this model!
Time for this trial:  6288.456168413162
Memory status after this trial: 
Memory allocated:  5.443359375
Memory cached:  6.0
