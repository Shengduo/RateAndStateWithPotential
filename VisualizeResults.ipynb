{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204440fb-2190-4edf-b436-98b50230d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available:  True\n",
      "Device is:  cuda:0\n",
      "Memory allocated:  0.0\n",
      "Memory cached:  0.0\n"
     ]
    }
   ],
   "source": [
    "#ï¼©mport necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xitorch\n",
    "from xitorch.optimize import rootfinder\n",
    "import optuna\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib \n",
    "import torch.optim as optim\n",
    "\n",
    "# Memory management on GPU\n",
    "import gc\n",
    "\n",
    "# Import time\n",
    "import time\n",
    "\n",
    "# Testify whether GPU is available\n",
    "print(\"Cuda is available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Device is: \", device)\n",
    "\n",
    "def memory_stats():\n",
    "    print(\"Memory allocated: \", torch.cuda.memory_allocated()/1024**2)\n",
    "    print(\"Memory cached: \", torch.cuda.memory_reserved()/1024**2)\n",
    "memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc87966-4946-46ad-b93e-6623eecf877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  dim_xi =  0   --------------------\n",
      "best_params:  {'W_layers': 6, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 9, 'D_layers': 7, 'D_layer_units_exponent_0': 8, 'D_layer_units_exponent_1': 7, 'D_layer_units_exponent_2': 10, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 4, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 4, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 8, 'D_dagger_layer_units_exponent_4': 10, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 6, 'log_learning_rate': -1.3076749726724581, 'log_learning_rate_D': -1.2873674609771453, 'log_learning_rate_D_dagger': -3.6977633460284145, 'training_batch_size': 10, 'training_p': 2}\n",
      "best_value:  0.0665002316236496\n",
      "--------------------  dim_xi =  1   --------------------\n",
      "best_params:  {'W_layers': 4, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 8, 'D_layers': 4, 'D_layer_units_exponent_0': 7, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 9, 'log_learning_rate': -3.350423166071998, 'log_learning_rate_D': -4.401744724499052, 'training_batch_size': 9, 'training_p': 8}\n",
      "best_value:  0.03143104538321495\n",
      "--------------------  dim_xi =  2   --------------------\n",
      "best_params:  {'W_layers': 7, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 10, 'W_layer_units_exponent_4': 5, 'W_layer_units_exponent_5': 5, 'W_layer_units_exponent_6': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 4, 'D_layer_units_exponent_4': 5, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'D_layer_units_exponent_7': 5, 'log_learning_rate': -2.9869054430287116, 'log_learning_rate_D': -2.0449539240944894, 'training_batch_size': 6, 'training_p': 5}\n",
      "best_value:  0.03132004663348198\n"
     ]
    }
   ],
   "source": [
    "dim_xis = [0, 1, 2]\n",
    "for idx, dim_xi in enumerate(dim_xis):\n",
    "    print(\"-\" * 20, \" dim_xi = \", dim_xi, \" \", \"-\" * 20)\n",
    "    # shit = joblib.load('./data/1104study_dim_xi_logV_DLeg_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1104_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1106_smallDRS_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1108_bigDRS_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1108_bigDRS_Burigede_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    shit = joblib.load('./data/Stupid_1116_bigDRS_Burigede_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    print(\"best_params: \", shit.best_params)\n",
    "    print(\"best_value: \", shit.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eca610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
