{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204440fb-2190-4edf-b436-98b50230d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available:  True\n",
      "Device is:  cuda:0\n",
      "Memory allocated:  0.0\n",
      "Memory cached:  0.0\n"
     ]
    }
   ],
   "source": [
    "#ï¼©mport necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xitorch\n",
    "from xitorch.optimize import rootfinder\n",
    "import optuna\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib \n",
    "import torch.optim as optim\n",
    "\n",
    "# Memory management on GPU\n",
    "import gc\n",
    "\n",
    "# Import time\n",
    "import time\n",
    "\n",
    "# Testify whether GPU is available\n",
    "print(\"Cuda is available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Device is: \", device)\n",
    "\n",
    "def memory_stats():\n",
    "    print(\"Memory allocated: \", torch.cuda.memory_allocated()/1024**2)\n",
    "    print(\"Memory cached: \", torch.cuda.memory_reserved()/1024**2)\n",
    "memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc87966-4946-46ad-b93e-6623eecf877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  dim_xi =  0   --------------------\n",
      "best_params:  {'W_layers': 5, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 8, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 7, 'D_layers': 8, 'D_layer_units_exponent_0': 6, 'D_layer_units_exponent_1': 10, 'D_layer_units_exponent_2': 6, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 6, 'D_layer_units_exponent_5': 9, 'D_layer_units_exponent_6': 6, 'D_layer_units_exponent_7': 10, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 7, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 9, 'log_learning_rate': -1.9690797859132163, 'log_learning_rate_D': -2.2393364950028993, 'log_learning_rate_D_dagger': -3.3928247551507336, 'training_batch_size': 12, 'training_p': 5}\n",
      "best_value:  0.05145559832453728\n",
      "--------------------  dim_xi =  1   --------------------\n",
      "best_params:  {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 6, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 6, 'D_layers': 2, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 5, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 5, 'D_dagger_layer_units_exponent_4': 9, 'log_learning_rate': -2.715763003277496, 'log_learning_rate_D': -3.97635733234261, 'log_learning_rate_D_dagger': -3.6092569710939744, 'training_batch_size': 12, 'training_p': 5}\n",
      "best_value:  0.024036098271608353\n",
      "--------------------  dim_xi =  2   --------------------\n",
      "best_params:  {'W_layers': 6, 'W_layer_units_exponent_0': 6, 'W_layer_units_exponent_1': 6, 'W_layer_units_exponent_2': 5, 'W_layer_units_exponent_3': 8, 'W_layer_units_exponent_4': 6, 'W_layer_units_exponent_5': 4, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 7, 'D_dagger_layers': 6, 'D_dagger_layer_units_exponent_0': 10, 'D_dagger_layer_units_exponent_1': 10, 'D_dagger_layer_units_exponent_2': 4, 'D_dagger_layer_units_exponent_3': 7, 'D_dagger_layer_units_exponent_4': 5, 'D_dagger_layer_units_exponent_5': 7, 'log_learning_rate': -3.445906263657938, 'log_learning_rate_D': -3.447175315889106, 'log_learning_rate_D_dagger': -4.3834083321822535, 'training_batch_size': 7, 'training_p': 6}\n",
      "best_value:  0.0227485504001379\n",
      "--------------------  dim_xi =  4   --------------------\n",
      "best_params:  {'W_layers': 5, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 5, 'W_layer_units_exponent_2': 7, 'W_layer_units_exponent_3': 4, 'W_layer_units_exponent_4': 10, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 6, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_layer_units_exponent_4': 9, 'D_layer_units_exponent_5': 5, 'D_layer_units_exponent_6': 8, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 9, 'D_dagger_layer_units_exponent_2': 7, 'D_dagger_layer_units_exponent_3': 6, 'D_dagger_layer_units_exponent_4': 8, 'D_dagger_layer_units_exponent_5': 4, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -4.135377120074108, 'log_learning_rate_D': -3.9020519152360245, 'log_learning_rate_D_dagger': -3.2753824940187086, 'training_batch_size': 10, 'training_p': 4}\n",
      "best_value:  0.023379547521471977\n",
      "--------------------  dim_xi =  8   --------------------\n",
      "best_params:  {'W_layers': 2, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 10, 'D_layers': 4, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 9, 'D_layer_units_exponent_2': 9, 'D_layer_units_exponent_3': 9, 'D_dagger_layers': 2, 'D_dagger_layer_units_exponent_0': 8, 'D_dagger_layer_units_exponent_1': 6, 'log_learning_rate': -4.414104435260213, 'log_learning_rate_D': -3.790476796545983, 'log_learning_rate_D_dagger': -3.658992206006611, 'training_batch_size': 11, 'training_p': 7}\n",
      "best_value:  0.025320781394839287\n"
     ]
    }
   ],
   "source": [
    "dim_xis = [0, 1, 2, 4, 8]\n",
    "for idx, dim_xi in enumerate(dim_xis):\n",
    "    print(\"-\" * 20, \" dim_xi = \", dim_xi, \" \", \"-\" * 20)\n",
    "    # shit = joblib.load('./data/1104study_dim_xi_logV_DLeg_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1104_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    shit = joblib.load('./data/1106_smallDRS_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    print(\"best_params: \", shit.best_params)\n",
    "    print(\"best_value: \", shit.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eca610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
