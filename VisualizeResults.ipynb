{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204440fb-2190-4edf-b436-98b50230d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shengduo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available:  True\n",
      "Device is:  cuda:0\n",
      "Memory allocated:  0.0\n",
      "Memory cached:  0.0\n"
     ]
    }
   ],
   "source": [
    "#ï¼©mport necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xitorch\n",
    "from xitorch.optimize import rootfinder\n",
    "import optuna\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib \n",
    "import torch.optim as optim\n",
    "\n",
    "# Memory management on GPU\n",
    "import gc\n",
    "\n",
    "# Import time\n",
    "import time\n",
    "\n",
    "# Testify whether GPU is available\n",
    "print(\"Cuda is available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Device is: \", device)\n",
    "\n",
    "def memory_stats():\n",
    "    print(\"Memory allocated: \", torch.cuda.memory_allocated()/1024**2)\n",
    "    print(\"Memory cached: \", torch.cuda.memory_reserved()/1024**2)\n",
    "memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc87966-4946-46ad-b93e-6623eecf877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  dim_xi =  0   --------------------\n",
      "best_params:  {'W_layers': 7, 'W_layer_units_exponent_0': 9, 'W_layer_units_exponent_1': 4, 'W_layer_units_exponent_2': 4, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 10, 'W_layer_units_exponent_5': 8, 'W_layer_units_exponent_6': 10, 'D_layers': 2, 'D_layer_units_exponent_0': 9, 'D_layer_units_exponent_1': 4, 'D_dagger_layers': 7, 'D_dagger_layer_units_exponent_0': 5, 'D_dagger_layer_units_exponent_1': 8, 'D_dagger_layer_units_exponent_2': 10, 'D_dagger_layer_units_exponent_3': 4, 'D_dagger_layer_units_exponent_4': 4, 'D_dagger_layer_units_exponent_5': 7, 'D_dagger_layer_units_exponent_6': 7, 'log_learning_rate': -1.4706747579143615, 'log_learning_rate_D': -2.8190349329386506, 'log_learning_rate_D_dagger': -3.630524267938959, 'training_batch_size': 10, 'training_p': 2}\n",
      "best_value:  0.06574658304452896\n",
      "--------------------  dim_xi =  1   --------------------\n",
      "best_params:  {'W_layers': 8, 'W_layer_units_exponent_0': 7, 'W_layer_units_exponent_1': 7, 'W_layer_units_exponent_2': 8, 'W_layer_units_exponent_3': 5, 'W_layer_units_exponent_4': 8, 'W_layer_units_exponent_5': 6, 'W_layer_units_exponent_6': 5, 'W_layer_units_exponent_7': 8, 'D_layers': 7, 'D_layer_units_exponent_0': 5, 'D_layer_units_exponent_1': 4, 'D_layer_units_exponent_2': 5, 'D_layer_units_exponent_3': 8, 'D_layer_units_exponent_4': 7, 'D_layer_units_exponent_5': 4, 'D_layer_units_exponent_6': 4, 'log_learning_rate': -3.437177513916772, 'log_learning_rate_D': -3.2585867302589007, 'training_batch_size': 6, 'training_p': 3}\n",
      "best_value:  0.03707868605852127\n",
      "--------------------  dim_xi =  2   --------------------\n",
      "best_params:  {'W_layers': 3, 'W_layer_units_exponent_0': 8, 'W_layer_units_exponent_1': 9, 'W_layer_units_exponent_2': 6, 'D_layers': 7, 'D_layer_units_exponent_0': 10, 'D_layer_units_exponent_1': 8, 'D_layer_units_exponent_2': 8, 'D_layer_units_exponent_3': 6, 'D_layer_units_exponent_4': 10, 'D_layer_units_exponent_5': 8, 'D_layer_units_exponent_6': 6, 'log_learning_rate': -4.624155355788742, 'log_learning_rate_D': -4.733092773022294, 'training_batch_size': 10, 'training_p': 8}\n",
      "best_value:  0.03669334203004837\n"
     ]
    }
   ],
   "source": [
    "dim_xis = [0, 1, 2]\n",
    "for idx, dim_xi in enumerate(dim_xis):\n",
    "    print(\"-\" * 20, \" dim_xi = \", dim_xi, \" \", \"-\" * 20)\n",
    "    # shit = joblib.load('./data/1104study_dim_xi_logV_DLeg_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1104_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1106_smallDRS_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1108_bigDRS_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    # shit = joblib.load('./data/1108_bigDRS_Burigede_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    shit = joblib.load('./data/Stupid_1108_bigDRS_Burigede_WDsep_study_dim_xi_logV_DLeg_D_dagger_ELU1_{0}.pkl'.format(dim_xi))\n",
    "    print(\"best_params: \", shit.best_params)\n",
    "    print(\"best_value: \", shit.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eca610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
